{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Project \"Piper\" User Documentation \u00b6 Continuous delivery is a method to develop software with short feedback cycles. It is applicable to projects both for SAP Cloud Platform and SAP on-premise platforms. SAP implements tooling for continuous delivery in project \"Piper\". The goal of project \"Piper\" is to substantially ease setting up continuous delivery in your project using SAP technologies. What you get \u00b6 To get you started quickly, project \"Piper\" offers you the following artifacts: A set of ready-made Continuous Delivery pipelines for direct use in your project General Purpose Pipeline SAP Cloud SDK Pipeline A shared library that contains reusable step implementations, which enable you to customize our preconfigured pipelines, or to even build your own customized ones A standalone command line utility for Linux and a GitHub Action Note: This version is still in early development. Feel free to use it and provide feedback , but don't expect all the features of the Jenkins library A set of Docker images to setup a CI/CD environment in minutes using sophisticated life-cycle management To find out which offering is right for you, we recommend to look at the ready-made pipelines first. In many cases, they should satisfy your requirements, and if this is the case, you don't need to build your own pipeline. The best-practice way: Ready-made pipelines \u00b6 Are you building a standalone SAP Cloud Platform application? Then continue reading about our general purpose pipeline , which supports various technologies and programming languages. Are you building an application with the SAP Cloud SDK and/or SAP Cloud Application Programming Model? Then we can offer you a pipeline specifically tailored to SAP Cloud SDK and SAP Cloud Application Programming Model applications The do-it-yourself way: Build with Library \u00b6 The shared library contains building blocks for your own pipeline, following our best practice Jenkins pipelines described in the Scenarios section. The best practice pipelines are based on the general concepts of Pipelines as Code, as introduced in Jenkins 2 . With that you have the power of the Jenkins community at hand to optimize your pipelines. You can run the best practice Jenkins pipelines out of the box, take them as a starting point for project-specific adaptations or implement your own pipelines from scratch using the shared library. For an example, you might want to check out our \"Build and Deploy SAPUI5 or SAP Fiori Applications on SAP Cloud Platform with Jenkins\" scenario . Extensibility \u00b6 For the vast majority of standard projects, the features of the ready-made pipelines should be enough to implement Continuous Delivery with little effort in a best-practice compliant way. If you require more flexibility, our documentation on Extensibility discusses available options. API \u00b6 All steps ( vars and resources directory) are intended to be used by Pipelines and are considered API. All the classes / groovy-scripts contained in the src folder are by default not part of the API and are subjected to change without prior notice. Types and methods annotated with @API are considered to be API, used e.g. from other shared libraries. Changes to those methods/types needs to be announced, discussed and agreed.","title":"Home"},{"location":"#project-piper-user-documentation","text":"Continuous delivery is a method to develop software with short feedback cycles. It is applicable to projects both for SAP Cloud Platform and SAP on-premise platforms. SAP implements tooling for continuous delivery in project \"Piper\". The goal of project \"Piper\" is to substantially ease setting up continuous delivery in your project using SAP technologies.","title":"Project \"Piper\" User Documentation"},{"location":"#what-you-get","text":"To get you started quickly, project \"Piper\" offers you the following artifacts: A set of ready-made Continuous Delivery pipelines for direct use in your project General Purpose Pipeline SAP Cloud SDK Pipeline A shared library that contains reusable step implementations, which enable you to customize our preconfigured pipelines, or to even build your own customized ones A standalone command line utility for Linux and a GitHub Action Note: This version is still in early development. Feel free to use it and provide feedback , but don't expect all the features of the Jenkins library A set of Docker images to setup a CI/CD environment in minutes using sophisticated life-cycle management To find out which offering is right for you, we recommend to look at the ready-made pipelines first. In many cases, they should satisfy your requirements, and if this is the case, you don't need to build your own pipeline.","title":"What you get"},{"location":"#the-best-practice-way-ready-made-pipelines","text":"Are you building a standalone SAP Cloud Platform application? Then continue reading about our general purpose pipeline , which supports various technologies and programming languages. Are you building an application with the SAP Cloud SDK and/or SAP Cloud Application Programming Model? Then we can offer you a pipeline specifically tailored to SAP Cloud SDK and SAP Cloud Application Programming Model applications","title":"The best-practice way: Ready-made pipelines"},{"location":"#the-do-it-yourself-way-build-with-library","text":"The shared library contains building blocks for your own pipeline, following our best practice Jenkins pipelines described in the Scenarios section. The best practice pipelines are based on the general concepts of Pipelines as Code, as introduced in Jenkins 2 . With that you have the power of the Jenkins community at hand to optimize your pipelines. You can run the best practice Jenkins pipelines out of the box, take them as a starting point for project-specific adaptations or implement your own pipelines from scratch using the shared library. For an example, you might want to check out our \"Build and Deploy SAPUI5 or SAP Fiori Applications on SAP Cloud Platform with Jenkins\" scenario .","title":"The do-it-yourself way: Build with Library"},{"location":"#extensibility","text":"For the vast majority of standard projects, the features of the ready-made pipelines should be enough to implement Continuous Delivery with little effort in a best-practice compliant way. If you require more flexibility, our documentation on Extensibility discusses available options.","title":"Extensibility"},{"location":"#api","text":"All steps ( vars and resources directory) are intended to be used by Pipelines and are considered API. All the classes / groovy-scripts contained in the src folder are by default not part of the API and are subjected to change without prior notice. Types and methods annotated with @API are considered to be API, used e.g. from other shared libraries. Changes to those methods/types needs to be announced, discussed and agreed.","title":"API"},{"location":"configuration/","text":"Configuration \u00b6 Configure your project through a yml-file, which is located at .pipeline/config.yml in the master branch of your source code repository. Your configuration inherits from the default configuration located at https://github.com/SAP/jenkins-library/blob/master/resources/default_pipeline_environment.yml . Adding custom parameters Please note that adding custom parameters to the configuration is at your own risk. We may introduce new parameters at any time which may clash with your custom parameters. Configuration of the Piper steps as well the Piper templates can be done in a hierarchical manner. Directly passed step parameters will always take precedence over other configuration values and defaults Stage configuration parameters define a Jenkins pipeline stage dependent set of parameters (e.g. deployment options for the Acceptance stage) Step configuration defines how steps behave in general (e.g. step cloudFoundryDeploy ) General configuration parameters define parameters which are available across step boundaries Custom default configuration provided by the user through a reference in the customDefaults parameter of the project configuration Default configuration comes with the Piper library and is always available Collecting telemetry data \u00b6 In order to improve this Jenkins library we are collecting telemetry data. Data is send using com.sap.piper.pushToSWA Following data (non-personal) is collected for example: Hashed job url, e.g. 4944f745e03f5f79daf0001eec9276ce351d3035 hash calculation is done in your Jenkins server and no original values are transmitted Name of library step which has been executed, like e.g. artifactSetVersion Certain parameters of the executed steps, e.g. buildTool=maven We store the telemetry data for not longer than 6 months on premises of SAP SE. Disable collection of telemetry data If you do not want to send telemetry data you can easily deactivate this. This is done with either of the following two ways: General deactivation in your .pipeline/config.yml file by setting the configuration parameter general -> collectTelemetryData: false (default setting can be found in the library defaults ). Please note: this will only take effect in all steps if you run setupCommonPipelineEnvironment at the beginning of your pipeline Individual deactivation per step by passing the parameter collectTelemetryData: false , like e.g. setVersion script:this, collectTelemetryData: false Example configuration \u00b6 general : gitSshKeyCredentialsId : GitHub_Test_SSH steps : cloudFoundryDeploy : deployTool : 'cf_native' cloudFoundry : org : 'testOrg' space : 'testSpace' credentialsId : 'MY_CF_CREDENTIALSID_IN_JENKINS' newmanExecute : newmanCollection : 'myNewmanCollection.file' newmanEnvironment : 'myNewmanEnvironment' newmanGlobals : 'myNewmanGlobals' Access to configuration from custom scripts \u00b6 Configuration is loaded into commonPipelineEnvironment during step setupCommonPipelineEnvironment . You can access the configuration values via commonPipelineEnvironment.configuration which will return you the complete configuration map. Thus following access is for example possible (accessing gitSshKeyCredentialsId from general section): commonPipelineEnvironment . configuration . general . gitSshKeyCredentialsId Access to configuration in custom library steps \u00b6 Within library steps the ConfigurationHelper object is used. You can see its usage in all the Piper steps, for example newmanExecute . Custom default configuration \u00b6 For projects that are composed of multiple repositories (microservices), it might be desired to provide custom default configurations. To do that, create a YAML file which is accessible from your CI/CD environment and configure it in your project configuration. For example, the custom default configuration can be stored in a GitHub repository and accessed via the \"raw\" URL: customDefaults : [ 'https://my.github.local/raw/someorg/custom-defaults/master/backend-service.yml' ] general : ... Note, the parameter customDefaults is required to be a list of strings and needs to be defined as a separate section of the project configuration. In addition, the item order in the list implies the precedence, i.e., the last item of the customDefaults list has highest precedence. It is important to ensure that the HTTP response body is proper YAML, as the pipeline will attempt to parse it. Anonymous read access to the custom-defaults repository is required. The custom default configuration is merged with the project's .pipeline/config.yml . Note, the project's config takes precedence, so you can override the custom default configuration in your project's local configuration. This might be useful to provide a default value that needs to be changed only in some projects. An overview of the configuration hierarchy is given at the beginning of this page. If you have different types of projects, they might require different custom default configuration. For example, you might not require all projects to have a certain code check (like Whitesource, etc.) active. This can be achieved by having multiple YAML files in the custom-defaults repository. Configure the URL to the respective configuration file in the projects as described above.","title":"Configuration"},{"location":"configuration/#configuration","text":"Configure your project through a yml-file, which is located at .pipeline/config.yml in the master branch of your source code repository. Your configuration inherits from the default configuration located at https://github.com/SAP/jenkins-library/blob/master/resources/default_pipeline_environment.yml . Adding custom parameters Please note that adding custom parameters to the configuration is at your own risk. We may introduce new parameters at any time which may clash with your custom parameters. Configuration of the Piper steps as well the Piper templates can be done in a hierarchical manner. Directly passed step parameters will always take precedence over other configuration values and defaults Stage configuration parameters define a Jenkins pipeline stage dependent set of parameters (e.g. deployment options for the Acceptance stage) Step configuration defines how steps behave in general (e.g. step cloudFoundryDeploy ) General configuration parameters define parameters which are available across step boundaries Custom default configuration provided by the user through a reference in the customDefaults parameter of the project configuration Default configuration comes with the Piper library and is always available","title":"Configuration"},{"location":"configuration/#collecting-telemetry-data","text":"In order to improve this Jenkins library we are collecting telemetry data. Data is send using com.sap.piper.pushToSWA Following data (non-personal) is collected for example: Hashed job url, e.g. 4944f745e03f5f79daf0001eec9276ce351d3035 hash calculation is done in your Jenkins server and no original values are transmitted Name of library step which has been executed, like e.g. artifactSetVersion Certain parameters of the executed steps, e.g. buildTool=maven We store the telemetry data for not longer than 6 months on premises of SAP SE. Disable collection of telemetry data If you do not want to send telemetry data you can easily deactivate this. This is done with either of the following two ways: General deactivation in your .pipeline/config.yml file by setting the configuration parameter general -> collectTelemetryData: false (default setting can be found in the library defaults ). Please note: this will only take effect in all steps if you run setupCommonPipelineEnvironment at the beginning of your pipeline Individual deactivation per step by passing the parameter collectTelemetryData: false , like e.g. setVersion script:this, collectTelemetryData: false","title":"Collecting telemetry data"},{"location":"configuration/#example-configuration","text":"general : gitSshKeyCredentialsId : GitHub_Test_SSH steps : cloudFoundryDeploy : deployTool : 'cf_native' cloudFoundry : org : 'testOrg' space : 'testSpace' credentialsId : 'MY_CF_CREDENTIALSID_IN_JENKINS' newmanExecute : newmanCollection : 'myNewmanCollection.file' newmanEnvironment : 'myNewmanEnvironment' newmanGlobals : 'myNewmanGlobals'","title":"Example configuration"},{"location":"configuration/#access-to-configuration-from-custom-scripts","text":"Configuration is loaded into commonPipelineEnvironment during step setupCommonPipelineEnvironment . You can access the configuration values via commonPipelineEnvironment.configuration which will return you the complete configuration map. Thus following access is for example possible (accessing gitSshKeyCredentialsId from general section): commonPipelineEnvironment . configuration . general . gitSshKeyCredentialsId","title":"Access to configuration from custom scripts"},{"location":"configuration/#access-to-configuration-in-custom-library-steps","text":"Within library steps the ConfigurationHelper object is used. You can see its usage in all the Piper steps, for example newmanExecute .","title":"Access to configuration in custom library steps"},{"location":"configuration/#custom-default-configuration","text":"For projects that are composed of multiple repositories (microservices), it might be desired to provide custom default configurations. To do that, create a YAML file which is accessible from your CI/CD environment and configure it in your project configuration. For example, the custom default configuration can be stored in a GitHub repository and accessed via the \"raw\" URL: customDefaults : [ 'https://my.github.local/raw/someorg/custom-defaults/master/backend-service.yml' ] general : ... Note, the parameter customDefaults is required to be a list of strings and needs to be defined as a separate section of the project configuration. In addition, the item order in the list implies the precedence, i.e., the last item of the customDefaults list has highest precedence. It is important to ensure that the HTTP response body is proper YAML, as the pipeline will attempt to parse it. Anonymous read access to the custom-defaults repository is required. The custom default configuration is merged with the project's .pipeline/config.yml . Note, the project's config takes precedence, so you can override the custom default configuration in your project's local configuration. This might be useful to provide a default value that needs to be changed only in some projects. An overview of the configuration hierarchy is given at the beginning of this page. If you have different types of projects, they might require different custom default configuration. For example, you might not require all projects to have a certain code check (like Whitesource, etc.) active. This can be achieved by having multiple YAML files in the custom-defaults repository. Configure the URL to the respective configuration file in the projects as described above.","title":"Custom default configuration"},{"location":"extensibility/","text":"Extensibility \u00b6 When using one of the ready-made pipelines of project \"Piper\", you don't have to write custom pipeline code. The pipelines are centrally maintained and can be used with only a small amount of declarative configuration as documented here . For the vast majority of standard projects, the features of the ready-made pipelines should be enough to implement Continuous Delivery with little effort in a best-practice compliant way. If you miss a feature or discover a bug in one of our pipelines, please see if there is already an open issue in our GitHub repository and if not, open a new one. In some cases, it's not desirable to include specialized features in the ready-made pipelines. However, you can still benefit from their qualities, if you address your requirements through an extension . Extensions are custom bits of pipeline coding, which you can use to implement special requirements. This page explains extensibility options in project \"Piper\". For a high level overview of available options and how to interface with them, see this figure: Before building extensions, please make sure that there is no alternative that works better for you. Options for extensibility, in the order in which we recommend considering them: 1. Extend individual stages \u00b6 In this option, you use the centrally maintained pipeline but can change individual stages, if required. To do so, create a file called <StageName>.groovy (for example, Acceptance.groovy or lint.groovy ) in .pipeline/extensions/ in the source code repository of your application. For this, you need to know the technical identifiers for stage names. For the general purpose pipeline, you can find them in the pipeline source file . For the SAP Cloud SDK pipeline, you can find them in this GitHub search query . The centrally maintained pipeline checks if such a file exists and if it does, executes it. A parameter of type Map that contains the following keys is passed to the extension: script : Defines the global script environment of the Jenkinsfile run. This makes sure that the correct configuration environment can be passed to project \"Piper\" steps and allows access to the commonPipelineEnvironment , for example. originalStage : Allows you to execute the \"original\" stage at any place in your script. If omitting a call to originalStage() , only your code is executed. stageName : Name of the current stage config : Configuration of the stage and general config (including all defaults) Here is a simple example for such an extension, which you can use as a starting point: void call ( Map params ) { //access stage name echo \"Start - Extension for stage: ${params.stageName}\" //access config echo \"Current stage config: ${params.config}\" //execute original stage as defined in the template params . originalStage () //access overall pipeline script object echo \"Branch: ${params.script.commonPipelineEnvironment.gitBranch}\" echo \"End - Extension for stage: ${params.stageName}\" } return this return this Don't forget the return this , which is required at the end of all extension scripts. This is due to how Groovy loads scripts internally. Init stage cannot be extended Please note that the Init stage also checks out your current repository including your extensions. Therefore, it is not possible to use extensions on this stage. Disable Extensions Execution By default, there is a possibility for extensions to get executed. In case of disabling it, please ensure to set PIPER_DISABLE_EXTENSIONS to true . Setting this parameter to true excludes the execution of extension files in .pipeline/extensions/<StageName>.groovy . Practical example \u00b6 For a more practical example, you can use extensions in the SAP Cloud SDK pipeline to add custom linters to your pipeline. A linter is a tool that can check the source code for certain stylistic criteria. Many teams choose to use a linter to ensure a common programming style. For example, if you want to use Checkstyle in your codebase, you might use an extension similar to this one in a file called .pipeline/extensions/lint.groovy in your project: def call ( Map parameters ) { parameters . originalStage () // Runs the built-in linters mavenExecute ( script: parameters . script , flags: [ '--batch-mode' ], pomPath: 'application/pom.xml' , m2Path: s4SdkGlobals . m2Directory , goals: [ 'checkstyle:checkstyle' ], ) recordIssues blameDisabled: true , enabledForFailure: true , aggregatingResults: false , tool: checkStyle () } return this This code snippet has three components, let's see what is happening here: Firstly, we run the original stage. This runs ESLint on JavaScript/TypeScript source files as this is a standard feature of SAP Cloud SDK pipeline. Secondly, we run the checkstyle maven plugin using the mavenExecute Jenkins library step as provided by project \"Piper\". This serves as an example for how flexible you can re-use what project \"Piper\" already provides in your extension. Finally, we use the Jenkins Warnings NG plugin and its step recordIssues to make the findings visible in the Jenkins user interface. This example can be adapted for other linters of your choice. Be sure to checkout the Library steps section of this documentation if you want to do this. Project \"Piper\" provides some basic building blocks such as dockerExecute and the already mentioned mavenExecute which might be helpful. 2. Modified Ready-Made Pipeline \u00b6 This option describes how you can copy and paste one of the centrally maintained pipelines to make changes to it that are not possible otherwise. For example, you can't change the order of stages and the stages that run in parallel or add new stages to a centrally maintained pipeline. A modified Ready-Made Pipeline allows you to modify your declarative pipeline based on the syntax Jenkins provides . This might be done for an individual project (in the Jenkinsfile ), or in a separate Git repository so it can be used for multiple projects. Single project \u00b6 The default Jenkinsfile of centrally maintained pipelines does nothing else but loading the pipeline and running it. This is convenient but limits the modifiable aspects of the pipeline. If one of your projects uses the pipeline, the easiest way to do this modification is to copy the pipeline into your Jenkinsfile . The basic structure of your Jenkinsfile should be the following: @Library ( /* Shared library definition, see below */ ) _ call script: this void call ( parameters ) { // Your pipeline code based on our ready-made pipelines } The actual pipeline code (the call method in the listing above) can be found here: General purpose pipeline SAP Cloud SDK pipeline Use the correct shared library definition Which shared library you need depends on the pipeline you're using. For the general purpose pipeline , you need 'piper-lib-os' . For the SAP Cloud SDK pipeline , you need 's4sdk-pipeline-library' . For the version identifier, please see the section How to stay up-to-date in this document. Multiple projects \u00b6 If you have multiple projects that share a similar architecture, it might be desirable to share one modified pipeline amongst them. Similar to what you can do in an individual Jenkinsfile , you can copy the pipeline to your own shared library and modify it. To do this, create a new Git repository in your preferred Git hosting service. It must be compliant to how Jenkins shared libraries are built . In a nutshell, this means that you need a vars directory inside which you can place a copy of your preferred pipeline. A minimal example of such a library could have the following directory structure: ./vars/myCustomPipeline.groovy ./README.md myCustomPipeline.groovy contains the modified pipeline code of the general purpose pipeline or SAP Cloud SDK Pipeline . Note The name of your custom pipeline must differ from the other pipelines provided by project \"Piper\" because Jenkins requires names across multiple libraries to be unique. This library must be placed in a Git repository, which is available for Jenkins and must be configured in Jenkins as documented here . The following screenshot shows an example of the configuration in Jenkins. Note that the name (1) must be the same as the one you use in your Jenkinsfile . The Jenkinsfile of your individual projects would look similar to the following: @Library ([ 'piper-lib-os' , 'my-own-pipeline' ]) _ myCustomPipeline script: this Be sure to adapt the names and version identifiers accordingly, as described in How to stay up-to-date . How to stay up-to-date \u00b6 Regardless of which of the above options you choose, one downside of this approach is that your pipeline will be out of sync with the centrally maintained pipelines at some point in time. We strongly recommend doing as little modification as possible to fulfil your requirements. Please be aware that stages may have dependencies on each other. Don't depend on stage implementation details Your pipeline should treat stages as a black box, the stage implementations are not a published API and may be subject to change at any time. Avoid accidental breaking changes By default, Jenkins uses the master branch of shared libraries. This way, you're always automatically using the latest and greatest version. The downside is that in rare cases, breaking changes might happen. Another potential issue is that your builds are not repeatable , that means building the same version of your application twice might have a different result. For those reasons, you might want to consider to fix versions to a released version like in this example: @Library('my-shared-library@v1.0') _ Find the most recent release for the jenkins-library and for the SAP Cloud SDK Pipeline on GitHub. To stay up to date with the latest releases, you can \"watch\" releases for those repositories on GitHub . When to go with a modified ready-made pipeline This option is right for you if none of the provided ready-made pipelines serves your purpose, and individual stage extensions don't provide enough flexibility. Advanced tips and information \u00b6 When you consider adding additional capabilities, your first stop should be the Jenkins Pipeline Steps Reference . Here you get an overview of what kind of capabilities are already available and a list of related parameters, which you can use to customize the existing implementation. The provided information should help you understand and extend the functionality of your pipeline. 3. New Pipeline from Scratch \u00b6 Since project \"Piper\" fully builds on Jenkins Pipelines as Code , you can also go with your own pipeline from scratch in a Jenkinsfile . Decoupling If you choose this option, you will be decoupled from the innovations provided with project \"Piper\", unless you re-use stages (as indicated above under 2. Modified ready-made pipelines ), for example. We recommend using this only when none of the other provided options suit your use case.","title":"Extensibility"},{"location":"extensibility/#extensibility","text":"When using one of the ready-made pipelines of project \"Piper\", you don't have to write custom pipeline code. The pipelines are centrally maintained and can be used with only a small amount of declarative configuration as documented here . For the vast majority of standard projects, the features of the ready-made pipelines should be enough to implement Continuous Delivery with little effort in a best-practice compliant way. If you miss a feature or discover a bug in one of our pipelines, please see if there is already an open issue in our GitHub repository and if not, open a new one. In some cases, it's not desirable to include specialized features in the ready-made pipelines. However, you can still benefit from their qualities, if you address your requirements through an extension . Extensions are custom bits of pipeline coding, which you can use to implement special requirements. This page explains extensibility options in project \"Piper\". For a high level overview of available options and how to interface with them, see this figure: Before building extensions, please make sure that there is no alternative that works better for you. Options for extensibility, in the order in which we recommend considering them:","title":"Extensibility"},{"location":"extensibility/#1-extend-individual-stages","text":"In this option, you use the centrally maintained pipeline but can change individual stages, if required. To do so, create a file called <StageName>.groovy (for example, Acceptance.groovy or lint.groovy ) in .pipeline/extensions/ in the source code repository of your application. For this, you need to know the technical identifiers for stage names. For the general purpose pipeline, you can find them in the pipeline source file . For the SAP Cloud SDK pipeline, you can find them in this GitHub search query . The centrally maintained pipeline checks if such a file exists and if it does, executes it. A parameter of type Map that contains the following keys is passed to the extension: script : Defines the global script environment of the Jenkinsfile run. This makes sure that the correct configuration environment can be passed to project \"Piper\" steps and allows access to the commonPipelineEnvironment , for example. originalStage : Allows you to execute the \"original\" stage at any place in your script. If omitting a call to originalStage() , only your code is executed. stageName : Name of the current stage config : Configuration of the stage and general config (including all defaults) Here is a simple example for such an extension, which you can use as a starting point: void call ( Map params ) { //access stage name echo \"Start - Extension for stage: ${params.stageName}\" //access config echo \"Current stage config: ${params.config}\" //execute original stage as defined in the template params . originalStage () //access overall pipeline script object echo \"Branch: ${params.script.commonPipelineEnvironment.gitBranch}\" echo \"End - Extension for stage: ${params.stageName}\" } return this return this Don't forget the return this , which is required at the end of all extension scripts. This is due to how Groovy loads scripts internally. Init stage cannot be extended Please note that the Init stage also checks out your current repository including your extensions. Therefore, it is not possible to use extensions on this stage. Disable Extensions Execution By default, there is a possibility for extensions to get executed. In case of disabling it, please ensure to set PIPER_DISABLE_EXTENSIONS to true . Setting this parameter to true excludes the execution of extension files in .pipeline/extensions/<StageName>.groovy .","title":"1. Extend individual stages"},{"location":"extensibility/#practical-example","text":"For a more practical example, you can use extensions in the SAP Cloud SDK pipeline to add custom linters to your pipeline. A linter is a tool that can check the source code for certain stylistic criteria. Many teams choose to use a linter to ensure a common programming style. For example, if you want to use Checkstyle in your codebase, you might use an extension similar to this one in a file called .pipeline/extensions/lint.groovy in your project: def call ( Map parameters ) { parameters . originalStage () // Runs the built-in linters mavenExecute ( script: parameters . script , flags: [ '--batch-mode' ], pomPath: 'application/pom.xml' , m2Path: s4SdkGlobals . m2Directory , goals: [ 'checkstyle:checkstyle' ], ) recordIssues blameDisabled: true , enabledForFailure: true , aggregatingResults: false , tool: checkStyle () } return this This code snippet has three components, let's see what is happening here: Firstly, we run the original stage. This runs ESLint on JavaScript/TypeScript source files as this is a standard feature of SAP Cloud SDK pipeline. Secondly, we run the checkstyle maven plugin using the mavenExecute Jenkins library step as provided by project \"Piper\". This serves as an example for how flexible you can re-use what project \"Piper\" already provides in your extension. Finally, we use the Jenkins Warnings NG plugin and its step recordIssues to make the findings visible in the Jenkins user interface. This example can be adapted for other linters of your choice. Be sure to checkout the Library steps section of this documentation if you want to do this. Project \"Piper\" provides some basic building blocks such as dockerExecute and the already mentioned mavenExecute which might be helpful.","title":"Practical example"},{"location":"extensibility/#2-modified-ready-made-pipeline","text":"This option describes how you can copy and paste one of the centrally maintained pipelines to make changes to it that are not possible otherwise. For example, you can't change the order of stages and the stages that run in parallel or add new stages to a centrally maintained pipeline. A modified Ready-Made Pipeline allows you to modify your declarative pipeline based on the syntax Jenkins provides . This might be done for an individual project (in the Jenkinsfile ), or in a separate Git repository so it can be used for multiple projects.","title":"2. Modified Ready-Made Pipeline"},{"location":"extensibility/#single-project","text":"The default Jenkinsfile of centrally maintained pipelines does nothing else but loading the pipeline and running it. This is convenient but limits the modifiable aspects of the pipeline. If one of your projects uses the pipeline, the easiest way to do this modification is to copy the pipeline into your Jenkinsfile . The basic structure of your Jenkinsfile should be the following: @Library ( /* Shared library definition, see below */ ) _ call script: this void call ( parameters ) { // Your pipeline code based on our ready-made pipelines } The actual pipeline code (the call method in the listing above) can be found here: General purpose pipeline SAP Cloud SDK pipeline Use the correct shared library definition Which shared library you need depends on the pipeline you're using. For the general purpose pipeline , you need 'piper-lib-os' . For the SAP Cloud SDK pipeline , you need 's4sdk-pipeline-library' . For the version identifier, please see the section How to stay up-to-date in this document.","title":"Single project"},{"location":"extensibility/#multiple-projects","text":"If you have multiple projects that share a similar architecture, it might be desirable to share one modified pipeline amongst them. Similar to what you can do in an individual Jenkinsfile , you can copy the pipeline to your own shared library and modify it. To do this, create a new Git repository in your preferred Git hosting service. It must be compliant to how Jenkins shared libraries are built . In a nutshell, this means that you need a vars directory inside which you can place a copy of your preferred pipeline. A minimal example of such a library could have the following directory structure: ./vars/myCustomPipeline.groovy ./README.md myCustomPipeline.groovy contains the modified pipeline code of the general purpose pipeline or SAP Cloud SDK Pipeline . Note The name of your custom pipeline must differ from the other pipelines provided by project \"Piper\" because Jenkins requires names across multiple libraries to be unique. This library must be placed in a Git repository, which is available for Jenkins and must be configured in Jenkins as documented here . The following screenshot shows an example of the configuration in Jenkins. Note that the name (1) must be the same as the one you use in your Jenkinsfile . The Jenkinsfile of your individual projects would look similar to the following: @Library ([ 'piper-lib-os' , 'my-own-pipeline' ]) _ myCustomPipeline script: this Be sure to adapt the names and version identifiers accordingly, as described in How to stay up-to-date .","title":"Multiple projects"},{"location":"extensibility/#how-to-stay-up-to-date","text":"Regardless of which of the above options you choose, one downside of this approach is that your pipeline will be out of sync with the centrally maintained pipelines at some point in time. We strongly recommend doing as little modification as possible to fulfil your requirements. Please be aware that stages may have dependencies on each other. Don't depend on stage implementation details Your pipeline should treat stages as a black box, the stage implementations are not a published API and may be subject to change at any time. Avoid accidental breaking changes By default, Jenkins uses the master branch of shared libraries. This way, you're always automatically using the latest and greatest version. The downside is that in rare cases, breaking changes might happen. Another potential issue is that your builds are not repeatable , that means building the same version of your application twice might have a different result. For those reasons, you might want to consider to fix versions to a released version like in this example: @Library('my-shared-library@v1.0') _ Find the most recent release for the jenkins-library and for the SAP Cloud SDK Pipeline on GitHub. To stay up to date with the latest releases, you can \"watch\" releases for those repositories on GitHub . When to go with a modified ready-made pipeline This option is right for you if none of the provided ready-made pipelines serves your purpose, and individual stage extensions don't provide enough flexibility.","title":"How to stay up-to-date"},{"location":"extensibility/#advanced-tips-and-information","text":"When you consider adding additional capabilities, your first stop should be the Jenkins Pipeline Steps Reference . Here you get an overview of what kind of capabilities are already available and a list of related parameters, which you can use to customize the existing implementation. The provided information should help you understand and extend the functionality of your pipeline.","title":"Advanced tips and information"},{"location":"extensibility/#3-new-pipeline-from-scratch","text":"Since project \"Piper\" fully builds on Jenkins Pipelines as Code , you can also go with your own pipeline from scratch in a Jenkinsfile . Decoupling If you choose this option, you will be decoupled from the innovations provided with project \"Piper\", unless you re-use stages (as indicated above under 2. Modified ready-made pipelines ), for example. We recommend using this only when none of the other provided options suit your use case.","title":"3. New Pipeline from Scratch"},{"location":"guidedtour/","text":"Getting Started with Project \"Piper\" \u00b6 Follow this guided tour to become familiar with the basics of using project \"Piper\". The public sample application cloud-cf-helloworld-nodejs will be enriched with a pipeline which syncs the sources, builds these as MTA and deploys the result into a Cloud Foundry environment. The application contains a simple nodejs application. Deployed as web service, it serves static data. Recommendation: We recommend to clone the sample application cloud-cf-helloworld-nodejs and execute the instructions on your own repository. See (Optional) Sample Application . The stated instructions assume the use of this application. Prerequisites \u00b6 You have installed a Linux system with at least 4 GB memory. Note: We have tested our samples on Ubuntu 16.04. On Microsoft Windows, you might face some issues. You have installed the newest version of Docker. See Docker Community Edition . Note: we have tested on Docker 18.09.6. Your system has access to GitHub.com . Recommended: Install the Cx Server Life-cycle Management for Jenkins \u00b6 Cx Server is a life-cycle management tool to bootstrap a pre-configured Jenkins instance within minutes. All required plugins and shared libraries are included automatically. It is based on Docker images provided by project \"Piper\". To get started, initialize Cx Server by using this docker run command: docker run -it --rm -u $( id -u ) : $( id -g ) -v \" ${ PWD } \" :/cx-server/mount/ ppiper/cx-server-companion:latest init-cx-server This creates a few files in your current working directory. The shell script cx-server and the configuration file server.cfg are of special interest. Now, you can start the Jenkins server by using the following command: chmod +x ./cx-server ./cx-server start For more information on the Cx Server and how to customize your Jenkins, have a look at the Operations Guide for Cx Server . For alternative approaches to setup a Jenkins build sever which fits the needs of the project \"Piper\" pipelines and steps please read the Infrastructure Overview . (Optional) Sample Application \u00b6 Choosing the best sample application Depending on the type of project you're interested in, different sample applications might be interesting. For SAP Cloud SDK, please have a look at the Address Manager example application. Copy the sources of the application into your own Git repository. While we will ask you to fork the application's repository into a GitHub space, you can use any version control system based on Git like GitLab or plain git . Note: A public GitHub repository is visible to the public. The configuration files may contain data you don't want to expose, so use a private repository. Create an organization on GitHub, if you haven't any yet. See Creating a new organization . Duplicate the repository cloud-cf-helloworld-nodejs into your GitHub organization. Make this repository private . Note: Forked public repositories cannot be made private. Get an account and space in the Cloud Foundry environment. For the deployment of the application you need access to a space on the Cloud Foundry environment of the SAP Cloud Platform. If you haven't any yet, get a Trial Account . Select the 1_REST_persist_in_Memory branch of your cloud-cf-helloworld-nodejs fork. Other branches might work as well, but this one is tested. Create Your First Pipeline \u00b6 Get your application repository in place. Create a new file with the name Jenkinsfile in the root level of your repository and enter the following code: @Library('piper-lib-os') _ node() { stage('prepare') { checkout scm setupCommonPipelineEnvironment script:this } } The \"prepare\" step synchronizes the repository and initializes the project specific settings. For more information about Jenkinsfiles and pipelines, see Using a Jenkinsfile . Save your changes to your remote repository. To set up a Jenkins job for your repository, open the Jenkins UI under http://<jenkins-server-address>:<http-port> and choose New Item . Per default, the cx-server starts Jenkins on HTTP port 80 . For more information, see the Jenkins User Documentation . Provide a name for your new item (for example, My First Pipeline ) and select Multibranch Pipeline . Note: The ready-made continuous delivery pipelines of project \"Piper\" must run as Multibranch Pipeline . For Branch Sources , choose Add source , select Git as source repository. For Project Repository in the Git section, enter the URL of your Git repository, for example https://github.com/<your-org>/cloud-cf-helloworld-nodejs . Note: If your repository is protected, you must provide your credentials in Credentials . For Discover branches , choose Add and Filter by name (with wildcards) . A multibranch pipeline can execute different Jenkinsfiles for different branches. In this case, however, configure the pipeline of a single branch only. For Include in the Filter by name section, enter the branch name 1_REST_persist_in_Memory . Choose Save . Result: Jenkins scans the repository for branches and filters them according to the specified Includes . If the branch is detected, it is built. For additional information about multibranch pipelines, please refer to the Jenkins documentation . Add a Build Step \u00b6 In your Jenkinsfile , add the following code snippet: stage('build') { mtaBuild script: this } The mtaBuild step calls a build tool to build a multi-target application (MTA). The tool consumes an MTA descriptor that contains the metadata of all entities which comprise an application or are used by one during deployment or runtime, and the dependencies between them. For more information about MTAs, see sap.com . Create the MTA descriptor file with the name mta.yaml in the root level of the repository. Insert the following code: _schema-version: 2.1.0 ID: com.sap.piper.node.hello.world version: 1.0.0 description: A Hello World sample application provider: SAP Sample generator modules: - name: piper.node.hello.world type: nodejs path: . Configure the step to build an MTA for the Cloud Foundry environment. Create the configuration file .pipeline/config.yml relative to the root level of the repository and insert the following content: general: steps: mtaBuild: buildTarget: 'CF' For additional information about the configuration, have a look at the Common Configuration Guide and the MTA build step documentation . Save your changes to your remote repository. To run your pipeline, choose Build Now in the job UI. Result: The pipeline processed two stages, the \"prepare\" and the \"build\". Add a Deploy Step \u00b6 In your Jenkinsfile , add the following code snippet: stage('deploy') { cloudFoundryDeploy script: this } The cloudFoundryDeploy step calls the Cloud Foundry command line client to deploy the built MTA into SAP Cloud Platform. To configure the step to deploy into the Cloud Foundry environment, in your repository, open the .pipeline/config.yml and add the following content: cloudFoundryDeploy: deployTool: 'mtaDeployPlugin' deployType: 'standard' cloudFoundry: org: '<your-organisation>' space: '<your-space>' credentialsId: 'CF_CREDENTIALSID' Note: look after the indentation of the step within the YAML. Specify the organisation and space properties. For more information about the configuration, see the Common Configuration Guide and cloudFoundryDeploy . The key CF_CREDENTIALSID refers to a user-password credential you must create in Jenkins: In Jenkins, choose Credentials from the main menu and add a Username with Password entry. Save the Credential Save your changes to your remote repository. To run your pipeline, choose Build Now in the job UI. Result: The pipeline processed the three stages \"prepare\", \"build\" and \"deploy\". If your pipeline fails, compare its files to the final Jenkinsfile , the config.yml , and the mta.yaml . Note : YAML files are surprisingly sensitive regarding indentation. Open Application \u00b6 Your application has been deployed into your space in the Cloud Foundry space on SAP Cloud Platform. Login to SAP Cloud Platform and navigate into you space. Result: Your space contains the application piper.node.hello.world , the state of the application is Started . Open the application name to get into the Application Overview . Open the Application Route and add /users to the URL. Result: The application returns a list of user data. What's Next \u00b6 You are now familiar with the basics of using project \"Piper\". Through the concept of pipeline as code, project \"Piper\" and Jenkins pipelines are extremely powerful. While Jenkins pipelines offer a full set of common programming features, project \"Piper\" adds SAP-specific flavors. Have a look at the different Scenarios to understand how to easily integrate SAP systems with defaults. Dive into the ready-made continuous delivery pipelines: the General Purpose Pipeline and SAP Cloud SDK Pipeline help you quickly build and deliver your apps. Browse the steadily increasing list of features you can implement through the project \"Piper\" Steps . The Configuration pattern supports simple pipelines that can be reused by multiple applications. To understand the principles of inheritance and customization, have a look at the the configuration documentation. Please also consult the blog post on setting up Continuous Delivery for S/4HANA extensions and get tons of informations around the application development with the S/4HANA Cloud SDK .","title":"Getting Started With Project \"Piper\""},{"location":"guidedtour/#getting-started-with-project-piper","text":"Follow this guided tour to become familiar with the basics of using project \"Piper\". The public sample application cloud-cf-helloworld-nodejs will be enriched with a pipeline which syncs the sources, builds these as MTA and deploys the result into a Cloud Foundry environment. The application contains a simple nodejs application. Deployed as web service, it serves static data. Recommendation: We recommend to clone the sample application cloud-cf-helloworld-nodejs and execute the instructions on your own repository. See (Optional) Sample Application . The stated instructions assume the use of this application.","title":"Getting Started with Project \"Piper\""},{"location":"guidedtour/#prerequisites","text":"You have installed a Linux system with at least 4 GB memory. Note: We have tested our samples on Ubuntu 16.04. On Microsoft Windows, you might face some issues. You have installed the newest version of Docker. See Docker Community Edition . Note: we have tested on Docker 18.09.6. Your system has access to GitHub.com .","title":"Prerequisites"},{"location":"guidedtour/#recommended-install-the-cx-server-life-cycle-management-for-jenkins","text":"Cx Server is a life-cycle management tool to bootstrap a pre-configured Jenkins instance within minutes. All required plugins and shared libraries are included automatically. It is based on Docker images provided by project \"Piper\". To get started, initialize Cx Server by using this docker run command: docker run -it --rm -u $( id -u ) : $( id -g ) -v \" ${ PWD } \" :/cx-server/mount/ ppiper/cx-server-companion:latest init-cx-server This creates a few files in your current working directory. The shell script cx-server and the configuration file server.cfg are of special interest. Now, you can start the Jenkins server by using the following command: chmod +x ./cx-server ./cx-server start For more information on the Cx Server and how to customize your Jenkins, have a look at the Operations Guide for Cx Server . For alternative approaches to setup a Jenkins build sever which fits the needs of the project \"Piper\" pipelines and steps please read the Infrastructure Overview .","title":"Recommended: Install the Cx Server Life-cycle Management for Jenkins"},{"location":"guidedtour/#optional-sample-application","text":"Choosing the best sample application Depending on the type of project you're interested in, different sample applications might be interesting. For SAP Cloud SDK, please have a look at the Address Manager example application. Copy the sources of the application into your own Git repository. While we will ask you to fork the application's repository into a GitHub space, you can use any version control system based on Git like GitLab or plain git . Note: A public GitHub repository is visible to the public. The configuration files may contain data you don't want to expose, so use a private repository. Create an organization on GitHub, if you haven't any yet. See Creating a new organization . Duplicate the repository cloud-cf-helloworld-nodejs into your GitHub organization. Make this repository private . Note: Forked public repositories cannot be made private. Get an account and space in the Cloud Foundry environment. For the deployment of the application you need access to a space on the Cloud Foundry environment of the SAP Cloud Platform. If you haven't any yet, get a Trial Account . Select the 1_REST_persist_in_Memory branch of your cloud-cf-helloworld-nodejs fork. Other branches might work as well, but this one is tested.","title":"(Optional) Sample Application"},{"location":"guidedtour/#create-your-first-pipeline","text":"Get your application repository in place. Create a new file with the name Jenkinsfile in the root level of your repository and enter the following code: @Library('piper-lib-os') _ node() { stage('prepare') { checkout scm setupCommonPipelineEnvironment script:this } } The \"prepare\" step synchronizes the repository and initializes the project specific settings. For more information about Jenkinsfiles and pipelines, see Using a Jenkinsfile . Save your changes to your remote repository. To set up a Jenkins job for your repository, open the Jenkins UI under http://<jenkins-server-address>:<http-port> and choose New Item . Per default, the cx-server starts Jenkins on HTTP port 80 . For more information, see the Jenkins User Documentation . Provide a name for your new item (for example, My First Pipeline ) and select Multibranch Pipeline . Note: The ready-made continuous delivery pipelines of project \"Piper\" must run as Multibranch Pipeline . For Branch Sources , choose Add source , select Git as source repository. For Project Repository in the Git section, enter the URL of your Git repository, for example https://github.com/<your-org>/cloud-cf-helloworld-nodejs . Note: If your repository is protected, you must provide your credentials in Credentials . For Discover branches , choose Add and Filter by name (with wildcards) . A multibranch pipeline can execute different Jenkinsfiles for different branches. In this case, however, configure the pipeline of a single branch only. For Include in the Filter by name section, enter the branch name 1_REST_persist_in_Memory . Choose Save . Result: Jenkins scans the repository for branches and filters them according to the specified Includes . If the branch is detected, it is built. For additional information about multibranch pipelines, please refer to the Jenkins documentation .","title":"Create Your First Pipeline"},{"location":"guidedtour/#add-a-build-step","text":"In your Jenkinsfile , add the following code snippet: stage('build') { mtaBuild script: this } The mtaBuild step calls a build tool to build a multi-target application (MTA). The tool consumes an MTA descriptor that contains the metadata of all entities which comprise an application or are used by one during deployment or runtime, and the dependencies between them. For more information about MTAs, see sap.com . Create the MTA descriptor file with the name mta.yaml in the root level of the repository. Insert the following code: _schema-version: 2.1.0 ID: com.sap.piper.node.hello.world version: 1.0.0 description: A Hello World sample application provider: SAP Sample generator modules: - name: piper.node.hello.world type: nodejs path: . Configure the step to build an MTA for the Cloud Foundry environment. Create the configuration file .pipeline/config.yml relative to the root level of the repository and insert the following content: general: steps: mtaBuild: buildTarget: 'CF' For additional information about the configuration, have a look at the Common Configuration Guide and the MTA build step documentation . Save your changes to your remote repository. To run your pipeline, choose Build Now in the job UI. Result: The pipeline processed two stages, the \"prepare\" and the \"build\".","title":"Add a Build Step"},{"location":"guidedtour/#add-a-deploy-step","text":"In your Jenkinsfile , add the following code snippet: stage('deploy') { cloudFoundryDeploy script: this } The cloudFoundryDeploy step calls the Cloud Foundry command line client to deploy the built MTA into SAP Cloud Platform. To configure the step to deploy into the Cloud Foundry environment, in your repository, open the .pipeline/config.yml and add the following content: cloudFoundryDeploy: deployTool: 'mtaDeployPlugin' deployType: 'standard' cloudFoundry: org: '<your-organisation>' space: '<your-space>' credentialsId: 'CF_CREDENTIALSID' Note: look after the indentation of the step within the YAML. Specify the organisation and space properties. For more information about the configuration, see the Common Configuration Guide and cloudFoundryDeploy . The key CF_CREDENTIALSID refers to a user-password credential you must create in Jenkins: In Jenkins, choose Credentials from the main menu and add a Username with Password entry. Save the Credential Save your changes to your remote repository. To run your pipeline, choose Build Now in the job UI. Result: The pipeline processed the three stages \"prepare\", \"build\" and \"deploy\". If your pipeline fails, compare its files to the final Jenkinsfile , the config.yml , and the mta.yaml . Note : YAML files are surprisingly sensitive regarding indentation.","title":"Add a Deploy Step"},{"location":"guidedtour/#open-application","text":"Your application has been deployed into your space in the Cloud Foundry space on SAP Cloud Platform. Login to SAP Cloud Platform and navigate into you space. Result: Your space contains the application piper.node.hello.world , the state of the application is Started . Open the application name to get into the Application Overview . Open the Application Route and add /users to the URL. Result: The application returns a list of user data.","title":"Open Application"},{"location":"guidedtour/#whats-next","text":"You are now familiar with the basics of using project \"Piper\". Through the concept of pipeline as code, project \"Piper\" and Jenkins pipelines are extremely powerful. While Jenkins pipelines offer a full set of common programming features, project \"Piper\" adds SAP-specific flavors. Have a look at the different Scenarios to understand how to easily integrate SAP systems with defaults. Dive into the ready-made continuous delivery pipelines: the General Purpose Pipeline and SAP Cloud SDK Pipeline help you quickly build and deliver your apps. Browse the steadily increasing list of features you can implement through the project \"Piper\" Steps . The Configuration pattern supports simple pipelines that can be reused by multiple applications. To understand the principles of inheritance and customization, have a look at the the configuration documentation. Please also consult the blog post on setting up Continuous Delivery for S/4HANA extensions and get tons of informations around the application development with the S/4HANA Cloud SDK .","title":"What's Next"},{"location":"cli/","text":"Project \"Piper\" CLI \u00b6 The CLI is built using the go programming language and thus is distributed in a single binary file for Linux. The latest released version can be downloaded via wget https://github.com/SAP/jenkins-library/releases/latest/download/piper . Specific versions an be downloaded from the GitHub releases page. Once available in $PATH , it is ready to use. To verify the version you got, run piper version . To read the online help, run piper help . Note Since this is a binary compiled for Linux systems, you won't be able to use it on macOS or Windows systems. You might try running it inside Docker on those systems. If you're interested in using it with GitHub Actions, see the Project \"Piper\" Action which makes the tool more convinient to use.","title":"Command line tool"},{"location":"cli/#project-piper-cli","text":"The CLI is built using the go programming language and thus is distributed in a single binary file for Linux. The latest released version can be downloaded via wget https://github.com/SAP/jenkins-library/releases/latest/download/piper . Specific versions an be downloaded from the GitHub releases page. Once available in $PATH , it is ready to use. To verify the version you got, run piper version . To read the online help, run piper help . Note Since this is a binary compiled for Linux systems, you won't be able to use it on macOS or Windows systems. You might try running it inside Docker on those systems. If you're interested in using it with GitHub Actions, see the Project \"Piper\" Action which makes the tool more convinient to use.","title":"Project \"Piper\" CLI"},{"location":"infrastructure/customjenkins/","text":"Custom Jenkins Setup \u00b6 Although we recommend using the Cx Server, you can also run project \"Piper\" on your own Jenkins installation. In this case, however, you have to care for some settings the Cx Server gives you for free. Also, the support of non-Cx Server installations is challenging. This section describes the adjustments that might be necessary. Requirements \u00b6 You have installed Java Runtime Environment 8. You have installed Jenkins v 2.60.3 or higher running on Linux. We've tested with debian-stretch. A Jenkins user with administration rights. Your Jenkins instance has access to github.com . Docker \u00b6 Most of the tools project \"Piper\" uses to build, test, and deploy your application are available as out-of-the-box Docker images. You don't need to manually install them on your Jenkins server or Jenkins nodes, nor care for updates. Instead, these are automatically pulled from hub.docker.com . Install Docker if you haven't installed it, yet. To install the newest version of Docker, see Docker Community Edition . Note: We've tested on Docker 18.09.6. If your Jenkins server already runs as Docker container, make sure the tools container can run on the Docker host. Extend the Docker call in the following way: docker run ... -v /var/run/docker.sock:/var/run/docker.sock ... Plugins \u00b6 Project \"Piper\" requires a set of plugins installed on your Jenkins server. This set may evolve in the future. Make sure that all plugins of the appropriate versions are installed. The Cx server repository contains an up-to-date list of the required plugins. To ease the installation, download the list with the following command and use the Jenkins client : curl -o plugins.txt https://raw.githubusercontent.com/SAP/devops-docker-cx-server/master/jenkins-master/plugins.txt On the Jenkins server, run the following command with a user that has administration rights: cat plugins.txt | awk '{system(\"java \" \"-jar jenkins-cli.jar -s http://localhost:8080 -auth ${ADM_USER}:${ADM_PASSWD} install-plugin \" $1)}' Shared Library \u00b6 Shared libraries extending the Jenkins pipeline are defined within the Jenkins system configuration. A library is defined by a link to its source repository and an appropriate version identifier. To add the project \"Piper\"s library, execute the following steps: Open the Jenkins UI under http://<jenkins-server-address>:<http-port> , login with administration privileges, and choose Manage Jenkins > Configure System . Scroll down to section Global Pipeline Libraries and choose the Add button. A new library is created. For Library Name , enter piper-lib-os . For Default Version , enter the branch or tag you want to consume (e.g. master or v0.1 ). For Retrieval Method , choose Modern SCM . For Source Code Management , choose Git . For Project Repository , enter the GitHub URL of the project Piper shared library https://github.com/SAP/jenkins-library . Save your changes. Result: The library is available as piper-lib-os . To use it by any pipeline, add the following line to its Jenkinsfile : @Library ( 'piper-lib-os' ) _ When the pipeline is launched, Jenkins downloads the corresponding library as source and compiles it before the pipeline is processed. User Permission Issue \u00b6 Your native Jenkins installation defines the user jenkins as a service user. If it doesn't exist, it is created. In this case, the user ID is the next free number determined by /etc/passwd - probably starting from 100 . In contrast, the official Jenkins Docker image defines the user jenkins with the user ID 1000 as a service user inside the container. So, the service user ID of your native Jenkins server most likely differs from the user ID of the official Jenkins Docker image. This could have impacts. Project \"Piper\" runs many pipeline steps as Docker images. If a Docker container is created, the Jenkins Docker plugin passes the Jenkins user and group ID as a process owner into the Docker container. Binding a folder from the host machine into the container - used to exchange files between steps - results in file permission issues, if the user inside the container doesn't have rights for the folder on the host machine or vice versa. Although you won't face this issue with images of project \"Piper\" , some 3rd-party Docker images follow this convention and expect to be executed under userid 1000 , like node.js , which is used by a set of additional steps. If you face such a user permission issue , choose between the following options: Change the ID of your Jenkins service user to 1000 . Create your own images and solve the permission issues by removing the file system restrictions. Adjust the configuration accordingly, for example, adjust the npmExecute step of your project's YAML: npmExecute: dockerImage: 'my-node:8-stretch' Set up a namespace. The user permission issue 781 of the project \"Piper\" repository describes how to set up a Linux kernel user namespace to prevent the mismatch of user IDs. Note: This solution is experimental and should be well-considered.","title":"Custom Jenkins Setup"},{"location":"infrastructure/customjenkins/#custom-jenkins-setup","text":"Although we recommend using the Cx Server, you can also run project \"Piper\" on your own Jenkins installation. In this case, however, you have to care for some settings the Cx Server gives you for free. Also, the support of non-Cx Server installations is challenging. This section describes the adjustments that might be necessary.","title":"Custom Jenkins Setup"},{"location":"infrastructure/customjenkins/#requirements","text":"You have installed Java Runtime Environment 8. You have installed Jenkins v 2.60.3 or higher running on Linux. We've tested with debian-stretch. A Jenkins user with administration rights. Your Jenkins instance has access to github.com .","title":"Requirements"},{"location":"infrastructure/customjenkins/#docker","text":"Most of the tools project \"Piper\" uses to build, test, and deploy your application are available as out-of-the-box Docker images. You don't need to manually install them on your Jenkins server or Jenkins nodes, nor care for updates. Instead, these are automatically pulled from hub.docker.com . Install Docker if you haven't installed it, yet. To install the newest version of Docker, see Docker Community Edition . Note: We've tested on Docker 18.09.6. If your Jenkins server already runs as Docker container, make sure the tools container can run on the Docker host. Extend the Docker call in the following way: docker run ... -v /var/run/docker.sock:/var/run/docker.sock ...","title":"Docker"},{"location":"infrastructure/customjenkins/#plugins","text":"Project \"Piper\" requires a set of plugins installed on your Jenkins server. This set may evolve in the future. Make sure that all plugins of the appropriate versions are installed. The Cx server repository contains an up-to-date list of the required plugins. To ease the installation, download the list with the following command and use the Jenkins client : curl -o plugins.txt https://raw.githubusercontent.com/SAP/devops-docker-cx-server/master/jenkins-master/plugins.txt On the Jenkins server, run the following command with a user that has administration rights: cat plugins.txt | awk '{system(\"java \" \"-jar jenkins-cli.jar -s http://localhost:8080 -auth ${ADM_USER}:${ADM_PASSWD} install-plugin \" $1)}'","title":"Plugins"},{"location":"infrastructure/customjenkins/#shared-library","text":"Shared libraries extending the Jenkins pipeline are defined within the Jenkins system configuration. A library is defined by a link to its source repository and an appropriate version identifier. To add the project \"Piper\"s library, execute the following steps: Open the Jenkins UI under http://<jenkins-server-address>:<http-port> , login with administration privileges, and choose Manage Jenkins > Configure System . Scroll down to section Global Pipeline Libraries and choose the Add button. A new library is created. For Library Name , enter piper-lib-os . For Default Version , enter the branch or tag you want to consume (e.g. master or v0.1 ). For Retrieval Method , choose Modern SCM . For Source Code Management , choose Git . For Project Repository , enter the GitHub URL of the project Piper shared library https://github.com/SAP/jenkins-library . Save your changes. Result: The library is available as piper-lib-os . To use it by any pipeline, add the following line to its Jenkinsfile : @Library ( 'piper-lib-os' ) _ When the pipeline is launched, Jenkins downloads the corresponding library as source and compiles it before the pipeline is processed.","title":"Shared Library"},{"location":"infrastructure/customjenkins/#user-permission-issue","text":"Your native Jenkins installation defines the user jenkins as a service user. If it doesn't exist, it is created. In this case, the user ID is the next free number determined by /etc/passwd - probably starting from 100 . In contrast, the official Jenkins Docker image defines the user jenkins with the user ID 1000 as a service user inside the container. So, the service user ID of your native Jenkins server most likely differs from the user ID of the official Jenkins Docker image. This could have impacts. Project \"Piper\" runs many pipeline steps as Docker images. If a Docker container is created, the Jenkins Docker plugin passes the Jenkins user and group ID as a process owner into the Docker container. Binding a folder from the host machine into the container - used to exchange files between steps - results in file permission issues, if the user inside the container doesn't have rights for the folder on the host machine or vice versa. Although you won't face this issue with images of project \"Piper\" , some 3rd-party Docker images follow this convention and expect to be executed under userid 1000 , like node.js , which is used by a set of additional steps. If you face such a user permission issue , choose between the following options: Change the ID of your Jenkins service user to 1000 . Create your own images and solve the permission issues by removing the file system restrictions. Adjust the configuration accordingly, for example, adjust the npmExecute step of your project's YAML: npmExecute: dockerImage: 'my-node:8-stretch' Set up a namespace. The user permission issue 781 of the project \"Piper\" repository describes how to set up a Linux kernel user namespace to prevent the mismatch of user IDs. Note: This solution is experimental and should be well-considered.","title":"User Permission Issue"},{"location":"infrastructure/overview/","text":"Infrastructure \u00b6 Besides SAP specific Jenkins library steps and out-of-the-box pipelines, project \"Piper\" offers also documentation and tooling to start the corresponding Jenkins server with all the configuration required to run project \"Piper\" pipelines. The core of the Jenkins infrastructure tooling is a set of Docker images . There is a main Docker image containing a preconfigured Jenkins and several tooling images used in the specific project \"Piper\" steps. The document and the linked resources explain the various ways of starting such a Jenkins server based on these Docker images. Cx Server (Recommended) \u00b6 Cx Server is a life-cycle management tool to bootstrap a pre-configured Jenkins instance within minutes on your own (virtual) server. It uses the Docker images mentioned above. As it would be cumbersome to start the Docker image manually with all required parameters and sidecar images, this command line tool automates the bootstraping. Setting up a Jenkins master \u00b6 For the following steps you will need a server or another machine which has Docker installed and configured. To get started, initialize the Cx Server by using this docker run command: docker run -it --rm -u $( id -u ) : $( id -g ) -v \" ${ PWD } \" :/cx-server/mount/ ppiper/cx-server-companion:latest init-cx-server This creates a few files in your current working directory. The shell script cx-server and the configuration file server.cfg are of special interest. Now, you can start the Jenkins server by using the following command: chmod +x ./cx-server ./cx-server start For more information on the Cx Server and how to customize your Jenkins, have a look at the Operations Guide for Cx Server . Setting up Jenkins agents \u00b6 With more and more qualities checked automatically in the pipeline, more and more resources are required to handle the workload. This section shows how to scale the pipeline by adding Jenkins build agents . However, before setting up agents please consider also other ways to scale the build infrastructure. It might be an option to have only one Jenkins master with lots of resources (cpu cores, memory) per project or team. This has the advantage of bringing more configuration flexibility and isolation for the individual teams but has the disadvantage that parts of the configuration have to be maintained twice. Furthermore, having agents and thus network communication between the build servers increases the risk of failures. To add an agent to the Jenkins master, please make sure to fulfil the following requirements similar to the ones for the Jenkins master: Access to a new server which runs on Linux Docker installed on this server The connection between the master and the agents will be established via ssh. As the Jenkins master runs in a Docker container, the ssh setup steps, such as creating and storing a private/public key pair or maintaining the konwn hosts file has to be done inside this container. To execute these steps inside the container, execute the following command on the server where the Jenkins master is running: docker exec -it cx-jenkins-master bash Inside the container make sure to be able to access the server where the Jenkins agent should be started by running the following command. As user you should use a user which is able to execute docker commands, i.e. starting a docker container. ssh <docker-user>@<host/ip> To be able to access the agent via ssh with the command above you might need to generate a new ssh key with ssh-keygen , store it in the .ssh folder and register the public key on the agent server. You might also need to add server\u2019s fingerprint to the list of known hosts. For more information around establishing a ssh connection please consult the ssh documentation . To setup a new Jenkins agent, open \"Manage Jenkins\" > \"Manage Nodes\" > \"New Nodes\" and create a new \"Permanent Agent\" Please define /var/jenkins_home as \"Remote root directory\". The launch method has to be \"Launch agent via execution of command on the master\" and the command should be: ./var/jenkins_home/launch-jenkins-agent.sh <user> <host> [image] . User and host should equal the values you used above to test the ssh connection. The following picture shows an example configuration. Kubernetes (Experimental) \u00b6 Hosting Jenkins master and agents means that we bind the required resources to the purpose of executing builds. There are good chances that, these resources stay idle for the most part of the day, i.e. if you have high peak loads. Autoscaling of the infrastructure solves such a problem. Instead of reserving the resources proactively, the pipeline creates the Jenkins agents dynamically on a Kubernetes cluster during the execution. Once the agent completes the dedicated task, it is deleted and the resources are freed. Project \"Piper\" supports running the pipeline as well as individual steps in a Kubernetes Cluster. Please note that this feature is currently only experimental. To setup the Jenkins master in Kubernetes you can use helm. The documentation to install Jenkins using helm can be found here . To use the Jenkins image provided by project Piper, pass ppiper/jenkins-master as a value for the Master.Image command line argument while deploying Jenkins to Kubernetes. The successfully completed deployment consists of a Jenkins pod with port 80 and 50000 exposed for HTTP and internal JNLP traffic respectively. The deployment also creates two services each to listen to incoming HTTP traffic on port 80 and the internal JNLP traffic on port 50000. Please note that in this example setup, the SSL/TLS termination happens at the load balancer, hence all the traffic between a load balancer and the Jenkins pod is unencrypted. Project \"Piper\" needs an environment variable set in the Jenkins to run the workload in Kubernetes. In order to set the environment variable, navigate to \"Manage Jenkins\" > \"Configure System\" > \"Global Properties\". Add an environment variable ON_K8S and set the value to true: Afterwards, you should be able to run project \"Piper\" pipelines in Kubernetes. Custom Jenkins \u00b6 On your own: Custom Jenkins Setup \u00b6 If you use your own Jenkins installation, you need to care for the configuration that is specific to project \"Piper\". This option should only be considered if you know why you need it, otherwise using the Cx Server life-cycle management makes your life much easier. If you choose to go this path, follow the Custom Jenkins Setup guide . Note: This option is not supported for SAP Cloud SDK projects.","title":"Overview"},{"location":"infrastructure/overview/#infrastructure","text":"Besides SAP specific Jenkins library steps and out-of-the-box pipelines, project \"Piper\" offers also documentation and tooling to start the corresponding Jenkins server with all the configuration required to run project \"Piper\" pipelines. The core of the Jenkins infrastructure tooling is a set of Docker images . There is a main Docker image containing a preconfigured Jenkins and several tooling images used in the specific project \"Piper\" steps. The document and the linked resources explain the various ways of starting such a Jenkins server based on these Docker images.","title":"Infrastructure"},{"location":"infrastructure/overview/#cx-server-recommended","text":"Cx Server is a life-cycle management tool to bootstrap a pre-configured Jenkins instance within minutes on your own (virtual) server. It uses the Docker images mentioned above. As it would be cumbersome to start the Docker image manually with all required parameters and sidecar images, this command line tool automates the bootstraping.","title":"Cx Server (Recommended)"},{"location":"infrastructure/overview/#setting-up-a-jenkins-master","text":"For the following steps you will need a server or another machine which has Docker installed and configured. To get started, initialize the Cx Server by using this docker run command: docker run -it --rm -u $( id -u ) : $( id -g ) -v \" ${ PWD } \" :/cx-server/mount/ ppiper/cx-server-companion:latest init-cx-server This creates a few files in your current working directory. The shell script cx-server and the configuration file server.cfg are of special interest. Now, you can start the Jenkins server by using the following command: chmod +x ./cx-server ./cx-server start For more information on the Cx Server and how to customize your Jenkins, have a look at the Operations Guide for Cx Server .","title":"Setting up a Jenkins master"},{"location":"infrastructure/overview/#setting-up-jenkins-agents","text":"With more and more qualities checked automatically in the pipeline, more and more resources are required to handle the workload. This section shows how to scale the pipeline by adding Jenkins build agents . However, before setting up agents please consider also other ways to scale the build infrastructure. It might be an option to have only one Jenkins master with lots of resources (cpu cores, memory) per project or team. This has the advantage of bringing more configuration flexibility and isolation for the individual teams but has the disadvantage that parts of the configuration have to be maintained twice. Furthermore, having agents and thus network communication between the build servers increases the risk of failures. To add an agent to the Jenkins master, please make sure to fulfil the following requirements similar to the ones for the Jenkins master: Access to a new server which runs on Linux Docker installed on this server The connection between the master and the agents will be established via ssh. As the Jenkins master runs in a Docker container, the ssh setup steps, such as creating and storing a private/public key pair or maintaining the konwn hosts file has to be done inside this container. To execute these steps inside the container, execute the following command on the server where the Jenkins master is running: docker exec -it cx-jenkins-master bash Inside the container make sure to be able to access the server where the Jenkins agent should be started by running the following command. As user you should use a user which is able to execute docker commands, i.e. starting a docker container. ssh <docker-user>@<host/ip> To be able to access the agent via ssh with the command above you might need to generate a new ssh key with ssh-keygen , store it in the .ssh folder and register the public key on the agent server. You might also need to add server\u2019s fingerprint to the list of known hosts. For more information around establishing a ssh connection please consult the ssh documentation . To setup a new Jenkins agent, open \"Manage Jenkins\" > \"Manage Nodes\" > \"New Nodes\" and create a new \"Permanent Agent\" Please define /var/jenkins_home as \"Remote root directory\". The launch method has to be \"Launch agent via execution of command on the master\" and the command should be: ./var/jenkins_home/launch-jenkins-agent.sh <user> <host> [image] . User and host should equal the values you used above to test the ssh connection. The following picture shows an example configuration.","title":"Setting up Jenkins agents"},{"location":"infrastructure/overview/#kubernetes-experimental","text":"Hosting Jenkins master and agents means that we bind the required resources to the purpose of executing builds. There are good chances that, these resources stay idle for the most part of the day, i.e. if you have high peak loads. Autoscaling of the infrastructure solves such a problem. Instead of reserving the resources proactively, the pipeline creates the Jenkins agents dynamically on a Kubernetes cluster during the execution. Once the agent completes the dedicated task, it is deleted and the resources are freed. Project \"Piper\" supports running the pipeline as well as individual steps in a Kubernetes Cluster. Please note that this feature is currently only experimental. To setup the Jenkins master in Kubernetes you can use helm. The documentation to install Jenkins using helm can be found here . To use the Jenkins image provided by project Piper, pass ppiper/jenkins-master as a value for the Master.Image command line argument while deploying Jenkins to Kubernetes. The successfully completed deployment consists of a Jenkins pod with port 80 and 50000 exposed for HTTP and internal JNLP traffic respectively. The deployment also creates two services each to listen to incoming HTTP traffic on port 80 and the internal JNLP traffic on port 50000. Please note that in this example setup, the SSL/TLS termination happens at the load balancer, hence all the traffic between a load balancer and the Jenkins pod is unencrypted. Project \"Piper\" needs an environment variable set in the Jenkins to run the workload in Kubernetes. In order to set the environment variable, navigate to \"Manage Jenkins\" > \"Configure System\" > \"Global Properties\". Add an environment variable ON_K8S and set the value to true: Afterwards, you should be able to run project \"Piper\" pipelines in Kubernetes.","title":"Kubernetes (Experimental)"},{"location":"infrastructure/overview/#custom-jenkins","text":"","title":"Custom Jenkins"},{"location":"infrastructure/overview/#on-your-own-custom-jenkins-setup","text":"If you use your own Jenkins installation, you need to care for the configuration that is specific to project \"Piper\". This option should only be considered if you know why you need it, otherwise using the Cx Server life-cycle management makes your life much easier. If you choose to go this path, follow the Custom Jenkins Setup guide . Note: This option is not supported for SAP Cloud SDK projects.","title":"On your own: Custom Jenkins Setup"},{"location":"pipelines/abapEnvironment/configuration/","text":"Configuration \u00b6 In this section, you can learn how to create a configuration in a (GitHub) repository to run an ABAP Environment Pipeline. This sepcific example will create a pipeline, which executes ATC checks after creating a new ABAP Environment system. In the end, the system will be deprovisioned. You can have a look at different pipeline configurations in our SAP-samples repository . 1. Prerequisites \u00b6 Configure your Jenkins Server according to the documentation . Create a git repository on a host reachable by the Jenkins server (e.g. GitHub.com). The pipeline will be configured in this repository. Create a GitHub User with read access. The entitlements for the ABAP Environment system are available in the SAP Cloud Platform global account and assigned to the subaccount. A Cloud Foundry Organization & Space with the allocated entitlements are available. A Cloud Foundry User & Password with the required authorization (\"Space Developer\") in the Organization and Space are available. User and Password were saved in the Jenkins Credentials Store. 2. Jenkinsfile \u00b6 Create a file named Jenkinsfile in your repository with the following content: @Library('piper-lib-os') _ abapEnvironmentPipeline script: this The annotation @Library('piper-lib-os') is a reference to the Jenkins Configuration, where you configured the Piper Library as a \"Global Pipeline Library\". If you want to avoid breaking changes we advise you to use a specific release of the Piper Library instead of the default master branch. This can be achieved by either adapting the configuration (see documentation ) or by specifying the release within the annotaion: @Library('piper-lib-os@v1.53.0') _ An Overview of the releases of the Piper Library can be found here . 3. Manifest for Service Creation \u00b6 Create a file manifest.yml . The pipeline will create a SAP Cloud Platform ABAP Environment System in the beginning (and delete it in the end). This file describes the ABAP instance, which will be created: --- create-services : - name : \"abapEnvironmentPipeline\" broker : \"abap\" plan : \"16_abap_64_db\" parameters : \"{ \\\"admin_email\\\" : \\\"user@example.com\\\", \\\"description\\\" : \\\"System for ABAP Pipeline\\\" }\" The example values are a suggestion. Please change them accordingly and don't forget to enter your own email address. Please be aware that creating a SAP Cloud ABAP Environment instance may incur costs. Please have a look at the step documentation for more details. 4. Configuration for the Communication \u00b6 The communication to the ABAP system is done using a Communication Arrangement. The Communication Arrangement is created during the pipeline via the command cf create-service-key . The configuration for the command needs to be stored in a JSON file. Create the file sap_com_0510.json in the repository with the following content: { \"scenario_id\" : \"SAP_COM_0510\" , \"type\" : \"basic\" } Please have a look at the step documentation for more details. 5. Configuration for ATC \u00b6 Create a file atcConfig.yml to store the configuration for the ATC run. In this file, you can specify which Packages or Software Components shall be checked. Please have a look at the step documentation for more details. Here is an example of the configuration: atcobjects: softwarecomponent: - name: \"/DMO/REPO\" Please have a look at the step documentation for more details. 6. Technical Pipeline Configuration \u00b6 Create a file .pipeline/config.yml where you store the configuration for the pipeline, e.g. apiEndpoints and credentialIds. The steps make use of the Credentials Store of the Jenkins Server. Here is an example of the configuration file: general: cfApiEndpoint: 'https://api.cf.eu10.hana.ondemand.com' cfOrg: 'your-cf-org' cfSpace: 'yourSpace' cfCredentialsId: 'cfAuthentification' cfServiceInstance: 'abapEnvironmentPipeline' cfServiceKeyName: 'jenkins_sap_com_0510' stages: Prepare System: cfServiceManifest: 'manifest.yml' cfServiceKeyConfig: 'sap_com_0510.json' Clone Repositories: repositoryNames: ['/DMO/REPO'] ATC: atcConfig: 'atcConfig.yml' steps: cloudFoundryDeleteService: cfDeleteServiceKeys: true If one stage of the pipeline is not configured in this yml file, the stage will not be executed during the pipeline run. If the stage Prepare System is configured, the system will be deprovisioned in the cleanup routine - although it is necessary to configure the step cloudFoundryDeleteService as above. Please make sure the parameters align with the values defined in the other configuration files, e.g. the service name in the manifest.yml needs to be the same as the value in general.cfServiceInstance . The values for cfApiEndpoint , cfOrg and cfSpace can be found in the respective overview pages in the SAP Cloud Platform Cockpit. The Cloud Foundry credentials, saved in the Jenkins credentials store with the ID cfCredentialsId , must refer to a user with the required authorizations (\"Space Developer\") for the Cloud Foundry Organization and Space. 7. Create a Jenkins Pipeline \u00b6 On your Jenkinsserver click on New Item to create a new pipeline. Provide a name and select the type Pipeline . On the creation screen for the pipeline, scroll to the section Pipeline and select Pipeline script from SCM . Provide the URL (and credentials - if required) of the repository, in which you configured the pipeline. Make sure the Script Path points to your Jenkinsfile - if you created the Jenkinsfile according to the documentation above, the default value should be correct. If you want to configure a build trigger, this can be done in the section of the same name. Here is one example: to run the pipeline every night, you can tick the box \"Run periodically\". In the visible input field, you can specify a shedule. Click on the questionsmark to read the documentation. The following example will result in the pipeline running every night between 3am and 4am. H H(3-4) * * * Extension \u00b6 You can extend each stage of this pipeline following the documentation . For example, this can be used to display ATC results utilizing the checkstyle format with the Warnings Next Generation Plugin ( GitHub Project ). To achieve this, create a file .pipeline/extensions/ATC.groovy with the following content: void call ( Map params ) { //access stage name echo \"Start - Extension for stage: ${params.stageName}\" //access config echo \"Current stage config: ${params.config}\" //execute original stage as defined in the template params . originalStage () recordIssues tools: [ checkStyle ( pattern: '**/ATCResults.xml' )], qualityGates: [[ threshold: 1 , type: 'TOTAL' , unstable: true ]] echo \"End - Extension for stage: ${params.stageName}\" } return this While tools: [checkStyle(pattern: '**/**/ATCResults.xml')] will display the ATC findings using the checkstyle format, qualityGates: [[threshold: 1, type: 'TOTAL', unstable: true]] will set the build result to UNSTABLE in case the ATC results contain at least one warning or error. Stage Names \u00b6 The stage name for the extension is usually the displayed name, e.g. ATC.groovy or Prepare System.groovy . One exception is the generated Post stage. While the displayed name is \"Declarative: Post Actions\", you can extend this stage using Post.groovy .","title":"Configuration"},{"location":"pipelines/abapEnvironment/configuration/#configuration","text":"In this section, you can learn how to create a configuration in a (GitHub) repository to run an ABAP Environment Pipeline. This sepcific example will create a pipeline, which executes ATC checks after creating a new ABAP Environment system. In the end, the system will be deprovisioned. You can have a look at different pipeline configurations in our SAP-samples repository .","title":"Configuration"},{"location":"pipelines/abapEnvironment/configuration/#1-prerequisites","text":"Configure your Jenkins Server according to the documentation . Create a git repository on a host reachable by the Jenkins server (e.g. GitHub.com). The pipeline will be configured in this repository. Create a GitHub User with read access. The entitlements for the ABAP Environment system are available in the SAP Cloud Platform global account and assigned to the subaccount. A Cloud Foundry Organization & Space with the allocated entitlements are available. A Cloud Foundry User & Password with the required authorization (\"Space Developer\") in the Organization and Space are available. User and Password were saved in the Jenkins Credentials Store.","title":"1. Prerequisites"},{"location":"pipelines/abapEnvironment/configuration/#2-jenkinsfile","text":"Create a file named Jenkinsfile in your repository with the following content: @Library('piper-lib-os') _ abapEnvironmentPipeline script: this The annotation @Library('piper-lib-os') is a reference to the Jenkins Configuration, where you configured the Piper Library as a \"Global Pipeline Library\". If you want to avoid breaking changes we advise you to use a specific release of the Piper Library instead of the default master branch. This can be achieved by either adapting the configuration (see documentation ) or by specifying the release within the annotaion: @Library('piper-lib-os@v1.53.0') _ An Overview of the releases of the Piper Library can be found here .","title":"2. Jenkinsfile"},{"location":"pipelines/abapEnvironment/configuration/#3-manifest-for-service-creation","text":"Create a file manifest.yml . The pipeline will create a SAP Cloud Platform ABAP Environment System in the beginning (and delete it in the end). This file describes the ABAP instance, which will be created: --- create-services : - name : \"abapEnvironmentPipeline\" broker : \"abap\" plan : \"16_abap_64_db\" parameters : \"{ \\\"admin_email\\\" : \\\"user@example.com\\\", \\\"description\\\" : \\\"System for ABAP Pipeline\\\" }\" The example values are a suggestion. Please change them accordingly and don't forget to enter your own email address. Please be aware that creating a SAP Cloud ABAP Environment instance may incur costs. Please have a look at the step documentation for more details.","title":"3. Manifest for Service Creation"},{"location":"pipelines/abapEnvironment/configuration/#4-configuration-for-the-communication","text":"The communication to the ABAP system is done using a Communication Arrangement. The Communication Arrangement is created during the pipeline via the command cf create-service-key . The configuration for the command needs to be stored in a JSON file. Create the file sap_com_0510.json in the repository with the following content: { \"scenario_id\" : \"SAP_COM_0510\" , \"type\" : \"basic\" } Please have a look at the step documentation for more details.","title":"4. Configuration for the Communication"},{"location":"pipelines/abapEnvironment/configuration/#5-configuration-for-atc","text":"Create a file atcConfig.yml to store the configuration for the ATC run. In this file, you can specify which Packages or Software Components shall be checked. Please have a look at the step documentation for more details. Here is an example of the configuration: atcobjects: softwarecomponent: - name: \"/DMO/REPO\" Please have a look at the step documentation for more details.","title":"5. Configuration for ATC"},{"location":"pipelines/abapEnvironment/configuration/#6-technical-pipeline-configuration","text":"Create a file .pipeline/config.yml where you store the configuration for the pipeline, e.g. apiEndpoints and credentialIds. The steps make use of the Credentials Store of the Jenkins Server. Here is an example of the configuration file: general: cfApiEndpoint: 'https://api.cf.eu10.hana.ondemand.com' cfOrg: 'your-cf-org' cfSpace: 'yourSpace' cfCredentialsId: 'cfAuthentification' cfServiceInstance: 'abapEnvironmentPipeline' cfServiceKeyName: 'jenkins_sap_com_0510' stages: Prepare System: cfServiceManifest: 'manifest.yml' cfServiceKeyConfig: 'sap_com_0510.json' Clone Repositories: repositoryNames: ['/DMO/REPO'] ATC: atcConfig: 'atcConfig.yml' steps: cloudFoundryDeleteService: cfDeleteServiceKeys: true If one stage of the pipeline is not configured in this yml file, the stage will not be executed during the pipeline run. If the stage Prepare System is configured, the system will be deprovisioned in the cleanup routine - although it is necessary to configure the step cloudFoundryDeleteService as above. Please make sure the parameters align with the values defined in the other configuration files, e.g. the service name in the manifest.yml needs to be the same as the value in general.cfServiceInstance . The values for cfApiEndpoint , cfOrg and cfSpace can be found in the respective overview pages in the SAP Cloud Platform Cockpit. The Cloud Foundry credentials, saved in the Jenkins credentials store with the ID cfCredentialsId , must refer to a user with the required authorizations (\"Space Developer\") for the Cloud Foundry Organization and Space.","title":"6. Technical Pipeline Configuration"},{"location":"pipelines/abapEnvironment/configuration/#7-create-a-jenkins-pipeline","text":"On your Jenkinsserver click on New Item to create a new pipeline. Provide a name and select the type Pipeline . On the creation screen for the pipeline, scroll to the section Pipeline and select Pipeline script from SCM . Provide the URL (and credentials - if required) of the repository, in which you configured the pipeline. Make sure the Script Path points to your Jenkinsfile - if you created the Jenkinsfile according to the documentation above, the default value should be correct. If you want to configure a build trigger, this can be done in the section of the same name. Here is one example: to run the pipeline every night, you can tick the box \"Run periodically\". In the visible input field, you can specify a shedule. Click on the questionsmark to read the documentation. The following example will result in the pipeline running every night between 3am and 4am. H H(3-4) * * *","title":"7. Create a Jenkins Pipeline"},{"location":"pipelines/abapEnvironment/configuration/#extension","text":"You can extend each stage of this pipeline following the documentation . For example, this can be used to display ATC results utilizing the checkstyle format with the Warnings Next Generation Plugin ( GitHub Project ). To achieve this, create a file .pipeline/extensions/ATC.groovy with the following content: void call ( Map params ) { //access stage name echo \"Start - Extension for stage: ${params.stageName}\" //access config echo \"Current stage config: ${params.config}\" //execute original stage as defined in the template params . originalStage () recordIssues tools: [ checkStyle ( pattern: '**/ATCResults.xml' )], qualityGates: [[ threshold: 1 , type: 'TOTAL' , unstable: true ]] echo \"End - Extension for stage: ${params.stageName}\" } return this While tools: [checkStyle(pattern: '**/**/ATCResults.xml')] will display the ATC findings using the checkstyle format, qualityGates: [[threshold: 1, type: 'TOTAL', unstable: true]] will set the build result to UNSTABLE in case the ATC results contain at least one warning or error.","title":"Extension"},{"location":"pipelines/abapEnvironment/configuration/#stage-names","text":"The stage name for the extension is usually the displayed name, e.g. ATC.groovy or Prepare System.groovy . One exception is the generated Post stage. While the displayed name is \"Declarative: Post Actions\", you can extend this stage using Post.groovy .","title":"Stage Names"},{"location":"pipelines/abapEnvironment/introduction/","text":"ABAP Environment Pipeline \u00b6 The goal of the ABAP Environment Pipeline is to enable Continuous Integration for the SAP Cloud Platform ABAP Environment, also known as Steampunk. In the current state, the pipeline enables you to pull Software Components to specifc systems and perform ATC checks. The following stages and steps are part of the pipeline: Stage Steps Init - Prepare System cloudFoundryCreateService , cloudFoundryCreateServiceKey Clone Repositories abapEnvironmentPullGitRepo ATC abapEnvironmentRunATCCheck Post cloudFoundryDeleteService Below you can find more details about the different stages. Here you can find more information about how to configure your pipeline. Init \u00b6 In this stage, the pipeline is initialized. Nothing to see here. Prepare System \u00b6 In this stage, the ABAP Environment system is created. This is done with the cloudFoundryCreateService step. Limitation As some parts of the system configuration is done after the Cloud Foundry instance was created, the following workaround is currently necessary: An authorized user has to manually confirm that the ABAP Environment system is ready. This is the case when the email has been received by the initially provided administrator (as configured in the file manifest.yml - as described in configuration ). Redefining the \"Prepare System\" stage via an extension could circumvent the manual confirmation and replace it with an optimistic wait statement - this, however, may lead to a failing pipeline in case the system is not ready in time. After the confirmation, the Communication Arrangement SAP_COM_0510 (SAP Cloud Platform ABAP Environment - Software Component Test Integration) is created using the step cloudFoundryCreateServiceKey. With the creation of the Communication Arrangement, a User and Password is created on the ABAP Environment system for the APIs that are used in the following stages. Clone Repositories \u00b6 In this stage, the Software Components / Git repositories are pulled to the ABAP Environment system using the step abapEnvironmentPullGitRepo. The step can receive a list of Software Components / repositories and pulls them successively. ATC \u00b6 In this stage, ATC checks can be executed using abapEnvironmentRunATCCheck. The step can receive Software Components or packages (configured in YML file - as described in configuration ). The results are returned in the checkstlye format. With the use of a pipeline extension, quality gates can be configured (see step documentation or the \"Extensions\" section in the configuration ). Post \u00b6 At the end of every pipeline (successful or unsuccessful), the system is deprovisioned using the step cloudFoundryDeleteService.","title":"Introduction"},{"location":"pipelines/abapEnvironment/introduction/#abap-environment-pipeline","text":"The goal of the ABAP Environment Pipeline is to enable Continuous Integration for the SAP Cloud Platform ABAP Environment, also known as Steampunk. In the current state, the pipeline enables you to pull Software Components to specifc systems and perform ATC checks. The following stages and steps are part of the pipeline: Stage Steps Init - Prepare System cloudFoundryCreateService , cloudFoundryCreateServiceKey Clone Repositories abapEnvironmentPullGitRepo ATC abapEnvironmentRunATCCheck Post cloudFoundryDeleteService Below you can find more details about the different stages. Here you can find more information about how to configure your pipeline.","title":"ABAP Environment Pipeline"},{"location":"pipelines/abapEnvironment/introduction/#init","text":"In this stage, the pipeline is initialized. Nothing to see here.","title":"Init"},{"location":"pipelines/abapEnvironment/introduction/#prepare-system","text":"In this stage, the ABAP Environment system is created. This is done with the cloudFoundryCreateService step. Limitation As some parts of the system configuration is done after the Cloud Foundry instance was created, the following workaround is currently necessary: An authorized user has to manually confirm that the ABAP Environment system is ready. This is the case when the email has been received by the initially provided administrator (as configured in the file manifest.yml - as described in configuration ). Redefining the \"Prepare System\" stage via an extension could circumvent the manual confirmation and replace it with an optimistic wait statement - this, however, may lead to a failing pipeline in case the system is not ready in time. After the confirmation, the Communication Arrangement SAP_COM_0510 (SAP Cloud Platform ABAP Environment - Software Component Test Integration) is created using the step cloudFoundryCreateServiceKey. With the creation of the Communication Arrangement, a User and Password is created on the ABAP Environment system for the APIs that are used in the following stages.","title":"Prepare System"},{"location":"pipelines/abapEnvironment/introduction/#clone-repositories","text":"In this stage, the Software Components / Git repositories are pulled to the ABAP Environment system using the step abapEnvironmentPullGitRepo. The step can receive a list of Software Components / repositories and pulls them successively.","title":"Clone Repositories"},{"location":"pipelines/abapEnvironment/introduction/#atc","text":"In this stage, ATC checks can be executed using abapEnvironmentRunATCCheck. The step can receive Software Components or packages (configured in YML file - as described in configuration ). The results are returned in the checkstlye format. With the use of a pipeline extension, quality gates can be configured (see step documentation or the \"Extensions\" section in the configuration ).","title":"ATC"},{"location":"pipelines/abapEnvironment/introduction/#post","text":"At the end of every pipeline (successful or unsuccessful), the system is deprovisioned using the step cloudFoundryDeleteService.","title":"Post"},{"location":"pipelines/cloud-sdk/build-tools/","text":"Build Tools \u00b6 The SAP Cloud SDK supports multiple programming languages (Java and JavaScript) and can be used in the SAP Cloud Application Programming Model. For each of these variants project templates exists (as referenced in the project's main Readme file). These templates introduce standard tooling, such as build tools, and a standard structure. The SAP Cloud SDK Continuous Delivery Toolkit expects that the project follows this structure and depends on the build tools introduced by these templates. The supported build tools are: Maven for Java projects npm for JavaScript projects MTA for Multi-Target Application Model projects MTA itself makes use of other build tools, such as Maven and npm depending on what types of modules your application has. Note: The npm pipeline variant is in an early state. Some interfaces might change. We recommend consuming a fixed released version as described in the project Readme . Feature Matrix \u00b6 Support for the different features of the pipeline may vary in each variant of the SDK pipeline build tool. The following table gives an overview over the features available per build tool. Feature Maven npm MTA Maven MTA npm Automatic Versioning x x x x Build x x x x Backend Integration Tests x x x x Frontend Integration Tests x x x x Backend Unit Tests x x x x Frontend Unit Tests x x x x NPM Dependency Audit x x x x Linting x x x Static Code Checks x x End-To-End Tests x x x Performance Tests x x Resilience Checks x x S4HANA Public APIs x x Code Coverage Checks x x x x Checkmarx Integration x x Fortify Integration x x SourceClear Integration x Whitesource Integration x x x x Deployment to Nexus x x x Zero Downtime Deployment x x x\u00b9 x\u00b9 Download Cache x x x x \u00b9 MTA projects can only be deployed to the Cloud Foundry Environment Java/Node.js runtime versions \u00b6 Runtime versions used in builds are determined by Docker images. For Java, the default is still (as of August 2020) version 8. For more details, please check the documentation of the SAP Cloud SDK for Java . In case you need to use a specific Java version to build your application, you may do so by setting another Docker image in your .pipeline/config.yml file. See documentation of the pipeline configuration and look for the dockerImage key on where this option applies. In most cases, it should be suffcient to configure an image for the mavenExecute step like so: steps : mavenExecute : dockerImage : 'maven:3.6.3-jdk-11' Projects Requirements \u00b6 Each variant of the pipeline has different requirements regarding the project structure, location of reports and tooling. Stages not listed here do not have a special requirement. In any case, please also consult the documentation of the pipeline configuration , as some stages have to be activated by providing configuration values. Build Tool Independent Requirements \u00b6 In order to run in the pipeline your project has to include the following two files in the root folder: Jenkinsfile and .pipeline/config.yml . You can copy both files from this github repository . There are two variants of the configuration file. Please pick the corresponding version for your deployment target and rename it properly. Frontend Unit Tests \u00b6 The command npm run ci-frontend-unit-test will be executed in this stage. Furthermore, the test results have to be stored in the folder ./s4hana_pipeline/reports/frontend-unit in the root directory. The required format of the test result report is the JUnit format as an .xml file. The code coverage report can be published as html report and in the cobertura format. The cobertura report as html report has to be stored in the directory ./s4hana_pipeline/reports/coverage-reports/frontend-unit/report-html/ut/ as an index.html file. These coverage reports will then be published in Jenkins. Furthermore, if configured in the .pipeline/config.yml , the pipeline ensures the configured level of code coverage. In MTA projects Frontend Unit Tests are executed for every module of type html5 . Frontend Integration Tests \u00b6 The command npm run ci-it-frontend will be executed in this stage and has to be defined in the package.json in the root. In this stage, the frontend should be tested end-to-end without the backend. Therefore, even a browser is started to simulate user interactions. Furthermore, the test results have to be stored in the folder ./s4hana_pipeline/reports/frontend-integration in the root directory of the project. The required format of the test result report is the JUnit format as an .xml file. The user is responsible to use a proper reporter for generating the results. It is recommended to use the same tools as in the package.json of this example project . Backend Unit Tests \u00b6 Maven \u00b6 Maven unit-tests are executed as part of the mavenBuild step. They are supposed to be placed inside of application/src/test . Java MTA modules \u00b6 We run the command mvn test in each Java MTA module. Npm and Nodejs MTA modules \u00b6 For each package.json where the script ci-backend-unit-test is defined the command npm run ci-backend-unit-test will be executed in this stage. Furthermore, the test results have to be stored in the folder ./s4hana_pipeline/reports/backend-unit/ in the root directory of the project. The required format of the test result report is the JUnit format as an .xml file. For the code coverage the results have to be stored in the folder ./s4hana_pipeline/reports/coverage-reports/backend-unit/ in the cobertura format as an xml file. The user is responsible to use a proper reporter for generating the results. We recommend the tools used in the package.json of this example project . If you have multiple npm packages with unit tests the names of the report files must have unique names. Backend Integration Tests \u00b6 Maven and Java MTA modules \u00b6 If there is a maven module called integration-tests we run maven test in this module. Npm and Nodejs MTA modules \u00b6 For each package.json where the script ci-it-backend is defined the command npm run ci-it-backend will be executed in this stage. Furthermore, the test results have to be stored in the folder ./s4hana_pipeline/reports/backend-integration in the root directory of the project. The required format of the test result report is the JUnit format as an .xml file. For the code coverage the results have to be stored in the folder ./s4hana_pipeline/reports/coverage-reports/backend-integration/ in the cobertura format as an xml file. The user is responsible to use a proper reporter for generating the results. We recommend the tools used in the package.json of this example project . If you have multiple npm packages with unit tests the names of the report files must have unique names. Lint \u00b6 For each package.json where the script ci-lint is defined the command npm run ci-lint will be executed in this stage. The required format of the linting results is the checkstyle format as an xml file. The linting results have to be stored in a file named *cilint.xml , which may reside in any directory of the project. The linting results will then be published in Jenkins. If no script ci-lint is defined, the pipeline will check SAPUI5 components, if present, for the SAPUI5 recommended best practices. If none of the scenarios described apply and Javascript or Typescript files are present in the project, the pipeline will automatically execute ESLint. If no ESLint configuration files are present in the project directory, a general purpose configuration is used to lint all Javascript and/or Typescript files of the project. If, on the other hand, ESLint configuration files exist in the project, they will be used to lint Javascript files in the project. The execution happens according to ESLint's default execution behavior, i.e., for each JS file the ESLint config in that directory or one of the parent directories will be used to lint the file. Note, in this case only those files will be linted, for which an ESLint config exists. More details on the execution behavior of ESLint and the usage of configuration files can be found in the related documentation . Note, if it is necessary to disable the default linting behavior, it is possible to, e.g., define a script \"ci-lint\" : \"exit 0\" in your package.json . We recommend the use of a custom defined ci-lint script in your package.json to address project specific linting requirements. End-to-End Tests \u00b6 This stage is only executed if you configured it in the file .pipeline/config.yml . The command npm run ci-e2e will be executed in this stage. The url which is defined as appUrl in the file .pipeline/config.yml will be passed as argument named launchUrl to the tests. This can be reproduced locally by executing: npm run ci-e2e -- --launchUrl=https://path/to/your/running/application The credentials also defined in the file .pipeline/config.yml will be available during the test execution as environment variables named e2e_username and e2e_password . The test results have to be stored in the folder ./s4hana_pipeline/reports/e2e in the root directory. The required format of the test result report is the Cucumber format as an .json file, or the JUnit format as an xml file. Also, screenshots can be stored in this folder. The screenshots and reports will then be published in Jenkins. The user is responsible to use a proper reporter for generating the results. Performance Tests \u00b6 This stage is only executed if you configured it in the file .pipeline/config.yml . Performance tests can be executed using JMeter or Gatling . If only JMeter is used as a performance tests tool then test plans can be placed in a default location, which is the directory {project_root}/performance-tests . However, if JMeter is used along with Gatling, then JMeter test plans should be kept in a subdirectory under a directory performance-tests for example ./performance-tests/JMeter/ . The gatling test project including the pom.xml should be placed in the directory {project_root}/performance-tests . Afterwards, Gatling has to be enable in the configuration. Deployments \u00b6 For all deployments to Cloud Foundry (excluding MTA) there has to be a file called manifest.yml . This file may only contain exactly one application. Note: For JavaScript projects the path of the application should point to the folder deployment . Java / Maven \u00b6 For Maven the pipeline expects the following structure. The project should have three maven modules named: application integration-tests The module application should contain the application code and unit tests. The module integration-tests should contain integration tests. Furthermore, the test modules have to include the following dependency: <dependency> <groupId> com.sap.cloud.s4hana.quality </groupId> <artifactId> listeners-all </artifactId> <scope> test </scope> </dependency> JavaScript / npm \u00b6 The project has to use npm and include a package.json in the root directory. In the pipeline stages, specific scripts in the package.json are called to build the project or run tests. Furthermore, the pipeline expects reports, such as test results, to be written into certain folders. These stage specific requirements are documented below. Build \u00b6 By default npm ci will be executed. After npm ci the command npm run ci-build will be executed. This script can be used to, for example, compile Typescript resources or webpack the frontend. In the build stage, also development dependencies are installed and tests should also be compiled. Afterwards the command npm run ci-package will be executed. This step should prepare the deployment by copying all deployment relevant files into the folder deployment located in the root of the project. This folder should not contain any non-production-related resources, such as tests or development dependencies. This directory has to be defined as path in the manifest.yml . Note: This steps runs isolated from the steps before. Thus, e.g. modifying node_modules with npm prune --production will not have an effect for later stages, such as the test execution. SAP Cloud Application Programming Model / MTA \u00b6 The project structure follows the standard structure for projects created via the SAP Cloud Platform Business Application SAP Web IDE Template with some constraints. Please leave the basic structure of the generated project intact. Make sure to check the Include support for continuous delivery pipeline of SAP Cloud SDK checkbox, which will automatically add the required files for continous delivery in your project. If you already created your project without this option, you'll need to copy and paste two files into the root directory of your project, and commit them to your git repository: Jenkinsfile .pipeline/config.yml Note: The file must be named .pipeline/config.yml , despite the different name of the file template Further constrains on the project structure (this is all correct in projects generated from the SAP Cloud Platform Business Application SAP Web IDE Template): On the project root level, a pom.xml file is required. Java services are Maven projects which include the application- and the unit-test code. A service is typically called srv , but the name can be chosen freely. An integration-test module must exist on the root level. This module is where integration between the services can be tested. In summary, the project structure should look like this: . \u251c\u2500\u2500 Jenkinsfile \u251c\u2500\u2500 .pipeline \u2502 \u2514\u2500\u2500 config.yml \u251c\u2500\u2500 app // web application, not required \u251c\u2500\u2500 db // only if database module exists \u251c\u2500\u2500 integration-tests \u2502 \u251c\u2500\u2500 pom.xml \u2502 \u2514\u2500\u2500 src \u2502 \u2514\u2500\u2500 test \u251c\u2500\u2500 mta.yaml \u251c\u2500\u2500 package.json \u251c\u2500\u2500 pom.xml \u2514\u2500\u2500 srv \u251c\u2500\u2500 pom.xml \u2514\u2500\u2500 src \u251c\u2500\u2500 main \u2514\u2500\u2500 test // Unit-Tests for this service","title":"Build Tools"},{"location":"pipelines/cloud-sdk/build-tools/#build-tools","text":"The SAP Cloud SDK supports multiple programming languages (Java and JavaScript) and can be used in the SAP Cloud Application Programming Model. For each of these variants project templates exists (as referenced in the project's main Readme file). These templates introduce standard tooling, such as build tools, and a standard structure. The SAP Cloud SDK Continuous Delivery Toolkit expects that the project follows this structure and depends on the build tools introduced by these templates. The supported build tools are: Maven for Java projects npm for JavaScript projects MTA for Multi-Target Application Model projects MTA itself makes use of other build tools, such as Maven and npm depending on what types of modules your application has. Note: The npm pipeline variant is in an early state. Some interfaces might change. We recommend consuming a fixed released version as described in the project Readme .","title":"Build Tools"},{"location":"pipelines/cloud-sdk/build-tools/#feature-matrix","text":"Support for the different features of the pipeline may vary in each variant of the SDK pipeline build tool. The following table gives an overview over the features available per build tool. Feature Maven npm MTA Maven MTA npm Automatic Versioning x x x x Build x x x x Backend Integration Tests x x x x Frontend Integration Tests x x x x Backend Unit Tests x x x x Frontend Unit Tests x x x x NPM Dependency Audit x x x x Linting x x x Static Code Checks x x End-To-End Tests x x x Performance Tests x x Resilience Checks x x S4HANA Public APIs x x Code Coverage Checks x x x x Checkmarx Integration x x Fortify Integration x x SourceClear Integration x Whitesource Integration x x x x Deployment to Nexus x x x Zero Downtime Deployment x x x\u00b9 x\u00b9 Download Cache x x x x \u00b9 MTA projects can only be deployed to the Cloud Foundry Environment","title":"Feature Matrix"},{"location":"pipelines/cloud-sdk/build-tools/#javanodejs-runtime-versions","text":"Runtime versions used in builds are determined by Docker images. For Java, the default is still (as of August 2020) version 8. For more details, please check the documentation of the SAP Cloud SDK for Java . In case you need to use a specific Java version to build your application, you may do so by setting another Docker image in your .pipeline/config.yml file. See documentation of the pipeline configuration and look for the dockerImage key on where this option applies. In most cases, it should be suffcient to configure an image for the mavenExecute step like so: steps : mavenExecute : dockerImage : 'maven:3.6.3-jdk-11'","title":"Java/Node.js runtime versions"},{"location":"pipelines/cloud-sdk/build-tools/#projects-requirements","text":"Each variant of the pipeline has different requirements regarding the project structure, location of reports and tooling. Stages not listed here do not have a special requirement. In any case, please also consult the documentation of the pipeline configuration , as some stages have to be activated by providing configuration values.","title":"Projects Requirements"},{"location":"pipelines/cloud-sdk/build-tools/#build-tool-independent-requirements","text":"In order to run in the pipeline your project has to include the following two files in the root folder: Jenkinsfile and .pipeline/config.yml . You can copy both files from this github repository . There are two variants of the configuration file. Please pick the corresponding version for your deployment target and rename it properly.","title":"Build Tool Independent Requirements"},{"location":"pipelines/cloud-sdk/build-tools/#frontend-unit-tests","text":"The command npm run ci-frontend-unit-test will be executed in this stage. Furthermore, the test results have to be stored in the folder ./s4hana_pipeline/reports/frontend-unit in the root directory. The required format of the test result report is the JUnit format as an .xml file. The code coverage report can be published as html report and in the cobertura format. The cobertura report as html report has to be stored in the directory ./s4hana_pipeline/reports/coverage-reports/frontend-unit/report-html/ut/ as an index.html file. These coverage reports will then be published in Jenkins. Furthermore, if configured in the .pipeline/config.yml , the pipeline ensures the configured level of code coverage. In MTA projects Frontend Unit Tests are executed for every module of type html5 .","title":"Frontend Unit Tests"},{"location":"pipelines/cloud-sdk/build-tools/#frontend-integration-tests","text":"The command npm run ci-it-frontend will be executed in this stage and has to be defined in the package.json in the root. In this stage, the frontend should be tested end-to-end without the backend. Therefore, even a browser is started to simulate user interactions. Furthermore, the test results have to be stored in the folder ./s4hana_pipeline/reports/frontend-integration in the root directory of the project. The required format of the test result report is the JUnit format as an .xml file. The user is responsible to use a proper reporter for generating the results. It is recommended to use the same tools as in the package.json of this example project .","title":"Frontend Integration Tests"},{"location":"pipelines/cloud-sdk/build-tools/#backend-unit-tests","text":"","title":"Backend Unit Tests"},{"location":"pipelines/cloud-sdk/build-tools/#maven","text":"Maven unit-tests are executed as part of the mavenBuild step. They are supposed to be placed inside of application/src/test .","title":"Maven"},{"location":"pipelines/cloud-sdk/build-tools/#java-mta-modules","text":"We run the command mvn test in each Java MTA module.","title":"Java MTA modules"},{"location":"pipelines/cloud-sdk/build-tools/#npm-and-nodejs-mta-modules","text":"For each package.json where the script ci-backend-unit-test is defined the command npm run ci-backend-unit-test will be executed in this stage. Furthermore, the test results have to be stored in the folder ./s4hana_pipeline/reports/backend-unit/ in the root directory of the project. The required format of the test result report is the JUnit format as an .xml file. For the code coverage the results have to be stored in the folder ./s4hana_pipeline/reports/coverage-reports/backend-unit/ in the cobertura format as an xml file. The user is responsible to use a proper reporter for generating the results. We recommend the tools used in the package.json of this example project . If you have multiple npm packages with unit tests the names of the report files must have unique names.","title":"Npm and Nodejs MTA modules"},{"location":"pipelines/cloud-sdk/build-tools/#backend-integration-tests","text":"","title":"Backend Integration Tests"},{"location":"pipelines/cloud-sdk/build-tools/#maven-and-java-mta-modules","text":"If there is a maven module called integration-tests we run maven test in this module.","title":"Maven and Java MTA modules"},{"location":"pipelines/cloud-sdk/build-tools/#npm-and-nodejs-mta-modules_1","text":"For each package.json where the script ci-it-backend is defined the command npm run ci-it-backend will be executed in this stage. Furthermore, the test results have to be stored in the folder ./s4hana_pipeline/reports/backend-integration in the root directory of the project. The required format of the test result report is the JUnit format as an .xml file. For the code coverage the results have to be stored in the folder ./s4hana_pipeline/reports/coverage-reports/backend-integration/ in the cobertura format as an xml file. The user is responsible to use a proper reporter for generating the results. We recommend the tools used in the package.json of this example project . If you have multiple npm packages with unit tests the names of the report files must have unique names.","title":"Npm and Nodejs MTA modules"},{"location":"pipelines/cloud-sdk/build-tools/#lint","text":"For each package.json where the script ci-lint is defined the command npm run ci-lint will be executed in this stage. The required format of the linting results is the checkstyle format as an xml file. The linting results have to be stored in a file named *cilint.xml , which may reside in any directory of the project. The linting results will then be published in Jenkins. If no script ci-lint is defined, the pipeline will check SAPUI5 components, if present, for the SAPUI5 recommended best practices. If none of the scenarios described apply and Javascript or Typescript files are present in the project, the pipeline will automatically execute ESLint. If no ESLint configuration files are present in the project directory, a general purpose configuration is used to lint all Javascript and/or Typescript files of the project. If, on the other hand, ESLint configuration files exist in the project, they will be used to lint Javascript files in the project. The execution happens according to ESLint's default execution behavior, i.e., for each JS file the ESLint config in that directory or one of the parent directories will be used to lint the file. Note, in this case only those files will be linted, for which an ESLint config exists. More details on the execution behavior of ESLint and the usage of configuration files can be found in the related documentation . Note, if it is necessary to disable the default linting behavior, it is possible to, e.g., define a script \"ci-lint\" : \"exit 0\" in your package.json . We recommend the use of a custom defined ci-lint script in your package.json to address project specific linting requirements.","title":"Lint"},{"location":"pipelines/cloud-sdk/build-tools/#end-to-end-tests","text":"This stage is only executed if you configured it in the file .pipeline/config.yml . The command npm run ci-e2e will be executed in this stage. The url which is defined as appUrl in the file .pipeline/config.yml will be passed as argument named launchUrl to the tests. This can be reproduced locally by executing: npm run ci-e2e -- --launchUrl=https://path/to/your/running/application The credentials also defined in the file .pipeline/config.yml will be available during the test execution as environment variables named e2e_username and e2e_password . The test results have to be stored in the folder ./s4hana_pipeline/reports/e2e in the root directory. The required format of the test result report is the Cucumber format as an .json file, or the JUnit format as an xml file. Also, screenshots can be stored in this folder. The screenshots and reports will then be published in Jenkins. The user is responsible to use a proper reporter for generating the results.","title":"End-to-End Tests"},{"location":"pipelines/cloud-sdk/build-tools/#performance-tests","text":"This stage is only executed if you configured it in the file .pipeline/config.yml . Performance tests can be executed using JMeter or Gatling . If only JMeter is used as a performance tests tool then test plans can be placed in a default location, which is the directory {project_root}/performance-tests . However, if JMeter is used along with Gatling, then JMeter test plans should be kept in a subdirectory under a directory performance-tests for example ./performance-tests/JMeter/ . The gatling test project including the pom.xml should be placed in the directory {project_root}/performance-tests . Afterwards, Gatling has to be enable in the configuration.","title":"Performance Tests"},{"location":"pipelines/cloud-sdk/build-tools/#deployments","text":"For all deployments to Cloud Foundry (excluding MTA) there has to be a file called manifest.yml . This file may only contain exactly one application. Note: For JavaScript projects the path of the application should point to the folder deployment .","title":"Deployments"},{"location":"pipelines/cloud-sdk/build-tools/#java-maven","text":"For Maven the pipeline expects the following structure. The project should have three maven modules named: application integration-tests The module application should contain the application code and unit tests. The module integration-tests should contain integration tests. Furthermore, the test modules have to include the following dependency: <dependency> <groupId> com.sap.cloud.s4hana.quality </groupId> <artifactId> listeners-all </artifactId> <scope> test </scope> </dependency>","title":"Java / Maven"},{"location":"pipelines/cloud-sdk/build-tools/#javascript-npm","text":"The project has to use npm and include a package.json in the root directory. In the pipeline stages, specific scripts in the package.json are called to build the project or run tests. Furthermore, the pipeline expects reports, such as test results, to be written into certain folders. These stage specific requirements are documented below.","title":"JavaScript / npm"},{"location":"pipelines/cloud-sdk/build-tools/#build","text":"By default npm ci will be executed. After npm ci the command npm run ci-build will be executed. This script can be used to, for example, compile Typescript resources or webpack the frontend. In the build stage, also development dependencies are installed and tests should also be compiled. Afterwards the command npm run ci-package will be executed. This step should prepare the deployment by copying all deployment relevant files into the folder deployment located in the root of the project. This folder should not contain any non-production-related resources, such as tests or development dependencies. This directory has to be defined as path in the manifest.yml . Note: This steps runs isolated from the steps before. Thus, e.g. modifying node_modules with npm prune --production will not have an effect for later stages, such as the test execution.","title":"Build"},{"location":"pipelines/cloud-sdk/build-tools/#sap-cloud-application-programming-model-mta","text":"The project structure follows the standard structure for projects created via the SAP Cloud Platform Business Application SAP Web IDE Template with some constraints. Please leave the basic structure of the generated project intact. Make sure to check the Include support for continuous delivery pipeline of SAP Cloud SDK checkbox, which will automatically add the required files for continous delivery in your project. If you already created your project without this option, you'll need to copy and paste two files into the root directory of your project, and commit them to your git repository: Jenkinsfile .pipeline/config.yml Note: The file must be named .pipeline/config.yml , despite the different name of the file template Further constrains on the project structure (this is all correct in projects generated from the SAP Cloud Platform Business Application SAP Web IDE Template): On the project root level, a pom.xml file is required. Java services are Maven projects which include the application- and the unit-test code. A service is typically called srv , but the name can be chosen freely. An integration-test module must exist on the root level. This module is where integration between the services can be tested. In summary, the project structure should look like this: . \u251c\u2500\u2500 Jenkinsfile \u251c\u2500\u2500 .pipeline \u2502 \u2514\u2500\u2500 config.yml \u251c\u2500\u2500 app // web application, not required \u251c\u2500\u2500 db // only if database module exists \u251c\u2500\u2500 integration-tests \u2502 \u251c\u2500\u2500 pom.xml \u2502 \u2514\u2500\u2500 src \u2502 \u2514\u2500\u2500 test \u251c\u2500\u2500 mta.yaml \u251c\u2500\u2500 package.json \u251c\u2500\u2500 pom.xml \u2514\u2500\u2500 srv \u251c\u2500\u2500 pom.xml \u2514\u2500\u2500 src \u251c\u2500\u2500 main \u2514\u2500\u2500 test // Unit-Tests for this service","title":"SAP Cloud Application Programming Model / MTA"},{"location":"pipelines/cloud-sdk/cloud-qualities/","text":"Checked Qualities in the SAP Cloud SDK Pipeline \u00b6 The goal of the SAP Cloud SDK Pipeline is to help you build high quality applications which run on SAP Cloud Platform. To achieve this, the SAP Cloud SDK Pipeline checks qualities when building your application. This document summarizes the qualities that are checked by the SAP Cloud SDK Pipeline. SAP Cloud SDK Specific Checks \u00b6 Required Dependencies \u00b6 For the SAP Cloud SDK specific checks to work, a few dependencies are required in unit and integration tests. The Cloud SDK pipeline will check if the odata-querylistener, rfc-querylistener, and the httpclient-listener dependencies are in the unit- and integration tests maven modules. If one of those dependencies is missing the pipeline will add the listeners-all dependency to the pom on the fly before executing the respective tests. That means for a user of the SDK it is not necessary to add those dependencies manually, but it can be beneficial to speed up the runtime of the pipeline since the pom.xml won't be changed if the dependencies are available. Only Depend on Official API \u00b6 This quality checks for usage of unofficial RFC and OData services. Only official API from the SAP API Business Hub should be used, since unofficial API don't provide any stable interfaces. A list of official API can be found in this blog post . Resilient Network Calls \u00b6 When building extension applications on SAP Cloud Platform, you always deal with a distributed system. There is at least two applications in this scenario: Your extension application, and SAP S/4HANA. In distributed systems, you may not assume that the network is reliable. To mitigate unreliable networks, a pattern called circuit breaker is commonly used. The idea is that you define a fallback action in case the network fails too often in a short time span. The fallback might use cached data, or default values, depending on what works best in your problem domain. To implement this pattern, the SAP Cloud SDK integrates with the Hystrix library. The version 3 of the SAP Cloud SDK integrates with the resilience4j library. This quality check tests, that your remote calls are wrapped in a Hystrix command (v2) or in a ResilienceDecorator (v3). The build will fail with a error message like Your project accesses downstream systems in a non-resilient manner if this is not the case. More information on building resilient applications is available in this blog post . Functional Tests \u00b6 Ensuring the functional correctness of an application requires automated tests, which are part of the application code. Those qualities depend on the test code written by the application developer. Unit Tests \u00b6 The purpose of unit tests is to verify the correctness of a single unit in isolation. Other components than the unit under test may be mocked for testing purposes. Place your unit tests in the appropriate Maven module ( unit-tests ) in order to make the pipeline run them automatically. Integration Tests \u00b6 Integration tests work on a higher level compared to unit tests. They should ensure that independently tested units work together as they need to. In the context of extension applications on SAP Cloud Platform, this means to ensure interoperability of your application with S/4HANA and interoperability between your application's backend and frontend component . Place your integration tests in the appropriate Maven module ( integration-tests ) in order to make the pipeline run them automatically. For more detailed description, refer to this blog post . End-to-End Tests \u00b6 End-to-end tests use your application, like a human user would by clicking buttons, entering text into forms and waiting for the result. Place your end-to-end tests in the e2e-tests directory and ensure the ci-e2e script in package.json runs the right command. The output folder for the reports needs to be s4hana_pipeline/reports/e2e . Code Coverage \u00b6 Code coverage refers to how much of your application code is tested. The build fails, if the test coverage of your code drops below a certain threshold. To fix such a build failure, check which parts of your code are not tested yet and write missing tests. The code coverage is tested using JaCoCo Java Code Coverage Library . Non-Functional Tests \u00b6 Performance \u00b6 Performance relates to how quickly your application reacts under heavy load. For implementing performance tests, you can chose between to Open Source tools: JMeter and Gatling . If you're not familiar with both of them, we recommend using Gatling. More information on testing the performance of your application is available in this blog post . Static Code Checks \u00b6 Static code checks look for potential issues in code without running the program. The SAP Cloud SDK Pipeline includes commonly used static checks using both PMD and SpotBugs . In addition to the default checks of those tools, it adds the following SAP Cloud SDK specific checks: To make post-mortem debugging possible Log the exception in the catch block or in a called handling method or reference it in a new thrown exception Reference the exception when logging inside a catch block In order to allow a smooth transition from Neo to Cloud Foundry, you should use the platform independent abstractions provided by the SAP S4HANA Cloud SDK Lint \u00b6 The pipeline automatically checks JavaScript and XML files in SAPUI5 components for the SAPUI5 recommended best practices. Custom linters can be implemented by development teams, if desired. This allows to enforce a common coding style within a team of developers, thus making it easier to focus on the application code, rather then discussing minor style issues. Third-Party Tools \u00b6 The SAP Cloud SDK Pipeline also integrates with commercial third party code analyzer services, if you wish to use them. Currently, Checkmarx , WhiteSource , and SourceClear are available. For those scans to be enabled, they need to be configured in the pipeline configuration file .","title":"Cloud Qualities"},{"location":"pipelines/cloud-sdk/cloud-qualities/#checked-qualities-in-the-sap-cloud-sdk-pipeline","text":"The goal of the SAP Cloud SDK Pipeline is to help you build high quality applications which run on SAP Cloud Platform. To achieve this, the SAP Cloud SDK Pipeline checks qualities when building your application. This document summarizes the qualities that are checked by the SAP Cloud SDK Pipeline.","title":"Checked Qualities in the SAP Cloud SDK Pipeline"},{"location":"pipelines/cloud-sdk/cloud-qualities/#sap-cloud-sdk-specific-checks","text":"","title":"SAP Cloud SDK Specific Checks"},{"location":"pipelines/cloud-sdk/cloud-qualities/#required-dependencies","text":"For the SAP Cloud SDK specific checks to work, a few dependencies are required in unit and integration tests. The Cloud SDK pipeline will check if the odata-querylistener, rfc-querylistener, and the httpclient-listener dependencies are in the unit- and integration tests maven modules. If one of those dependencies is missing the pipeline will add the listeners-all dependency to the pom on the fly before executing the respective tests. That means for a user of the SDK it is not necessary to add those dependencies manually, but it can be beneficial to speed up the runtime of the pipeline since the pom.xml won't be changed if the dependencies are available.","title":"Required Dependencies"},{"location":"pipelines/cloud-sdk/cloud-qualities/#only-depend-on-official-api","text":"This quality checks for usage of unofficial RFC and OData services. Only official API from the SAP API Business Hub should be used, since unofficial API don't provide any stable interfaces. A list of official API can be found in this blog post .","title":"Only Depend on Official API"},{"location":"pipelines/cloud-sdk/cloud-qualities/#resilient-network-calls","text":"When building extension applications on SAP Cloud Platform, you always deal with a distributed system. There is at least two applications in this scenario: Your extension application, and SAP S/4HANA. In distributed systems, you may not assume that the network is reliable. To mitigate unreliable networks, a pattern called circuit breaker is commonly used. The idea is that you define a fallback action in case the network fails too often in a short time span. The fallback might use cached data, or default values, depending on what works best in your problem domain. To implement this pattern, the SAP Cloud SDK integrates with the Hystrix library. The version 3 of the SAP Cloud SDK integrates with the resilience4j library. This quality check tests, that your remote calls are wrapped in a Hystrix command (v2) or in a ResilienceDecorator (v3). The build will fail with a error message like Your project accesses downstream systems in a non-resilient manner if this is not the case. More information on building resilient applications is available in this blog post .","title":"Resilient Network Calls"},{"location":"pipelines/cloud-sdk/cloud-qualities/#functional-tests","text":"Ensuring the functional correctness of an application requires automated tests, which are part of the application code. Those qualities depend on the test code written by the application developer.","title":"Functional Tests"},{"location":"pipelines/cloud-sdk/cloud-qualities/#unit-tests","text":"The purpose of unit tests is to verify the correctness of a single unit in isolation. Other components than the unit under test may be mocked for testing purposes. Place your unit tests in the appropriate Maven module ( unit-tests ) in order to make the pipeline run them automatically.","title":"Unit Tests"},{"location":"pipelines/cloud-sdk/cloud-qualities/#integration-tests","text":"Integration tests work on a higher level compared to unit tests. They should ensure that independently tested units work together as they need to. In the context of extension applications on SAP Cloud Platform, this means to ensure interoperability of your application with S/4HANA and interoperability between your application's backend and frontend component . Place your integration tests in the appropriate Maven module ( integration-tests ) in order to make the pipeline run them automatically. For more detailed description, refer to this blog post .","title":"Integration Tests"},{"location":"pipelines/cloud-sdk/cloud-qualities/#end-to-end-tests","text":"End-to-end tests use your application, like a human user would by clicking buttons, entering text into forms and waiting for the result. Place your end-to-end tests in the e2e-tests directory and ensure the ci-e2e script in package.json runs the right command. The output folder for the reports needs to be s4hana_pipeline/reports/e2e .","title":"End-to-End Tests"},{"location":"pipelines/cloud-sdk/cloud-qualities/#code-coverage","text":"Code coverage refers to how much of your application code is tested. The build fails, if the test coverage of your code drops below a certain threshold. To fix such a build failure, check which parts of your code are not tested yet and write missing tests. The code coverage is tested using JaCoCo Java Code Coverage Library .","title":"Code Coverage"},{"location":"pipelines/cloud-sdk/cloud-qualities/#non-functional-tests","text":"","title":"Non-Functional Tests"},{"location":"pipelines/cloud-sdk/cloud-qualities/#performance","text":"Performance relates to how quickly your application reacts under heavy load. For implementing performance tests, you can chose between to Open Source tools: JMeter and Gatling . If you're not familiar with both of them, we recommend using Gatling. More information on testing the performance of your application is available in this blog post .","title":"Performance"},{"location":"pipelines/cloud-sdk/cloud-qualities/#static-code-checks","text":"Static code checks look for potential issues in code without running the program. The SAP Cloud SDK Pipeline includes commonly used static checks using both PMD and SpotBugs . In addition to the default checks of those tools, it adds the following SAP Cloud SDK specific checks: To make post-mortem debugging possible Log the exception in the catch block or in a called handling method or reference it in a new thrown exception Reference the exception when logging inside a catch block In order to allow a smooth transition from Neo to Cloud Foundry, you should use the platform independent abstractions provided by the SAP S4HANA Cloud SDK","title":"Static Code Checks"},{"location":"pipelines/cloud-sdk/cloud-qualities/#lint","text":"The pipeline automatically checks JavaScript and XML files in SAPUI5 components for the SAPUI5 recommended best practices. Custom linters can be implemented by development teams, if desired. This allows to enforce a common coding style within a team of developers, thus making it easier to focus on the application code, rather then discussing minor style issues.","title":"Lint"},{"location":"pipelines/cloud-sdk/cloud-qualities/#third-party-tools","text":"The SAP Cloud SDK Pipeline also integrates with commercial third party code analyzer services, if you wish to use them. Currently, Checkmarx , WhiteSource , and SourceClear are available. For those scans to be enabled, they need to be configured in the pipeline configuration file .","title":"Third-Party Tools"},{"location":"pipelines/cloud-sdk/introduction/","text":"SAP Cloud SDK Pipeline \u00b6 If you are building an application with SAP Cloud SDK , the SAP Cloud SDK pipeline helps you to quickly build and deliver your app in high quality. Thanks to highly streamlined components, setting up and delivering your first project will just take minutes. Qualities and Pipeline Features \u00b6 The SAP Cloud SDK pipeline is based on project \"Piper\" and offers unique features for assuring that your SAP Cloud SDK based application fulfills the highest quality standards. In conjunction with the SAP Cloud SDK libraries, the pipeline helps you to implement and automatically assure application qualities, for example: Functional correctness via: Backend and frontend unit tests Backend and frontend integration tests User acceptance testing via headless browser end-to-end tests Non-functional qualities via: Dynamic resilience checks Performance tests based on Gatling or JMeter Code Security scans based on Checkmarx and Fortify Dependency vulnerability scans based on Whitesource IP compliance scan based on Whitesource Zero-downtime deployment Proper logging of application errors For more details, see Cloud Qualities . Supported Project Types \u00b6 The pipeline supports the following types of projects: Java projects based on the SAP Cloud SDK Archetypes . JavaScript projects based on the SAP Cloud SDK JavaScript Scaffolding . TypeScript projects based on the SAP Cloud SDK TypeScript Scaffolding . SAP Cloud Application Programming Model (CAP) projects based on the SAP Cloud Platform Business Application WebIDE Template. You can find more details about the supported project types and build tools in Build Tools . Legal Notes \u00b6 Note: This license of this repository does not apply to the SAP Cloud SDK for Continuous Delivery Logo referenced in this page","title":"Introduction"},{"location":"pipelines/cloud-sdk/introduction/#sap-cloud-sdk-pipeline","text":"If you are building an application with SAP Cloud SDK , the SAP Cloud SDK pipeline helps you to quickly build and deliver your app in high quality. Thanks to highly streamlined components, setting up and delivering your first project will just take minutes.","title":"SAP Cloud SDK Pipeline"},{"location":"pipelines/cloud-sdk/introduction/#qualities-and-pipeline-features","text":"The SAP Cloud SDK pipeline is based on project \"Piper\" and offers unique features for assuring that your SAP Cloud SDK based application fulfills the highest quality standards. In conjunction with the SAP Cloud SDK libraries, the pipeline helps you to implement and automatically assure application qualities, for example: Functional correctness via: Backend and frontend unit tests Backend and frontend integration tests User acceptance testing via headless browser end-to-end tests Non-functional qualities via: Dynamic resilience checks Performance tests based on Gatling or JMeter Code Security scans based on Checkmarx and Fortify Dependency vulnerability scans based on Whitesource IP compliance scan based on Whitesource Zero-downtime deployment Proper logging of application errors For more details, see Cloud Qualities .","title":"Qualities and Pipeline Features"},{"location":"pipelines/cloud-sdk/introduction/#supported-project-types","text":"The pipeline supports the following types of projects: Java projects based on the SAP Cloud SDK Archetypes . JavaScript projects based on the SAP Cloud SDK JavaScript Scaffolding . TypeScript projects based on the SAP Cloud SDK TypeScript Scaffolding . SAP Cloud Application Programming Model (CAP) projects based on the SAP Cloud Platform Business Application WebIDE Template. You can find more details about the supported project types and build tools in Build Tools .","title":"Supported Project Types"},{"location":"pipelines/cloud-sdk/introduction/#legal-notes","text":"Note: This license of this repository does not apply to the SAP Cloud SDK for Continuous Delivery Logo referenced in this page","title":"Legal Notes"},{"location":"scenarios/CAP_Scenario/","text":"Build and Deploy SAP Cloud Application Programming Model Applications \u00b6 In this scenario, we will setup a CI/CD Pipeline for a SAP Cloud Application Programming Model (CAP) project, which is based on the SAP Cloud Platform Business Application WebIDE Template. Prerequisites \u00b6 You have an account on SAP Cloud Platform in the Cloud Foundry environment. See Accounts . You have setup a suitable Jenkins instance as described in Guided Tour Context \u00b6 The Application Programming Model for SAP Cloud Platform is an end-to-end best practice guide for developing applications on SAP Cloud Platform and provides a supportive set of APIs, languages, and libraries. For more information about the SAP Cloud Application Programming Model, see Working with the SAP Cloud Application Programming Model . Getting started \u00b6 To get started, generate a project in SAP Web IDE based on the SAP Cloud Platform Business Application template. Make sure to check the Include support for continuous delivery pipeline of SAP Cloud SDK checkbox, as in this screenshot: This will generate a project which already includes a Jenkinsfile , and a pipeline_config.yml file. New location of pipeline configuration file The SAP Cloud SDK Pipeline recently changed the default location for the configuration file from pipeline_config.yml to .config/pipeline to have a consistent user experience with other piper pipelines. For a limited amount of time starting with version v29 both locations can be used. In the following the configuration file is referenced by its new location. In case you already created your project without this option, you'll need to copy and paste two files into the root directory of your project, and commit them to your git repository: Jenkinsfile .pipeline/config.yml Note: The file must be named .pipeline/config.yml , despite the different name of the file template Using the right project structure This only applies to projects created based on the SAP Cloud Platform Business Application template after September 6th 2019. They must comply with the structure which is described here . If your project uses SAP HANA containers (HDI), you'll need to configure createHdiContainer and cloudFoundry in the backendIntegrationTests stage in your .pipeline/config.yml file as documented here Now, you'll need to push the code to a git repository. This is required because the pipeline gets your code via git. This might be GitHub, or any other cloud or on-premise git solution you have in your company. Be sure to configure the productionDeployment stage so your changes are deployed to SAP Cloud Platform automatically. Legacy documentation \u00b6 If your project is not based on the SAP Cloud Platform Business Application WebIDE template, you could either migrate your code to comply with the structure which is described here , or you can use a self built pipeline, as described in this section. Prerequisites \u00b6 You have an account on SAP Cloud Platform in the Cloud Foundry environment. See Accounts . You have downloaded and installed the Cloud Foundry command line interface (CLI). See Download and Install the Cloud Foundry Command Line Interface . You have installed the multi-target application plug-in for the Cloud Foundry command line interface. See Install the Multi-Target Application Plug-in in the Cloud Foundry Environment . You have installed the Java Runtime Environment 8. You have installed Jenkins 2.60.3 or higher. You have set up Project \u201cPiper\u201d. See README . You have installed the Multi-Target Application (MTA) Archive Builder 1.0.6 or newer. See SAP Development Tools . You have installed Node.js including node and npm. See Node.js . Context \u00b6 The Application Programming Model for SAP Cloud Platform is an end-to-end best practice guide for developing applications on SAP Cloud Platform and provides a supportive set of APIs, languages, and libraries. For more information about the SAP Cloud Application Programming Model, see Working with the SAP Cloud Application Programming Model . In this scenario, we want to show how to implement a basic continuous delivery process for developing applications according to this programming model with the help of project \"Piper\" on Jenkins. This basic scenario can be adapted and enriched according to your specific needs. Example \u00b6 Jenkinsfile \u00b6 @Library ( 'piper-lib-os' ) _ node (){ stage ( 'Prepare' ) { deleteDir () checkout scm setupCommonPipelineEnvironment script: this } stage ( 'Build' ) { mtaBuild script: this } stage ( 'Deploy' ) { cloudFoundryDeploy script: this , deployTool: 'mtaDeployPlugin' } } Configuration ( .pipeline/config.yml ) \u00b6 steps : mtaBuild : buildTarget : 'CF' cloudFoundryDeploy : cloudFoundry : credentialsId : 'CF' apiEndpoint : '<CF Endpoint>' org : '<CF Organization>' space : '<CF Space>' Parameters \u00b6 For the detailed description of the relevant parameters, see: mtaBuild cloudFoundryDeploy","title":"Build and Deploy Applications with Jenkins and the SAP Cloud Application Programming Model"},{"location":"scenarios/CAP_Scenario/#build-and-deploy-sap-cloud-application-programming-model-applications","text":"In this scenario, we will setup a CI/CD Pipeline for a SAP Cloud Application Programming Model (CAP) project, which is based on the SAP Cloud Platform Business Application WebIDE Template.","title":"Build and Deploy SAP Cloud Application Programming Model Applications"},{"location":"scenarios/CAP_Scenario/#prerequisites","text":"You have an account on SAP Cloud Platform in the Cloud Foundry environment. See Accounts . You have setup a suitable Jenkins instance as described in Guided Tour","title":"Prerequisites"},{"location":"scenarios/CAP_Scenario/#context","text":"The Application Programming Model for SAP Cloud Platform is an end-to-end best practice guide for developing applications on SAP Cloud Platform and provides a supportive set of APIs, languages, and libraries. For more information about the SAP Cloud Application Programming Model, see Working with the SAP Cloud Application Programming Model .","title":"Context"},{"location":"scenarios/CAP_Scenario/#getting-started","text":"To get started, generate a project in SAP Web IDE based on the SAP Cloud Platform Business Application template. Make sure to check the Include support for continuous delivery pipeline of SAP Cloud SDK checkbox, as in this screenshot: This will generate a project which already includes a Jenkinsfile , and a pipeline_config.yml file. New location of pipeline configuration file The SAP Cloud SDK Pipeline recently changed the default location for the configuration file from pipeline_config.yml to .config/pipeline to have a consistent user experience with other piper pipelines. For a limited amount of time starting with version v29 both locations can be used. In the following the configuration file is referenced by its new location. In case you already created your project without this option, you'll need to copy and paste two files into the root directory of your project, and commit them to your git repository: Jenkinsfile .pipeline/config.yml Note: The file must be named .pipeline/config.yml , despite the different name of the file template Using the right project structure This only applies to projects created based on the SAP Cloud Platform Business Application template after September 6th 2019. They must comply with the structure which is described here . If your project uses SAP HANA containers (HDI), you'll need to configure createHdiContainer and cloudFoundry in the backendIntegrationTests stage in your .pipeline/config.yml file as documented here Now, you'll need to push the code to a git repository. This is required because the pipeline gets your code via git. This might be GitHub, or any other cloud or on-premise git solution you have in your company. Be sure to configure the productionDeployment stage so your changes are deployed to SAP Cloud Platform automatically.","title":"Getting started"},{"location":"scenarios/CAP_Scenario/#legacy-documentation","text":"If your project is not based on the SAP Cloud Platform Business Application WebIDE template, you could either migrate your code to comply with the structure which is described here , or you can use a self built pipeline, as described in this section.","title":"Legacy documentation"},{"location":"scenarios/CAP_Scenario/#prerequisites_1","text":"You have an account on SAP Cloud Platform in the Cloud Foundry environment. See Accounts . You have downloaded and installed the Cloud Foundry command line interface (CLI). See Download and Install the Cloud Foundry Command Line Interface . You have installed the multi-target application plug-in for the Cloud Foundry command line interface. See Install the Multi-Target Application Plug-in in the Cloud Foundry Environment . You have installed the Java Runtime Environment 8. You have installed Jenkins 2.60.3 or higher. You have set up Project \u201cPiper\u201d. See README . You have installed the Multi-Target Application (MTA) Archive Builder 1.0.6 or newer. See SAP Development Tools . You have installed Node.js including node and npm. See Node.js .","title":"Prerequisites"},{"location":"scenarios/CAP_Scenario/#context_1","text":"The Application Programming Model for SAP Cloud Platform is an end-to-end best practice guide for developing applications on SAP Cloud Platform and provides a supportive set of APIs, languages, and libraries. For more information about the SAP Cloud Application Programming Model, see Working with the SAP Cloud Application Programming Model . In this scenario, we want to show how to implement a basic continuous delivery process for developing applications according to this programming model with the help of project \"Piper\" on Jenkins. This basic scenario can be adapted and enriched according to your specific needs.","title":"Context"},{"location":"scenarios/CAP_Scenario/#example","text":"","title":"Example"},{"location":"scenarios/CAP_Scenario/#jenkinsfile","text":"@Library ( 'piper-lib-os' ) _ node (){ stage ( 'Prepare' ) { deleteDir () checkout scm setupCommonPipelineEnvironment script: this } stage ( 'Build' ) { mtaBuild script: this } stage ( 'Deploy' ) { cloudFoundryDeploy script: this , deployTool: 'mtaDeployPlugin' } }","title":"Jenkinsfile"},{"location":"scenarios/CAP_Scenario/#configuration-pipelineconfigyml","text":"steps : mtaBuild : buildTarget : 'CF' cloudFoundryDeploy : cloudFoundry : credentialsId : 'CF' apiEndpoint : '<CF Endpoint>' org : '<CF Organization>' space : '<CF Space>'","title":"Configuration (.pipeline/config.yml)"},{"location":"scenarios/CAP_Scenario/#parameters","text":"For the detailed description of the relevant parameters, see: mtaBuild cloudFoundryDeploy","title":"Parameters"},{"location":"scenarios/TMS_Extension/","text":"Integrate SAP Cloud Platform Transport Management Into Your CI/CD Pipeline \u00b6 Extend your CI/CD pipeline with SAP Cloud Platform Transport Management (Transport Management, for short) to add an enterprise-ready change and release management process and enable the transport of cloud-based applications on SAP Cloud Platform between several stages. Context \u00b6 This procedure explains how to upload a multitarget application from a CI/CD pipeline to Transport Management and then import it into its target environment. Transport Management allows you to manage the transport of development artifacts and application-specific content between different SAP Cloud Platform accounts. It adds transparency to the audit trail of changes so that you get information about who performed which changes in your production accounts and when they did it. At the same time, Transport Management enables a separation of concerns: For example, a developer of an application or of SAP Cloud Platform content artifacts can trigger the propagation of changes, while the resulting transport is handled by a central operations team. For more information, see SAP Cloud Platform Transport Management . The following graphic provides an overview about the interplay between continuous integration and Transport Management: Prerequisites \u00b6 You have an existing CI pipeline, which you want to extend with Transport Management. You have an MTA project, and the folder structure of its sources corresponds to the standard MTA structure. For more information, see The Multitarget Application Model . You have access to Transport Management. See Provide Access to SAP Cloud Platform Transport Management . You have set up SAP Cloud Platform Transport Management and created a service key. See Set Up the Environment to Transport Content Archives directly in an Application . You have configured your transport landscape. See Configuring the Landscape . Procedure \u00b6 You can use this scenario to extend any CI process that meets the prerequisites, for example, the one described in Build and Deploy SAPUI5 or SAP Fiori Applications on SAP Cloud Platform with Jenkins . The following graphic shows an example of the detailed procedure when combining continuous integration and Transport Management: The process flow contains the following steps: The CI server builds a multitarget application (MTA) archive. The MTA is uploaded into the import queue of the target node, which is specified in the CI pipeline (in this example, PRE-PROD). Optionally, for transports in Cloud Foundry environment, MTA extension descriptors can be uploaded to the nodes in the transport landscape to provide node-specific import configurations. The MTA extension descriptor file must either be part of the repository, or be the result of the build process. The release manager manually triggers the import, or schedules it, which results in the physical deployment of the MTA archive into the corresponding subaccount (in this example, PRE-PROD). If an MTA extension descriptor was uploaded for this node, it will be used for the import. As soon as the import is executed, a transport is triggered along the defined transport route so that the MTA archive reaches the import queue of the next node (in this example, PROD). There, the physical import into the corresponding subaccount can be either triggered manually by the release manager or automatically by using the scheduling mechanisms of Transport Management. Example \u00b6 Jenkinsfile \u00b6 If you use the pipeline of the following code snippet, you only have to configure it in the .pipeline/config.yml. Following the convention for pipeline definitions, use a Jenkinsfile, which resides in the root directory of your development sources. @Library ( 'piper-lib-os' ) _ piperPipeline script: this Configuration ( .pipeline/config.yml ) \u00b6 This is a basic configuration example, which is also located in the sources of the project. steps : tmsUpload : credentialsId : tms-secret-key nodeName : PRE-PROD mtaPath : com.piper.example.tms.mtar customDescription : Custom-Transport-Description # uploading MTA extension descriptors, optional step mtaVersion : 1.0.0 nodeExtDescriptorMapping : PRE-PROD : 'scv_x_preprod.mtaext' PROD : 'scv_x_prod.mtaext' stages : Release : tmsUpload : true Configuration for the Upload to Transport Management \u00b6 Parameter Description credentialsId Credentials that are used for the file and node uploads to Transport Management. nodeName Defines the name of the node to which the *.mtar file is uploaded. mtaPath Defines the path to the *.mtar file for the upload to Transport Management. customDescription Optional: Description of a transport request. Overwrites the default (Default: Corresponding Git Commit-ID). nodeExtDescriptorMapping Optional: Defines the mapping between a transport node and the MTA extension descriptor file that is used for the transport node. You specify the node name and the relative path to the MTA extension descriptor file using the following syntax: nodeExtDescriptorMapping: [nodeName: 'example.mtaext', nodeName2: 'example2.mtaext', \u2026] . mtaVersion Optional: Defines the version of the MTA for which the MTA extension descriptor is used. You can use an asterisk (*) to accept any MTA version, or use a specific version compliant with SemVer 2.0, e.g. 1.0.0 (see semver.org). If the parameter is not configured, an asterisk is used. Parameters \u00b6 For a detailed description of the relevant parameters, see tmsUpload .","title":"Integrate SAP Cloud Platform Transport Management Into Your CI/CD Pipeline"},{"location":"scenarios/TMS_Extension/#integrate-sap-cloud-platform-transport-management-into-your-cicd-pipeline","text":"Extend your CI/CD pipeline with SAP Cloud Platform Transport Management (Transport Management, for short) to add an enterprise-ready change and release management process and enable the transport of cloud-based applications on SAP Cloud Platform between several stages.","title":"Integrate SAP Cloud Platform Transport Management Into Your CI/CD Pipeline"},{"location":"scenarios/TMS_Extension/#context","text":"This procedure explains how to upload a multitarget application from a CI/CD pipeline to Transport Management and then import it into its target environment. Transport Management allows you to manage the transport of development artifacts and application-specific content between different SAP Cloud Platform accounts. It adds transparency to the audit trail of changes so that you get information about who performed which changes in your production accounts and when they did it. At the same time, Transport Management enables a separation of concerns: For example, a developer of an application or of SAP Cloud Platform content artifacts can trigger the propagation of changes, while the resulting transport is handled by a central operations team. For more information, see SAP Cloud Platform Transport Management . The following graphic provides an overview about the interplay between continuous integration and Transport Management:","title":"Context"},{"location":"scenarios/TMS_Extension/#prerequisites","text":"You have an existing CI pipeline, which you want to extend with Transport Management. You have an MTA project, and the folder structure of its sources corresponds to the standard MTA structure. For more information, see The Multitarget Application Model . You have access to Transport Management. See Provide Access to SAP Cloud Platform Transport Management . You have set up SAP Cloud Platform Transport Management and created a service key. See Set Up the Environment to Transport Content Archives directly in an Application . You have configured your transport landscape. See Configuring the Landscape .","title":"Prerequisites"},{"location":"scenarios/TMS_Extension/#procedure","text":"You can use this scenario to extend any CI process that meets the prerequisites, for example, the one described in Build and Deploy SAPUI5 or SAP Fiori Applications on SAP Cloud Platform with Jenkins . The following graphic shows an example of the detailed procedure when combining continuous integration and Transport Management: The process flow contains the following steps: The CI server builds a multitarget application (MTA) archive. The MTA is uploaded into the import queue of the target node, which is specified in the CI pipeline (in this example, PRE-PROD). Optionally, for transports in Cloud Foundry environment, MTA extension descriptors can be uploaded to the nodes in the transport landscape to provide node-specific import configurations. The MTA extension descriptor file must either be part of the repository, or be the result of the build process. The release manager manually triggers the import, or schedules it, which results in the physical deployment of the MTA archive into the corresponding subaccount (in this example, PRE-PROD). If an MTA extension descriptor was uploaded for this node, it will be used for the import. As soon as the import is executed, a transport is triggered along the defined transport route so that the MTA archive reaches the import queue of the next node (in this example, PROD). There, the physical import into the corresponding subaccount can be either triggered manually by the release manager or automatically by using the scheduling mechanisms of Transport Management.","title":"Procedure"},{"location":"scenarios/TMS_Extension/#example","text":"","title":"Example"},{"location":"scenarios/TMS_Extension/#jenkinsfile","text":"If you use the pipeline of the following code snippet, you only have to configure it in the .pipeline/config.yml. Following the convention for pipeline definitions, use a Jenkinsfile, which resides in the root directory of your development sources. @Library ( 'piper-lib-os' ) _ piperPipeline script: this","title":"Jenkinsfile"},{"location":"scenarios/TMS_Extension/#configuration-pipelineconfigyml","text":"This is a basic configuration example, which is also located in the sources of the project. steps : tmsUpload : credentialsId : tms-secret-key nodeName : PRE-PROD mtaPath : com.piper.example.tms.mtar customDescription : Custom-Transport-Description # uploading MTA extension descriptors, optional step mtaVersion : 1.0.0 nodeExtDescriptorMapping : PRE-PROD : 'scv_x_preprod.mtaext' PROD : 'scv_x_prod.mtaext' stages : Release : tmsUpload : true","title":"Configuration (.pipeline/config.yml)"},{"location":"scenarios/TMS_Extension/#configuration-for-the-upload-to-transport-management","text":"Parameter Description credentialsId Credentials that are used for the file and node uploads to Transport Management. nodeName Defines the name of the node to which the *.mtar file is uploaded. mtaPath Defines the path to the *.mtar file for the upload to Transport Management. customDescription Optional: Description of a transport request. Overwrites the default (Default: Corresponding Git Commit-ID). nodeExtDescriptorMapping Optional: Defines the mapping between a transport node and the MTA extension descriptor file that is used for the transport node. You specify the node name and the relative path to the MTA extension descriptor file using the following syntax: nodeExtDescriptorMapping: [nodeName: 'example.mtaext', nodeName2: 'example2.mtaext', \u2026] . mtaVersion Optional: Defines the version of the MTA for which the MTA extension descriptor is used. You can use an asterisk (*) to accept any MTA version, or use a specific version compliant with SemVer 2.0, e.g. 1.0.0 (see semver.org). If the parameter is not configured, an asterisk is used.","title":"Configuration for the Upload to Transport Management"},{"location":"scenarios/TMS_Extension/#parameters","text":"For a detailed description of the relevant parameters, see tmsUpload .","title":"Parameters"},{"location":"scenarios/changeManagement/","text":"Build and Deploy Hybrid Applications with Jenkins and SAP Solution Manager \u00b6 Set up an agile development process with Jenkins CI, which automatically feeds changes into SAP Solution Manager. Prerequisites \u00b6 You have installed the Java Runtime Environment 8. You have installed Jenkins 2.60.3 or higher. You have set up Project \u201cPiper\u201d. See README . You have installed SAP Solution Manager 7.2 SP6. See README . You have installed the Multi-Target Application (MTA) Archive Builder 1.0.6 or newer. See SAP Development Tools . Note: This is only required if you don't use a Docker-based environment. You have installed Node.js including node and npm. See Node.js . Note: This is only required if you don't use a Docker-based environment. Context \u00b6 In many SAP development scenarios, it is vital to synchronize both backend and frontend deliveries. These deliveries are typically an SAP UI5 application and an ABAP backend from which it is served. The SAP UI5 parts are often developed using agile practices and use Continuous Integration pipelines that automatically build, test, and deploy the application. Note This scenario description is an example. You can apply the process to other scenarios and component sets, as well. In this scenario, we want to show how an agile development process with Jenkins CI can automatically feed changes into SAP Solution Manager. In SAP Solution Manager, all parts of the application stack come together and can be subject to classic change and transport management. The basic workflow is as follows: The pipeline scans the Git commit messages for a line like ChangeDocument : <changeDocumentId> , and validates that the change is in the correct status in development . For more information, see checkChangeInDevelopment . An example for the commit message looks as follows: Fix terminology in documentation Terminology must be consistent with official channels. ChangeDocument: <Your Change Document ID> Note: The blank line between message header and message description is mandatory. To communicate with SAP Solution Manager, the pipeline uses credentials that must be stored on Jenkins using the credential ID CM . For more information, see checkChangeInDevelopment . The required transport request is created on the fly. Note: The change document can contain various components (for example, UI and backend components). The changes of your development team trigger the Jenkins pipeline. It builds and validates the changes and attaches them to the respective transport request. As soon as the development process is completed, the change document in SAP Solution Manager can be set to status to be tested and all components can be transported to the test system. Hybrid Application Development Workflow \u00b6 Example \u00b6 Jenkinsfile \u00b6 @Library ( 'piper-lib-os' ) _ node () { stage ( 'prepare' ) { checkout scm setupCommonPipelineEnvironment script: this checkChangeInDevelopment script: this } stage ( 'buildMta' ) { mtaBuild script: this } stage ( 'uploadToTransportRequest' ) { transportRequestCreate script: this transportRequestUploadFile script: this transportRequestRelease script: this } } Configuration ( .pipeline/config.yml ) \u00b6 #Steps Specific Configuration general : changeManagement : endpoint : 'https://<backend-system>/sap/opu/odata/sap/AI_CRM_GW_CM_CI_SRV' credentialsId : 'CM' type : 'SOLMAN' steps : mtaBuild : buildTarget : 'NEO' transportRequestCreate : developmentSystemId : '<value for developmentSystemId>' transportRequestUploadFile : applicationId : 'HCP' Parameters \u00b6 For the detailed description of the relevant parameters, see: checkChangeInDevelopment mtaBuild transportRequestCreate transportRequestUploadFile transportRequestRelease","title":"Build and Deploy Hybrid Applications with Jenkins and SAP Solution Manager"},{"location":"scenarios/changeManagement/#build-and-deploy-hybrid-applications-with-jenkins-and-sap-solution-manager","text":"Set up an agile development process with Jenkins CI, which automatically feeds changes into SAP Solution Manager.","title":"Build and Deploy Hybrid Applications with Jenkins and SAP Solution Manager"},{"location":"scenarios/changeManagement/#prerequisites","text":"You have installed the Java Runtime Environment 8. You have installed Jenkins 2.60.3 or higher. You have set up Project \u201cPiper\u201d. See README . You have installed SAP Solution Manager 7.2 SP6. See README . You have installed the Multi-Target Application (MTA) Archive Builder 1.0.6 or newer. See SAP Development Tools . Note: This is only required if you don't use a Docker-based environment. You have installed Node.js including node and npm. See Node.js . Note: This is only required if you don't use a Docker-based environment.","title":"Prerequisites"},{"location":"scenarios/changeManagement/#context","text":"In many SAP development scenarios, it is vital to synchronize both backend and frontend deliveries. These deliveries are typically an SAP UI5 application and an ABAP backend from which it is served. The SAP UI5 parts are often developed using agile practices and use Continuous Integration pipelines that automatically build, test, and deploy the application. Note This scenario description is an example. You can apply the process to other scenarios and component sets, as well. In this scenario, we want to show how an agile development process with Jenkins CI can automatically feed changes into SAP Solution Manager. In SAP Solution Manager, all parts of the application stack come together and can be subject to classic change and transport management. The basic workflow is as follows: The pipeline scans the Git commit messages for a line like ChangeDocument : <changeDocumentId> , and validates that the change is in the correct status in development . For more information, see checkChangeInDevelopment . An example for the commit message looks as follows: Fix terminology in documentation Terminology must be consistent with official channels. ChangeDocument: <Your Change Document ID> Note: The blank line between message header and message description is mandatory. To communicate with SAP Solution Manager, the pipeline uses credentials that must be stored on Jenkins using the credential ID CM . For more information, see checkChangeInDevelopment . The required transport request is created on the fly. Note: The change document can contain various components (for example, UI and backend components). The changes of your development team trigger the Jenkins pipeline. It builds and validates the changes and attaches them to the respective transport request. As soon as the development process is completed, the change document in SAP Solution Manager can be set to status to be tested and all components can be transported to the test system.","title":"Context"},{"location":"scenarios/changeManagement/#hybrid-application-development-workflow","text":"","title":"Hybrid Application Development Workflow"},{"location":"scenarios/changeManagement/#example","text":"","title":"Example"},{"location":"scenarios/changeManagement/#jenkinsfile","text":"@Library ( 'piper-lib-os' ) _ node () { stage ( 'prepare' ) { checkout scm setupCommonPipelineEnvironment script: this checkChangeInDevelopment script: this } stage ( 'buildMta' ) { mtaBuild script: this } stage ( 'uploadToTransportRequest' ) { transportRequestCreate script: this transportRequestUploadFile script: this transportRequestRelease script: this } }","title":"Jenkinsfile"},{"location":"scenarios/changeManagement/#configuration-pipelineconfigyml","text":"#Steps Specific Configuration general : changeManagement : endpoint : 'https://<backend-system>/sap/opu/odata/sap/AI_CRM_GW_CM_CI_SRV' credentialsId : 'CM' type : 'SOLMAN' steps : mtaBuild : buildTarget : 'NEO' transportRequestCreate : developmentSystemId : '<value for developmentSystemId>' transportRequestUploadFile : applicationId : 'HCP'","title":"Configuration (.pipeline/config.yml)"},{"location":"scenarios/changeManagement/#parameters","text":"For the detailed description of the relevant parameters, see: checkChangeInDevelopment mtaBuild transportRequestCreate transportRequestUploadFile transportRequestRelease","title":"Parameters"},{"location":"scenarios/ui5-sap-cp/Readme/","text":"Build and Deploy SAPUI5 or SAP Fiori Applications on SAP Cloud Platform with Jenkins \u00b6 Build an application based on SAPUI5 or SAP Fiori with Jenkins and deploy the build result into an SAP Cloud Platform account in the Neo environment. Prerequisites \u00b6 You have installed the Java Runtime Environment 8. You have installed Jenkins 2.60.3 or higher. You have set up Project \u201cPiper\u201d. See README . You have installed the Multi-Target Application (MTA) Archive Builder 1.0.6 or newer. See SAP Development Tools . You have installed Node.js including node and npm. See Node.js . You have installed the SAP Cloud Platform Neo Environment SDK. See SAP Development Tools . Project Prerequisites \u00b6 This scenario requires additional files in your project and in the execution environment on your Jenkins instance. On the project level, provide and adjust the following template: File Name Description Position .npmrc This file contains a reference to the SAP NPM registry ( @sap:registry https://npm.sap.com ), which is required to fetch the dependencies required to build the application. Place the .npmrc file in the root directory of your project. mta.yaml This file controls the behavior of the MTA toolset. Place the mta.yaml file in your application root folder and adjust the values in brackets with your data. package.json This file lists the required development dependencies for the build. Add the content of the package.json file to your existing package.json file. Gruntfile.js This file controls the grunt build. By default the tasks clean , build , and lint are executed. Place the Gruntfile.js in the root directory of your project. Context \u00b6 This scenario combines various different steps to create a complete pipeline. In this scenario, we want to show how to build an application based on SAPUI5 or SAP Fiori by using the multi-target application (MTA) concept and how to deploy the build result into an SAP Cloud Platform account in the Neo environment. This document comprises the mtaBuild and the neoDeploy steps. Screenshot: Build and Deploy Process in Jenkins \u00b6 Example \u00b6 Jenkinsfile \u00b6 Following the convention for pipeline definitions, use a Jenkinsfile which resides in the root directory of your development sources. @Library ( 'piper-lib-os' ) _ fioriOnCloudPlatformPipeline script: this fioriOnCloudPlatform is a so called scenario step that wraps the mtaBuild and the neoDeploy steps. Configuration ( .pipeline/config.yml ) \u00b6 This is a basic configuration example, which is also located in the sources of the project. The configuration corresponds to the steps wrapped in fioriOnCloudPlatformPipeline . steps : mtaBuild : buildTarget : 'NEO' platform : 'neo' neoDeploy : neo : credentialsId : 'NEO_DEPLOY' account : 'your-account-id' host : 'hana.ondemand.com' Configuration for the MTA Build \u00b6 Parameter Description buildTarget The target platform to which the mtar can be deployed. Possible values are: CF , NEO , XSA mtaJarLocation The location of the multi-target application archive builder jar file, including file name and extension. Configuration for the Deployment to SAP Cloud Platform \u00b6 Parameter Description account The SAP Cloud Platform account to deploy to. credentialsId The Jenkins credentials that contain the user and password which are used for the deployment on SAP Cloud Platform. host The SAP Cloud Platform host to deploy to. Parameters \u00b6 For the detailed description of the relevant parameters, see: mtaBuild neoDeploy","title":"Build and Deploy SAP UI5 or SAP Fiori Applications on SAP Cloud Platform with Jenkins"},{"location":"scenarios/ui5-sap-cp/Readme/#build-and-deploy-sapui5-or-sap-fiori-applications-on-sap-cloud-platform-with-jenkins","text":"Build an application based on SAPUI5 or SAP Fiori with Jenkins and deploy the build result into an SAP Cloud Platform account in the Neo environment.","title":"Build and Deploy SAPUI5 or SAP Fiori Applications on SAP Cloud Platform with Jenkins"},{"location":"scenarios/ui5-sap-cp/Readme/#prerequisites","text":"You have installed the Java Runtime Environment 8. You have installed Jenkins 2.60.3 or higher. You have set up Project \u201cPiper\u201d. See README . You have installed the Multi-Target Application (MTA) Archive Builder 1.0.6 or newer. See SAP Development Tools . You have installed Node.js including node and npm. See Node.js . You have installed the SAP Cloud Platform Neo Environment SDK. See SAP Development Tools .","title":"Prerequisites"},{"location":"scenarios/ui5-sap-cp/Readme/#project-prerequisites","text":"This scenario requires additional files in your project and in the execution environment on your Jenkins instance. On the project level, provide and adjust the following template: File Name Description Position .npmrc This file contains a reference to the SAP NPM registry ( @sap:registry https://npm.sap.com ), which is required to fetch the dependencies required to build the application. Place the .npmrc file in the root directory of your project. mta.yaml This file controls the behavior of the MTA toolset. Place the mta.yaml file in your application root folder and adjust the values in brackets with your data. package.json This file lists the required development dependencies for the build. Add the content of the package.json file to your existing package.json file. Gruntfile.js This file controls the grunt build. By default the tasks clean , build , and lint are executed. Place the Gruntfile.js in the root directory of your project.","title":"Project Prerequisites"},{"location":"scenarios/ui5-sap-cp/Readme/#context","text":"This scenario combines various different steps to create a complete pipeline. In this scenario, we want to show how to build an application based on SAPUI5 or SAP Fiori by using the multi-target application (MTA) concept and how to deploy the build result into an SAP Cloud Platform account in the Neo environment. This document comprises the mtaBuild and the neoDeploy steps.","title":"Context"},{"location":"scenarios/ui5-sap-cp/Readme/#screenshot-build-and-deploy-process-in-jenkins","text":"","title":"Screenshot: Build and Deploy Process in Jenkins"},{"location":"scenarios/ui5-sap-cp/Readme/#example","text":"","title":"Example"},{"location":"scenarios/ui5-sap-cp/Readme/#jenkinsfile","text":"Following the convention for pipeline definitions, use a Jenkinsfile which resides in the root directory of your development sources. @Library ( 'piper-lib-os' ) _ fioriOnCloudPlatformPipeline script: this fioriOnCloudPlatform is a so called scenario step that wraps the mtaBuild and the neoDeploy steps.","title":"Jenkinsfile"},{"location":"scenarios/ui5-sap-cp/Readme/#configuration-pipelineconfigyml","text":"This is a basic configuration example, which is also located in the sources of the project. The configuration corresponds to the steps wrapped in fioriOnCloudPlatformPipeline . steps : mtaBuild : buildTarget : 'NEO' platform : 'neo' neoDeploy : neo : credentialsId : 'NEO_DEPLOY' account : 'your-account-id' host : 'hana.ondemand.com'","title":"Configuration (.pipeline/config.yml)"},{"location":"scenarios/ui5-sap-cp/Readme/#configuration-for-the-mta-build","text":"Parameter Description buildTarget The target platform to which the mtar can be deployed. Possible values are: CF , NEO , XSA mtaJarLocation The location of the multi-target application archive builder jar file, including file name and extension.","title":"Configuration for the MTA Build"},{"location":"scenarios/ui5-sap-cp/Readme/#configuration-for-the-deployment-to-sap-cloud-platform","text":"Parameter Description account The SAP Cloud Platform account to deploy to. credentialsId The Jenkins credentials that contain the user and password which are used for the deployment on SAP Cloud Platform. host The SAP Cloud Platform host to deploy to.","title":"Configuration for the Deployment to SAP Cloud Platform"},{"location":"scenarios/ui5-sap-cp/Readme/#parameters","text":"For the detailed description of the relevant parameters, see: mtaBuild neoDeploy","title":"Parameters"},{"location":"scenarios/upload-to-transportrequest/Readme/","text":"Build an SAP Fiori Application and Attach It to a Transport Request on an ABAP System with Jenkins \u00b6 Build an application based on SAPUI5 or SAP Fiori with Jenkins and attach the build result to a transport request in an SAP ABAP system. Generally, you can choose between two technical ways to attach a binary to an ABAP transport request: We support uploads through RFC and through OData. Which option to use depends on the version of your ABAP system. For AS ABAP 7.50 SP08, 7.51 SP07, or 7.52 SP03 and newer, use the OData-based upload, for older versions, use the RFC-based upload. Prerequisites \u00b6 You have set up your Docker environment . You have set up project \u201cPiper\u201d. See guided tour . You have a transport request. In General it is possible to create a transport request on the fly. But the example here is based on an already existing transport request. Depending on the version of the ABAP system: Docker image for attaching binaries to transport requests via RFC available. Due to legal reasons there is no pre-build docker image. How to create the docker image is explained here Project Prerequisites \u00b6 This scenario requires additional files in your project and in the execution environment on your Jenkins instance. On the project level, provide and adjust the following template: File Name Description Position mta.yaml This file controls the behavior of the MTA toolset. Place the mta.yaml file in your application root folder and adjust the values in brackets with your data. Depending on the modules in your MTA, additional configuration files are required, e.g. pom.xml or package.json . Context \u00b6 This scenario combines various different steps to create a complete pipeline. In this scenario, we want to show how to build an application based on SAPUI5 or SAP Fiori by using the multitarget application (MTA) concept and how to attach the build result to a transport request inside an ABAP system. This document comprises the mtaBuild and the transportRequestUploadFile steps. In case of an RFC based upload the binary is not streamed to the ABAP endpoint. Instead an URL pointing to the binary needs to be provided. Hence the binary must be published first so that it can be accessed via HTTP. This can happen by uploading the binary to a blob store or by archiving the artifact on Jenkins. The corresponding URL needs to be provided when the artifact is attached to the transport request. The transport request can be created on the fly (see transportRequestCreate ) or we can use an already existing transport request. In case we use an already existing transport request Id the transport request Id needs to be provided in the git commit history (see example below) or the transport request Id needs to be provided inside the job (e.g. as a job parameter). The transport request can be closed by the pipeline job (see transportRequestRelease ). This is an example of a Git commit message containing the transport request ID: The headline The body. The blank line above is mandatory (Git standard). TransportRequest: <YOUR TRANSPORT REQUEST ID> By default, the Git commits between the merge base with the base branch (default: master ) and the current branch head are traversed. Screenshot: Build and Deploy Process in Jenkins \u00b6 Examples \u00b6 Upload via RFC \u00b6 Jenkinsfile \u00b6 Following the convention for pipeline definitions, use a Jenkinsfile , which resides in the root directory of your development sources. @Library ( 'piper-lib-os' ) _ pipeline { agent any stages { stage ( \"prepare\" ) { steps { deleteDir () checkout scm setupCommonPipelineEnvironment script: this } } stage ( 'build' ) { steps { // It depends on your project, what needs to be done here. Maybe it's sufficient to zip the sources mtaBuild script: this } } stage ( 'publish' ) { steps { // This uploads the binary into a blob store so that it can be attached to a transport request later sh \"curl --upload-file <deployable> <BLOB_STORE/path/to/application>\" // OR (in case there is no BLOB_STORE available) // This makes the artifact available on Nexus. The URL is the following: // <JENKINS_URL>/job/<JOB_NAME>/<BUILD_NUMBER>/artifact/<DEPLOYABLE>. Nota bene: this format is not an Jenkins API. // The build number can be retrieved during the build through ${currentBuild.number} archiveArtifacts artifacts: < deployable > } } // This attaches the deployable to a transport request stage ( 'attach' ) { steps { transportRequestUploadFile script: this , transportRequestId: '<TRANSPORT_REQUEST_ID>' , // This can be omitted if present inside a Git commit message applicationUrl: '<THE_URL_TO_THE_DEPLOYABLE_ACCORDING_TO_PUBLISH_STAGE>' } } } } Configuration ( .pipeline/config.yml ) \u00b6 This is a basic configuration example, which is also located in the sources of the project. general : changeManagement : type : 'RFC' endpoint : 'the RFC endpoint' # e.g. example.com' credentialsId : 'RFC' # The ID under which the credentials are provided on Jenkins defaults to 'CM' rfc : developmentInstance : '01' # needs to be adjusted developmentClient : '001' # needs to be adjusted docker : image : '<imageId>' # the image needs to be built on user side. The corresponding ID needs to be provided here. options : [] envVars : {} pullImage : true|false # true if the image is provided by a company-specific Docker registry steps : transportRequestUploadFile : codePage : <the code page>, # e.g. 'Cp1252' acceptUnixStyleLineEndings : true|false applicationName : '/your/application/name' applicationDescription : 'Application description' abapPackage : '/abap/package' Upload via ODATA \u00b6 Jenkinsfile \u00b6 Following the convention for pipeline definitions, use a Jenkinsfile , which resides in the root directory of your development sources. @Library ( 'piper-lib-os' ) _ pipeline { agent any stages { stage ( \"prepare\" ) { steps { deleteDir () checkout scm setupCommonPipelineEnvironment script: this } } stage ( 'build' ) { steps { // It depends on your project, what needs to be done here. Maybe it's sufficient to zip the sources mtaBuild script: this } } // This attaches the deployable to a transport request, // if you have a prior call to mtaBuild, this step sets the deployable stage ( 'attach' ) { steps { transportRequestUploadFile script: this , transportRequestId: '<TRANSPORT_REQUEST_ID>' // This can be omitted if present inside a Git commit message } } } } Configuration ( .pipeline/config.yml ) \u00b6 This is a basic configuration example, which is also located in the sources of the project. general : changeManagement : type : 'CTS' endpoint : 'the ODATA endpoint' # e.g. 'http://example.org/sap/opu/odata/SAP/SCTS_CLOUD_API_ODATA_SRV/' credentialsId : 'CTS' # The ID under which the credentials are provided on Jenkins defaults to 'CM' clientOpts : '' # additional java options, e.g. '-Djavax.net.ssl.trustStore=/path/to/truststore.jks' Parameters \u00b6 For the detailed description of the relevant parameters, see: mtaBuild transportRequestUploadFile","title":"Build an SAP Fiori Application and Attach It to a Transport Request on an ABAP System with Jenkins"},{"location":"scenarios/upload-to-transportrequest/Readme/#build-an-sap-fiori-application-and-attach-it-to-a-transport-request-on-an-abap-system-with-jenkins","text":"Build an application based on SAPUI5 or SAP Fiori with Jenkins and attach the build result to a transport request in an SAP ABAP system. Generally, you can choose between two technical ways to attach a binary to an ABAP transport request: We support uploads through RFC and through OData. Which option to use depends on the version of your ABAP system. For AS ABAP 7.50 SP08, 7.51 SP07, or 7.52 SP03 and newer, use the OData-based upload, for older versions, use the RFC-based upload.","title":"Build an SAP Fiori Application and Attach It to a Transport Request on an ABAP System with Jenkins"},{"location":"scenarios/upload-to-transportrequest/Readme/#prerequisites","text":"You have set up your Docker environment . You have set up project \u201cPiper\u201d. See guided tour . You have a transport request. In General it is possible to create a transport request on the fly. But the example here is based on an already existing transport request. Depending on the version of the ABAP system: Docker image for attaching binaries to transport requests via RFC available. Due to legal reasons there is no pre-build docker image. How to create the docker image is explained here","title":"Prerequisites"},{"location":"scenarios/upload-to-transportrequest/Readme/#project-prerequisites","text":"This scenario requires additional files in your project and in the execution environment on your Jenkins instance. On the project level, provide and adjust the following template: File Name Description Position mta.yaml This file controls the behavior of the MTA toolset. Place the mta.yaml file in your application root folder and adjust the values in brackets with your data. Depending on the modules in your MTA, additional configuration files are required, e.g. pom.xml or package.json .","title":"Project Prerequisites"},{"location":"scenarios/upload-to-transportrequest/Readme/#context","text":"This scenario combines various different steps to create a complete pipeline. In this scenario, we want to show how to build an application based on SAPUI5 or SAP Fiori by using the multitarget application (MTA) concept and how to attach the build result to a transport request inside an ABAP system. This document comprises the mtaBuild and the transportRequestUploadFile steps. In case of an RFC based upload the binary is not streamed to the ABAP endpoint. Instead an URL pointing to the binary needs to be provided. Hence the binary must be published first so that it can be accessed via HTTP. This can happen by uploading the binary to a blob store or by archiving the artifact on Jenkins. The corresponding URL needs to be provided when the artifact is attached to the transport request. The transport request can be created on the fly (see transportRequestCreate ) or we can use an already existing transport request. In case we use an already existing transport request Id the transport request Id needs to be provided in the git commit history (see example below) or the transport request Id needs to be provided inside the job (e.g. as a job parameter). The transport request can be closed by the pipeline job (see transportRequestRelease ). This is an example of a Git commit message containing the transport request ID: The headline The body. The blank line above is mandatory (Git standard). TransportRequest: <YOUR TRANSPORT REQUEST ID> By default, the Git commits between the merge base with the base branch (default: master ) and the current branch head are traversed.","title":"Context"},{"location":"scenarios/upload-to-transportrequest/Readme/#screenshot-build-and-deploy-process-in-jenkins","text":"","title":"Screenshot: Build and Deploy Process in Jenkins"},{"location":"scenarios/upload-to-transportrequest/Readme/#examples","text":"","title":"Examples"},{"location":"scenarios/upload-to-transportrequest/Readme/#upload-via-rfc","text":"","title":"Upload via RFC"},{"location":"scenarios/upload-to-transportrequest/Readme/#jenkinsfile","text":"Following the convention for pipeline definitions, use a Jenkinsfile , which resides in the root directory of your development sources. @Library ( 'piper-lib-os' ) _ pipeline { agent any stages { stage ( \"prepare\" ) { steps { deleteDir () checkout scm setupCommonPipelineEnvironment script: this } } stage ( 'build' ) { steps { // It depends on your project, what needs to be done here. Maybe it's sufficient to zip the sources mtaBuild script: this } } stage ( 'publish' ) { steps { // This uploads the binary into a blob store so that it can be attached to a transport request later sh \"curl --upload-file <deployable> <BLOB_STORE/path/to/application>\" // OR (in case there is no BLOB_STORE available) // This makes the artifact available on Nexus. The URL is the following: // <JENKINS_URL>/job/<JOB_NAME>/<BUILD_NUMBER>/artifact/<DEPLOYABLE>. Nota bene: this format is not an Jenkins API. // The build number can be retrieved during the build through ${currentBuild.number} archiveArtifacts artifacts: < deployable > } } // This attaches the deployable to a transport request stage ( 'attach' ) { steps { transportRequestUploadFile script: this , transportRequestId: '<TRANSPORT_REQUEST_ID>' , // This can be omitted if present inside a Git commit message applicationUrl: '<THE_URL_TO_THE_DEPLOYABLE_ACCORDING_TO_PUBLISH_STAGE>' } } } }","title":"Jenkinsfile"},{"location":"scenarios/upload-to-transportrequest/Readme/#configuration-pipelineconfigyml","text":"This is a basic configuration example, which is also located in the sources of the project. general : changeManagement : type : 'RFC' endpoint : 'the RFC endpoint' # e.g. example.com' credentialsId : 'RFC' # The ID under which the credentials are provided on Jenkins defaults to 'CM' rfc : developmentInstance : '01' # needs to be adjusted developmentClient : '001' # needs to be adjusted docker : image : '<imageId>' # the image needs to be built on user side. The corresponding ID needs to be provided here. options : [] envVars : {} pullImage : true|false # true if the image is provided by a company-specific Docker registry steps : transportRequestUploadFile : codePage : <the code page>, # e.g. 'Cp1252' acceptUnixStyleLineEndings : true|false applicationName : '/your/application/name' applicationDescription : 'Application description' abapPackage : '/abap/package'","title":"Configuration (.pipeline/config.yml)"},{"location":"scenarios/upload-to-transportrequest/Readme/#upload-via-odata","text":"","title":"Upload via ODATA"},{"location":"scenarios/upload-to-transportrequest/Readme/#jenkinsfile_1","text":"Following the convention for pipeline definitions, use a Jenkinsfile , which resides in the root directory of your development sources. @Library ( 'piper-lib-os' ) _ pipeline { agent any stages { stage ( \"prepare\" ) { steps { deleteDir () checkout scm setupCommonPipelineEnvironment script: this } } stage ( 'build' ) { steps { // It depends on your project, what needs to be done here. Maybe it's sufficient to zip the sources mtaBuild script: this } } // This attaches the deployable to a transport request, // if you have a prior call to mtaBuild, this step sets the deployable stage ( 'attach' ) { steps { transportRequestUploadFile script: this , transportRequestId: '<TRANSPORT_REQUEST_ID>' // This can be omitted if present inside a Git commit message } } } }","title":"Jenkinsfile"},{"location":"scenarios/upload-to-transportrequest/Readme/#configuration-pipelineconfigyml_1","text":"This is a basic configuration example, which is also located in the sources of the project. general : changeManagement : type : 'CTS' endpoint : 'the ODATA endpoint' # e.g. 'http://example.org/sap/opu/odata/SAP/SCTS_CLOUD_API_ODATA_SRV/' credentialsId : 'CTS' # The ID under which the credentials are provided on Jenkins defaults to 'CM' clientOpts : '' # additional java options, e.g. '-Djavax.net.ssl.trustStore=/path/to/truststore.jks'","title":"Configuration (.pipeline/config.yml)"},{"location":"scenarios/upload-to-transportrequest/Readme/#parameters","text":"For the detailed description of the relevant parameters, see: mtaBuild transportRequestUploadFile","title":"Parameters"},{"location":"scenarios/xsa-deploy/Readme/","text":"Build and Deploy SAP Fiori Applications on SAP HANA Extended Application Services, Advanced Model \u00b6 Build an application based on SAPUI5 or SAP Fiori with Jenkins and deploy the build result to SAP HANA extended application services, advanced model. Prerequisites \u00b6 Docker environment All artifacts referenced during the build are available either on Service Market Place or via public repositories. You have set up Project \u201cPiper\u201d. See guided tour . Docker image for xs deployment is locally available. Due to legal reasons, there is no pre-build Docker image. How to create the Docker image is explained here . Project Prerequisites \u00b6 This scenario requires additional files in your project and in the execution environment on your Jenkins instance. For details see: XSA developer quick start guide . Context \u00b6 This scenario combines various different steps to create a complete pipeline. In this scenario, we want to show how to build a Multitarget Application (MTA) and deploy the build result into an on-prem SAP HANA XS advances system. This document comprises the mtaBuild and the xsDeploy steps. Screenshot: Build and Deploy Process in Jenkins \u00b6 Example \u00b6 Jenkinsfile \u00b6 Following the convention for pipeline definitions, use a Jenkinsfile , which resides in the root directory of your development sources. @Library ( 'piper-lib-os' ) _ pipeline { agent any stages { stage ( \"prepare\" ) { steps { deleteDir () checkout scm setupCommonPipelineEnvironment script: this } } stage ( 'build' ) { steps { mtaBuild script: this } } stage ( 'deploy' ) { steps { xsDeploy script: this } } } } Configuration ( .pipeline/config.yml ) \u00b6 This is a basic configuration example, which is also located in the sources of the project. steps : mtaBuild : buildTarget : 'XSA' xsDeploy : apiUrl : '<API_URL>' # e.g. 'https://example.org:30030' # credentialsId: 'XS' omitted, 'XS' is the default docker : dockerImage : '<ID_OF_THE_DOCKER_IMAGE' # for legal reasons no docker image is provided. # dockerPullImage: true # default: 'false'. Needs to be set to 'true' in case the image is served from a docker registry loginOpts : '' # during setup for non-productive builds we might set here. '--skip-ssl-validation' org : '<ORG_NAME>' space : '<SPACE>' Configuration for the MTA Build \u00b6 Parameter Description buildTarget The target platform to which the mtar can be deployed. In this case, the target platform is XSA . Configuration for the Deployment to XSA \u00b6 Parameter Description credentialsId The Jenkins credentials that contain user and password required for the deployment on SAP Cloud Platform. mode DeployMode. See stepDocu for more details. org The org. See stepDocu for more details. space The space. See stepDocu for more details. Parameters \u00b6 For the detailed description of the relevant parameters, see: mtaBuild xsDeploy","title":"Build and Deploy SAP Fiori Applications on SAP HANA XS Advanced"},{"location":"scenarios/xsa-deploy/Readme/#build-and-deploy-sap-fiori-applications-on-sap-hana-extended-application-services-advanced-model","text":"Build an application based on SAPUI5 or SAP Fiori with Jenkins and deploy the build result to SAP HANA extended application services, advanced model.","title":"Build and Deploy SAP Fiori Applications on SAP HANA Extended Application Services, Advanced Model"},{"location":"scenarios/xsa-deploy/Readme/#prerequisites","text":"Docker environment All artifacts referenced during the build are available either on Service Market Place or via public repositories. You have set up Project \u201cPiper\u201d. See guided tour . Docker image for xs deployment is locally available. Due to legal reasons, there is no pre-build Docker image. How to create the Docker image is explained here .","title":"Prerequisites"},{"location":"scenarios/xsa-deploy/Readme/#project-prerequisites","text":"This scenario requires additional files in your project and in the execution environment on your Jenkins instance. For details see: XSA developer quick start guide .","title":"Project Prerequisites"},{"location":"scenarios/xsa-deploy/Readme/#context","text":"This scenario combines various different steps to create a complete pipeline. In this scenario, we want to show how to build a Multitarget Application (MTA) and deploy the build result into an on-prem SAP HANA XS advances system. This document comprises the mtaBuild and the xsDeploy steps.","title":"Context"},{"location":"scenarios/xsa-deploy/Readme/#screenshot-build-and-deploy-process-in-jenkins","text":"","title":"Screenshot: Build and Deploy Process in Jenkins"},{"location":"scenarios/xsa-deploy/Readme/#example","text":"","title":"Example"},{"location":"scenarios/xsa-deploy/Readme/#jenkinsfile","text":"Following the convention for pipeline definitions, use a Jenkinsfile , which resides in the root directory of your development sources. @Library ( 'piper-lib-os' ) _ pipeline { agent any stages { stage ( \"prepare\" ) { steps { deleteDir () checkout scm setupCommonPipelineEnvironment script: this } } stage ( 'build' ) { steps { mtaBuild script: this } } stage ( 'deploy' ) { steps { xsDeploy script: this } } } }","title":"Jenkinsfile"},{"location":"scenarios/xsa-deploy/Readme/#configuration-pipelineconfigyml","text":"This is a basic configuration example, which is also located in the sources of the project. steps : mtaBuild : buildTarget : 'XSA' xsDeploy : apiUrl : '<API_URL>' # e.g. 'https://example.org:30030' # credentialsId: 'XS' omitted, 'XS' is the default docker : dockerImage : '<ID_OF_THE_DOCKER_IMAGE' # for legal reasons no docker image is provided. # dockerPullImage: true # default: 'false'. Needs to be set to 'true' in case the image is served from a docker registry loginOpts : '' # during setup for non-productive builds we might set here. '--skip-ssl-validation' org : '<ORG_NAME>' space : '<SPACE>'","title":"Configuration (.pipeline/config.yml)"},{"location":"scenarios/xsa-deploy/Readme/#configuration-for-the-mta-build","text":"Parameter Description buildTarget The target platform to which the mtar can be deployed. In this case, the target platform is XSA .","title":"Configuration for the MTA Build"},{"location":"scenarios/xsa-deploy/Readme/#configuration-for-the-deployment-to-xsa","text":"Parameter Description credentialsId The Jenkins credentials that contain user and password required for the deployment on SAP Cloud Platform. mode DeployMode. See stepDocu for more details. org The org. See stepDocu for more details. space The space. See stepDocu for more details.","title":"Configuration for the Deployment to XSA"},{"location":"scenarios/xsa-deploy/Readme/#parameters","text":"For the detailed description of the relevant parameters, see: mtaBuild xsDeploy","title":"Parameters"},{"location":"stages/acceptance/","text":"Acceptance \u00b6 In this stage the application/service is typically deployed and automated acceptance tests are executed. This is to make sure that new functionality is tested end-to-end there is no end-to-end regression in existing functionality Stage Content \u00b6 This stage comprises following steps which are activated depending on your use-case/configuration: step step description cloudFoundryDeploy For Cloud Foundry use-cases: Performs deployment to Cloud Foundry space/org. gaugeExecuteTests Performs behavior-driven tests using Gauge test framework against the deployed application/service. healthExecuteCheck Performs health check in order to prove one aspect of operational readiness. In order to be able to respond to health checks from infrastructure components (like load balancers) it is important to provide one unprotected application endpoint which allows a judgement about the health of your application. multicloudDeploy Can perform both deployments to cloud foundry and neo targets. Preferred over cloudFoundryDeploy and neoDeploy, if configured. neoDeploy For Neo use-cases: Performs deployment to Neo landscape. newmanExecute Performs API testing using Newman against the deployed application/service. npmExecuteEndToEndTests Executes end to end tests by running the npm script 'ci-e2e' defined in the project's package.json file. testsPublishResults Publishes test results to Jenkins. It will automatically be active in cases tests are executed. uiVeri5ExecuteTests Performs end-to-end UI testing using UIVeri5 test framework against the deployed application/service. Stage Activation \u00b6 This stage will be active if any one of the following conditions is met: Stage configuration in config.yml file contains entries for this stage. Any of the conditions are met which are explained in the section Step Activation . Step Activation \u00b6 For this stage no conditions are assigned to steps. Additional Stage Parameters \u00b6 name mandatory default possible values script yes script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. Configuration of Additional Stage Parameters \u00b6 The stage parameters need to be defined in the section stages of config.yml file .","title":"Acceptance Stage"},{"location":"stages/acceptance/#acceptance","text":"In this stage the application/service is typically deployed and automated acceptance tests are executed. This is to make sure that new functionality is tested end-to-end there is no end-to-end regression in existing functionality","title":"Acceptance"},{"location":"stages/acceptance/#stage-content","text":"This stage comprises following steps which are activated depending on your use-case/configuration: step step description cloudFoundryDeploy For Cloud Foundry use-cases: Performs deployment to Cloud Foundry space/org. gaugeExecuteTests Performs behavior-driven tests using Gauge test framework against the deployed application/service. healthExecuteCheck Performs health check in order to prove one aspect of operational readiness. In order to be able to respond to health checks from infrastructure components (like load balancers) it is important to provide one unprotected application endpoint which allows a judgement about the health of your application. multicloudDeploy Can perform both deployments to cloud foundry and neo targets. Preferred over cloudFoundryDeploy and neoDeploy, if configured. neoDeploy For Neo use-cases: Performs deployment to Neo landscape. newmanExecute Performs API testing using Newman against the deployed application/service. npmExecuteEndToEndTests Executes end to end tests by running the npm script 'ci-e2e' defined in the project's package.json file. testsPublishResults Publishes test results to Jenkins. It will automatically be active in cases tests are executed. uiVeri5ExecuteTests Performs end-to-end UI testing using UIVeri5 test framework against the deployed application/service.","title":"Stage Content"},{"location":"stages/acceptance/#stage-activation","text":"This stage will be active if any one of the following conditions is met: Stage configuration in config.yml file contains entries for this stage. Any of the conditions are met which are explained in the section Step Activation .","title":"Stage Activation"},{"location":"stages/acceptance/#step-activation","text":"For this stage no conditions are assigned to steps.","title":"Step Activation"},{"location":"stages/acceptance/#additional-stage-parameters","text":"name mandatory default possible values script yes script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters.","title":"Additional Stage Parameters"},{"location":"stages/acceptance/#configuration-of-additional-stage-parameters","text":"The stage parameters need to be defined in the section stages of config.yml file .","title":"Configuration of Additional Stage Parameters"},{"location":"stages/additionalunittests/","text":"Additional Unit Tests \u00b6 In this stage unit tests, which can not or should not be executed in the central build environment, are executed. These are for example Karma(OPA5 & QUnit) tests. Stage Content \u00b6 This stage comprises following steps which are activated depending on your use-case/configuration: step step description batsExecuteTests Executes bats tests which are for example suitable for testing Docker images via a shell. karmaExecuteTests Executes karma tests which are for example suitable for OPA5 testing as well as QUnit testing of SAP UI5 apps. testsPublishResults Publishes test results to Jenkins. It will automatically be active in cases tests are executed. Stage Activation \u00b6 This stage will be active if any one of the following conditions is met: Stage configuration in config.yml file contains entries for this stage. Any of the conditions are met which are explained in the section Step Activation . Step Activation \u00b6 For this stage no conditions are assigned to steps. Additional Stage Parameters \u00b6 name mandatory default possible values script yes script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. Configuration of Additional Stage Parameters \u00b6 The stage parameters need to be defined in the section stages of config.yml file .","title":"Additional Unit Test Stage"},{"location":"stages/additionalunittests/#additional-unit-tests","text":"In this stage unit tests, which can not or should not be executed in the central build environment, are executed. These are for example Karma(OPA5 & QUnit) tests.","title":"Additional Unit Tests"},{"location":"stages/additionalunittests/#stage-content","text":"This stage comprises following steps which are activated depending on your use-case/configuration: step step description batsExecuteTests Executes bats tests which are for example suitable for testing Docker images via a shell. karmaExecuteTests Executes karma tests which are for example suitable for OPA5 testing as well as QUnit testing of SAP UI5 apps. testsPublishResults Publishes test results to Jenkins. It will automatically be active in cases tests are executed.","title":"Stage Content"},{"location":"stages/additionalunittests/#stage-activation","text":"This stage will be active if any one of the following conditions is met: Stage configuration in config.yml file contains entries for this stage. Any of the conditions are met which are explained in the section Step Activation .","title":"Stage Activation"},{"location":"stages/additionalunittests/#step-activation","text":"For this stage no conditions are assigned to steps.","title":"Step Activation"},{"location":"stages/additionalunittests/#additional-stage-parameters","text":"name mandatory default possible values script yes script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters.","title":"Additional Stage Parameters"},{"location":"stages/additionalunittests/#configuration-of-additional-stage-parameters","text":"The stage parameters need to be defined in the section stages of config.yml file .","title":"Configuration of Additional Stage Parameters"},{"location":"stages/build/","text":"Build \u00b6 In this stage a build is executed which typically also executes tests and code checks. They type of build is defined using the configuration buildTool , see also step buildExecute Stage Content \u00b6 This stage comprises following steps which are activated depending on your use-case/configuration: step step description buildExecute Starts build execution. This is always being executed. checksPublishResults Publishes check results to Jenkins. It will always be active. pipelineStashFilesAfterBuild Executes stashing of files after build execution.<br / Build results are stashed with stash name buildResult . Note: Please make sure that your build artifacts are contained here since this stash is the foundation for subsequent tests and checks, e.g. deployment to a test landscape. testsPublishResults Publishes test results to Jenkins. It will always be active. Stage Activation \u00b6 This stage will be active if any one of the following conditions is met: Stage configuration in config.yml file contains entries for this stage. Any of the conditions are met which are explained in the section Step Activation . Step Activation \u00b6 For this stage no conditions are assigned to steps. Additional Stage Parameters \u00b6 name mandatory default possible values script yes script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. Configuration of Additional Stage Parameters \u00b6 The stage parameters need to be defined in the section stages of config.yml file .","title":"Build Stage"},{"location":"stages/build/#build","text":"In this stage a build is executed which typically also executes tests and code checks. They type of build is defined using the configuration buildTool , see also step buildExecute","title":"Build"},{"location":"stages/build/#stage-content","text":"This stage comprises following steps which are activated depending on your use-case/configuration: step step description buildExecute Starts build execution. This is always being executed. checksPublishResults Publishes check results to Jenkins. It will always be active. pipelineStashFilesAfterBuild Executes stashing of files after build execution.<br / Build results are stashed with stash name buildResult . Note: Please make sure that your build artifacts are contained here since this stash is the foundation for subsequent tests and checks, e.g. deployment to a test landscape. testsPublishResults Publishes test results to Jenkins. It will always be active.","title":"Stage Content"},{"location":"stages/build/#stage-activation","text":"This stage will be active if any one of the following conditions is met: Stage configuration in config.yml file contains entries for this stage. Any of the conditions are met which are explained in the section Step Activation .","title":"Stage Activation"},{"location":"stages/build/#step-activation","text":"For this stage no conditions are assigned to steps.","title":"Step Activation"},{"location":"stages/build/#additional-stage-parameters","text":"name mandatory default possible values script yes script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters.","title":"Additional Stage Parameters"},{"location":"stages/build/#configuration-of-additional-stage-parameters","text":"The stage parameters need to be defined in the section stages of config.yml file .","title":"Configuration of Additional Stage Parameters"},{"location":"stages/compliance/","text":"Compliance \u00b6 In this stage important compliance-relevant checks will be conducted. Currently, there is no default implementation of the stage. This you can expect soon ... Stage Content \u00b6 This stage comprises following steps which are activated depending on your use-case/configuration: step step description Stage Activation \u00b6 This stage will be active if any one of the following conditions is met: Stage configuration in config.yml file contains entries for this stage. Any of the conditions are met which are explained in the section Step Activation . Step Activation \u00b6 For this stage no conditions are assigned to steps. Additional Stage Parameters \u00b6 name mandatory default possible values script yes script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. Configuration of Additional Stage Parameters \u00b6 The stage parameters need to be defined in the section stages of config.yml file .","title":"Compliance"},{"location":"stages/compliance/#compliance","text":"In this stage important compliance-relevant checks will be conducted. Currently, there is no default implementation of the stage. This you can expect soon ...","title":"Compliance"},{"location":"stages/compliance/#stage-content","text":"This stage comprises following steps which are activated depending on your use-case/configuration: step step description","title":"Stage Content"},{"location":"stages/compliance/#stage-activation","text":"This stage will be active if any one of the following conditions is met: Stage configuration in config.yml file contains entries for this stage. Any of the conditions are met which are explained in the section Step Activation .","title":"Stage Activation"},{"location":"stages/compliance/#step-activation","text":"For this stage no conditions are assigned to steps.","title":"Step Activation"},{"location":"stages/compliance/#additional-stage-parameters","text":"name mandatory default possible values script yes script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters.","title":"Additional Stage Parameters"},{"location":"stages/compliance/#configuration-of-additional-stage-parameters","text":"The stage parameters need to be defined in the section stages of config.yml file .","title":"Configuration of Additional Stage Parameters"},{"location":"stages/confirm/","text":"Confirm \u00b6 In this stage a manual confirmation is requested before processing subsequent stages like Promote and Release . This stage will be active in two scenarios: - manual activation of this stage - in case of an 'UNSTABLE' build (even when manual confirmation is inactive) Stage Content \u00b6 This stage comprises following steps which are activated depending on your use-case/configuration: step step description Stage Activation \u00b6 This stage will be active if any one of the following conditions is met: Stage configuration in config.yml file contains entries for this stage. Any of the conditions are met which are explained in the section Step Activation . Step Activation \u00b6 For this stage no conditions are assigned to steps. Additional Stage Parameters \u00b6 name mandatory default possible values manualConfirmation no true true , false manualConfirmationMessage no Shall we proceed to Promote & Release? manualConfirmationTimeout no 720 script yes manualConfirmation - Specifies if a manual confirmation is active before running the Promote and Release stages of the pipeline. manualConfirmationMessage - Defines message displayed as default manual confirmation. Please note: only used in case pipeline is in state SUCCESSFUL manualConfirmationTimeout - Defines how many hours a manual confirmation is possible for a dedicated pipeline. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. Configuration of Additional Stage Parameters \u00b6 The stage parameters need to be defined in the section stages of config.yml file .","title":"Confirm Stage"},{"location":"stages/confirm/#confirm","text":"In this stage a manual confirmation is requested before processing subsequent stages like Promote and Release . This stage will be active in two scenarios: - manual activation of this stage - in case of an 'UNSTABLE' build (even when manual confirmation is inactive)","title":"Confirm"},{"location":"stages/confirm/#stage-content","text":"This stage comprises following steps which are activated depending on your use-case/configuration: step step description","title":"Stage Content"},{"location":"stages/confirm/#stage-activation","text":"This stage will be active if any one of the following conditions is met: Stage configuration in config.yml file contains entries for this stage. Any of the conditions are met which are explained in the section Step Activation .","title":"Stage Activation"},{"location":"stages/confirm/#step-activation","text":"For this stage no conditions are assigned to steps.","title":"Step Activation"},{"location":"stages/confirm/#additional-stage-parameters","text":"name mandatory default possible values manualConfirmation no true true , false manualConfirmationMessage no Shall we proceed to Promote & Release? manualConfirmationTimeout no 720 script yes manualConfirmation - Specifies if a manual confirmation is active before running the Promote and Release stages of the pipeline. manualConfirmationMessage - Defines message displayed as default manual confirmation. Please note: only used in case pipeline is in state SUCCESSFUL manualConfirmationTimeout - Defines how many hours a manual confirmation is possible for a dedicated pipeline. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters.","title":"Additional Stage Parameters"},{"location":"stages/confirm/#configuration-of-additional-stage-parameters","text":"The stage parameters need to be defined in the section stages of config.yml file .","title":"Configuration of Additional Stage Parameters"},{"location":"stages/examples/","text":"Example Configurations \u00b6 This page shows you some pipeline configuration examples. As Jenkinsfile only following code is required: @Library('piper-lib') _ piperPipeline script: this Pure Pull-Request Voting \u00b6 .pipeline/config.yml: general : buildTool : 'npm' Using custom defaults \u00b6 It is possible to use custom defaults as indicated on the section about Configuration . In order to use a custom defaults only a simple extension to the Jenkinsfile is required: @Library(['piper-lib-os', 'myCustomLibrary']) _ piperPipeline script: this, customDefaults: ['myCustomDefaults.yml'] more examples to come ... \u00b6","title":"Examples"},{"location":"stages/examples/#example-configurations","text":"This page shows you some pipeline configuration examples. As Jenkinsfile only following code is required: @Library('piper-lib') _ piperPipeline script: this","title":"Example Configurations"},{"location":"stages/examples/#pure-pull-request-voting","text":".pipeline/config.yml: general : buildTool : 'npm'","title":"Pure Pull-Request Voting"},{"location":"stages/examples/#using-custom-defaults","text":"It is possible to use custom defaults as indicated on the section about Configuration . In order to use a custom defaults only a simple extension to the Jenkinsfile is required: @Library(['piper-lib-os', 'myCustomLibrary']) _ piperPipeline script: this, customDefaults: ['myCustomDefaults.yml']","title":"Using custom defaults"},{"location":"stages/examples/#more-examples-to-come","text":"","title":"more examples to come ..."},{"location":"stages/init/","text":"Init \u00b6 This stage initializes the pipeline run and prepares further execution. It will check out your repository and perform some steps to initialize your pipeline run. Stage Content \u00b6 This stage comprises following steps which are activated depending on your use-case/configuration: step step description Stage Activation \u00b6 This stage will be active if any one of the following conditions is met: Stage configuration in config.yml file contains entries for this stage. Any of the conditions are met which are explained in the section Step Activation . Step Activation \u00b6 For this stage no conditions are assigned to steps. Additional Stage Parameters \u00b6 name mandatory default possible values buildTool yes docker , kaniko , maven , mta, ``npm productiveBranch no master script yes stashSettings no verbose no true , false buildTool - Defines the build tool used. productiveBranch - Defines the main branch for your pipeline. Typically this is the master branch, which does not need to be set explicitly. Only change this in exceptional cases script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. stashSettings - Defines the library resource containing the stash settings to be performed before and after each stage. Caution: changing the default will break the standard behavior of the pipeline - thus only relevant when including Init stage into custom pipelines! verbose - Whether verbose output should be produced. Configuration of Additional Stage Parameters \u00b6 The stage parameters need to be defined in the section stages of config.yml file .","title":"Init Stage"},{"location":"stages/init/#init","text":"This stage initializes the pipeline run and prepares further execution. It will check out your repository and perform some steps to initialize your pipeline run.","title":"Init"},{"location":"stages/init/#stage-content","text":"This stage comprises following steps which are activated depending on your use-case/configuration: step step description","title":"Stage Content"},{"location":"stages/init/#stage-activation","text":"This stage will be active if any one of the following conditions is met: Stage configuration in config.yml file contains entries for this stage. Any of the conditions are met which are explained in the section Step Activation .","title":"Stage Activation"},{"location":"stages/init/#step-activation","text":"For this stage no conditions are assigned to steps.","title":"Step Activation"},{"location":"stages/init/#additional-stage-parameters","text":"name mandatory default possible values buildTool yes docker , kaniko , maven , mta, ``npm productiveBranch no master script yes stashSettings no verbose no true , false buildTool - Defines the build tool used. productiveBranch - Defines the main branch for your pipeline. Typically this is the master branch, which does not need to be set explicitly. Only change this in exceptional cases script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. stashSettings - Defines the library resource containing the stash settings to be performed before and after each stage. Caution: changing the default will break the standard behavior of the pipeline - thus only relevant when including Init stage into custom pipelines! verbose - Whether verbose output should be produced.","title":"Additional Stage Parameters"},{"location":"stages/init/#configuration-of-additional-stage-parameters","text":"The stage parameters need to be defined in the section stages of config.yml file .","title":"Configuration of Additional Stage Parameters"},{"location":"stages/integration/","text":"Integration \u00b6 The stage allows to execute project-specific integration tests. Typically, integration tests are very project-specific, thus they can be defined here using the stage extension mechanism . Stage Content \u00b6 This stage comprises following steps which are activated depending on your use-case/configuration: step step description mavenExecuteIntegration Runs backend integration tests via the Jacoco Maven-plugin npmExecuteScripts Runs npm scripts to run generic integration tests written on JavaScript testsPublishResults Publishes test results to Jenkins. It will automatically be active in cases tests are executed. Stage Activation \u00b6 This stage will be active if any one of the following conditions is met: Stage configuration in config.yml file contains entries for this stage. Any of the conditions are met which are explained in the section Step Activation . Step Activation \u00b6 For this stage no conditions are assigned to steps. Additional Stage Parameters \u00b6 name mandatory default possible values script yes script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. Configuration of Additional Stage Parameters \u00b6 The stage parameters need to be defined in the section stages of config.yml file .","title":"Integration Stage"},{"location":"stages/integration/#integration","text":"The stage allows to execute project-specific integration tests. Typically, integration tests are very project-specific, thus they can be defined here using the stage extension mechanism .","title":"Integration"},{"location":"stages/integration/#stage-content","text":"This stage comprises following steps which are activated depending on your use-case/configuration: step step description mavenExecuteIntegration Runs backend integration tests via the Jacoco Maven-plugin npmExecuteScripts Runs npm scripts to run generic integration tests written on JavaScript testsPublishResults Publishes test results to Jenkins. It will automatically be active in cases tests are executed.","title":"Stage Content"},{"location":"stages/integration/#stage-activation","text":"This stage will be active if any one of the following conditions is met: Stage configuration in config.yml file contains entries for this stage. Any of the conditions are met which are explained in the section Step Activation .","title":"Stage Activation"},{"location":"stages/integration/#step-activation","text":"For this stage no conditions are assigned to steps.","title":"Step Activation"},{"location":"stages/integration/#additional-stage-parameters","text":"name mandatory default possible values script yes script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters.","title":"Additional Stage Parameters"},{"location":"stages/integration/#configuration-of-additional-stage-parameters","text":"The stage parameters need to be defined in the section stages of config.yml file .","title":"Configuration of Additional Stage Parameters"},{"location":"stages/introduction/","text":"Project \"Piper\" general purpose pipeline \u00b6 The pipeline consists of a sequence of stages where each contains a number of individual steps. First step: Pull Request Pipeline \u00b6 In order to validate pull-requests to your GitHub repository you need to perform two simple steps: 1. Create Pipeline configuration \u00b6 Create a file .pipeline/config.yml in your repository (typically in master branch) with the following content: general : buildTool : 'npm' buildTool Please make sure that you specify the correct build tool. Following are currently supported: docker kaniko maven mta npm If your build tool is not in the list you can still use further options as described for Pull-Request Voting Stage 2. Create Jenkinsfile \u00b6 Create a file called Jenkinsfile in the root of your repository (typically in master branch) with the following content: @Library ( 'piper-lib-os' ) _ piperPipeline script: this There is typically no need to further touch this file Using custom defaults It is possible to overwrite/extend the pipeline defaults with custom defaults. piperPipeline script: this, customDefaults: ['myCustomDefaults.yml'] You find more details about the custom defaults in the configuration section Second step: Prepare pipeline for your main branch. \u00b6 Extend your configuration to also contain git ssh credentials information. Your .pipeline/config.yml should then look like: general : buildTool : 'npm' gitSshKeyCredentialsId : 'credentials-id-in-jenkins' gitSshKeyCredentialsId The pointer to the Jenkins credentials containing your ssh private key is an important part of the pipeline run. The credentials are for example required to push automatic versioning information to your GitHub repository. Subsequent steps: Configure individual stages \u00b6 The stages of the pipeline can be configured individually. As a general rule of thumb, only stages with an existing configuration are executed. If no dedicated configuration is required for a step, the precence of relevant files in the repository trigger the step execution. This smart and context-aware way of configuration allows you an iterative approach to configuring the individual steps. The pipeline comprises following stages: Init \u00b6 This stage takes care that the pipeline is initialized correctly. It will for example: Check out the GitHub repository Set up the overall pipeline configuration and perform basic checks Identify which pipeline stages to execute based on the configuration and file patterns Perform automatic versioning of the software artifact in case the master branch pipeline is executed. You find details about this stage on Init Stage Details Pull-Request Voting \u00b6 This stage is responsible for validating pull-requests, see also above. You find further details about this stage on the page Pull-Request Voting . Build \u00b6 In this stage the build of the software artifact is performed. The build artifact will be stash ed for use in subsequent stages. For Docker builds the build result will be uploaded to a container registry (as per your configuration). Afterwards the results of static checks & unit tests are published on the Jenkins. You find details about this stage on the page Build . Additional Unit Tests \u00b6 In this stage additional unit-like tests are executed which should not run during the build. Currently, this stage holds the execution of a Karma runner which allows for qUnit tests OPA5 (One Page Acceptance tests) for SAP UI5 You find details about this stage on the page Additional Unit Tests . Integration \u00b6 In the Integration stage a custom integration test script can be executed. Acceptance \u00b6 Default implementation will come soon ... Currently custom logic can be added using the stage extension mechanism . Security \u00b6 Default implementation will come soon ... Currently custom logic can be added using the stage extension mechanism . Performance \u00b6 Default implementation will come soon ... Currently custom logic can be added using the stage extension mechanism . Compliance \u00b6 Default implementation will come soon ... Currently custom logic can be added using the stage extension mechanism . Confirm \u00b6 The Confirm stage , if executed, stops the pipeline execution and asks for manual confirmation before proceeding to the stages Promote and Release . Promote \u00b6 Default implementation will come soon ... Currently custom logic can be added using the stage extension mechanism . Release \u00b6 Default implementation will come soon ... Currently custom logic can be added using the stage extension mechanism .","title":"Introduction"},{"location":"stages/introduction/#project-piper-general-purpose-pipeline","text":"The pipeline consists of a sequence of stages where each contains a number of individual steps.","title":"Project \"Piper\" general purpose pipeline"},{"location":"stages/introduction/#first-step-pull-request-pipeline","text":"In order to validate pull-requests to your GitHub repository you need to perform two simple steps:","title":"First step: Pull Request Pipeline"},{"location":"stages/introduction/#1-create-pipeline-configuration","text":"Create a file .pipeline/config.yml in your repository (typically in master branch) with the following content: general : buildTool : 'npm' buildTool Please make sure that you specify the correct build tool. Following are currently supported: docker kaniko maven mta npm If your build tool is not in the list you can still use further options as described for Pull-Request Voting Stage","title":"1. Create Pipeline configuration"},{"location":"stages/introduction/#2-create-jenkinsfile","text":"Create a file called Jenkinsfile in the root of your repository (typically in master branch) with the following content: @Library ( 'piper-lib-os' ) _ piperPipeline script: this There is typically no need to further touch this file Using custom defaults It is possible to overwrite/extend the pipeline defaults with custom defaults. piperPipeline script: this, customDefaults: ['myCustomDefaults.yml'] You find more details about the custom defaults in the configuration section","title":"2. Create Jenkinsfile"},{"location":"stages/introduction/#second-step-prepare-pipeline-for-your-main-branch","text":"Extend your configuration to also contain git ssh credentials information. Your .pipeline/config.yml should then look like: general : buildTool : 'npm' gitSshKeyCredentialsId : 'credentials-id-in-jenkins' gitSshKeyCredentialsId The pointer to the Jenkins credentials containing your ssh private key is an important part of the pipeline run. The credentials are for example required to push automatic versioning information to your GitHub repository.","title":"Second step: Prepare pipeline for your main branch."},{"location":"stages/introduction/#subsequent-steps-configure-individual-stages","text":"The stages of the pipeline can be configured individually. As a general rule of thumb, only stages with an existing configuration are executed. If no dedicated configuration is required for a step, the precence of relevant files in the repository trigger the step execution. This smart and context-aware way of configuration allows you an iterative approach to configuring the individual steps. The pipeline comprises following stages:","title":"Subsequent steps: Configure individual stages"},{"location":"stages/introduction/#init","text":"This stage takes care that the pipeline is initialized correctly. It will for example: Check out the GitHub repository Set up the overall pipeline configuration and perform basic checks Identify which pipeline stages to execute based on the configuration and file patterns Perform automatic versioning of the software artifact in case the master branch pipeline is executed. You find details about this stage on Init Stage Details","title":"Init"},{"location":"stages/introduction/#pull-request-voting","text":"This stage is responsible for validating pull-requests, see also above. You find further details about this stage on the page Pull-Request Voting .","title":"Pull-Request Voting"},{"location":"stages/introduction/#build","text":"In this stage the build of the software artifact is performed. The build artifact will be stash ed for use in subsequent stages. For Docker builds the build result will be uploaded to a container registry (as per your configuration). Afterwards the results of static checks & unit tests are published on the Jenkins. You find details about this stage on the page Build .","title":"Build"},{"location":"stages/introduction/#additional-unit-tests","text":"In this stage additional unit-like tests are executed which should not run during the build. Currently, this stage holds the execution of a Karma runner which allows for qUnit tests OPA5 (One Page Acceptance tests) for SAP UI5 You find details about this stage on the page Additional Unit Tests .","title":"Additional Unit Tests"},{"location":"stages/introduction/#integration","text":"In the Integration stage a custom integration test script can be executed.","title":"Integration"},{"location":"stages/introduction/#acceptance","text":"Default implementation will come soon ... Currently custom logic can be added using the stage extension mechanism .","title":"Acceptance"},{"location":"stages/introduction/#security","text":"Default implementation will come soon ... Currently custom logic can be added using the stage extension mechanism .","title":"Security"},{"location":"stages/introduction/#performance","text":"Default implementation will come soon ... Currently custom logic can be added using the stage extension mechanism .","title":"Performance"},{"location":"stages/introduction/#compliance","text":"Default implementation will come soon ... Currently custom logic can be added using the stage extension mechanism .","title":"Compliance"},{"location":"stages/introduction/#confirm","text":"The Confirm stage , if executed, stops the pipeline execution and asks for manual confirmation before proceeding to the stages Promote and Release .","title":"Confirm"},{"location":"stages/introduction/#promote","text":"Default implementation will come soon ... Currently custom logic can be added using the stage extension mechanism .","title":"Promote"},{"location":"stages/introduction/#release","text":"Default implementation will come soon ... Currently custom logic can be added using the stage extension mechanism .","title":"Release"},{"location":"stages/performance/","text":"Performance \u00b6 In this stage important performance-relevant checks will be conducted. Currently, there is no default implementation of the stage. This you can expect soon ... Stage Content \u00b6 This stage comprises following steps which are activated depending on your use-case/configuration: step step description Stage Activation \u00b6 This stage will be active if any one of the following conditions is met: Stage configuration in config.yml file contains entries for this stage. Any of the conditions are met which are explained in the section Step Activation . Step Activation \u00b6 For this stage no conditions are assigned to steps. Additional Stage Parameters \u00b6 name mandatory default possible values script yes script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. Configuration of Additional Stage Parameters \u00b6 The stage parameters need to be defined in the section stages of config.yml file .","title":"Performance Stage"},{"location":"stages/performance/#performance","text":"In this stage important performance-relevant checks will be conducted. Currently, there is no default implementation of the stage. This you can expect soon ...","title":"Performance"},{"location":"stages/performance/#stage-content","text":"This stage comprises following steps which are activated depending on your use-case/configuration: step step description","title":"Stage Content"},{"location":"stages/performance/#stage-activation","text":"This stage will be active if any one of the following conditions is met: Stage configuration in config.yml file contains entries for this stage. Any of the conditions are met which are explained in the section Step Activation .","title":"Stage Activation"},{"location":"stages/performance/#step-activation","text":"For this stage no conditions are assigned to steps.","title":"Step Activation"},{"location":"stages/performance/#additional-stage-parameters","text":"name mandatory default possible values script yes script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters.","title":"Additional Stage Parameters"},{"location":"stages/performance/#configuration-of-additional-stage-parameters","text":"The stage parameters need to be defined in the section stages of config.yml file .","title":"Configuration of Additional Stage Parameters"},{"location":"stages/promote/","text":"Promote \u00b6 This stage is responsible to promote build artifacts to an artifact repository / container registry where they can be used from in production deployments. Stage Content \u00b6 This stage comprises following steps which are activated depending on your use-case/configuration: step step description containerPushToRegistry For Docker builds: pushes the Docker image to a container registry. Stage Activation \u00b6 This stage will be active if any one of the following conditions is met: Stage configuration in config.yml file contains entries for this stage. Any of the conditions are met which are explained in the section Step Activation . Step Activation \u00b6 For this stage no conditions are assigned to steps. Additional Stage Parameters \u00b6 name mandatory default possible values script yes script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. Configuration of Additional Stage Parameters \u00b6 The stage parameters need to be defined in the section stages of config.yml file .","title":"Promote Stage"},{"location":"stages/promote/#promote","text":"This stage is responsible to promote build artifacts to an artifact repository / container registry where they can be used from in production deployments.","title":"Promote"},{"location":"stages/promote/#stage-content","text":"This stage comprises following steps which are activated depending on your use-case/configuration: step step description containerPushToRegistry For Docker builds: pushes the Docker image to a container registry.","title":"Stage Content"},{"location":"stages/promote/#stage-activation","text":"This stage will be active if any one of the following conditions is met: Stage configuration in config.yml file contains entries for this stage. Any of the conditions are met which are explained in the section Step Activation .","title":"Stage Activation"},{"location":"stages/promote/#step-activation","text":"For this stage no conditions are assigned to steps.","title":"Step Activation"},{"location":"stages/promote/#additional-stage-parameters","text":"name mandatory default possible values script yes script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters.","title":"Additional Stage Parameters"},{"location":"stages/promote/#configuration-of-additional-stage-parameters","text":"The stage parameters need to be defined in the section stages of config.yml file .","title":"Configuration of Additional Stage Parameters"},{"location":"stages/prvoting/","text":"Pull-Request Voting \u00b6 This stage is executed for every pull-request. For non-Docker builds it will execute the respective build (including unit tests, static checks, ...). Build Tool not in the list? For build tools which are currently not in the list a custom dockerImage can be used with a custom dockerCommand as per step buildExecute For buildTool: docker a local Docker build will be executed in case a Docker deamon is available, if not buildTool: 'kaniko' will be used instead. Advanced Pull-Request Voting \u00b6 It is possible to trigger dedicated tests/checks pull request comments pull request labels Following steps are currently supported step name comment pull-request label karmaExecuteTests /piper karma pr_karma whitesourceExecuteScan /piper whitesource pr_whitesource Stage Content \u00b6 This stage comprises following steps which are activated depending on your use-case/configuration: step step description buildExecute Triggers the build execution. checksPublishResults Publishes check results to Jenkins. It will always be active. karmaExecuteTests Executes karma tests. For example suitable for OPA5 testing as well as QUnit testing of SAP UI5 apps. This step is not active by default. It can be activated by: * using pull request comments or pull request lables (see Advanced Pull-Request Voting . * explicit activation via stage configuration. testsPublishResults Publishes test results to Jenkins. It will always be active. whitesourceExecuteScan Executes a WhiteSource scan This step is not active by default. It can be activated by: * using pull request comments or pull request lables (see Advanced Pull-Request Voting . * explicit activation via stage configuration. Stage Activation \u00b6 This stage will be active if any one of the following conditions is met: Stage configuration in config.yml file contains entries for this stage. Any of the conditions are met which are explained in the section Step Activation . Step Activation \u00b6 For this stage no conditions are assigned to steps. Additional Stage Parameters \u00b6 name mandatory default possible values buildTool no docker , kaniko , maven , mta , npm script yes buildTool - Defines the build tool used. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. Configuration of Additional Stage Parameters \u00b6 The stage parameters need to be defined in the section stages of config.yml file .","title":"Pull-Request Voting Stage"},{"location":"stages/prvoting/#pull-request-voting","text":"This stage is executed for every pull-request. For non-Docker builds it will execute the respective build (including unit tests, static checks, ...). Build Tool not in the list? For build tools which are currently not in the list a custom dockerImage can be used with a custom dockerCommand as per step buildExecute For buildTool: docker a local Docker build will be executed in case a Docker deamon is available, if not buildTool: 'kaniko' will be used instead.","title":"Pull-Request Voting"},{"location":"stages/prvoting/#advanced-pull-request-voting","text":"It is possible to trigger dedicated tests/checks pull request comments pull request labels Following steps are currently supported step name comment pull-request label karmaExecuteTests /piper karma pr_karma whitesourceExecuteScan /piper whitesource pr_whitesource","title":"Advanced Pull-Request Voting"},{"location":"stages/prvoting/#stage-content","text":"This stage comprises following steps which are activated depending on your use-case/configuration: step step description buildExecute Triggers the build execution. checksPublishResults Publishes check results to Jenkins. It will always be active. karmaExecuteTests Executes karma tests. For example suitable for OPA5 testing as well as QUnit testing of SAP UI5 apps. This step is not active by default. It can be activated by: * using pull request comments or pull request lables (see Advanced Pull-Request Voting . * explicit activation via stage configuration. testsPublishResults Publishes test results to Jenkins. It will always be active. whitesourceExecuteScan Executes a WhiteSource scan This step is not active by default. It can be activated by: * using pull request comments or pull request lables (see Advanced Pull-Request Voting . * explicit activation via stage configuration.","title":"Stage Content"},{"location":"stages/prvoting/#stage-activation","text":"This stage will be active if any one of the following conditions is met: Stage configuration in config.yml file contains entries for this stage. Any of the conditions are met which are explained in the section Step Activation .","title":"Stage Activation"},{"location":"stages/prvoting/#step-activation","text":"For this stage no conditions are assigned to steps.","title":"Step Activation"},{"location":"stages/prvoting/#additional-stage-parameters","text":"name mandatory default possible values buildTool no docker , kaniko , maven , mta , npm script yes buildTool - Defines the build tool used. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters.","title":"Additional Stage Parameters"},{"location":"stages/prvoting/#configuration-of-additional-stage-parameters","text":"The stage parameters need to be defined in the section stages of config.yml file .","title":"Configuration of Additional Stage Parameters"},{"location":"stages/release/","text":"Release \u00b6 This stage is responsible to release/deploy artifacts into your productive landscape. Stage Content \u00b6 This stage comprises following steps which are activated depending on your use-case/configuration: step step description cloudFoundryDeploy For Cloud Foundry use-cases: Performs deployment to Cloud Foundry space/org. githubPublishRelease Publishes release information to GitHub. healthExecuteCheck Performs health check in order to prove that deployment was successful. multicloudDeploy Can perform both to cloud foundry and neo targets. Preferred over cloudFoundryDeploy and neoDeploy, if configured. neoDeploy For Neo use-cases: Performs deployment to Neo landscape. npmExecuteEndToEndTests Executes smoke tests by running the npm script 'ci-smoke' defined in the project's package.json file. tmsUpload For TMS use-cases: Performs upload to Transport Management Service node Stage Activation \u00b6 This stage will be active if any one of the following conditions is met: Stage configuration in config.yml file contains entries for this stage. Any of the conditions are met which are explained in the section Step Activation . Step Activation \u00b6 For this stage no conditions are assigned to steps. Additional Stage Parameters \u00b6 name mandatory default possible values script yes script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. Configuration of Additional Stage Parameters \u00b6 The stage parameters need to be defined in the section stages of config.yml file .","title":"Release Stage"},{"location":"stages/release/#release","text":"This stage is responsible to release/deploy artifacts into your productive landscape.","title":"Release"},{"location":"stages/release/#stage-content","text":"This stage comprises following steps which are activated depending on your use-case/configuration: step step description cloudFoundryDeploy For Cloud Foundry use-cases: Performs deployment to Cloud Foundry space/org. githubPublishRelease Publishes release information to GitHub. healthExecuteCheck Performs health check in order to prove that deployment was successful. multicloudDeploy Can perform both to cloud foundry and neo targets. Preferred over cloudFoundryDeploy and neoDeploy, if configured. neoDeploy For Neo use-cases: Performs deployment to Neo landscape. npmExecuteEndToEndTests Executes smoke tests by running the npm script 'ci-smoke' defined in the project's package.json file. tmsUpload For TMS use-cases: Performs upload to Transport Management Service node","title":"Stage Content"},{"location":"stages/release/#stage-activation","text":"This stage will be active if any one of the following conditions is met: Stage configuration in config.yml file contains entries for this stage. Any of the conditions are met which are explained in the section Step Activation .","title":"Stage Activation"},{"location":"stages/release/#step-activation","text":"For this stage no conditions are assigned to steps.","title":"Step Activation"},{"location":"stages/release/#additional-stage-parameters","text":"name mandatory default possible values script yes script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters.","title":"Additional Stage Parameters"},{"location":"stages/release/#configuration-of-additional-stage-parameters","text":"The stage parameters need to be defined in the section stages of config.yml file .","title":"Configuration of Additional Stage Parameters"},{"location":"stages/security/","text":"Security \u00b6 In this stage important security-relevant checks will be conducted. This is to achieve a decent level of security for your application. Stage Content \u00b6 This stage comprises following steps which are activated depending on your use-case/configuration: step step description checkmarxExecuteScan Executes a Checkmarx scan fortifyExecuteScan Executes a Fortify scan whitesourceExecuteScan Executes a WhiteSource scan Stage Activation \u00b6 This stage will be active if any one of the following conditions is met: Stage configuration in config.yml file contains entries for this stage. Any of the conditions are met which are explained in the section Step Activation . Step Activation \u00b6 For this stage no conditions are assigned to steps. Additional Stage Parameters \u00b6 name mandatory default possible values script yes script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. Configuration of Additional Stage Parameters \u00b6 The stage parameters need to be defined in the section stages of config.yml file .","title":"Security Stage"},{"location":"stages/security/#security","text":"In this stage important security-relevant checks will be conducted. This is to achieve a decent level of security for your application.","title":"Security"},{"location":"stages/security/#stage-content","text":"This stage comprises following steps which are activated depending on your use-case/configuration: step step description checkmarxExecuteScan Executes a Checkmarx scan fortifyExecuteScan Executes a Fortify scan whitesourceExecuteScan Executes a WhiteSource scan","title":"Stage Content"},{"location":"stages/security/#stage-activation","text":"This stage will be active if any one of the following conditions is met: Stage configuration in config.yml file contains entries for this stage. Any of the conditions are met which are explained in the section Step Activation .","title":"Stage Activation"},{"location":"stages/security/#step-activation","text":"For this stage no conditions are assigned to steps.","title":"Step Activation"},{"location":"stages/security/#additional-stage-parameters","text":"name mandatory default possible values script yes script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters.","title":"Additional Stage Parameters"},{"location":"stages/security/#configuration-of-additional-stage-parameters","text":"The stage parameters need to be defined in the section stages of config.yml file .","title":"Configuration of Additional Stage Parameters"},{"location":"steps/abapEnvironmentCheckoutBranch/","text":"abapEnvironmentCheckoutBranch \u00b6 Switches between branches of a git repository on a SAP Cloud Platform ABAP Environment system Description \u00b6 This step switches between branches of a git repository (Software Component) on a SAP Cloud Platform ABAP Environment system. Please provide either of the following options: The host and credentials the Cloud Platform ABAP Environment system itself. The credentials must be configured for the Communication Scenario SAP_COM_0510. The Cloud Foundry parameters (API endpoint, organization, space), credentials, the service instance for the ABAP service and the service key for the Communication Scenario SAP_COM_0510. Only provide one of those options with the respective credentials. If all values are provided, the direct communication (via host) has priority. Usage \u00b6 We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line . Jenkins pipelines \u00b6 abapEnvironmentCheckoutBranch script: this Command line \u00b6 piper abapEnvironmentCheckoutBranch Prerequisites \u00b6 A SAP Cloud Platform ABAP Environment system is available. On this system, a Communication User , a Communication System and a Communication Arrangement is setup for the Communication Scenario \"SAP Cloud Platform ABAP Environment - Software Component Test Integration (SAP_COM_0510)\". This can be done manually through the respective applications on the SAP Cloud Platform ABAP Environment System or through creating a service key for the system on cloud foundry with the parameters {\"scenario_id\": \"SAP_COM_0510\", \"type\": \"basic\"}. In a pipeline, you can do this with the step cloudFoundryCreateServiceKey . In addition, the software component should be cloned into the system instance. You can do this with the step abapEnvironmentPullGitRepo . Parameters \u00b6 Overview \u00b6 Name Mandatory Additional information abapCredentialsId yes id of credentials ( using credentials ) branchName yes password yes pass via ENV or Jenkins credentials repositoryName yes script yes reference to Jenkins main pipeline script username yes pass via ENV or Jenkins credentials cfApiEndpoint no cfOrg no cfServiceInstance no cfServiceKeyName no cfSpace no containerCommand no containerShell no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no dockerVolumeBind no dockerWorkspace no host no verbose no activates debug output Details \u00b6 abapCredentialsId \u00b6 Jenkins-specific: Used for proper environment setup. Jenkins credentials ID containing user and password to authenticate to the Cloud Platform ABAP Environment system or the Cloud Foundry API back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none branchName \u00b6 Specifies a Branch of a Repository (Software Component) on the SAP Cloud Platform ABAP Environment system back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_branchName (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none cfApiEndpoint \u00b6 Cloud Foundry API Enpoint back to overview Scope Details Aliases cloudFoundry/apiEndpoint Type string Mandatory no Default $PIPER_cfApiEndpoint (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none cfOrg \u00b6 Cloud Foundry target organization back to overview Scope Details Aliases cloudFoundry/org Type string Mandatory no Default $PIPER_cfOrg (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none cfServiceInstance \u00b6 Cloud Foundry Service Instance back to overview Scope Details Aliases cloudFoundry/serviceInstance Type string Mandatory no Default $PIPER_cfServiceInstance (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none cfServiceKeyName \u00b6 Cloud Foundry Service Key back to overview Scope Details Aliases - cloudFoundry/serviceKey - cloudFoundry/serviceKeyName - cfServiceKeyName Type string Mandatory no Default $PIPER_cfServiceKeyName (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none cfSpace \u00b6 Cloud Foundry target space back to overview Scope Details Aliases cloudFoundry/space Type string Mandatory no Default $PIPER_cfSpace (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none containerCommand \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default (/usr/bin/tail -f /dev/null). back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none containerShell \u00b6 Jenkins-specific: Used for proper environment setup. Allows to specify the shell to be executed for container with containerName. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerEnvVars \u00b6 Jenkins-specific: Used for proper environment setup. Environment variables to set in the container, e.g. [http_proxy: \"proxy:8080\"]. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerImage \u00b6 Jenkins-specific: Used for proper environment setup. Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerName \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Name of the container launching dockerImage. SideCar only: Name of the container in local network. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerOptions \u00b6 Jenkins-specific: Used for proper environment setup. Docker options to be set when starting the container. back to overview Scope Details Aliases - Type []string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerPullImage \u00b6 Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerVolumeBind \u00b6 Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the docker container. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerWorkspace \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none host \u00b6 Specifies the host address of the SAP Cloud Platform ABAP Environment system back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_host (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none password \u00b6 Password for either the Cloud Foundry API or the Communication Arrangement for SAP_COM_0510 back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_password (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none repositoryName \u00b6 Specifies a Repository (Software Component) on the SAP Cloud Platform ABAP Environment system back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_repositoryName (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none script \u00b6 Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none username \u00b6 User for either the Cloud Foundry API or the Communication Arrangement for SAP_COM_0510 back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_username (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none verbose \u00b6 verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none \u00b6 Example: Configuration in the config.yml \u00b6 The recommended way to configure your pipeline is via the config.yml file. In this case, calling the step in the Jenkinsfile is reduced to one line: abapEnvironmentCheckoutBranch script: this If you want to provide the host and credentials of the Communication Arrangement directly, the configuration could look as follows: steps : abapEnvironmentCheckoutBranch : repositoryName : '/DMO/GIT_REPOSITORY' branchName : 'my-demo-branch' abapCredentialsId : 'abapCredentialsId' host : '1234-abcd-5678-efgh-ijk.abap.eu10.hana.ondemand.com' Please note that the branchName parameter specifies the target branch you want to switch on. Also keep in mind that the repositoryName parameter must define a single repository. If you want to read the host and credentials from the cloud foundry service key of the respective instance, the configuration could look as follows: steps : abapEnvironmentCheckoutBranch : repositoryName : '/DMO/GIT_REPOSITORY' branchName : 'my-demo-branch' cfCredentialsId : 'cfCredentialsId' cfApiEndpoint : 'https://test.server.com' cfOrg : 'cfOrg' cfSpace : 'cfSpace' cfServiceInstance : 'cfServiceInstance' cfServiceKeyName : 'cfServiceKeyName' Example: Configuration in the Jenkinsfile \u00b6 It is also possible to call the steps - including all parameters - directly in the Jenkinsfile. In the first example, the host and the credentialsId of the Communication Arrangement are directly provided. abapEnvironmentCheckoutBranach ( script: this , repositoryName: '/DMO/GIT_REPOSITORY' , branchName: 'my-demo-branch' , abapCredentialsId: 'abapCredentialsId' , host: '1234-abcd-5678-efgh-ijk.abap.eu10.hana.ondemand.com' ) In the second example, the host and credentialsId will be read from the provided cloud foundry service key of the specified service instance. abapEnvironmentCheckoutBranch ( script: this , repositoryName: '/DMO/GIT_REPOSITORY' , branchName: 'my-demo-branch' abapCredentialsId: 'cfCredentialsId' , cfApiEndpoint: 'https://test.server.com' , cfOrg: 'cfOrg' , cfSpace: 'cfSpace' , cfServiceInstance: 'cfServiceInstance' , cfServiceKeyName: 'cfServiceKeyName' )","title":"abapEnvironmentCheckoutBranch"},{"location":"steps/abapEnvironmentCheckoutBranch/#abapenvironmentcheckoutbranch","text":"Switches between branches of a git repository on a SAP Cloud Platform ABAP Environment system","title":"abapEnvironmentCheckoutBranch"},{"location":"steps/abapEnvironmentCheckoutBranch/#description","text":"This step switches between branches of a git repository (Software Component) on a SAP Cloud Platform ABAP Environment system. Please provide either of the following options: The host and credentials the Cloud Platform ABAP Environment system itself. The credentials must be configured for the Communication Scenario SAP_COM_0510. The Cloud Foundry parameters (API endpoint, organization, space), credentials, the service instance for the ABAP service and the service key for the Communication Scenario SAP_COM_0510. Only provide one of those options with the respective credentials. If all values are provided, the direct communication (via host) has priority.","title":"Description"},{"location":"steps/abapEnvironmentCheckoutBranch/#usage","text":"We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line .","title":"Usage"},{"location":"steps/abapEnvironmentCheckoutBranch/#jenkins-pipelines","text":"abapEnvironmentCheckoutBranch script: this","title":"Jenkins pipelines"},{"location":"steps/abapEnvironmentCheckoutBranch/#command-line","text":"piper abapEnvironmentCheckoutBranch","title":"Command line"},{"location":"steps/abapEnvironmentCheckoutBranch/#prerequisites","text":"A SAP Cloud Platform ABAP Environment system is available. On this system, a Communication User , a Communication System and a Communication Arrangement is setup for the Communication Scenario \"SAP Cloud Platform ABAP Environment - Software Component Test Integration (SAP_COM_0510)\". This can be done manually through the respective applications on the SAP Cloud Platform ABAP Environment System or through creating a service key for the system on cloud foundry with the parameters {\"scenario_id\": \"SAP_COM_0510\", \"type\": \"basic\"}. In a pipeline, you can do this with the step cloudFoundryCreateServiceKey . In addition, the software component should be cloned into the system instance. You can do this with the step abapEnvironmentPullGitRepo .","title":"Prerequisites"},{"location":"steps/abapEnvironmentCheckoutBranch/#parameters","text":"","title":"Parameters"},{"location":"steps/abapEnvironmentCheckoutBranch/#overview","text":"Name Mandatory Additional information abapCredentialsId yes id of credentials ( using credentials ) branchName yes password yes pass via ENV or Jenkins credentials repositoryName yes script yes reference to Jenkins main pipeline script username yes pass via ENV or Jenkins credentials cfApiEndpoint no cfOrg no cfServiceInstance no cfServiceKeyName no cfSpace no containerCommand no containerShell no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no dockerVolumeBind no dockerWorkspace no host no verbose no activates debug output","title":"Overview"},{"location":"steps/abapEnvironmentCheckoutBranch/#details","text":"","title":"Details"},{"location":"steps/abapEnvironmentCheckoutBranch/#abapcredentialsid","text":"Jenkins-specific: Used for proper environment setup. Jenkins credentials ID containing user and password to authenticate to the Cloud Platform ABAP Environment system or the Cloud Foundry API back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"abapCredentialsId"},{"location":"steps/abapEnvironmentCheckoutBranch/#branchname","text":"Specifies a Branch of a Repository (Software Component) on the SAP Cloud Platform ABAP Environment system back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_branchName (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"branchName"},{"location":"steps/abapEnvironmentCheckoutBranch/#cfapiendpoint","text":"Cloud Foundry API Enpoint back to overview Scope Details Aliases cloudFoundry/apiEndpoint Type string Mandatory no Default $PIPER_cfApiEndpoint (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"cfApiEndpoint"},{"location":"steps/abapEnvironmentCheckoutBranch/#cforg","text":"Cloud Foundry target organization back to overview Scope Details Aliases cloudFoundry/org Type string Mandatory no Default $PIPER_cfOrg (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"cfOrg"},{"location":"steps/abapEnvironmentCheckoutBranch/#cfserviceinstance","text":"Cloud Foundry Service Instance back to overview Scope Details Aliases cloudFoundry/serviceInstance Type string Mandatory no Default $PIPER_cfServiceInstance (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"cfServiceInstance"},{"location":"steps/abapEnvironmentCheckoutBranch/#cfservicekeyname","text":"Cloud Foundry Service Key back to overview Scope Details Aliases - cloudFoundry/serviceKey - cloudFoundry/serviceKeyName - cfServiceKeyName Type string Mandatory no Default $PIPER_cfServiceKeyName (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"cfServiceKeyName"},{"location":"steps/abapEnvironmentCheckoutBranch/#cfspace","text":"Cloud Foundry target space back to overview Scope Details Aliases cloudFoundry/space Type string Mandatory no Default $PIPER_cfSpace (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"cfSpace"},{"location":"steps/abapEnvironmentCheckoutBranch/#containercommand","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default (/usr/bin/tail -f /dev/null). back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"containerCommand"},{"location":"steps/abapEnvironmentCheckoutBranch/#containershell","text":"Jenkins-specific: Used for proper environment setup. Allows to specify the shell to be executed for container with containerName. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"containerShell"},{"location":"steps/abapEnvironmentCheckoutBranch/#dockerenvvars","text":"Jenkins-specific: Used for proper environment setup. Environment variables to set in the container, e.g. [http_proxy: \"proxy:8080\"]. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerEnvVars"},{"location":"steps/abapEnvironmentCheckoutBranch/#dockerimage","text":"Jenkins-specific: Used for proper environment setup. Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerImage"},{"location":"steps/abapEnvironmentCheckoutBranch/#dockername","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Name of the container launching dockerImage. SideCar only: Name of the container in local network. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerName"},{"location":"steps/abapEnvironmentCheckoutBranch/#dockeroptions","text":"Jenkins-specific: Used for proper environment setup. Docker options to be set when starting the container. back to overview Scope Details Aliases - Type []string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerOptions"},{"location":"steps/abapEnvironmentCheckoutBranch/#dockerpullimage","text":"Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerPullImage"},{"location":"steps/abapEnvironmentCheckoutBranch/#dockervolumebind","text":"Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the docker container. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerVolumeBind"},{"location":"steps/abapEnvironmentCheckoutBranch/#dockerworkspace","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerWorkspace"},{"location":"steps/abapEnvironmentCheckoutBranch/#host","text":"Specifies the host address of the SAP Cloud Platform ABAP Environment system back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_host (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"host"},{"location":"steps/abapEnvironmentCheckoutBranch/#password","text":"Password for either the Cloud Foundry API or the Communication Arrangement for SAP_COM_0510 back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_password (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"password"},{"location":"steps/abapEnvironmentCheckoutBranch/#repositoryname","text":"Specifies a Repository (Software Component) on the SAP Cloud Platform ABAP Environment system back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_repositoryName (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"repositoryName"},{"location":"steps/abapEnvironmentCheckoutBranch/#script","text":"Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none","title":"script"},{"location":"steps/abapEnvironmentCheckoutBranch/#username","text":"User for either the Cloud Foundry API or the Communication Arrangement for SAP_COM_0510 back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_username (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"username"},{"location":"steps/abapEnvironmentCheckoutBranch/#verbose","text":"verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"verbose"},{"location":"steps/abapEnvironmentCheckoutBranch/#example-configuration-in-the-configyml","text":"The recommended way to configure your pipeline is via the config.yml file. In this case, calling the step in the Jenkinsfile is reduced to one line: abapEnvironmentCheckoutBranch script: this If you want to provide the host and credentials of the Communication Arrangement directly, the configuration could look as follows: steps : abapEnvironmentCheckoutBranch : repositoryName : '/DMO/GIT_REPOSITORY' branchName : 'my-demo-branch' abapCredentialsId : 'abapCredentialsId' host : '1234-abcd-5678-efgh-ijk.abap.eu10.hana.ondemand.com' Please note that the branchName parameter specifies the target branch you want to switch on. Also keep in mind that the repositoryName parameter must define a single repository. If you want to read the host and credentials from the cloud foundry service key of the respective instance, the configuration could look as follows: steps : abapEnvironmentCheckoutBranch : repositoryName : '/DMO/GIT_REPOSITORY' branchName : 'my-demo-branch' cfCredentialsId : 'cfCredentialsId' cfApiEndpoint : 'https://test.server.com' cfOrg : 'cfOrg' cfSpace : 'cfSpace' cfServiceInstance : 'cfServiceInstance' cfServiceKeyName : 'cfServiceKeyName'","title":"Example: Configuration in the config.yml"},{"location":"steps/abapEnvironmentCheckoutBranch/#example-configuration-in-the-jenkinsfile","text":"It is also possible to call the steps - including all parameters - directly in the Jenkinsfile. In the first example, the host and the credentialsId of the Communication Arrangement are directly provided. abapEnvironmentCheckoutBranach ( script: this , repositoryName: '/DMO/GIT_REPOSITORY' , branchName: 'my-demo-branch' , abapCredentialsId: 'abapCredentialsId' , host: '1234-abcd-5678-efgh-ijk.abap.eu10.hana.ondemand.com' ) In the second example, the host and credentialsId will be read from the provided cloud foundry service key of the specified service instance. abapEnvironmentCheckoutBranch ( script: this , repositoryName: '/DMO/GIT_REPOSITORY' , branchName: 'my-demo-branch' abapCredentialsId: 'cfCredentialsId' , cfApiEndpoint: 'https://test.server.com' , cfOrg: 'cfOrg' , cfSpace: 'cfSpace' , cfServiceInstance: 'cfServiceInstance' , cfServiceKeyName: 'cfServiceKeyName' )","title":"Example: Configuration in the Jenkinsfile"},{"location":"steps/abapEnvironmentPullGitRepo/","text":"abapEnvironmentPullGitRepo \u00b6 Pulls a git repository to a SAP Cloud Platform ABAP Environment system Description \u00b6 Pulls a git repository (Software Component) to a SAP Cloud Platform ABAP Environment system. Please provide either of the following options: The host and credentials the Cloud Platform ABAP Environment system itself. The credentials must be configured for the Communication Scenario SAP_COM_0510. The Cloud Foundry parameters (API endpoint, organization, space), credentials, the service instance for the ABAP service and the service key for the Communication Scenario SAP_COM_0510. Only provide one of those options with the respective credentials. If all values are provided, the direct communication (via host) has priority. Usage \u00b6 We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line . Jenkins pipelines \u00b6 abapEnvironmentPullGitRepo script: this Command line \u00b6 piper abapEnvironmentPullGitRepo Prerequisites \u00b6 A SAP Cloud Platform ABAP Environment system is available. On this system, a Communication User , a Communication System and a Communication Arrangement is setup for the Communication Scenario \"SAP Cloud Platform ABAP Environment - Software Component Test Integration (SAP_COM_0510)\". This can be done manually through the respective applications on the SAP Cloud Platform ABAP Environment System or through creating a service key for the system on cloud foundry with the parameters {\"scenario_id\": \"SAP_COM_0510\", \"type\": \"basic\"}. In a pipeline, you can do this with the step cloudFoundryCreateServiceKey . Parameters \u00b6 Overview \u00b6 Name Mandatory Additional information abapCredentialsId yes id of credentials ( using credentials ) password yes pass via ENV or Jenkins credentials repositoryNames yes script yes reference to Jenkins main pipeline script username yes pass via ENV or Jenkins credentials cfApiEndpoint no cfOrg no cfServiceInstance no cfServiceKeyName no cfSpace no containerCommand no containerShell no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no dockerVolumeBind no dockerWorkspace no host no verbose no activates debug output Details \u00b6 abapCredentialsId \u00b6 Jenkins-specific: Used for proper environment setup. Jenkins credentials ID containing user and password to authenticate to the Cloud Platform ABAP Environment system or the Cloud Foundry API back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none cfApiEndpoint \u00b6 Cloud Foundry API Enpoint back to overview Scope Details Aliases cloudFoundry/apiEndpoint Type string Mandatory no Default $PIPER_cfApiEndpoint (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none cfOrg \u00b6 Cloud Foundry target organization back to overview Scope Details Aliases cloudFoundry/org Type string Mandatory no Default $PIPER_cfOrg (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none cfServiceInstance \u00b6 Cloud Foundry Service Instance back to overview Scope Details Aliases cloudFoundry/serviceInstance Type string Mandatory no Default $PIPER_cfServiceInstance (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none cfServiceKeyName \u00b6 Cloud Foundry Service Key back to overview Scope Details Aliases - cloudFoundry/serviceKey - cloudFoundry/serviceKeyName - cfServiceKey Type string Mandatory no Default $PIPER_cfServiceKeyName (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none cfSpace \u00b6 Cloud Foundry target space back to overview Scope Details Aliases cloudFoundry/space Type string Mandatory no Default $PIPER_cfSpace (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none containerCommand \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default (/usr/bin/tail -f /dev/null). back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none containerShell \u00b6 Jenkins-specific: Used for proper environment setup. Allows to specify the shell to be executed for container with containerName. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerEnvVars \u00b6 Jenkins-specific: Used for proper environment setup. Environment variables to set in the container, e.g. [http_proxy: \"proxy:8080\"]. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerImage \u00b6 Jenkins-specific: Used for proper environment setup. Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerName \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Name of the container launching dockerImage. SideCar only: Name of the container in local network. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerOptions \u00b6 Jenkins-specific: Used for proper environment setup. Docker options to be set when starting the container. back to overview Scope Details Aliases - Type []string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerPullImage \u00b6 Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerVolumeBind \u00b6 Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the docker container. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerWorkspace \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none host \u00b6 Specifies the host address of the SAP Cloud Platform ABAP Environment system back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_host (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none password \u00b6 Password for either the Cloud Foundry API or the Communication Arrangement for SAP_COM_0510 back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_password (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none repositoryNames \u00b6 Specifies a list of Repositories (Software Components) on the SAP Cloud Platform ABAP Environment system back to overview Scope Details Aliases - Type []string Mandatory yes Default $PIPER_repositoryNames (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none script \u00b6 Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none username \u00b6 User for either the Cloud Foundry API or the Communication Arrangement for SAP_COM_0510 back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_username (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none verbose \u00b6 verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none \u00b6 Example: Configuration in the config.yml \u00b6 The recommended way to configure your pipeline is via the config.yml file. In this case, calling the step in the Jenkinsfile is reduced to one line: abapEnvironmentPullGitRepo script: this If you want to provide the host and credentials of the Communication Arrangement directly, the configuration could look as follows: steps : abapEnvironmentPullGitRepo : repositoryNames : [ '/DMO/GIT_REPOSITORY' ] abapCredentialsId : 'abapCredentialsId' host : '1234-abcd-5678-efgh-ijk.abap.eu10.hana.ondemand.com' If you want to read the host and credentials from the cloud foundry service key of the respective instance, the configuration could look as follows: steps : abapEnvironmentPullGitRepo : repositoryNames : [ '/DMO/GIT_REPOSITORY' ] cfCredentialsId : 'cfCredentialsId' cfApiEndpoint : 'https://test.server.com' cfOrg : 'cfOrg' cfSpace : 'cfSpace' cfServiceInstance : 'cfServiceInstance' cfServiceKeyName : 'cfServiceKeyName' Example: Configuration in the Jenkinsfile \u00b6 It is also possible to call the steps - including all parameters - directly in the Jenkinsfile. In the first example, the host and the credentialsId of the Communication Arrangement are directly provided. abapEnvironmentPullGitRepo ( script: this , repositoryNames: [ '/DMO/GIT_REPOSITORY' ], abapCredentialsId: 'abapCredentialsId' , host: '1234-abcd-5678-efgh-ijk.abap.eu10.hana.ondemand.com' ) In the second example, the host and credentialsId will be read from the provided cloud foundry service key of the specified service instance. abapEnvironmentPullGitRepo ( script: this , repositoryNames: [ '/DMO/GIT_REPOSITORY' , '/DMO/GIT_REPO' ], abapCredentialsId: 'cfCredentialsId' , cfApiEndpoint: 'https://test.server.com' , cfOrg: 'cfOrg' , cfSpace: 'cfSpace' , cfServiceInstance: 'cfServiceInstance' , cfServiceKeyName: 'cfServiceKeyName' )","title":"abapEnvironmentPullGitRepo"},{"location":"steps/abapEnvironmentPullGitRepo/#abapenvironmentpullgitrepo","text":"Pulls a git repository to a SAP Cloud Platform ABAP Environment system","title":"abapEnvironmentPullGitRepo"},{"location":"steps/abapEnvironmentPullGitRepo/#description","text":"Pulls a git repository (Software Component) to a SAP Cloud Platform ABAP Environment system. Please provide either of the following options: The host and credentials the Cloud Platform ABAP Environment system itself. The credentials must be configured for the Communication Scenario SAP_COM_0510. The Cloud Foundry parameters (API endpoint, organization, space), credentials, the service instance for the ABAP service and the service key for the Communication Scenario SAP_COM_0510. Only provide one of those options with the respective credentials. If all values are provided, the direct communication (via host) has priority.","title":"Description"},{"location":"steps/abapEnvironmentPullGitRepo/#usage","text":"We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line .","title":"Usage"},{"location":"steps/abapEnvironmentPullGitRepo/#jenkins-pipelines","text":"abapEnvironmentPullGitRepo script: this","title":"Jenkins pipelines"},{"location":"steps/abapEnvironmentPullGitRepo/#command-line","text":"piper abapEnvironmentPullGitRepo","title":"Command line"},{"location":"steps/abapEnvironmentPullGitRepo/#prerequisites","text":"A SAP Cloud Platform ABAP Environment system is available. On this system, a Communication User , a Communication System and a Communication Arrangement is setup for the Communication Scenario \"SAP Cloud Platform ABAP Environment - Software Component Test Integration (SAP_COM_0510)\". This can be done manually through the respective applications on the SAP Cloud Platform ABAP Environment System or through creating a service key for the system on cloud foundry with the parameters {\"scenario_id\": \"SAP_COM_0510\", \"type\": \"basic\"}. In a pipeline, you can do this with the step cloudFoundryCreateServiceKey .","title":"Prerequisites"},{"location":"steps/abapEnvironmentPullGitRepo/#parameters","text":"","title":"Parameters"},{"location":"steps/abapEnvironmentPullGitRepo/#overview","text":"Name Mandatory Additional information abapCredentialsId yes id of credentials ( using credentials ) password yes pass via ENV or Jenkins credentials repositoryNames yes script yes reference to Jenkins main pipeline script username yes pass via ENV or Jenkins credentials cfApiEndpoint no cfOrg no cfServiceInstance no cfServiceKeyName no cfSpace no containerCommand no containerShell no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no dockerVolumeBind no dockerWorkspace no host no verbose no activates debug output","title":"Overview"},{"location":"steps/abapEnvironmentPullGitRepo/#details","text":"","title":"Details"},{"location":"steps/abapEnvironmentPullGitRepo/#abapcredentialsid","text":"Jenkins-specific: Used for proper environment setup. Jenkins credentials ID containing user and password to authenticate to the Cloud Platform ABAP Environment system or the Cloud Foundry API back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"abapCredentialsId"},{"location":"steps/abapEnvironmentPullGitRepo/#cfapiendpoint","text":"Cloud Foundry API Enpoint back to overview Scope Details Aliases cloudFoundry/apiEndpoint Type string Mandatory no Default $PIPER_cfApiEndpoint (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"cfApiEndpoint"},{"location":"steps/abapEnvironmentPullGitRepo/#cforg","text":"Cloud Foundry target organization back to overview Scope Details Aliases cloudFoundry/org Type string Mandatory no Default $PIPER_cfOrg (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"cfOrg"},{"location":"steps/abapEnvironmentPullGitRepo/#cfserviceinstance","text":"Cloud Foundry Service Instance back to overview Scope Details Aliases cloudFoundry/serviceInstance Type string Mandatory no Default $PIPER_cfServiceInstance (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"cfServiceInstance"},{"location":"steps/abapEnvironmentPullGitRepo/#cfservicekeyname","text":"Cloud Foundry Service Key back to overview Scope Details Aliases - cloudFoundry/serviceKey - cloudFoundry/serviceKeyName - cfServiceKey Type string Mandatory no Default $PIPER_cfServiceKeyName (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"cfServiceKeyName"},{"location":"steps/abapEnvironmentPullGitRepo/#cfspace","text":"Cloud Foundry target space back to overview Scope Details Aliases cloudFoundry/space Type string Mandatory no Default $PIPER_cfSpace (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"cfSpace"},{"location":"steps/abapEnvironmentPullGitRepo/#containercommand","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default (/usr/bin/tail -f /dev/null). back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"containerCommand"},{"location":"steps/abapEnvironmentPullGitRepo/#containershell","text":"Jenkins-specific: Used for proper environment setup. Allows to specify the shell to be executed for container with containerName. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"containerShell"},{"location":"steps/abapEnvironmentPullGitRepo/#dockerenvvars","text":"Jenkins-specific: Used for proper environment setup. Environment variables to set in the container, e.g. [http_proxy: \"proxy:8080\"]. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerEnvVars"},{"location":"steps/abapEnvironmentPullGitRepo/#dockerimage","text":"Jenkins-specific: Used for proper environment setup. Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerImage"},{"location":"steps/abapEnvironmentPullGitRepo/#dockername","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Name of the container launching dockerImage. SideCar only: Name of the container in local network. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerName"},{"location":"steps/abapEnvironmentPullGitRepo/#dockeroptions","text":"Jenkins-specific: Used for proper environment setup. Docker options to be set when starting the container. back to overview Scope Details Aliases - Type []string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerOptions"},{"location":"steps/abapEnvironmentPullGitRepo/#dockerpullimage","text":"Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerPullImage"},{"location":"steps/abapEnvironmentPullGitRepo/#dockervolumebind","text":"Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the docker container. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerVolumeBind"},{"location":"steps/abapEnvironmentPullGitRepo/#dockerworkspace","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerWorkspace"},{"location":"steps/abapEnvironmentPullGitRepo/#host","text":"Specifies the host address of the SAP Cloud Platform ABAP Environment system back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_host (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"host"},{"location":"steps/abapEnvironmentPullGitRepo/#password","text":"Password for either the Cloud Foundry API or the Communication Arrangement for SAP_COM_0510 back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_password (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"password"},{"location":"steps/abapEnvironmentPullGitRepo/#repositorynames","text":"Specifies a list of Repositories (Software Components) on the SAP Cloud Platform ABAP Environment system back to overview Scope Details Aliases - Type []string Mandatory yes Default $PIPER_repositoryNames (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"repositoryNames"},{"location":"steps/abapEnvironmentPullGitRepo/#script","text":"Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none","title":"script"},{"location":"steps/abapEnvironmentPullGitRepo/#username","text":"User for either the Cloud Foundry API or the Communication Arrangement for SAP_COM_0510 back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_username (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"username"},{"location":"steps/abapEnvironmentPullGitRepo/#verbose","text":"verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"verbose"},{"location":"steps/abapEnvironmentPullGitRepo/#example-configuration-in-the-configyml","text":"The recommended way to configure your pipeline is via the config.yml file. In this case, calling the step in the Jenkinsfile is reduced to one line: abapEnvironmentPullGitRepo script: this If you want to provide the host and credentials of the Communication Arrangement directly, the configuration could look as follows: steps : abapEnvironmentPullGitRepo : repositoryNames : [ '/DMO/GIT_REPOSITORY' ] abapCredentialsId : 'abapCredentialsId' host : '1234-abcd-5678-efgh-ijk.abap.eu10.hana.ondemand.com' If you want to read the host and credentials from the cloud foundry service key of the respective instance, the configuration could look as follows: steps : abapEnvironmentPullGitRepo : repositoryNames : [ '/DMO/GIT_REPOSITORY' ] cfCredentialsId : 'cfCredentialsId' cfApiEndpoint : 'https://test.server.com' cfOrg : 'cfOrg' cfSpace : 'cfSpace' cfServiceInstance : 'cfServiceInstance' cfServiceKeyName : 'cfServiceKeyName'","title":"Example: Configuration in the config.yml"},{"location":"steps/abapEnvironmentPullGitRepo/#example-configuration-in-the-jenkinsfile","text":"It is also possible to call the steps - including all parameters - directly in the Jenkinsfile. In the first example, the host and the credentialsId of the Communication Arrangement are directly provided. abapEnvironmentPullGitRepo ( script: this , repositoryNames: [ '/DMO/GIT_REPOSITORY' ], abapCredentialsId: 'abapCredentialsId' , host: '1234-abcd-5678-efgh-ijk.abap.eu10.hana.ondemand.com' ) In the second example, the host and credentialsId will be read from the provided cloud foundry service key of the specified service instance. abapEnvironmentPullGitRepo ( script: this , repositoryNames: [ '/DMO/GIT_REPOSITORY' , '/DMO/GIT_REPO' ], abapCredentialsId: 'cfCredentialsId' , cfApiEndpoint: 'https://test.server.com' , cfOrg: 'cfOrg' , cfSpace: 'cfSpace' , cfServiceInstance: 'cfServiceInstance' , cfServiceKeyName: 'cfServiceKeyName' )","title":"Example: Configuration in the Jenkinsfile"},{"location":"steps/abapEnvironmentRunATCCheck/","text":"abapEnvironmentRunATCCheck \u00b6 Runs an ATC Check Description \u00b6 This step is for triggering an ATC test run on an SAP Cloud Platform ABAP Environment system. Please provide either of the following options: The host and credentials the Cloud Platform ABAP Environment system itself. The credentials must be configured for the Communication Scenario SAP_COM_0510. The Cloud Foundry parameters (API endpoint, organization, space), credentials, the service instance for the ABAP service and the service key for the Communication Scenario SAP_COM_0510. Only provide one of those options with the respective credentials. If all values are provided, the direct communication (via host) has priority. Regardless of the option you chose, please make sure to provide the configuration for Software Components and Packages that you want to be checked analog to the examples listed on this page. Usage \u00b6 We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line . Jenkins pipelines \u00b6 abapEnvironmentRunATCCheck script: this Command line \u00b6 piper abapEnvironmentRunATCCheck Prerequisites \u00b6 A SAP Cloud Platform ABAP Environment system is available. On this system, a Communication User , a Communication System and a Communication Arrangement is setup for the Communication Scenario \u201cSAP Cloud Platform ABAP Environment - Software Component Test Integration (SAP_COM_0510)\u201c. This can be done manually through the respective applications on the SAP Cloud Platform ABAP Environment System or through creating a service key for the system on cloud foundry with the parameters {\u201cscenario_id\u201d: \u201cSAP_COM_0510\", \u201ctype\u201d: \u201cbasic\u201d}. In a pipeline, you can do this with the step cloudFoundryCreateServiceKey . You can either provide the ABAP endpoint configuration to directly trigger ann ATC run on the ABAP system or optionally provide the Cloud Foundry parameters with your credentials to read a Service Key of a SAP Cloud Platform ABAP Environment system in Cloud Foundry that contains all the details of the ABAP endpoint to trigger an ATC run. Regardless if you chose an ABAP endpoint directly or reading a Cloud Foundry Service Key you have to provide the configuration of the packages and software components you want to be checked in an ATC run in a .yml or .yaml file. This file must be stored in the same folder as the Jenkinsfile defining the pipeline. The Software Components and/or Packages you want to be checked must be present in the configured system in order to run the check. Please make sure that you have created or pulled the respective Software Components and/or Packages in the SAP Cloud Platform ABAP Environment system. Examples will be listed below. Parameters \u00b6 Overview \u00b6 Name Mandatory Additional information abapCredentialsId yes id of credentials ( using credentials ) atcConfig yes password yes script yes reference to Jenkins main pipeline script username yes cfApiEndpoint no cfOrg no cfServiceInstance no cfServiceKeyName no cfSpace no containerCommand no containerShell no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no dockerVolumeBind no dockerWorkspace no host no verbose no activates debug output Details \u00b6 abapCredentialsId \u00b6 Jenkins-specific: Used for proper environment setup. Jenkins credentials ID containing user and password to authenticate to the Cloud Platform ABAP Environment system or the Cloud Foundry API back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none atcConfig \u00b6 Path to a YAML configuration file for Packages and/or Software Components to be checked during ATC run back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_atcConfig (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none cfApiEndpoint \u00b6 Cloud Foundry API endpoint back to overview Scope Details Aliases cloudFoundry/apiEndpoint Type string Mandatory no Default $PIPER_cfApiEndpoint (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none cfOrg \u00b6 CF org back to overview Scope Details Aliases cloudFoundry/org Type string Mandatory no Default $PIPER_cfOrg (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none cfServiceInstance \u00b6 Parameter of ServiceInstance Name to delete CloudFoundry Service back to overview Scope Details Aliases cloudFoundry/serviceInstance Type string Mandatory no Default $PIPER_cfServiceInstance (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none cfServiceKeyName \u00b6 Parameter of CloudFoundry Service Key to be created back to overview Scope Details Aliases - cloudFoundry/serviceKey - cloudFoundry/serviceKeyName - cfServiceKey Type string Mandatory no Default $PIPER_cfServiceKeyName (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none cfSpace \u00b6 CF Space back to overview Scope Details Aliases cloudFoundry/space Type string Mandatory no Default $PIPER_cfSpace (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none containerCommand \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default (/usr/bin/tail -f /dev/null). back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none containerShell \u00b6 Jenkins-specific: Used for proper environment setup. Allows to specify the shell to be executed for container with containerName. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerEnvVars \u00b6 Jenkins-specific: Used for proper environment setup. Environment variables to set in the container, e.g. [http_proxy: \"proxy:8080\"]. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerImage \u00b6 Jenkins-specific: Used for proper environment setup. Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerName \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Name of the container launching dockerImage. SideCar only: Name of the container in local network. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerOptions \u00b6 Jenkins-specific: Used for proper environment setup. Docker options to be set when starting the container. back to overview Scope Details Aliases - Type []string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerPullImage \u00b6 Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerVolumeBind \u00b6 Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the docker container. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerWorkspace \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none host \u00b6 Specifies the host address of the SAP Cloud Platform ABAP Environment system back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_host (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none password \u00b6 User Password for CF User back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_password (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none script \u00b6 Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none username \u00b6 User or E-Mail for CF back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_username (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none verbose \u00b6 verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none \u00b6 Examples \u00b6 Configuration in the config.yml \u00b6 The recommended way to configure your pipeline is via the config.yml file. In this case, calling the step in the Jenkinsfile is reduced to one line: abapEnvironmentRunATCCheck script: this If you want to provide the host and credentials of the Communication Arrangement directly, the configuration could look as follows: steps : abapEnvironmentRunATCCheck : abapCredentialsId : 'abapCredentialsId' , host : 'https://myABAPendpoint.com' , atcConfig : 'atcconfig.yml' , ATC run via Cloud Foundry Service Key example in Jenkinsfile \u00b6 The following example triggers an ATC run via reading the Service Key of an ABAP instance in Cloud Foundry. You can store the credentials in Jenkins and use the cfCredentialsId parameter to authenticate to Cloud Foundry. The username and password to authenticate to ABAP system will then be read from the Cloud Foundry Service Key that is bound to the ABAP instance. This can be done accordingly: abapEnvironmentRunATCCheck ( cfApiEndpoint : 'https://test.server.com' , cfOrg : 'cfOrg' , cfSpace: 'cfSpace' , cfServiceInstance: 'myServiceInstance' , cfServiceKeyName: 'myServiceKey' , abapCredentialsId: 'cfCredentialsId' , atcConfig: 'atcconfig.yml' , script: this , ) To trigger the ATC run an ATC config file atcconfig.yml will be needed. Check section 'ATC config file example' for more information. ATC run via direct ABAP endpoint configuration in Jenkinsfile \u00b6 This example triggers an ATC run directly on the ABAP endpoint. In order to trigger the ATC run you have to pass the username and password for authentication to the ABAP endpoint via parameters as well as the ABAP endpoint/host. You can store the credentials in Jenkins and use the abapCredentialsId parameter to authenticate to the ABAP endpoint/host. This must be configured as following: abapEnvironmentRunATCCheck ( abapCredentialsId: 'abapCredentialsId' , host: 'https://myABAPendpoint.com' , atcConfig: 'atcconfig.yml' , script: this , ) To trigger the ATC run an ATC config file atcconfig.yml will be needed. Check section 'ATC config file example' for more information. ATC config file example \u00b6 The following section contains an example of an atcconfig.yml file. This file must be stored in the same Git folder where the Jenkinsfile is stored to run the pipeline. This folder must be taken as a SCM in the Jenkins pipeline to run the pipeline. You can specify a list of packages and/or software components to be checked. This must be in the same format as below example for a atcconfig.yml file. For each package that has to be checked you can configure if you want the subpackages to be included in checks or not. Please note that if you chose to provide both packages and software components to be checked with the atcconfig.yml file, the set of packages and the set of software components will be combinend by the API using a logical AND operation. Therefore, we advise to specify either the Software Components or Packages. See below example for an atcconfig.yml file with both packages and software components to be checked: atcobjects : package : - name : \"TestPackage\" includesubpackage : false - name : \"TestPackage2\" includesubpackage : true softwarecomponent : - name : \"TestComponent\" - name : \"TestComponent2\" The following example of an atcconfig.yml file that only contains packages to be checked: atcobjects : package : - name : \"TestPackage\" includesubpackage : false - name : \"TestPackage2\" includesubpackage : true The following example of an atcconfig.yml file that only contains software components to be checked: atcobjects : softwarecomponent : - name : \"TestComponent\" - name : \"TestComponent2\"","title":"abapEnvironmentRunATCCheck"},{"location":"steps/abapEnvironmentRunATCCheck/#abapenvironmentrunatccheck","text":"Runs an ATC Check","title":"abapEnvironmentRunATCCheck"},{"location":"steps/abapEnvironmentRunATCCheck/#description","text":"This step is for triggering an ATC test run on an SAP Cloud Platform ABAP Environment system. Please provide either of the following options: The host and credentials the Cloud Platform ABAP Environment system itself. The credentials must be configured for the Communication Scenario SAP_COM_0510. The Cloud Foundry parameters (API endpoint, organization, space), credentials, the service instance for the ABAP service and the service key for the Communication Scenario SAP_COM_0510. Only provide one of those options with the respective credentials. If all values are provided, the direct communication (via host) has priority. Regardless of the option you chose, please make sure to provide the configuration for Software Components and Packages that you want to be checked analog to the examples listed on this page.","title":"Description"},{"location":"steps/abapEnvironmentRunATCCheck/#usage","text":"We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line .","title":"Usage"},{"location":"steps/abapEnvironmentRunATCCheck/#jenkins-pipelines","text":"abapEnvironmentRunATCCheck script: this","title":"Jenkins pipelines"},{"location":"steps/abapEnvironmentRunATCCheck/#command-line","text":"piper abapEnvironmentRunATCCheck","title":"Command line"},{"location":"steps/abapEnvironmentRunATCCheck/#prerequisites","text":"A SAP Cloud Platform ABAP Environment system is available. On this system, a Communication User , a Communication System and a Communication Arrangement is setup for the Communication Scenario \u201cSAP Cloud Platform ABAP Environment - Software Component Test Integration (SAP_COM_0510)\u201c. This can be done manually through the respective applications on the SAP Cloud Platform ABAP Environment System or through creating a service key for the system on cloud foundry with the parameters {\u201cscenario_id\u201d: \u201cSAP_COM_0510\", \u201ctype\u201d: \u201cbasic\u201d}. In a pipeline, you can do this with the step cloudFoundryCreateServiceKey . You can either provide the ABAP endpoint configuration to directly trigger ann ATC run on the ABAP system or optionally provide the Cloud Foundry parameters with your credentials to read a Service Key of a SAP Cloud Platform ABAP Environment system in Cloud Foundry that contains all the details of the ABAP endpoint to trigger an ATC run. Regardless if you chose an ABAP endpoint directly or reading a Cloud Foundry Service Key you have to provide the configuration of the packages and software components you want to be checked in an ATC run in a .yml or .yaml file. This file must be stored in the same folder as the Jenkinsfile defining the pipeline. The Software Components and/or Packages you want to be checked must be present in the configured system in order to run the check. Please make sure that you have created or pulled the respective Software Components and/or Packages in the SAP Cloud Platform ABAP Environment system. Examples will be listed below.","title":"Prerequisites"},{"location":"steps/abapEnvironmentRunATCCheck/#parameters","text":"","title":"Parameters"},{"location":"steps/abapEnvironmentRunATCCheck/#overview","text":"Name Mandatory Additional information abapCredentialsId yes id of credentials ( using credentials ) atcConfig yes password yes script yes reference to Jenkins main pipeline script username yes cfApiEndpoint no cfOrg no cfServiceInstance no cfServiceKeyName no cfSpace no containerCommand no containerShell no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no dockerVolumeBind no dockerWorkspace no host no verbose no activates debug output","title":"Overview"},{"location":"steps/abapEnvironmentRunATCCheck/#details","text":"","title":"Details"},{"location":"steps/abapEnvironmentRunATCCheck/#abapcredentialsid","text":"Jenkins-specific: Used for proper environment setup. Jenkins credentials ID containing user and password to authenticate to the Cloud Platform ABAP Environment system or the Cloud Foundry API back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"abapCredentialsId"},{"location":"steps/abapEnvironmentRunATCCheck/#atcconfig","text":"Path to a YAML configuration file for Packages and/or Software Components to be checked during ATC run back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_atcConfig (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"atcConfig"},{"location":"steps/abapEnvironmentRunATCCheck/#cfapiendpoint","text":"Cloud Foundry API endpoint back to overview Scope Details Aliases cloudFoundry/apiEndpoint Type string Mandatory no Default $PIPER_cfApiEndpoint (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"cfApiEndpoint"},{"location":"steps/abapEnvironmentRunATCCheck/#cforg","text":"CF org back to overview Scope Details Aliases cloudFoundry/org Type string Mandatory no Default $PIPER_cfOrg (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"cfOrg"},{"location":"steps/abapEnvironmentRunATCCheck/#cfserviceinstance","text":"Parameter of ServiceInstance Name to delete CloudFoundry Service back to overview Scope Details Aliases cloudFoundry/serviceInstance Type string Mandatory no Default $PIPER_cfServiceInstance (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"cfServiceInstance"},{"location":"steps/abapEnvironmentRunATCCheck/#cfservicekeyname","text":"Parameter of CloudFoundry Service Key to be created back to overview Scope Details Aliases - cloudFoundry/serviceKey - cloudFoundry/serviceKeyName - cfServiceKey Type string Mandatory no Default $PIPER_cfServiceKeyName (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"cfServiceKeyName"},{"location":"steps/abapEnvironmentRunATCCheck/#cfspace","text":"CF Space back to overview Scope Details Aliases cloudFoundry/space Type string Mandatory no Default $PIPER_cfSpace (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"cfSpace"},{"location":"steps/abapEnvironmentRunATCCheck/#containercommand","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default (/usr/bin/tail -f /dev/null). back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"containerCommand"},{"location":"steps/abapEnvironmentRunATCCheck/#containershell","text":"Jenkins-specific: Used for proper environment setup. Allows to specify the shell to be executed for container with containerName. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"containerShell"},{"location":"steps/abapEnvironmentRunATCCheck/#dockerenvvars","text":"Jenkins-specific: Used for proper environment setup. Environment variables to set in the container, e.g. [http_proxy: \"proxy:8080\"]. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerEnvVars"},{"location":"steps/abapEnvironmentRunATCCheck/#dockerimage","text":"Jenkins-specific: Used for proper environment setup. Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerImage"},{"location":"steps/abapEnvironmentRunATCCheck/#dockername","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Name of the container launching dockerImage. SideCar only: Name of the container in local network. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerName"},{"location":"steps/abapEnvironmentRunATCCheck/#dockeroptions","text":"Jenkins-specific: Used for proper environment setup. Docker options to be set when starting the container. back to overview Scope Details Aliases - Type []string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerOptions"},{"location":"steps/abapEnvironmentRunATCCheck/#dockerpullimage","text":"Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerPullImage"},{"location":"steps/abapEnvironmentRunATCCheck/#dockervolumebind","text":"Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the docker container. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerVolumeBind"},{"location":"steps/abapEnvironmentRunATCCheck/#dockerworkspace","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerWorkspace"},{"location":"steps/abapEnvironmentRunATCCheck/#host","text":"Specifies the host address of the SAP Cloud Platform ABAP Environment system back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_host (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"host"},{"location":"steps/abapEnvironmentRunATCCheck/#password","text":"User Password for CF User back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_password (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"password"},{"location":"steps/abapEnvironmentRunATCCheck/#script","text":"Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none","title":"script"},{"location":"steps/abapEnvironmentRunATCCheck/#username","text":"User or E-Mail for CF back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_username (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"username"},{"location":"steps/abapEnvironmentRunATCCheck/#verbose","text":"verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"verbose"},{"location":"steps/abapEnvironmentRunATCCheck/#examples","text":"","title":"Examples"},{"location":"steps/abapEnvironmentRunATCCheck/#configuration-in-the-configyml","text":"The recommended way to configure your pipeline is via the config.yml file. In this case, calling the step in the Jenkinsfile is reduced to one line: abapEnvironmentRunATCCheck script: this If you want to provide the host and credentials of the Communication Arrangement directly, the configuration could look as follows: steps : abapEnvironmentRunATCCheck : abapCredentialsId : 'abapCredentialsId' , host : 'https://myABAPendpoint.com' , atcConfig : 'atcconfig.yml' ,","title":"Configuration in the config.yml"},{"location":"steps/abapEnvironmentRunATCCheck/#atc-run-via-cloud-foundry-service-key-example-in-jenkinsfile","text":"The following example triggers an ATC run via reading the Service Key of an ABAP instance in Cloud Foundry. You can store the credentials in Jenkins and use the cfCredentialsId parameter to authenticate to Cloud Foundry. The username and password to authenticate to ABAP system will then be read from the Cloud Foundry Service Key that is bound to the ABAP instance. This can be done accordingly: abapEnvironmentRunATCCheck ( cfApiEndpoint : 'https://test.server.com' , cfOrg : 'cfOrg' , cfSpace: 'cfSpace' , cfServiceInstance: 'myServiceInstance' , cfServiceKeyName: 'myServiceKey' , abapCredentialsId: 'cfCredentialsId' , atcConfig: 'atcconfig.yml' , script: this , ) To trigger the ATC run an ATC config file atcconfig.yml will be needed. Check section 'ATC config file example' for more information.","title":"ATC run via Cloud Foundry Service Key example in Jenkinsfile"},{"location":"steps/abapEnvironmentRunATCCheck/#atc-run-via-direct-abap-endpoint-configuration-in-jenkinsfile","text":"This example triggers an ATC run directly on the ABAP endpoint. In order to trigger the ATC run you have to pass the username and password for authentication to the ABAP endpoint via parameters as well as the ABAP endpoint/host. You can store the credentials in Jenkins and use the abapCredentialsId parameter to authenticate to the ABAP endpoint/host. This must be configured as following: abapEnvironmentRunATCCheck ( abapCredentialsId: 'abapCredentialsId' , host: 'https://myABAPendpoint.com' , atcConfig: 'atcconfig.yml' , script: this , ) To trigger the ATC run an ATC config file atcconfig.yml will be needed. Check section 'ATC config file example' for more information.","title":"ATC run via direct ABAP endpoint configuration in Jenkinsfile"},{"location":"steps/abapEnvironmentRunATCCheck/#atc-config-file-example","text":"The following section contains an example of an atcconfig.yml file. This file must be stored in the same Git folder where the Jenkinsfile is stored to run the pipeline. This folder must be taken as a SCM in the Jenkins pipeline to run the pipeline. You can specify a list of packages and/or software components to be checked. This must be in the same format as below example for a atcconfig.yml file. For each package that has to be checked you can configure if you want the subpackages to be included in checks or not. Please note that if you chose to provide both packages and software components to be checked with the atcconfig.yml file, the set of packages and the set of software components will be combinend by the API using a logical AND operation. Therefore, we advise to specify either the Software Components or Packages. See below example for an atcconfig.yml file with both packages and software components to be checked: atcobjects : package : - name : \"TestPackage\" includesubpackage : false - name : \"TestPackage2\" includesubpackage : true softwarecomponent : - name : \"TestComponent\" - name : \"TestComponent2\" The following example of an atcconfig.yml file that only contains packages to be checked: atcobjects : package : - name : \"TestPackage\" includesubpackage : false - name : \"TestPackage2\" includesubpackage : true The following example of an atcconfig.yml file that only contains software components to be checked: atcobjects : softwarecomponent : - name : \"TestComponent\" - name : \"TestComponent2\"","title":"ATC config file example"},{"location":"steps/artifactPrepareVersion/","text":"artifactPrepareVersion \u00b6 Prepares and potentially updates the artifact's version before building the artifact. Description \u00b6 Prepares and potentially updates the artifact's version before building the artifact. The continuous delivery process requires that each build is done with a unique version number. There are two common patterns found: 1. Continuous Deployment pattern with automatic versioning \u00b6 The team has full authority on <major>.<minor>.<patch> and can increase any part whenever required. Nonetheless, the automatic versioning makes sure that every build will create a unique version by appending <major>.<minor>.<patch> with a buildversion (we use a timestamp) and optinally the commitId. In order to represent this version also in the version control system the new unique version will be pushed with a dedicated tag ( <tagPrefix><major>.<minor>.<patch><unique extension> ). Depending on the build tool used and thus the allowed versioning format the <unique extension> varies. Remarks: There is no commit to master since this would create a perpetuum mobile and just trigger the next automatic build with automatic versioning, and so on ... Not creating a tag would lead to a loss of the final artifact version in scm which often is not acceptable You need to ensure that your CI/CD system can push back to your SCM (via providing ssh or HTTP(s) credentials) This pattern is the default behavior ( versioningType: cloud ) since this is suitable for most cloud deliveries. It is possible to use versioningType: cloud_noTag which has a slighly different behavior than described above: The new version will NOT be written as tag into the SCM but it is only available in the corresponding CI/CD workspace IMPORTANT NOTICE: Using the option cloud_noTag should not be picked in case you need to ensure a fully traceable path from SCM commit to your build artifact. 2. Pure version <major>.<minor>.<patch> \u00b6 This pattern is often used by teams that have cloud deliveries with no fully automated procedure, e.g. delivery after each takt. Another typical use-case is development of a library with regular releases where the versioning pattern should be consumable and thus ideally complies to a <major>.<minor>.<patch> pattern. The version is then either manually set by the team in the course of the development process or automatically pushed to master after a successful release. Unlike for the Continuous Deloyment pattern descibed above, in this case there is no dedicated tagging required for the build process since the version is already available in the repository. Configuration of this pattern is done via versioningType: library . Support of additional build tools \u00b6 Besides the buildTools provided out of the box (like maven , mta , npm , ...) it is possible to set buildTool: custom . This allows you to provide automatic versioning for tools using a: file with the version as only content: \u00b6 Define buildTool: custom as well as filePath: <path to your file> Please note: <path to your file> need to point either to a *.txt file or to a file without extension. ini file containing the version: \u00b6 Define buildTool: custom , filePath: <path to your ini-file> as well as parameters versionSection and versionSource to point to the version location (section & parameter name) within the file. Please note: <path to your file> need to point either to a *.cfg or a *.ini file. json file containing the version: \u00b6 Define buildTool: custom , filePath: <path to your *.json file as well as parameter versionSource to point to the parameter containing the version. yaml file containing the version \u00b6 Define buildTool: custom , filePath: <path to your *.yml/*.yaml file as well as parameter versionSource to point to the parameter containing the version. Usage \u00b6 We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line . Jenkins pipelines \u00b6 artifactPrepareVersion script: this Command line \u00b6 piper artifactPrepareVersion Outputs \u00b6 Output type Details commonPipelineEnvironment artifactVersion originalArtifactVersion git/commitId git/commitMessage Parameters \u00b6 Overview \u00b6 Name Mandatory Additional information buildTool yes gitHttpsCredentialsId yes id of credentials ( using credentials ) gitSshKeyCredentialsId yes id of credentials ( using credentials ) script yes reference to Jenkins main pipeline script commitUserName no containerCommand no containerShell no customVersionField no customVersionSection no customVersioningScheme no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no dockerVersionSource no dockerVolumeBind no dockerWorkspace no filePath no globalSettingsFile no includeCommitId no m2Path no password no pass via ENV or Jenkins credentials ( gitHttpsCredentialsId ) projectSettingsFile no shortCommitId no tagPrefix no unixTimestamp no username no pass via ENV or Jenkins credentials ( gitHttpsCredentialsId ) verbose no activates debug output versioningTemplate no versioningType no Details \u00b6 buildTool \u00b6 Defines the tool which is used for building the artifact. Supports custom , dub , golang , maven , mta , npm , pip , sbt . back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_buildTool (if set) Possible values - custom - docker - dub - golang - maven - mta - npm - pip - sbt Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none commitUserName \u00b6 Defines the user name which appears in version control for the versioning update (in case versioningType: cloud ). back to overview Scope Details Aliases gitUserName Type string Mandatory no Default Project Piper Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none containerCommand \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default (/usr/bin/tail -f /dev/null). back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none containerShell \u00b6 Jenkins-specific: Used for proper environment setup. Allows to specify the shell to be executed for container with containerName. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none customVersionField \u00b6 For buildTool: custom : Defines the field which contains the version in the descriptor file. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_customVersionField (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none customVersionSection \u00b6 For buildTool: custom : Defines the section for version retrieval in vase a .ini/ .cfg file is used. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_customVersionSection (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none customVersioningScheme \u00b6 For buildTool: custom : Defines the versioning scheme to be used (possible options pep440 , maven , semver2 ). back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_customVersioningScheme (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none dockerEnvVars \u00b6 Jenkins-specific: Used for proper environment setup. Environment variables to set in the container, e.g. [http_proxy: \"proxy:8080\"]. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerImage \u00b6 Jenkins-specific: Used for proper environment setup. Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. back to overview Scope Details Aliases - Type string Mandatory no Default buildTool= maven : maven:3.6-jdk-8 Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerName \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Name of the container launching dockerImage. SideCar only: Name of the container in local network. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerOptions \u00b6 Jenkins-specific: Used for proper environment setup. Docker options to be set when starting the container. back to overview Scope Details Aliases - Type []string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerPullImage \u00b6 Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default buildTool= maven : false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerVersionSource \u00b6 For buildTool: docker : Defines the source of the version. Can be FROM , any supported buildTool or an environment variable name. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_dockerVersionSource (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none dockerVolumeBind \u00b6 Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the docker container. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerWorkspace \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none filePath \u00b6 Defines a custom path to the descriptor file. Build tool specific defaults are used (e.g. maven: pom.xml , npm: package.json , mta: mta.yaml ). back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_filePath (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none gitHttpsCredentialsId \u00b6 Jenkins-specific: Used for proper environment setup. back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none gitSshKeyCredentialsId \u00b6 Jenkins-specific: Used for proper environment setup. back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none globalSettingsFile \u00b6 Maven only - Path to the mvn settings file that should be used as global settings file. back to overview Scope Details Aliases maven/globalSettingsFile Type string Mandatory no Default $PIPER_globalSettingsFile (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none includeCommitId \u00b6 Defines if the automatically generated version ( versioningType: cloud ) should include the commit id hash. back to overview Scope Details Aliases - Type bool Mandatory no Default true Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none m2Path \u00b6 Maven only - Path to the location of the local repository that should be used. back to overview Scope Details Aliases maven/m2Path Type string Mandatory no Default $PIPER_m2Path (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none password \u00b6 Password/token for git authentication. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_password (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references Jenkins credential id: id: gitHttpsCredentialsId reference to: password projectSettingsFile \u00b6 Maven only - Path to the mvn settings file that should be used as project settings file. back to overview Scope Details Aliases maven/projectSettingsFile Type string Mandatory no Default $PIPER_projectSettingsFile (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none script \u00b6 Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none shortCommitId \u00b6 Defines if a short version of the commitId should be used. GitHub format is used (first 7 characters). back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none tagPrefix \u00b6 Defines the prefix which is used for the git tag which is written during the versioning run (only versioningType: cloud ). back to overview Scope Details Aliases - Type string Mandatory no Default build_ Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none unixTimestamp \u00b6 Defines if the Unix timestamp number should be used as build number instead of the standard date format. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none username \u00b6 User name for git authentication back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_username (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references Jenkins credential id: id: gitHttpsCredentialsId reference to: username verbose \u00b6 verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none versioningTemplate \u00b6 DEPRECATED: Defines the template for the automatic version which will be created back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_versioningTemplate (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none versioningType \u00b6 Defines the type of versioning ( cloud : fully automatic, cloud_noTag : automatic but no tag created, library : manual, i.e. the pipeline will pick up the version from the build descriptor, but not generate a new version) back to overview Scope Details Aliases - Type string Mandatory no Default cloud Possible values - cloud - cloud_noTag - library Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none \u00b6","title":"artifactPrepareVersion"},{"location":"steps/artifactPrepareVersion/#artifactprepareversion","text":"Prepares and potentially updates the artifact's version before building the artifact.","title":"artifactPrepareVersion"},{"location":"steps/artifactPrepareVersion/#description","text":"Prepares and potentially updates the artifact's version before building the artifact. The continuous delivery process requires that each build is done with a unique version number. There are two common patterns found:","title":"Description"},{"location":"steps/artifactPrepareVersion/#1-continuous-deployment-pattern-with-automatic-versioning","text":"The team has full authority on <major>.<minor>.<patch> and can increase any part whenever required. Nonetheless, the automatic versioning makes sure that every build will create a unique version by appending <major>.<minor>.<patch> with a buildversion (we use a timestamp) and optinally the commitId. In order to represent this version also in the version control system the new unique version will be pushed with a dedicated tag ( <tagPrefix><major>.<minor>.<patch><unique extension> ). Depending on the build tool used and thus the allowed versioning format the <unique extension> varies. Remarks: There is no commit to master since this would create a perpetuum mobile and just trigger the next automatic build with automatic versioning, and so on ... Not creating a tag would lead to a loss of the final artifact version in scm which often is not acceptable You need to ensure that your CI/CD system can push back to your SCM (via providing ssh or HTTP(s) credentials) This pattern is the default behavior ( versioningType: cloud ) since this is suitable for most cloud deliveries. It is possible to use versioningType: cloud_noTag which has a slighly different behavior than described above: The new version will NOT be written as tag into the SCM but it is only available in the corresponding CI/CD workspace IMPORTANT NOTICE: Using the option cloud_noTag should not be picked in case you need to ensure a fully traceable path from SCM commit to your build artifact.","title":"1. Continuous Deployment pattern with automatic versioning"},{"location":"steps/artifactPrepareVersion/#2-pure-version-majorminorpatch","text":"This pattern is often used by teams that have cloud deliveries with no fully automated procedure, e.g. delivery after each takt. Another typical use-case is development of a library with regular releases where the versioning pattern should be consumable and thus ideally complies to a <major>.<minor>.<patch> pattern. The version is then either manually set by the team in the course of the development process or automatically pushed to master after a successful release. Unlike for the Continuous Deloyment pattern descibed above, in this case there is no dedicated tagging required for the build process since the version is already available in the repository. Configuration of this pattern is done via versioningType: library .","title":"2. Pure version &lt;major&gt;.&lt;minor&gt;.&lt;patch&gt;"},{"location":"steps/artifactPrepareVersion/#support-of-additional-build-tools","text":"Besides the buildTools provided out of the box (like maven , mta , npm , ...) it is possible to set buildTool: custom . This allows you to provide automatic versioning for tools using a:","title":"Support of additional build tools"},{"location":"steps/artifactPrepareVersion/#file-with-the-version-as-only-content","text":"Define buildTool: custom as well as filePath: <path to your file> Please note: <path to your file> need to point either to a *.txt file or to a file without extension.","title":"file with the version as only content:"},{"location":"steps/artifactPrepareVersion/#ini-file-containing-the-version","text":"Define buildTool: custom , filePath: <path to your ini-file> as well as parameters versionSection and versionSource to point to the version location (section & parameter name) within the file. Please note: <path to your file> need to point either to a *.cfg or a *.ini file.","title":"ini file containing the version:"},{"location":"steps/artifactPrepareVersion/#json-file-containing-the-version","text":"Define buildTool: custom , filePath: <path to your *.json file as well as parameter versionSource to point to the parameter containing the version.","title":"json file containing the version:"},{"location":"steps/artifactPrepareVersion/#yaml-file-containing-the-version","text":"Define buildTool: custom , filePath: <path to your *.yml/*.yaml file as well as parameter versionSource to point to the parameter containing the version.","title":"yaml file containing the version"},{"location":"steps/artifactPrepareVersion/#usage","text":"We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line .","title":"Usage"},{"location":"steps/artifactPrepareVersion/#jenkins-pipelines","text":"artifactPrepareVersion script: this","title":"Jenkins pipelines"},{"location":"steps/artifactPrepareVersion/#command-line","text":"piper artifactPrepareVersion","title":"Command line"},{"location":"steps/artifactPrepareVersion/#outputs","text":"Output type Details commonPipelineEnvironment artifactVersion originalArtifactVersion git/commitId git/commitMessage","title":"Outputs"},{"location":"steps/artifactPrepareVersion/#parameters","text":"","title":"Parameters"},{"location":"steps/artifactPrepareVersion/#overview","text":"Name Mandatory Additional information buildTool yes gitHttpsCredentialsId yes id of credentials ( using credentials ) gitSshKeyCredentialsId yes id of credentials ( using credentials ) script yes reference to Jenkins main pipeline script commitUserName no containerCommand no containerShell no customVersionField no customVersionSection no customVersioningScheme no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no dockerVersionSource no dockerVolumeBind no dockerWorkspace no filePath no globalSettingsFile no includeCommitId no m2Path no password no pass via ENV or Jenkins credentials ( gitHttpsCredentialsId ) projectSettingsFile no shortCommitId no tagPrefix no unixTimestamp no username no pass via ENV or Jenkins credentials ( gitHttpsCredentialsId ) verbose no activates debug output versioningTemplate no versioningType no","title":"Overview"},{"location":"steps/artifactPrepareVersion/#details","text":"","title":"Details"},{"location":"steps/artifactPrepareVersion/#buildtool","text":"Defines the tool which is used for building the artifact. Supports custom , dub , golang , maven , mta , npm , pip , sbt . back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_buildTool (if set) Possible values - custom - docker - dub - golang - maven - mta - npm - pip - sbt Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"buildTool"},{"location":"steps/artifactPrepareVersion/#commitusername","text":"Defines the user name which appears in version control for the versioning update (in case versioningType: cloud ). back to overview Scope Details Aliases gitUserName Type string Mandatory no Default Project Piper Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"commitUserName"},{"location":"steps/artifactPrepareVersion/#containercommand","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default (/usr/bin/tail -f /dev/null). back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"containerCommand"},{"location":"steps/artifactPrepareVersion/#containershell","text":"Jenkins-specific: Used for proper environment setup. Allows to specify the shell to be executed for container with containerName. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"containerShell"},{"location":"steps/artifactPrepareVersion/#customversionfield","text":"For buildTool: custom : Defines the field which contains the version in the descriptor file. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_customVersionField (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"customVersionField"},{"location":"steps/artifactPrepareVersion/#customversionsection","text":"For buildTool: custom : Defines the section for version retrieval in vase a .ini/ .cfg file is used. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_customVersionSection (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"customVersionSection"},{"location":"steps/artifactPrepareVersion/#customversioningscheme","text":"For buildTool: custom : Defines the versioning scheme to be used (possible options pep440 , maven , semver2 ). back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_customVersioningScheme (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"customVersioningScheme"},{"location":"steps/artifactPrepareVersion/#dockerenvvars","text":"Jenkins-specific: Used for proper environment setup. Environment variables to set in the container, e.g. [http_proxy: \"proxy:8080\"]. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerEnvVars"},{"location":"steps/artifactPrepareVersion/#dockerimage","text":"Jenkins-specific: Used for proper environment setup. Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. back to overview Scope Details Aliases - Type string Mandatory no Default buildTool= maven : maven:3.6-jdk-8 Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerImage"},{"location":"steps/artifactPrepareVersion/#dockername","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Name of the container launching dockerImage. SideCar only: Name of the container in local network. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerName"},{"location":"steps/artifactPrepareVersion/#dockeroptions","text":"Jenkins-specific: Used for proper environment setup. Docker options to be set when starting the container. back to overview Scope Details Aliases - Type []string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerOptions"},{"location":"steps/artifactPrepareVersion/#dockerpullimage","text":"Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default buildTool= maven : false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerPullImage"},{"location":"steps/artifactPrepareVersion/#dockerversionsource","text":"For buildTool: docker : Defines the source of the version. Can be FROM , any supported buildTool or an environment variable name. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_dockerVersionSource (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"dockerVersionSource"},{"location":"steps/artifactPrepareVersion/#dockervolumebind","text":"Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the docker container. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerVolumeBind"},{"location":"steps/artifactPrepareVersion/#dockerworkspace","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerWorkspace"},{"location":"steps/artifactPrepareVersion/#filepath","text":"Defines a custom path to the descriptor file. Build tool specific defaults are used (e.g. maven: pom.xml , npm: package.json , mta: mta.yaml ). back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_filePath (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"filePath"},{"location":"steps/artifactPrepareVersion/#githttpscredentialsid","text":"Jenkins-specific: Used for proper environment setup. back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"gitHttpsCredentialsId"},{"location":"steps/artifactPrepareVersion/#gitsshkeycredentialsid","text":"Jenkins-specific: Used for proper environment setup. back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"gitSshKeyCredentialsId"},{"location":"steps/artifactPrepareVersion/#globalsettingsfile","text":"Maven only - Path to the mvn settings file that should be used as global settings file. back to overview Scope Details Aliases maven/globalSettingsFile Type string Mandatory no Default $PIPER_globalSettingsFile (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"globalSettingsFile"},{"location":"steps/artifactPrepareVersion/#includecommitid","text":"Defines if the automatically generated version ( versioningType: cloud ) should include the commit id hash. back to overview Scope Details Aliases - Type bool Mandatory no Default true Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"includeCommitId"},{"location":"steps/artifactPrepareVersion/#m2path","text":"Maven only - Path to the location of the local repository that should be used. back to overview Scope Details Aliases maven/m2Path Type string Mandatory no Default $PIPER_m2Path (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"m2Path"},{"location":"steps/artifactPrepareVersion/#password","text":"Password/token for git authentication. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_password (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references Jenkins credential id: id: gitHttpsCredentialsId reference to: password","title":"password"},{"location":"steps/artifactPrepareVersion/#projectsettingsfile","text":"Maven only - Path to the mvn settings file that should be used as project settings file. back to overview Scope Details Aliases maven/projectSettingsFile Type string Mandatory no Default $PIPER_projectSettingsFile (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"projectSettingsFile"},{"location":"steps/artifactPrepareVersion/#script","text":"Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none","title":"script"},{"location":"steps/artifactPrepareVersion/#shortcommitid","text":"Defines if a short version of the commitId should be used. GitHub format is used (first 7 characters). back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"shortCommitId"},{"location":"steps/artifactPrepareVersion/#tagprefix","text":"Defines the prefix which is used for the git tag which is written during the versioning run (only versioningType: cloud ). back to overview Scope Details Aliases - Type string Mandatory no Default build_ Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"tagPrefix"},{"location":"steps/artifactPrepareVersion/#unixtimestamp","text":"Defines if the Unix timestamp number should be used as build number instead of the standard date format. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"unixTimestamp"},{"location":"steps/artifactPrepareVersion/#username","text":"User name for git authentication back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_username (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references Jenkins credential id: id: gitHttpsCredentialsId reference to: username","title":"username"},{"location":"steps/artifactPrepareVersion/#verbose","text":"verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"verbose"},{"location":"steps/artifactPrepareVersion/#versioningtemplate","text":"DEPRECATED: Defines the template for the automatic version which will be created back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_versioningTemplate (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"versioningTemplate"},{"location":"steps/artifactPrepareVersion/#versioningtype","text":"Defines the type of versioning ( cloud : fully automatic, cloud_noTag : automatic but no tag created, library : manual, i.e. the pipeline will pick up the version from the build descriptor, but not generate a new version) back to overview Scope Details Aliases - Type string Mandatory no Default cloud Possible values - cloud - cloud_noTag - library Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"versioningType"},{"location":"steps/artifactSetVersion/","text":"artifactSetVersion \u00b6 Description \u00b6 The continuous delivery process requires that each build is done with a unique version number. The version generated using this step will contain: Version (major.minor.patch) from descriptor file in master repository is preserved. Developers should be able to autonomously decide on increasing either part of this version number. Timestamp CommitId (by default the long version of the hash) Optionally, but enabled by default, the new version is pushed as a new tag into the source code repository (e.g. GitHub). If this option is chosen, git credentials and the repository URL needs to be provided. Since you might not want to configure the git credentials in Jenkins, committing and pushing can be disabled using the commitVersion parameter as described below. If you require strict reproducibility of your builds, this should be used. Prerequisites \u00b6 none Parameters \u00b6 name mandatory default possible values artifactType no appContainer buildTool yes dub , docker , golang , maven , mta , npm , pip , sbt commitVersion no true true , false dockerVersionSource no FROM, (ENV name),appVersion filePath no buildTool= dub : dub.json buildTool= docker : Dockerfile buildTool= golang : VERSION buildTool= maven : pom.xml buildTool= mta : mta.yaml buildTool= npm : package.json buildTool= pip : version.txt buildTool= sbt : sbtDescriptor.json gitCommitId no gitDisableSslVerification no false gitHttpsCredentialsId no git gitHttpsUrl for gitPushMode HTTPS gitPushMode no SSH 'SSH', 'HTTPS', 'NONE' gitSshKeyCredentialsId no `` gitSshUrl for gitPushMode SSH gitUserEMail no gitUserName no script yes tagPrefix no build_ timestamp no timestampTemplate no %Y%m%d%H%M%S verbose no false true , false versioningTemplate no buildTool= dub : ${version}-${timestamp}${commitId?\"+\"+commitId:\"\"} buildTool= docker : ${version}-${timestamp}${commitId?\"_\"+commitId:\"\"} buildTool= golang : ${version}-${timestamp}${commitId?\"+\"+commitId:\"\"} buildTool= maven : ${version}-${timestamp}${commitId?\"_\"+commitId:\"\"} buildTool= mta : ${version}-${timestamp}${commitId?\"+\"+commitId:\"\"} buildTool= npm : ${version}-${timestamp}${commitId?\"+\"+commitId:\"\"} buildTool= pip : ${version}.${timestamp}${commitId?\".\"+commitId:\"\"} buildTool= sbt : ${version}-${timestamp}${commitId?\"+\"+commitId:\"\"} artifactType - Defines the type of the artifact. buildTool - Defines the tool which is used for building the artifact. commitVersion - Controls if the changed version is committed and pushed to the git repository. If this is enabled (which is the default), you need to provide gitCredentialsId and gitSshUrl . dockerVersionSource - Specifies the source to be used for the main version which is used for generating the automatic version. * This can either be the version of the base image - as retrieved from the FROM statement within the Dockerfile, e.g. FROM jenkins:2.46.2 * Alternatively the name of an environment variable defined in the Docker image can be used which contains the version number, e.g. ENV MY_VERSION 1.2.3 * The third option appVersion applies only to the artifactType appContainer . Here the version of the app which is packaged into the container will be used as version for the container itself. filePath - Defines a custom path to the descriptor file. gitCommitId - Defines the version prefix of the automatically generated version. By default it will take the long commitId hash. You could pass any other string (e.g. the short commitId hash) to be used. In case you don't want to have the gitCommitId added to the automatic versioning string you could set the value to an empty string: '' . gitDisableSslVerification - Disables the ssl verification for git push. Intended to be used only for troubleshooting. Productive usage is not recommanded. gitHttpsCredentialsId - gitHttpsUrl - Defines the git https url to the source code repository. Used in conjunction with 'GitPushMode.HTTPS'. gitPushMode - Controls which protocol is used for performing push operation to remote repo. Required credentials needs to be configured ('gitSshKeyCredentialsId'/'gitHttpsCredentialsId'). Push is only performed in case 'commitVersion' is set to 'true'. gitSshKeyCredentialsId - Defines the ssh git credentials to be used for writing the tag. gitSshUrl - Defines the git ssh url to the source code repository. Used in conjunction with 'GitPushMode.SSH'. gitUserEMail - Allows to overwrite the global git setting 'user.email' available on your Jenkins server. gitUserName - Allows to overwrite the global git setting 'user.name' available on your Jenkins server. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. tagPrefix - Defines the prefix which is used for the git tag which is written during the versioning run. timestamp - Defines the timestamp to be used in the automatic version string. You could overwrite the default behavior by explicitly setting this string. timestampTemplate - Defines the template for the timestamp which will be part of the created version. verbose - Prints some more information for troubleshooting. May reveal security relevant information. Usage is recommanded for troubleshooting only. Productive usage is not recommended. versioningTemplate - Defines the template for the automatic version which will be created. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage artifactType X buildTool X commitVersion X dockerVersionSource X filePath X gitCommitId gitDisableSslVerification X gitHttpsCredentialsId X gitHttpsUrl X gitPushMode X gitSshKeyCredentialsId X gitSshUrl X gitUserEMail X gitUserName X script tagPrefix X timestamp X timestampTemplate X verbose X versioningTemplate X Dependencies \u00b6 The step depends on the following Jenkins plugins credentials-binding pipeline-utility-steps ssh-agent workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Example \u00b6 artifactSetVersion script: this , buildTool: 'maven'","title":"artifactSetVersion"},{"location":"steps/artifactSetVersion/#artifactsetversion","text":"","title":"artifactSetVersion"},{"location":"steps/artifactSetVersion/#description","text":"The continuous delivery process requires that each build is done with a unique version number. The version generated using this step will contain: Version (major.minor.patch) from descriptor file in master repository is preserved. Developers should be able to autonomously decide on increasing either part of this version number. Timestamp CommitId (by default the long version of the hash) Optionally, but enabled by default, the new version is pushed as a new tag into the source code repository (e.g. GitHub). If this option is chosen, git credentials and the repository URL needs to be provided. Since you might not want to configure the git credentials in Jenkins, committing and pushing can be disabled using the commitVersion parameter as described below. If you require strict reproducibility of your builds, this should be used.","title":"Description"},{"location":"steps/artifactSetVersion/#prerequisites","text":"none","title":"Prerequisites"},{"location":"steps/artifactSetVersion/#parameters","text":"name mandatory default possible values artifactType no appContainer buildTool yes dub , docker , golang , maven , mta , npm , pip , sbt commitVersion no true true , false dockerVersionSource no FROM, (ENV name),appVersion filePath no buildTool= dub : dub.json buildTool= docker : Dockerfile buildTool= golang : VERSION buildTool= maven : pom.xml buildTool= mta : mta.yaml buildTool= npm : package.json buildTool= pip : version.txt buildTool= sbt : sbtDescriptor.json gitCommitId no gitDisableSslVerification no false gitHttpsCredentialsId no git gitHttpsUrl for gitPushMode HTTPS gitPushMode no SSH 'SSH', 'HTTPS', 'NONE' gitSshKeyCredentialsId no `` gitSshUrl for gitPushMode SSH gitUserEMail no gitUserName no script yes tagPrefix no build_ timestamp no timestampTemplate no %Y%m%d%H%M%S verbose no false true , false versioningTemplate no buildTool= dub : ${version}-${timestamp}${commitId?\"+\"+commitId:\"\"} buildTool= docker : ${version}-${timestamp}${commitId?\"_\"+commitId:\"\"} buildTool= golang : ${version}-${timestamp}${commitId?\"+\"+commitId:\"\"} buildTool= maven : ${version}-${timestamp}${commitId?\"_\"+commitId:\"\"} buildTool= mta : ${version}-${timestamp}${commitId?\"+\"+commitId:\"\"} buildTool= npm : ${version}-${timestamp}${commitId?\"+\"+commitId:\"\"} buildTool= pip : ${version}.${timestamp}${commitId?\".\"+commitId:\"\"} buildTool= sbt : ${version}-${timestamp}${commitId?\"+\"+commitId:\"\"} artifactType - Defines the type of the artifact. buildTool - Defines the tool which is used for building the artifact. commitVersion - Controls if the changed version is committed and pushed to the git repository. If this is enabled (which is the default), you need to provide gitCredentialsId and gitSshUrl . dockerVersionSource - Specifies the source to be used for the main version which is used for generating the automatic version. * This can either be the version of the base image - as retrieved from the FROM statement within the Dockerfile, e.g. FROM jenkins:2.46.2 * Alternatively the name of an environment variable defined in the Docker image can be used which contains the version number, e.g. ENV MY_VERSION 1.2.3 * The third option appVersion applies only to the artifactType appContainer . Here the version of the app which is packaged into the container will be used as version for the container itself. filePath - Defines a custom path to the descriptor file. gitCommitId - Defines the version prefix of the automatically generated version. By default it will take the long commitId hash. You could pass any other string (e.g. the short commitId hash) to be used. In case you don't want to have the gitCommitId added to the automatic versioning string you could set the value to an empty string: '' . gitDisableSslVerification - Disables the ssl verification for git push. Intended to be used only for troubleshooting. Productive usage is not recommanded. gitHttpsCredentialsId - gitHttpsUrl - Defines the git https url to the source code repository. Used in conjunction with 'GitPushMode.HTTPS'. gitPushMode - Controls which protocol is used for performing push operation to remote repo. Required credentials needs to be configured ('gitSshKeyCredentialsId'/'gitHttpsCredentialsId'). Push is only performed in case 'commitVersion' is set to 'true'. gitSshKeyCredentialsId - Defines the ssh git credentials to be used for writing the tag. gitSshUrl - Defines the git ssh url to the source code repository. Used in conjunction with 'GitPushMode.SSH'. gitUserEMail - Allows to overwrite the global git setting 'user.email' available on your Jenkins server. gitUserName - Allows to overwrite the global git setting 'user.name' available on your Jenkins server. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. tagPrefix - Defines the prefix which is used for the git tag which is written during the versioning run. timestamp - Defines the timestamp to be used in the automatic version string. You could overwrite the default behavior by explicitly setting this string. timestampTemplate - Defines the template for the timestamp which will be part of the created version. verbose - Prints some more information for troubleshooting. May reveal security relevant information. Usage is recommanded for troubleshooting only. Productive usage is not recommended. versioningTemplate - Defines the template for the automatic version which will be created.","title":"Parameters"},{"location":"steps/artifactSetVersion/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage artifactType X buildTool X commitVersion X dockerVersionSource X filePath X gitCommitId gitDisableSslVerification X gitHttpsCredentialsId X gitHttpsUrl X gitPushMode X gitSshKeyCredentialsId X gitSshUrl X gitUserEMail X gitUserName X script tagPrefix X timestamp X timestampTemplate X verbose X versioningTemplate X","title":"Step configuration"},{"location":"steps/artifactSetVersion/#dependencies","text":"The step depends on the following Jenkins plugins credentials-binding pipeline-utility-steps ssh-agent workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/artifactSetVersion/#example","text":"artifactSetVersion script: this , buildTool: 'maven'","title":"Example"},{"location":"steps/batsExecuteTests/","text":"batsExecuteTests \u00b6 Description \u00b6 This step executes tests using the Bash Automated Testing System - bats-core Prerequisites \u00b6 You need to have a Bats test file. By default you would put this into directory src/test within your source code repository. Parameters \u00b6 name mandatory default possible values dockerEnvVars no dockerImage no node:lts-stretch dockerOptions no dockerWorkspace no /home/node envVars no [:] failOnError no false gitBranch no gitSshKeyCredentialsId no `` outputFormat no junit junit , tap repository no https://github.com/bats-core/bats-core.git script yes stashContent no [tests] testPackage no piper-bats testPath no src/test testRepository no dockerEnvVars - Environment variables to set in the container, e.g. [http_proxy: 'proxy:8080']. dockerImage - Name of the docker image that should be used. Configure with empty value to execute the command directly on the Jenkins system (not using a container). Omit to use the default image (cf. default_pipeline_environment.yml ) Overwrite to use custom Docker image. dockerOptions - Docker only: Docker options to be set when starting the container (List or String). dockerWorkspace - Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . envVars - Defines the environment variables to pass to the test execution. failOnError - Defines the behavior, in case tests fail. For example, in case of outputFormat: 'junit' you should set it to false . Otherwise test results cannot be recorded using the testsPublishhResults step afterwards. gitBranch - Defines the branch where the tests are located, in case the tests are not located in the master branch. gitSshKeyCredentialsId - Defines the access credentials for protected repositories. Note: In case of using a protected repository, testRepository should include the ssh link to the repository. outputFormat - Defines the format of the test result output. junit would be the standard for automated build environments but you could use also the option tap . repository - Defines the version of bats-core to be used. By default we use the version from the master branch. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. stashContent - Specific stashes that should be considered for the step execution. testPackage - For the transformation of the test result to xUnit format the node module tap-xunit is used. This parameter defines the name of the test package used in the xUnit result file. testPath - Defines either the directory which contains the test files ( *.bats ) or a single file. You can find further details in the Bats-core documentation . testRepository - Allows to load tests from another repository. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage dockerEnvVars X dockerImage X dockerOptions X dockerWorkspace X envVars X failOnError X gitBranch X gitSshKeyCredentialsId X outputFormat X repository X script stashContent X testPackage X testPath X testRepository X Dependencies \u00b6 The step depends on the following Jenkins plugins docker git kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Example \u00b6 batsExecuteTests script: this testsPublishResults junit: [ pattern: '**/Test-*.xml' , archive: true ] With `envVars` it is possible to pass either fixed values but also templates using [`commonPipelineEnvironment`](commonPipelineEnvironment.md). Example: ```yaml batsExecuteTests script: this, envVars = [ FIX_VALUE: 'my fixed value', CONTAINER_NAME: '${commonPipelineEnvironment.configuration.steps.executeBatsTests.dockerContainerName}', IMAGE_NAME: '${return commonPipelineEnvironment.getDockerImageNameAndTag()}' ] ``` This means within the test one could refer to environment variables by calling e.g. `run docker run --rm -i --name \\$CONTAINER_NAME --entrypoint /bin/bash \\$IMAGE_NAME echo \"Test\"`","title":"batsExecuteTests"},{"location":"steps/batsExecuteTests/#batsexecutetests","text":"","title":"batsExecuteTests"},{"location":"steps/batsExecuteTests/#description","text":"This step executes tests using the Bash Automated Testing System - bats-core","title":"Description"},{"location":"steps/batsExecuteTests/#prerequisites","text":"You need to have a Bats test file. By default you would put this into directory src/test within your source code repository.","title":"Prerequisites"},{"location":"steps/batsExecuteTests/#parameters","text":"name mandatory default possible values dockerEnvVars no dockerImage no node:lts-stretch dockerOptions no dockerWorkspace no /home/node envVars no [:] failOnError no false gitBranch no gitSshKeyCredentialsId no `` outputFormat no junit junit , tap repository no https://github.com/bats-core/bats-core.git script yes stashContent no [tests] testPackage no piper-bats testPath no src/test testRepository no dockerEnvVars - Environment variables to set in the container, e.g. [http_proxy: 'proxy:8080']. dockerImage - Name of the docker image that should be used. Configure with empty value to execute the command directly on the Jenkins system (not using a container). Omit to use the default image (cf. default_pipeline_environment.yml ) Overwrite to use custom Docker image. dockerOptions - Docker only: Docker options to be set when starting the container (List or String). dockerWorkspace - Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . envVars - Defines the environment variables to pass to the test execution. failOnError - Defines the behavior, in case tests fail. For example, in case of outputFormat: 'junit' you should set it to false . Otherwise test results cannot be recorded using the testsPublishhResults step afterwards. gitBranch - Defines the branch where the tests are located, in case the tests are not located in the master branch. gitSshKeyCredentialsId - Defines the access credentials for protected repositories. Note: In case of using a protected repository, testRepository should include the ssh link to the repository. outputFormat - Defines the format of the test result output. junit would be the standard for automated build environments but you could use also the option tap . repository - Defines the version of bats-core to be used. By default we use the version from the master branch. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. stashContent - Specific stashes that should be considered for the step execution. testPackage - For the transformation of the test result to xUnit format the node module tap-xunit is used. This parameter defines the name of the test package used in the xUnit result file. testPath - Defines either the directory which contains the test files ( *.bats ) or a single file. You can find further details in the Bats-core documentation . testRepository - Allows to load tests from another repository.","title":"Parameters"},{"location":"steps/batsExecuteTests/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage dockerEnvVars X dockerImage X dockerOptions X dockerWorkspace X envVars X failOnError X gitBranch X gitSshKeyCredentialsId X outputFormat X repository X script stashContent X testPackage X testPath X testRepository X","title":"Step configuration"},{"location":"steps/batsExecuteTests/#dependencies","text":"The step depends on the following Jenkins plugins docker git kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/batsExecuteTests/#example","text":"batsExecuteTests script: this testsPublishResults junit: [ pattern: '**/Test-*.xml' , archive: true ] With `envVars` it is possible to pass either fixed values but also templates using [`commonPipelineEnvironment`](commonPipelineEnvironment.md). Example: ```yaml batsExecuteTests script: this, envVars = [ FIX_VALUE: 'my fixed value', CONTAINER_NAME: '${commonPipelineEnvironment.configuration.steps.executeBatsTests.dockerContainerName}', IMAGE_NAME: '${return commonPipelineEnvironment.getDockerImageNameAndTag()}' ] ``` This means within the test one could refer to environment variables by calling e.g. `run docker run --rm -i --name \\$CONTAINER_NAME --entrypoint /bin/bash \\$IMAGE_NAME echo \"Test\"`","title":"Example"},{"location":"steps/buildExecute/","text":"buildExecute \u00b6 Description \u00b6 This step serves as generic entry point in pipelines for building artifacts. You can use pre-defined buildTool s. Alternatively you can define a command via dockerCommand which should be executed in dockerImage . This allows you to trigger any build tool using a defined Docker container which provides the required build infrastructure. When using buildTool: docker or buildTool: kaniko the created container image is uploaded to a container registry. You need to make sure that the required credentials are provided to the step. For all other buildTool s the artifact will just be stored in the workspace and could then be stash ed for later use. Prerequisites \u00b6 When performing a Docker build you need to maintain the respective credentials in your Jenkins credentials store. Further details for builds when a Docker deamon: see step containerPushToRegistry for builds using Kaniko: see step kanikoExecute Example \u00b6 buildExecute script: this , buildTool: 'maven' Parameters \u00b6 name mandatory default possible values buildTool no docker , kaniko , maven , mta , npm containerBuildOptions no dockerCommand no dockerImage no dockerImageName yes dockerImageTag yes dockerRegistryUrl no npmInstall no true npmRunScripts no [] script yes buildTool - Defines the tool used for the build. containerBuildOptions - Only for Docker builds on the local daemon: Defines the build options for the build. dockerCommand - For custom build types: Defines the command to be executed within the dockerImage in order to execute the build. dockerImage - For custom build types: Image to be used for builds in case they should run inside a custom Docker container dockerImageName - For Docker builds only (mandatory): name of the image to be built. dockerImageTag - For Docker builds only (mandatory): tag of the image to be built. dockerRegistryUrl - For Docker builds only: Defines the registry url where the image should be pushed to, incl. the protocol like https://my.registry.com . If it is not defined, image will not be pushed to a registry. npmInstall - For buildTool npm: Execute npm install (boolean, default 'true') npmRunScripts - For buildTool npm: List of npm run scripts to execute script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage buildTool X X containerBuildOptions X dockerCommand X dockerImage X dockerImageName X X dockerImageTag X dockerRegistryUrl X X npmInstall X npmRunScripts X script Dependencies \u00b6 The step depends on the following Jenkins plugins credentials-binding docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"buildExecute"},{"location":"steps/buildExecute/#buildexecute","text":"","title":"buildExecute"},{"location":"steps/buildExecute/#description","text":"This step serves as generic entry point in pipelines for building artifacts. You can use pre-defined buildTool s. Alternatively you can define a command via dockerCommand which should be executed in dockerImage . This allows you to trigger any build tool using a defined Docker container which provides the required build infrastructure. When using buildTool: docker or buildTool: kaniko the created container image is uploaded to a container registry. You need to make sure that the required credentials are provided to the step. For all other buildTool s the artifact will just be stored in the workspace and could then be stash ed for later use.","title":"Description"},{"location":"steps/buildExecute/#prerequisites","text":"When performing a Docker build you need to maintain the respective credentials in your Jenkins credentials store. Further details for builds when a Docker deamon: see step containerPushToRegistry for builds using Kaniko: see step kanikoExecute","title":"Prerequisites"},{"location":"steps/buildExecute/#example","text":"buildExecute script: this , buildTool: 'maven'","title":"Example"},{"location":"steps/buildExecute/#parameters","text":"name mandatory default possible values buildTool no docker , kaniko , maven , mta , npm containerBuildOptions no dockerCommand no dockerImage no dockerImageName yes dockerImageTag yes dockerRegistryUrl no npmInstall no true npmRunScripts no [] script yes buildTool - Defines the tool used for the build. containerBuildOptions - Only for Docker builds on the local daemon: Defines the build options for the build. dockerCommand - For custom build types: Defines the command to be executed within the dockerImage in order to execute the build. dockerImage - For custom build types: Image to be used for builds in case they should run inside a custom Docker container dockerImageName - For Docker builds only (mandatory): name of the image to be built. dockerImageTag - For Docker builds only (mandatory): tag of the image to be built. dockerRegistryUrl - For Docker builds only: Defines the registry url where the image should be pushed to, incl. the protocol like https://my.registry.com . If it is not defined, image will not be pushed to a registry. npmInstall - For buildTool npm: Execute npm install (boolean, default 'true') npmRunScripts - For buildTool npm: List of npm run scripts to execute script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters.","title":"Parameters"},{"location":"steps/buildExecute/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage buildTool X X containerBuildOptions X dockerCommand X dockerImage X dockerImageName X X dockerImageTag X dockerRegistryUrl X X npmInstall X npmRunScripts X script","title":"Step configuration"},{"location":"steps/buildExecute/#dependencies","text":"The step depends on the following Jenkins plugins credentials-binding docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/cfManifestSubstituteVariables/","text":"cfManifestSubstituteVariables \u00b6 Description \u00b6 Step to substitute variables in a given YAML file with those specified in one or more variables files given by the manifestVariablesFiles parameter. This follows the behavior of cf push --vars-file , and can be used as a pre-deployment step if commands other than cf push are used for deployment (e.g. cf blue-green-deploy ). The format to reference a variable in the manifest YAML file is to use double parentheses (( and )) , e.g. ((variableName)) . You can declare variable assignments as key value-pairs inside a YAML variables file following the Cloud Foundry standards format. Optionally, you can also specify a direct list of key-value mappings for variables using the manifestVariables parameter. Variables given in the manifestVariables list will take precedence over those found in variables files. This follows the behavior of cf push --var , and works in combination with manifestVariablesFiles . The step is activated by the presence of the file specified by the manifestFile parameter and all variables files specified by the manifestVariablesFiles parameter, or if variables are passed in directly via manifestVariables . In case no manifestVariablesFiles were explicitly specified, a default named manifest-variables.yml will be looked for and if present will activate this step also. This is to support convention over configuration. Parameters \u00b6 name mandatory default possible values manifestFile no manifestVariables no manifestVariablesFiles no outputManifestFile no script yes manifestFile - The String path of the Yaml file to replace variables in. Defaults to \"manifest.yml\" if not specified otherwise. manifestVariables - A List of Map entries for key-value pairs used for variable substitution within the file given by manifestFile . Defaults to an empty list, if not specified otherwise. This can be used to set variables like it is provided by cf push --var key=value . The order of the maps of variables given in the list is relevant in case there are conflicting variable names and values between maps contained within the list. In case of conflicts, the last specified map in the list will win. Though each map entry in the list can contain more than one key-value pair for variable substitution, it is recommended to stick to one entry per map, and rather declare more maps within the list. The reason is that if a map in the list contains more than one key-value entry, and the entries are conflicting, the conflict resolution behavior is undefined (since map entries have no sequence). Note: variables defined via manifestVariables always win over conflicting variables defined via any file given by manifestVariablesFiles - no matter what is declared before. This reproduces the same behavior as can be observed when using cf push --var in combination with cf push --vars-file . manifestVariablesFiles - The List of String paths of the Yaml files containing the variable values to use as a replacement in the manifest file. Defaults to [\"manifest-variables.yml\"] if not specified otherwise. The order of the files given in the list is relevant in case there are conflicting variable names and values within variable files. In such a case, the values of the last file win. outputManifestFile - The String path of the Yaml file to produce as output. If not specified this will default to manifestFile and overwrite it. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage manifestFile X manifestVariables X manifestVariablesFiles X outputManifestFile X script Dependencies \u00b6 The step depends on the following Jenkins plugins pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Side effects \u00b6 Unless configured otherwise, this step will replace the input manifest.yml with a version that has all variable references replaced. This alters the source tree in your Jenkins workspace. If you prefer to generate a separate output file, use the step's outputManifestFile parameter. Keep in mind, however, that your Cloud Foundry deployment step should then also reference this output file - otherwise CF deployment will fail with unresolved variable reference errors. Exceptions \u00b6 org.yaml.snakeyaml.scanner.ScannerException - in case any of the loaded input files contains malformed Yaml and cannot be parsed. hudson.AbortException - in case of internal errors and when not all variables could be replaced due to missing replacement values. Example \u00b6 Usage of pipeline step: cfManifestSubstituteVariables ( script: this , manifestFile: \"path/to/manifest.yml\" , //optional, default: manifest.yml manifestVariablesFiles: [ \"path/to/manifest-variables.yml\" ] //optional, default: ['manifest-variables.yml'] manifestVariables: [[ key : value ], [ key : value ]] //optional, default: [] ) For example, you can refer to the parameters using relative paths (similar to cf push --vars-file ): cfManifestSubstituteVariables ( script: this , manifestFile: \"manifest.yml\" , manifestVariablesFiles: [ \"manifest-variables.yml\" ] ) Furthermore, you can also specify variables and their values directly (similar to cf push --var ): cfManifestSubstituteVariables ( script: this , manifestFile: \"manifest.yml\" , manifestVariablesFiles: [ \"manifest-variables.yml\" ], manifestVariables: [[ key1 : value1 ], [ key2 : value2 ]] ) If you are using the Cloud Foundry Create-Service-Push CLI plugin you will most likely also have a services-manifest.yml file. Also in this file you can specify variable references, that can be resolved from the same variables file, e.g. like this: // resolve variables in manifest.yml cfManifestSubstituteVariables ( script: this , manifestFile: \"manifest.yml\" , manifestVariablesFiles: [ \"manifest-variables.yml\" ] ) // resolve variables in services-manifest.yml from same file. cfManifestSubstituteVariables ( script: this , manifestFile: \"services-manifest.yml\" , manifestVariablesFiles: [ \"manifest-variables.yml\" ] )","title":"cfManifestSubstituteVariables"},{"location":"steps/cfManifestSubstituteVariables/#cfmanifestsubstitutevariables","text":"","title":"cfManifestSubstituteVariables"},{"location":"steps/cfManifestSubstituteVariables/#description","text":"Step to substitute variables in a given YAML file with those specified in one or more variables files given by the manifestVariablesFiles parameter. This follows the behavior of cf push --vars-file , and can be used as a pre-deployment step if commands other than cf push are used for deployment (e.g. cf blue-green-deploy ). The format to reference a variable in the manifest YAML file is to use double parentheses (( and )) , e.g. ((variableName)) . You can declare variable assignments as key value-pairs inside a YAML variables file following the Cloud Foundry standards format. Optionally, you can also specify a direct list of key-value mappings for variables using the manifestVariables parameter. Variables given in the manifestVariables list will take precedence over those found in variables files. This follows the behavior of cf push --var , and works in combination with manifestVariablesFiles . The step is activated by the presence of the file specified by the manifestFile parameter and all variables files specified by the manifestVariablesFiles parameter, or if variables are passed in directly via manifestVariables . In case no manifestVariablesFiles were explicitly specified, a default named manifest-variables.yml will be looked for and if present will activate this step also. This is to support convention over configuration.","title":"Description"},{"location":"steps/cfManifestSubstituteVariables/#parameters","text":"name mandatory default possible values manifestFile no manifestVariables no manifestVariablesFiles no outputManifestFile no script yes manifestFile - The String path of the Yaml file to replace variables in. Defaults to \"manifest.yml\" if not specified otherwise. manifestVariables - A List of Map entries for key-value pairs used for variable substitution within the file given by manifestFile . Defaults to an empty list, if not specified otherwise. This can be used to set variables like it is provided by cf push --var key=value . The order of the maps of variables given in the list is relevant in case there are conflicting variable names and values between maps contained within the list. In case of conflicts, the last specified map in the list will win. Though each map entry in the list can contain more than one key-value pair for variable substitution, it is recommended to stick to one entry per map, and rather declare more maps within the list. The reason is that if a map in the list contains more than one key-value entry, and the entries are conflicting, the conflict resolution behavior is undefined (since map entries have no sequence). Note: variables defined via manifestVariables always win over conflicting variables defined via any file given by manifestVariablesFiles - no matter what is declared before. This reproduces the same behavior as can be observed when using cf push --var in combination with cf push --vars-file . manifestVariablesFiles - The List of String paths of the Yaml files containing the variable values to use as a replacement in the manifest file. Defaults to [\"manifest-variables.yml\"] if not specified otherwise. The order of the files given in the list is relevant in case there are conflicting variable names and values within variable files. In such a case, the values of the last file win. outputManifestFile - The String path of the Yaml file to produce as output. If not specified this will default to manifestFile and overwrite it. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters.","title":"Parameters"},{"location":"steps/cfManifestSubstituteVariables/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage manifestFile X manifestVariables X manifestVariablesFiles X outputManifestFile X script","title":"Step configuration"},{"location":"steps/cfManifestSubstituteVariables/#dependencies","text":"The step depends on the following Jenkins plugins pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/cfManifestSubstituteVariables/#side-effects","text":"Unless configured otherwise, this step will replace the input manifest.yml with a version that has all variable references replaced. This alters the source tree in your Jenkins workspace. If you prefer to generate a separate output file, use the step's outputManifestFile parameter. Keep in mind, however, that your Cloud Foundry deployment step should then also reference this output file - otherwise CF deployment will fail with unresolved variable reference errors.","title":"Side effects"},{"location":"steps/cfManifestSubstituteVariables/#exceptions","text":"org.yaml.snakeyaml.scanner.ScannerException - in case any of the loaded input files contains malformed Yaml and cannot be parsed. hudson.AbortException - in case of internal errors and when not all variables could be replaced due to missing replacement values.","title":"Exceptions"},{"location":"steps/cfManifestSubstituteVariables/#example","text":"Usage of pipeline step: cfManifestSubstituteVariables ( script: this , manifestFile: \"path/to/manifest.yml\" , //optional, default: manifest.yml manifestVariablesFiles: [ \"path/to/manifest-variables.yml\" ] //optional, default: ['manifest-variables.yml'] manifestVariables: [[ key : value ], [ key : value ]] //optional, default: [] ) For example, you can refer to the parameters using relative paths (similar to cf push --vars-file ): cfManifestSubstituteVariables ( script: this , manifestFile: \"manifest.yml\" , manifestVariablesFiles: [ \"manifest-variables.yml\" ] ) Furthermore, you can also specify variables and their values directly (similar to cf push --var ): cfManifestSubstituteVariables ( script: this , manifestFile: \"manifest.yml\" , manifestVariablesFiles: [ \"manifest-variables.yml\" ], manifestVariables: [[ key1 : value1 ], [ key2 : value2 ]] ) If you are using the Cloud Foundry Create-Service-Push CLI plugin you will most likely also have a services-manifest.yml file. Also in this file you can specify variable references, that can be resolved from the same variables file, e.g. like this: // resolve variables in manifest.yml cfManifestSubstituteVariables ( script: this , manifestFile: \"manifest.yml\" , manifestVariablesFiles: [ \"manifest-variables.yml\" ] ) // resolve variables in services-manifest.yml from same file. cfManifestSubstituteVariables ( script: this , manifestFile: \"services-manifest.yml\" , manifestVariablesFiles: [ \"manifest-variables.yml\" ] )","title":"Example"},{"location":"steps/checkChangeInDevelopment/","text":"checkChangeInDevelopment \u00b6 Description \u00b6 Checks if a Change Document in SAP Solution Manager is in status 'in development'. The change document id is retrieved from the git commit history. The change document id can also be provided via parameter changeDocumentId . Any value provided as parameter has a higher precedence than a value from the commit history. By default the git commit messages between origin/master and HEAD are scanned for a line like ChangeDocument : <changeDocumentId> . The commit range and the pattern can be configured. For details see 'parameters' table. Prerequisites \u00b6 Change Management Client 2.0.0 or compatible version - available for download on Maven Central. Note: This is only required if you don't use a Docker-based environment. Parameters \u00b6 name mandatory default possible values changeDocumentId yes changeManagement/changeDocumentLabel no ChangeDocument\\s?: regex pattern changeManagement/clientOpts no `` changeManagement/credentialsId no CM changeManagement/endpoint yes changeManagement/git/format no %b see git log --help changeManagement/git/from no origin/master changeManagement/git/to no HEAD failIfStatusIsNotInDevelopment no true true , false script yes changeDocumentId - The id of the change document to transport. If not provided, it is retrieved from the git commit history. changeManagement/changeDocumentLabel - A pattern used for identifying lines holding the change document id. changeManagement/clientOpts - Additional options for cm command line client, e.g. JAVA_OPTS. changeManagement/credentialsId - The id of the credentials to connect to the Solution Manager. The credentials needs to be maintained on Jenkins. changeManagement/endpoint - The service endpoint, e.g. Solution Manager, ABAP System. changeManagement/git/format - Specifies what part of the commit is scanned. By default the body of the commit message is scanned. changeManagement/git/from - The starting point for retrieving the change document id. changeManagement/git/to - The end point for retrieving the change document id. failIfStatusIsNotInDevelopment - When set to false the step will not fail in case the step is not in status 'in development'. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage changeDocumentId changeManagement/changeDocumentLabel X X changeManagement/clientOpts X X changeManagement/credentialsId X X changeManagement/endpoint X X changeManagement/git/format X X changeManagement/git/from X X changeManagement/git/to X X failIfStatusIsNotInDevelopment X script Dependencies \u00b6 The step depends on the following Jenkins plugins credentials-binding docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Exceptions \u00b6 AbortException : If the change id is not provided via parameter and if the change document id cannot be retrieved from the commit history. If the change is not in status in development . In this case no exception will be thrown when failIfStatusIsNotInDevelopment is set to false . IllegalArgumentException : If a mandatory property is not provided. Examples \u00b6 The step is configured using a customer configuration file provided as resource in an custom shared library. @Library ( 'piper-lib-os@master' ) _ // the shared lib containing the additional configuration // needs to be configured in Jenkins @Library ( 'foo@master' ) __ // inside the shared lib denoted by 'foo' the additional configuration file // needs to be located under 'resources' ('resoures/myConfig.yml') prepareDefaultValues script: this , customDefaults: 'myConfig.yml' Example content of 'resources/myConfig.yml' in branch 'master' of the repository denoted by 'foo' : general : changeManagement : changeDocumentLabel : 'ChangeDocument\\s?:' cmClientOpts : '-Djavax.net.ssl.trustStore=<path to truststore>' credentialsId : 'CM' endpoint : 'https://example.org/cm' git : from : 'HEAD~1' to : 'HEAD' format : '%b' The properties configured in section 'general/changeManagement' are shared between all change managment related steps. The properties can also be configured on a per-step basis: [ ... ] steps : checkChangeInDevelopment : changeManagement : endpoint : 'https://example.org/cm' [ ... ] failIfStatusIsNotInDevelopment : true The parameters can also be provided when the step is invoked: // simple case. All mandatory parameters provided via // configuration, changeDocumentId provided via commit // history checkChangeInDevelopment script: this // explict endpoint provided, we search for changeDocumentId // starting at the previous commit (HEAD~1) rather than on // 'origin/master' (the default). checkChangeInDevelopment ( script: this changeManagement: [ endpoint: 'https:example.org/cm' git: [ from: 'HEAD~1' ] ] )","title":"checkChangeInDevelopment"},{"location":"steps/checkChangeInDevelopment/#checkchangeindevelopment","text":"","title":"checkChangeInDevelopment"},{"location":"steps/checkChangeInDevelopment/#description","text":"Checks if a Change Document in SAP Solution Manager is in status 'in development'. The change document id is retrieved from the git commit history. The change document id can also be provided via parameter changeDocumentId . Any value provided as parameter has a higher precedence than a value from the commit history. By default the git commit messages between origin/master and HEAD are scanned for a line like ChangeDocument : <changeDocumentId> . The commit range and the pattern can be configured. For details see 'parameters' table.","title":"Description"},{"location":"steps/checkChangeInDevelopment/#prerequisites","text":"Change Management Client 2.0.0 or compatible version - available for download on Maven Central. Note: This is only required if you don't use a Docker-based environment.","title":"Prerequisites"},{"location":"steps/checkChangeInDevelopment/#parameters","text":"name mandatory default possible values changeDocumentId yes changeManagement/changeDocumentLabel no ChangeDocument\\s?: regex pattern changeManagement/clientOpts no `` changeManagement/credentialsId no CM changeManagement/endpoint yes changeManagement/git/format no %b see git log --help changeManagement/git/from no origin/master changeManagement/git/to no HEAD failIfStatusIsNotInDevelopment no true true , false script yes changeDocumentId - The id of the change document to transport. If not provided, it is retrieved from the git commit history. changeManagement/changeDocumentLabel - A pattern used for identifying lines holding the change document id. changeManagement/clientOpts - Additional options for cm command line client, e.g. JAVA_OPTS. changeManagement/credentialsId - The id of the credentials to connect to the Solution Manager. The credentials needs to be maintained on Jenkins. changeManagement/endpoint - The service endpoint, e.g. Solution Manager, ABAP System. changeManagement/git/format - Specifies what part of the commit is scanned. By default the body of the commit message is scanned. changeManagement/git/from - The starting point for retrieving the change document id. changeManagement/git/to - The end point for retrieving the change document id. failIfStatusIsNotInDevelopment - When set to false the step will not fail in case the step is not in status 'in development'. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters.","title":"Parameters"},{"location":"steps/checkChangeInDevelopment/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage changeDocumentId changeManagement/changeDocumentLabel X X changeManagement/clientOpts X X changeManagement/credentialsId X X changeManagement/endpoint X X changeManagement/git/format X X changeManagement/git/from X X changeManagement/git/to X X failIfStatusIsNotInDevelopment X script","title":"Step configuration"},{"location":"steps/checkChangeInDevelopment/#dependencies","text":"The step depends on the following Jenkins plugins credentials-binding docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/checkChangeInDevelopment/#exceptions","text":"AbortException : If the change id is not provided via parameter and if the change document id cannot be retrieved from the commit history. If the change is not in status in development . In this case no exception will be thrown when failIfStatusIsNotInDevelopment is set to false . IllegalArgumentException : If a mandatory property is not provided.","title":"Exceptions"},{"location":"steps/checkChangeInDevelopment/#examples","text":"The step is configured using a customer configuration file provided as resource in an custom shared library. @Library ( 'piper-lib-os@master' ) _ // the shared lib containing the additional configuration // needs to be configured in Jenkins @Library ( 'foo@master' ) __ // inside the shared lib denoted by 'foo' the additional configuration file // needs to be located under 'resources' ('resoures/myConfig.yml') prepareDefaultValues script: this , customDefaults: 'myConfig.yml' Example content of 'resources/myConfig.yml' in branch 'master' of the repository denoted by 'foo' : general : changeManagement : changeDocumentLabel : 'ChangeDocument\\s?:' cmClientOpts : '-Djavax.net.ssl.trustStore=<path to truststore>' credentialsId : 'CM' endpoint : 'https://example.org/cm' git : from : 'HEAD~1' to : 'HEAD' format : '%b' The properties configured in section 'general/changeManagement' are shared between all change managment related steps. The properties can also be configured on a per-step basis: [ ... ] steps : checkChangeInDevelopment : changeManagement : endpoint : 'https://example.org/cm' [ ... ] failIfStatusIsNotInDevelopment : true The parameters can also be provided when the step is invoked: // simple case. All mandatory parameters provided via // configuration, changeDocumentId provided via commit // history checkChangeInDevelopment script: this // explict endpoint provided, we search for changeDocumentId // starting at the previous commit (HEAD~1) rather than on // 'origin/master' (the default). checkChangeInDevelopment ( script: this changeManagement: [ endpoint: 'https:example.org/cm' git: [ from: 'HEAD~1' ] ] )","title":"Examples"},{"location":"steps/checkmarxExecuteScan/","text":"checkmarxExecuteScan \u00b6 Checkmarx is the recommended tool for security scans of JavaScript, iOS, Swift and Ruby code. Description \u00b6 Checkmarx is a Static Application Security Testing (SAST) tool to analyze i.e. Java- or TypeScript, Swift, Golang, Ruby code, and many other programming languages for security flaws based on a set of provided rules/queries that can be customized and extended. This step by default enforces a specific audit baseline for findings and therefore ensures that: No 'To Verify' High and Medium issues exist in your project Total number of High and Medium 'Confirmed' or 'Urgent' issues is zero * 10% of all Low issues are 'Confirmed' or 'Not Exploitable' You can adapt above thresholds specifically using the provided configuration parameters and i.e. check for absolute thresholds instead of percentage whereas we strongly recommend you to stay with the defaults provided. Usage \u00b6 We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line . Jenkins pipelines \u00b6 checkmarxExecuteScan script: this Command line \u00b6 piper checkmarxExecuteScan Outputs \u00b6 Output type Details influx measurement checkmarx_data high_issues high_not_false_postive high_not_exploitable high_confirmed high_urgent high_proposed_not_exploitable high_to_verify medium_issues medium_not_false_postive medium_not_exploitable medium_confirmed medium_urgent medium_proposed_not_exploitable medium_to_verify low_issues low_not_false_postive low_not_exploitable low_confirmed low_urgent low_proposed_not_exploitable low_to_verify information_issues information_not_false_postive information_not_exploitable information_confirmed information_urgent information_proposed_not_exploitable information_to_verify initiator_name owner scan_id project_id project_name team team_full_path_on_report_date scan_start scan_time lines_of_code_scanned files_scanned checkmarx_version scan_type preset deep_link report_creation_time Parameters \u00b6 Overview \u00b6 Name Mandatory Additional information checkmarxCredentialsId yes id of credentials ( using credentials ) password yes pass via ENV or Jenkins credentials ( checkmarxCredentialsId ) projectName yes script yes reference to Jenkins main pipeline script serverUrl yes username yes pass via ENV or Jenkins credentials ( checkmarxCredentialsId ) avoidDuplicateProjectScans no filterPattern no fullScanCycle no fullScansScheduled no generatePdfReport no incremental no preset no pullRequestName no sourceEncoding no teamId no teamName no verbose no activates debug output vulnerabilityThresholdEnabled no vulnerabilityThresholdHigh no vulnerabilityThresholdLow no vulnerabilityThresholdMedium no vulnerabilityThresholdResult no vulnerabilityThresholdUnit no Details \u00b6 avoidDuplicateProjectScans \u00b6 Whether duplicate scans of the same project state shall be avoided or not back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none checkmarxCredentialsId \u00b6 Jenkins-specific: Used for proper environment setup. The technical user/password credential used to communicate with the Checkmarx backend back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none filterPattern \u00b6 The filter pattern used to zip the files relevant for scanning, patterns can be negated by setting an exclamation mark in front i.e. !test/*.js would avoid adding any javascript files located in the test directory back to overview Scope Details Aliases - Type string Mandatory no Default !**/node_modules/**, !**/.xmake/**, !**/*_test.go, !**/vendor/**/*.go, **/*.html, **/*.xml, **/*.go, **/*.py, **/*.js, **/*.scala, **/*.ts Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none fullScanCycle \u00b6 Indicates how often a full scan should happen between the incremental scans when activated back to overview Scope Details Aliases - Type string Mandatory no Default 5 Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none fullScansScheduled \u00b6 Whether full scans are to be scheduled or not. Should be used in relation with incremental and fullScanCycle back to overview Scope Details Aliases - Type bool Mandatory no Default true Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none generatePdfReport \u00b6 Whether to generate a PDF report of the analysis results or not back to overview Scope Details Aliases - Type bool Mandatory no Default true Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none incremental \u00b6 Whether incremental scans are to be applied which optimizes the scan time but might reduce detection capabilities. Therefore full scans are still required from time to time and should be scheduled via fullScansScheduled and fullScanCycle back to overview Scope Details Aliases - Type bool Mandatory no Default true Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none password \u00b6 The password to authenticate back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_password (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references Jenkins credential id: id: checkmarxCredentialsId reference to: password preset \u00b6 The preset to use for scanning, if not set explicitly the step will attempt to look up the project's setting based on the availability of checkmarxCredentialsId back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_preset (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none projectName \u00b6 The name of the Checkmarx project to scan into back to overview Scope Details Aliases - checkmarxProject - checkMarxProjectName ( deprecated ) Type string Mandatory yes Default $PIPER_projectName (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none pullRequestName \u00b6 Used to supply the name for the newly created PR project branch when being used in pull request scenarios back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_pullRequestName (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none script \u00b6 Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none serverUrl \u00b6 The URL pointing to the root of the Checkmarx server to be used back to overview Scope Details Aliases checkmarxServerUrl Type string Mandatory yes Default $PIPER_serverUrl (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none sourceEncoding \u00b6 The source encoding to be used, if not set explicitly the project's default will be used back to overview Scope Details Aliases - Type string Mandatory no Default 1 Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none teamId \u00b6 The group ID related to your team which can be obtained via the Pipeline Syntax plugin as described in the Details section back to overview Scope Details Aliases - checkmarxGroupId - groupId ( deprecated ) Type string Mandatory no Default $PIPER_teamId (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none teamName \u00b6 The full name of the team to assign newly created projects to which is preferred to teamId back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_teamName (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none username \u00b6 The username to authenticate back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_username (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references Jenkins credential id: id: checkmarxCredentialsId reference to: username verbose \u00b6 verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none vulnerabilityThresholdEnabled \u00b6 Whether the thresholds are enabled or not. If enabled the build will be set to vulnerabilityThresholdResult in case a specific threshold value is exceeded back to overview Scope Details Aliases - Type bool Mandatory no Default true Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none vulnerabilityThresholdHigh \u00b6 The specific threshold for high severity findings back to overview Scope Details Aliases - Type int Mandatory no Default 100 Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none vulnerabilityThresholdLow \u00b6 The specific threshold for low severity findings back to overview Scope Details Aliases - Type int Mandatory no Default 10 Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none vulnerabilityThresholdMedium \u00b6 The specific threshold for medium severity findings back to overview Scope Details Aliases - Type int Mandatory no Default 100 Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none vulnerabilityThresholdResult \u00b6 The result of the build in case thresholds are enabled and exceeded back to overview Scope Details Aliases - Type string Mandatory no Default FAILURE Possible values - FAILURE Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none vulnerabilityThresholdUnit \u00b6 The unit for the threshold to apply. back to overview Scope Details Aliases - Type string Mandatory no Default percentage Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none \u00b6","title":"checkmarxExecuteScan"},{"location":"steps/checkmarxExecuteScan/#checkmarxexecutescan","text":"Checkmarx is the recommended tool for security scans of JavaScript, iOS, Swift and Ruby code.","title":"checkmarxExecuteScan"},{"location":"steps/checkmarxExecuteScan/#description","text":"Checkmarx is a Static Application Security Testing (SAST) tool to analyze i.e. Java- or TypeScript, Swift, Golang, Ruby code, and many other programming languages for security flaws based on a set of provided rules/queries that can be customized and extended. This step by default enforces a specific audit baseline for findings and therefore ensures that: No 'To Verify' High and Medium issues exist in your project Total number of High and Medium 'Confirmed' or 'Urgent' issues is zero * 10% of all Low issues are 'Confirmed' or 'Not Exploitable' You can adapt above thresholds specifically using the provided configuration parameters and i.e. check for absolute thresholds instead of percentage whereas we strongly recommend you to stay with the defaults provided.","title":"Description"},{"location":"steps/checkmarxExecuteScan/#usage","text":"We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line .","title":"Usage"},{"location":"steps/checkmarxExecuteScan/#jenkins-pipelines","text":"checkmarxExecuteScan script: this","title":"Jenkins pipelines"},{"location":"steps/checkmarxExecuteScan/#command-line","text":"piper checkmarxExecuteScan","title":"Command line"},{"location":"steps/checkmarxExecuteScan/#outputs","text":"Output type Details influx measurement checkmarx_data high_issues high_not_false_postive high_not_exploitable high_confirmed high_urgent high_proposed_not_exploitable high_to_verify medium_issues medium_not_false_postive medium_not_exploitable medium_confirmed medium_urgent medium_proposed_not_exploitable medium_to_verify low_issues low_not_false_postive low_not_exploitable low_confirmed low_urgent low_proposed_not_exploitable low_to_verify information_issues information_not_false_postive information_not_exploitable information_confirmed information_urgent information_proposed_not_exploitable information_to_verify initiator_name owner scan_id project_id project_name team team_full_path_on_report_date scan_start scan_time lines_of_code_scanned files_scanned checkmarx_version scan_type preset deep_link report_creation_time","title":"Outputs"},{"location":"steps/checkmarxExecuteScan/#parameters","text":"","title":"Parameters"},{"location":"steps/checkmarxExecuteScan/#overview","text":"Name Mandatory Additional information checkmarxCredentialsId yes id of credentials ( using credentials ) password yes pass via ENV or Jenkins credentials ( checkmarxCredentialsId ) projectName yes script yes reference to Jenkins main pipeline script serverUrl yes username yes pass via ENV or Jenkins credentials ( checkmarxCredentialsId ) avoidDuplicateProjectScans no filterPattern no fullScanCycle no fullScansScheduled no generatePdfReport no incremental no preset no pullRequestName no sourceEncoding no teamId no teamName no verbose no activates debug output vulnerabilityThresholdEnabled no vulnerabilityThresholdHigh no vulnerabilityThresholdLow no vulnerabilityThresholdMedium no vulnerabilityThresholdResult no vulnerabilityThresholdUnit no","title":"Overview"},{"location":"steps/checkmarxExecuteScan/#details","text":"","title":"Details"},{"location":"steps/checkmarxExecuteScan/#avoidduplicateprojectscans","text":"Whether duplicate scans of the same project state shall be avoided or not back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"avoidDuplicateProjectScans"},{"location":"steps/checkmarxExecuteScan/#checkmarxcredentialsid","text":"Jenkins-specific: Used for proper environment setup. The technical user/password credential used to communicate with the Checkmarx backend back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"checkmarxCredentialsId"},{"location":"steps/checkmarxExecuteScan/#filterpattern","text":"The filter pattern used to zip the files relevant for scanning, patterns can be negated by setting an exclamation mark in front i.e. !test/*.js would avoid adding any javascript files located in the test directory back to overview Scope Details Aliases - Type string Mandatory no Default !**/node_modules/**, !**/.xmake/**, !**/*_test.go, !**/vendor/**/*.go, **/*.html, **/*.xml, **/*.go, **/*.py, **/*.js, **/*.scala, **/*.ts Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"filterPattern"},{"location":"steps/checkmarxExecuteScan/#fullscancycle","text":"Indicates how often a full scan should happen between the incremental scans when activated back to overview Scope Details Aliases - Type string Mandatory no Default 5 Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"fullScanCycle"},{"location":"steps/checkmarxExecuteScan/#fullscansscheduled","text":"Whether full scans are to be scheduled or not. Should be used in relation with incremental and fullScanCycle back to overview Scope Details Aliases - Type bool Mandatory no Default true Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"fullScansScheduled"},{"location":"steps/checkmarxExecuteScan/#generatepdfreport","text":"Whether to generate a PDF report of the analysis results or not back to overview Scope Details Aliases - Type bool Mandatory no Default true Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"generatePdfReport"},{"location":"steps/checkmarxExecuteScan/#incremental","text":"Whether incremental scans are to be applied which optimizes the scan time but might reduce detection capabilities. Therefore full scans are still required from time to time and should be scheduled via fullScansScheduled and fullScanCycle back to overview Scope Details Aliases - Type bool Mandatory no Default true Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"incremental"},{"location":"steps/checkmarxExecuteScan/#password","text":"The password to authenticate back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_password (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references Jenkins credential id: id: checkmarxCredentialsId reference to: password","title":"password"},{"location":"steps/checkmarxExecuteScan/#preset","text":"The preset to use for scanning, if not set explicitly the step will attempt to look up the project's setting based on the availability of checkmarxCredentialsId back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_preset (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"preset"},{"location":"steps/checkmarxExecuteScan/#projectname","text":"The name of the Checkmarx project to scan into back to overview Scope Details Aliases - checkmarxProject - checkMarxProjectName ( deprecated ) Type string Mandatory yes Default $PIPER_projectName (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"projectName"},{"location":"steps/checkmarxExecuteScan/#pullrequestname","text":"Used to supply the name for the newly created PR project branch when being used in pull request scenarios back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_pullRequestName (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"pullRequestName"},{"location":"steps/checkmarxExecuteScan/#script","text":"Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none","title":"script"},{"location":"steps/checkmarxExecuteScan/#serverurl","text":"The URL pointing to the root of the Checkmarx server to be used back to overview Scope Details Aliases checkmarxServerUrl Type string Mandatory yes Default $PIPER_serverUrl (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"serverUrl"},{"location":"steps/checkmarxExecuteScan/#sourceencoding","text":"The source encoding to be used, if not set explicitly the project's default will be used back to overview Scope Details Aliases - Type string Mandatory no Default 1 Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"sourceEncoding"},{"location":"steps/checkmarxExecuteScan/#teamid","text":"The group ID related to your team which can be obtained via the Pipeline Syntax plugin as described in the Details section back to overview Scope Details Aliases - checkmarxGroupId - groupId ( deprecated ) Type string Mandatory no Default $PIPER_teamId (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"teamId"},{"location":"steps/checkmarxExecuteScan/#teamname","text":"The full name of the team to assign newly created projects to which is preferred to teamId back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_teamName (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"teamName"},{"location":"steps/checkmarxExecuteScan/#username","text":"The username to authenticate back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_username (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references Jenkins credential id: id: checkmarxCredentialsId reference to: username","title":"username"},{"location":"steps/checkmarxExecuteScan/#verbose","text":"verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"verbose"},{"location":"steps/checkmarxExecuteScan/#vulnerabilitythresholdenabled","text":"Whether the thresholds are enabled or not. If enabled the build will be set to vulnerabilityThresholdResult in case a specific threshold value is exceeded back to overview Scope Details Aliases - Type bool Mandatory no Default true Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"vulnerabilityThresholdEnabled"},{"location":"steps/checkmarxExecuteScan/#vulnerabilitythresholdhigh","text":"The specific threshold for high severity findings back to overview Scope Details Aliases - Type int Mandatory no Default 100 Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"vulnerabilityThresholdHigh"},{"location":"steps/checkmarxExecuteScan/#vulnerabilitythresholdlow","text":"The specific threshold for low severity findings back to overview Scope Details Aliases - Type int Mandatory no Default 10 Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"vulnerabilityThresholdLow"},{"location":"steps/checkmarxExecuteScan/#vulnerabilitythresholdmedium","text":"The specific threshold for medium severity findings back to overview Scope Details Aliases - Type int Mandatory no Default 100 Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"vulnerabilityThresholdMedium"},{"location":"steps/checkmarxExecuteScan/#vulnerabilitythresholdresult","text":"The result of the build in case thresholds are enabled and exceeded back to overview Scope Details Aliases - Type string Mandatory no Default FAILURE Possible values - FAILURE Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"vulnerabilityThresholdResult"},{"location":"steps/checkmarxExecuteScan/#vulnerabilitythresholdunit","text":"The unit for the threshold to apply. back to overview Scope Details Aliases - Type string Mandatory no Default percentage Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"vulnerabilityThresholdUnit"},{"location":"steps/checksPublishResults/","text":"checksPublishResults \u00b6 Description \u00b6 This step can publish static check results from various sources. Prerequisites \u00b6 static check result files - To use this step, there must be static check result files available. installed plugins: pmd dry findbugs checkstyle warnings core Parameters \u00b6 name mandatory default possible values aggregation no [active:true, thresholds:[fail:[high:0]]] true , false , Map archive no false checkstyle no [pattern:**/target/checkstyle-result.xml, archive:true, active:false, thresholds:[fail:[high:0]]] true , false , Map cpd no [pattern:**/target/cpd.xml, archive:true, active:false, thresholds:[fail:[high:0]]] true , false , Map eslint no [pattern:**/eslint.xml, archive:true, active:false, thresholds:[fail:[high:0]]] true , false , Map findbugs no [pattern:**/target/findbugsXml.xml, **/target/findbugs.xml, archive:true, active:false, thresholds:[fail:[high:0]]] true , false , Map pmd no [pattern:**/target/pmd.xml, archive:true, active:false, thresholds:[fail:[high:0]]] true , false , Map pylint no [pattern:**/pylint.log, archive:true, active:false, thresholds:[fail:[high:0]]] true , false , Map script yes tasks no [pattern:**/*.java, low:, normal:TODO,REVISE,XXX, high:FIXME, archive:true, active:false, thresholds:[fail:[high:0]]] true , false , Map aggregation - Allows to publish the check results. archive - checkstyle - Publishes Checkstyle findings with the Checkstyle plugin . cpd - Publishes CPD findings with the DRY plugin . eslint - Publishes ESLint findings (in JSLint format ) with the Warnings plugin . findbugs - Publishes Findbugs findings with the Findbugs plugin . pmd - Publishes PMD findings with the PMD plugin . pylint - Publishes PyLint findings with the Warnings plugin , pylint needs to run with --output-format=parseable option. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. tasks - Searches and publishes TODOs in files with the Task Scanner Plugin . aggregation \u00b6 parameter mandatory default possible values thresholds no none see thresholds tasks \u00b6 parameter mandatory default possible values pattern no '**/*.java' archive no true true , false high no 'FIXME' normal no 'TODO,REVISE,XXX' low no thresholds no none see thresholds pmd \u00b6 parameter mandatory default possible values pattern no '**/target/pmd.xml' archive no true true , false thresholds no none see thresholds cpd \u00b6 parameter mandatory default possible values pattern no '**/target/cpd.xml' archive no true true , false thresholds no none see thresholds findbugs \u00b6 parameter mandatory default possible values pattern no '**/target/findbugsXml.xml, **/target/findbugs.xml' archive no true true, false thresholds no none see thresholds checkstyle \u00b6 parameter mandatory default possible values pattern no '**/target/checkstyle-result.xml' archive no true true , false thresholds no none see thresholds eslint \u00b6 parameter mandatory default possible values pattern no '**/eslint.jslint.xml' archive no true true , false thresholds no none see thresholds pylint \u00b6 parameter mandatory default possible values pattern no '**/pylint.log' archive no true true , false thresholds no none see thresholds Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage aggregation X archive X checkstyle X cpd X eslint X findbugs X pmd X pylint X script tasks X Dependencies \u00b6 The step depends on the following Jenkins plugins pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Thresholds \u00b6 It is possible to define thresholds to fail the build on a certain count of findings. To achive this, just define your thresholds a followed for the specific check tool: thresholds: [ fail: [ all: 999 , low: 99 , normal: 9 , high: 0 ]] This way, the jenkins will fail the build on 1 high issue, 10 normal issues, 100 low issues or a total issue count of 1000. The thresholds parameter can be set for aggregation , tasks , pmd , cpd , findbugs , checkstyle , eslint and pylint . checksPublishResults ( tasks: true , pmd: [ pattern: '**/target/pmd-results.xml' , thresholds: [ fail: [ low: 100 ]]], cpd: [ archive: false ], aggregation: [ thresholds: [ fail: [ high: 0 ]]], archive: true ) Side effects \u00b6 If both ESLint and PyLint results are published, they are not correctly aggregated in the aggregator plugin. Exceptions \u00b6 none Example \u00b6 // publish java results from pmd, cpd, checkstyle & findbugs checksPublishResults archive: true , pmd: true , cpd: true , findbugs: true , checkstyle: true , aggregation: [ thresholds: [ fail: [ high: 0 ]]] // publish javascript results from ESLint checksPublishResults archive: true , eslint: [ pattern: '**/result-file-with-fancy-name.xml' ], aggregation: [ thresholds: [ fail: [ high: 0 , normal: 10 ]]] // publish scala results from scalastyle checksPublishResults archive: true , checkstyle: [ pattern: '**/target/scalastyle-result.xml' ] // publish python results from pylint checksPublishResults archive: true , pylint: [ pattern: '**/target/pylint.log' ]","title":"checksPublishResults"},{"location":"steps/checksPublishResults/#checkspublishresults","text":"","title":"checksPublishResults"},{"location":"steps/checksPublishResults/#description","text":"This step can publish static check results from various sources.","title":"Description"},{"location":"steps/checksPublishResults/#prerequisites","text":"static check result files - To use this step, there must be static check result files available. installed plugins: pmd dry findbugs checkstyle warnings core","title":"Prerequisites"},{"location":"steps/checksPublishResults/#parameters","text":"name mandatory default possible values aggregation no [active:true, thresholds:[fail:[high:0]]] true , false , Map archive no false checkstyle no [pattern:**/target/checkstyle-result.xml, archive:true, active:false, thresholds:[fail:[high:0]]] true , false , Map cpd no [pattern:**/target/cpd.xml, archive:true, active:false, thresholds:[fail:[high:0]]] true , false , Map eslint no [pattern:**/eslint.xml, archive:true, active:false, thresholds:[fail:[high:0]]] true , false , Map findbugs no [pattern:**/target/findbugsXml.xml, **/target/findbugs.xml, archive:true, active:false, thresholds:[fail:[high:0]]] true , false , Map pmd no [pattern:**/target/pmd.xml, archive:true, active:false, thresholds:[fail:[high:0]]] true , false , Map pylint no [pattern:**/pylint.log, archive:true, active:false, thresholds:[fail:[high:0]]] true , false , Map script yes tasks no [pattern:**/*.java, low:, normal:TODO,REVISE,XXX, high:FIXME, archive:true, active:false, thresholds:[fail:[high:0]]] true , false , Map aggregation - Allows to publish the check results. archive - checkstyle - Publishes Checkstyle findings with the Checkstyle plugin . cpd - Publishes CPD findings with the DRY plugin . eslint - Publishes ESLint findings (in JSLint format ) with the Warnings plugin . findbugs - Publishes Findbugs findings with the Findbugs plugin . pmd - Publishes PMD findings with the PMD plugin . pylint - Publishes PyLint findings with the Warnings plugin , pylint needs to run with --output-format=parseable option. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. tasks - Searches and publishes TODOs in files with the Task Scanner Plugin .","title":"Parameters"},{"location":"steps/checksPublishResults/#aggregation","text":"parameter mandatory default possible values thresholds no none see thresholds","title":"aggregation"},{"location":"steps/checksPublishResults/#tasks","text":"parameter mandatory default possible values pattern no '**/*.java' archive no true true , false high no 'FIXME' normal no 'TODO,REVISE,XXX' low no thresholds no none see thresholds","title":"tasks"},{"location":"steps/checksPublishResults/#pmd","text":"parameter mandatory default possible values pattern no '**/target/pmd.xml' archive no true true , false thresholds no none see thresholds","title":"pmd"},{"location":"steps/checksPublishResults/#cpd","text":"parameter mandatory default possible values pattern no '**/target/cpd.xml' archive no true true , false thresholds no none see thresholds","title":"cpd"},{"location":"steps/checksPublishResults/#findbugs","text":"parameter mandatory default possible values pattern no '**/target/findbugsXml.xml, **/target/findbugs.xml' archive no true true, false thresholds no none see thresholds","title":"findbugs"},{"location":"steps/checksPublishResults/#checkstyle","text":"parameter mandatory default possible values pattern no '**/target/checkstyle-result.xml' archive no true true , false thresholds no none see thresholds","title":"checkstyle"},{"location":"steps/checksPublishResults/#eslint","text":"parameter mandatory default possible values pattern no '**/eslint.jslint.xml' archive no true true , false thresholds no none see thresholds","title":"eslint"},{"location":"steps/checksPublishResults/#pylint","text":"parameter mandatory default possible values pattern no '**/pylint.log' archive no true true , false thresholds no none see thresholds","title":"pylint"},{"location":"steps/checksPublishResults/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage aggregation X archive X checkstyle X cpd X eslint X findbugs X pmd X pylint X script tasks X","title":"Step configuration"},{"location":"steps/checksPublishResults/#dependencies","text":"The step depends on the following Jenkins plugins pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/checksPublishResults/#thresholds","text":"It is possible to define thresholds to fail the build on a certain count of findings. To achive this, just define your thresholds a followed for the specific check tool: thresholds: [ fail: [ all: 999 , low: 99 , normal: 9 , high: 0 ]] This way, the jenkins will fail the build on 1 high issue, 10 normal issues, 100 low issues or a total issue count of 1000. The thresholds parameter can be set for aggregation , tasks , pmd , cpd , findbugs , checkstyle , eslint and pylint . checksPublishResults ( tasks: true , pmd: [ pattern: '**/target/pmd-results.xml' , thresholds: [ fail: [ low: 100 ]]], cpd: [ archive: false ], aggregation: [ thresholds: [ fail: [ high: 0 ]]], archive: true )","title":"Thresholds"},{"location":"steps/checksPublishResults/#side-effects","text":"If both ESLint and PyLint results are published, they are not correctly aggregated in the aggregator plugin.","title":"Side effects"},{"location":"steps/checksPublishResults/#exceptions","text":"none","title":"Exceptions"},{"location":"steps/checksPublishResults/#example","text":"// publish java results from pmd, cpd, checkstyle & findbugs checksPublishResults archive: true , pmd: true , cpd: true , findbugs: true , checkstyle: true , aggregation: [ thresholds: [ fail: [ high: 0 ]]] // publish javascript results from ESLint checksPublishResults archive: true , eslint: [ pattern: '**/result-file-with-fancy-name.xml' ], aggregation: [ thresholds: [ fail: [ high: 0 , normal: 10 ]]] // publish scala results from scalastyle checksPublishResults archive: true , checkstyle: [ pattern: '**/target/scalastyle-result.xml' ] // publish python results from pylint checksPublishResults archive: true , pylint: [ pattern: '**/target/pylint.log' ]","title":"Example"},{"location":"steps/cloudFoundryCreateService/","text":"cloudFoundryCreateService \u00b6 Creates one or multiple Services in Cloud Foundry Description \u00b6 Creates one or multiple Cloud Foundry Services in Cloud Foundry Mandatory: * Cloud Foundry API endpoint, Organization, Space and user are available Please provide either of the following options: If you chose to create a single Service the Service Instance Name, Service Plan and Service Broker of the Service to be created have to be available. You can set the optional cfCreateServiceConfig flag to configure the Service creation with your respective JSON configuration. The JSON configuration can either be an in-line JSON string or the path a dedicated JSON configuration file containing the JSON configuration. If you chose a dedicated config file, you must store the file in the same folder as your Jenkinsfile that starts the Pipeline in order for the Pipeline to be able to find the file. Most favourable SCM is Git. If you want the service to be created from a particular broker you can set the optional cfServiceBroker flag. You can set user provided tags for the Service creation using a flat list as the value for the optional cfServiceTags flag. The optional cfServiceBroker flag can be used when the service name is ambiguous. For creating one or multiple Cloud Foundry Services at once with the Cloud Foundry Create-Service-Push Plugin using the optional serviceManifest flag. If you chose to set this flag, the Create-Service-Push Plugin will be used for all Service creations in this step and you will need to provide a serviceManifest.yml file. In that case, above described flags and options will not be used for the Service creations, since you chose to use the Create-Service-Push Plugin. Please see below examples for more information on how to make use of the plugin with the appropriate step configuation. Additionally the Plugin provides the option to make use of variable substitution for the Service creations. You can find further information regarding the functionality of the Cloud Foundry Create-Service-Push Plugin in the respective documentation: Cloud Foundry Create-Service-Push Plugin Usage \u00b6 We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line . Jenkins pipelines \u00b6 cloudFoundryCreateService script: this Command line \u00b6 piper cloudFoundryCreateService Prerequisites \u00b6 You have a user for the SAP Cloud Platform Cloud Foundry Environment Credentials have been configured in Jenkins with a dedicated Id Parameters \u00b6 Overview \u00b6 Name Mandatory Additional information cfApiEndpoint yes cfCredentialsId yes id of credentials ( using credentials ) cfOrg yes cfSpace yes password yes pass via ENV or Jenkins credentials script yes reference to Jenkins main pipeline script username yes pass via ENV or Jenkins credentials cfCreateServiceConfig no cfService no cfServiceBroker no cfServiceInstanceName no cfServicePlan no cfServiceTags no containerCommand no containerShell no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no dockerVolumeBind no dockerWorkspace no manifestVariables no manifestVariablesFiles no serviceManifest no stashContent no verbose no activates debug output Details \u00b6 cfApiEndpoint \u00b6 Cloud Foundry API endpoint back to overview Scope Details Aliases cloudFoundry/apiEndpoint Type string Mandatory no Default https://api.cf.eu10.hana.ondemand.com Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none cfCreateServiceConfig \u00b6 Path to JSON file or JSON in-line string for a Cloud Foundry Service creation back to overview Scope Details Aliases cloudFoundry/createServiceConfig Type string Mandatory no Default $PIPER_cfCreateServiceConfig (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none cfCredentialsId \u00b6 Jenkins-specific: Used for proper environment setup. Jenkins credentials ID containing user and password to authenticate to the Cloud Foundry API back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none cfOrg \u00b6 Cloud Foundry org back to overview Scope Details Aliases cloudFoundry/org Type string Mandatory yes Default $PIPER_cfOrg (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none cfService \u00b6 Parameter for Cloud Foundry Service to be used for creating Cloud Foundry Service back to overview Scope Details Aliases cloudFoundry/service Type string Mandatory no Default $PIPER_cfService (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none cfServiceBroker \u00b6 Parameter for Service Broker to be used when creating a Cloud Foundry Service back to overview Scope Details Aliases cloudFoundry/serviceBroker Type string Mandatory no Default $PIPER_cfServiceBroker (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none cfServiceInstanceName \u00b6 Parameter for naming the Service Instance when creating a Cloud Foundry Service back to overview Scope Details Aliases cloudFoundry/serviceInstanceName Type string Mandatory no Default $PIPER_cfServiceInstanceName (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none cfServicePlan \u00b6 Parameter for Cloud Foundry Service Plan to be used when creating a Cloud Foundry Service back to overview Scope Details Aliases cloudFoundry/servicePlan Type string Mandatory no Default $PIPER_cfServicePlan (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none cfServiceTags \u00b6 Flat list of Tags to be used when creating a Cloud Foundry Service in a single string back to overview Scope Details Aliases cloudFoundry/serviceTags Type string Mandatory no Default $PIPER_cfServiceTags (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none cfSpace \u00b6 Cloud Foundry Space back to overview Scope Details Aliases cloudFoundry/space Type string Mandatory yes Default $PIPER_cfSpace (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none containerCommand \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default (/usr/bin/tail -f /dev/null). back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none containerShell \u00b6 Jenkins-specific: Used for proper environment setup. Allows to specify the shell to be executed for container with containerName. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerEnvVars \u00b6 Jenkins-specific: Used for proper environment setup. Environment variables to set in the container, e.g. [http_proxy: \"proxy:8080\"]. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerImage \u00b6 Jenkins-specific: Used for proper environment setup. Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerName \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Name of the container launching dockerImage. SideCar only: Name of the container in local network. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerOptions \u00b6 Jenkins-specific: Used for proper environment setup. Docker options to be set when starting the container. back to overview Scope Details Aliases - Type []string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerPullImage \u00b6 Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerVolumeBind \u00b6 Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the docker container. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerWorkspace \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none manifestVariables \u00b6 Defines a List of variables as key-value Map objects used for variable substitution within the file given by the Manifest. Defaults to an empty list, if not specified otherwise. This can be used to set variables like it is provided by cf push --var key=value . The order of the maps of variables given in the list is relevant in case there are conflicting variable names and values between maps contained within the list. In case of conflicts, the last specified map in the list will win. Though each map entry in the list can contain more than one key-value pair for variable substitution, it is recommended to stick to one entry per map, and rather declare more maps within the list. The reason is that if a map in the list contains more than one key-value entry, and the entries are conflicting, the conflict resolution behavior is undefined (since map entries have no sequence). Variables defined via manifestVariables always win over conflicting variables defined via any file given by manifestVariablesFiles - no matter what is declared before. This is the same behavior as can be observed when using cf push --var in combination with cf push --vars-file back to overview Scope Details Aliases - cloudFoundry/manifestVariables - cfManifestVariables Type []string Mandatory no Default $PIPER_manifestVariables (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none manifestVariablesFiles \u00b6 Defines the manifest variables Yaml files to be used to replace variable references in manifest. This parameter is optional and will default to manifest-variables.yml . This can be used to set variable files like it is provided by cf push --vars-file <file> . If the manifest is present and so are all variable files, a variable substitution will be triggered that uses the cfManifestSubstituteVariables step before deployment. The format of variable references follows the Cloud Foundry standard in https://docs.cloudfoundry.org/devguide/deploy-apps/manifest-attributes.html#variable-substitution back to overview Scope Details Aliases - cloudFoundry/manifestVariablesFiles - cfManifestVariablesFiles Type []string Mandatory no Default $PIPER_manifestVariablesFiles (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none password \u00b6 Password for Cloud Foundry User back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_password (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none script \u00b6 Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none serviceManifest \u00b6 Path to Cloud Foundry Service Manifest in YAML format for multiple service creations that are being passed to a Create-Service-Push Cloud Foundry cli plugin back to overview Scope Details Aliases - cloudFoundry/serviceManifest - cfServiceManifest Type string Mandatory no Default service-manifest.yml Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none stashContent \u00b6 Jenkins-specific: Used for proper environment setup. Specific stashes that should be considered for the step execution. back to overview Scope Details Aliases - Type []string Mandatory no Default - deployDescriptor Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none username \u00b6 User or E-Mail for CF back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_username (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none verbose \u00b6 verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none \u00b6 Example \u00b6 Single Service Creation in Cloud Foundry example with JSON-configuration in Jenkinsfile \u00b6 The following example creates a single Service in Cloud Foundry. It makes use of the cfCreateServiceConfig flag for passing a JSON configuration as an in-line parameter string as well as the cfServiceTags for providing user tags. You can store the credentials in Jenkins and use the cfCredentialsId parameter to authenticate to Cloud Foundry. This can be done accordingly: cloudFoundryCreateService ( cfApiEndpoint : 'https://test.server.com' , cfOrg : 'cfOrg' , cfSpace: 'cfSpace' , cfCredentialsId: 'cfCredentialsId' , cfService: 'myService' , cfServiceInstanceName: 'myServiceInstanceName' , cfServicePlan: 'myPlan' , cfCreateServiceConfig: '{\\\"example\\\":\\\"value\\\",\\\"example\\\":\\\"value\\\"}' , cfServiceTags: 'list, of, tags' , script: this , ) If you chose to having a dedicated JSON file for the JSON configuration for the cfCreateServiceConfig flag you can do so by referencing the file path accordingly. This file should be stored in the same folder as your Jenkinsfile that starts the Pipeline in order for the Pipeline to be able to find the file. Most favourable SCM is Git. Such a JSON file with the appropriate step configuration could look as follows: The JSON config file, e.g. createServiceConfig.json can look like this: { \"example\" : \"value\" , \"example\" : \"value\" } The step configuration needs to contain the path to the JSON file: cloudFoundryCreateService ( cfApiEndpoint : 'https://test.server.com' , cfOrg : 'cfOrg' , cfSpace: 'cfSpace' , cfCredentialsId: 'cfCredentialsId' , cfService: 'myService' , cfServiceInstanceName: 'myServiceInstanceName' , cfServicePlan: 'myPlan' , cfCreateServiceConfig: 'createServiceConfig.json' , cfServiceTags: 'list, of, tags' , script: this , ) Multiple Service Creation in Cloud Foundry example with manifest file in Jenkinsfile \u00b6 The following example shows the option to create multiple Services in Cloud Foundry. It makes use of the Cloud Foundry Create-Service-Push Plugin. This is described in above Prerequisites, please check this section for further information regarding its usage. This plugin enables this step to create multiple Cloud Foundry Services in one step. It requires a dedicated YAML file, e.g. manifest.yml , that contains all the information for creating the services, including their names, service plan and the service broker. Such a manifest.yml file needs to have the following structure, e.g. for creating three mongoDB Services with the Service Plan v4.0-dev: --- create-services : - name : \"testDatabase1\" broker : \"mongodb\" plan : \"v4.0-dev\" - name : \"testDatabase2\" broker : \"mongodb\" plan : \"v4.0-dev\" - name : \"testDatabase3\" broker : \"mongodb\" plan : \"v4.0-dev\" The path of the manifest.yml config file needs to be passed as a parameter in the serviceManifest flag. You can store the credentials in Jenkins and use the cfCredentialsId parameter to authenticate to Cloud Foundry. This can be done accordingly: cloudFoundryCreateService ( cfApiEndpoint : 'https://test.server.com' , cfOrg : 'cfOrg' , cfSpace: 'cfSpace' , cfCredentialsId: 'cfCredentialsId' , serviceManifest: 'manifest.yml' , script: this , ) Multiple Service Creation in Cloud Foundry example with manifest file and variable substitution in Jenkinsfile \u00b6 Additionally the Cloud Foundry Create-Service-Push Plugin offers the option to make use of variable substitution. This enables you to rename variables in the manifest.yml dynamically. It can be done either via providing the file path to a dedicated YAML file containing the information regarding the variable substitution values in the manifestVariablesFiles flag or via providing a String List in the manifestVariables flag. Either ways can be achieved as seen in below examples for creating MongoDB instances. For both ways you need to adapt the manifest.yml file to be relevant for variable substitution. This can be done according to below example: --- create-services : - name : ((name1)) broker : \"mongodb\" plan : \"v4.0-dev\" - name : ((name2)) broker : \"mongodb\" plan : \"v4.0-dev\" - name : ((name3)) broker : \"mongodb\" plan : \"v4.0-dev\" If you chose to have a dedicated file for the variable substitution values, it needs to have the following structure of the vars.yml file: name1 : test1 name2 : test2 name3 : test3 The path of the manifest.yml config file needs to be passed as a parameter in the serviceManifest flag as well as the path to the vars.yml file in the manifestVariablesFiles flag. You can store the credentials in Jenkins and use the cfCredentialsId parameter to authenticate to Cloud Foundry. This can be done accordingly: cloudFoundryCreateService ( cfApiEndpoint : 'https://test.server.com' , cfOrg : 'cfOrg' , cfSpace: 'cfSpace' , cfCredentialsId: 'cfCredentialsId' , serviceManifest: 'manifest.yml' , manifestVariablesFiles: 'vars.yml' , script: this , ) You can also pass the values for the variable substition as a string list for the manifestVariables flag. This needs to follow the pattern key=value. This can be done accordingly: cloudFoundryCreateService ( cfApiEndpoint : 'https://test.server.com' , cfOrg : 'cfOrg' , cfSpace: 'cfSpace' , cfCredentialsId: 'cfCredentialsId' , serviceManifest: 'manifest.yml' , manifestVariables: [ \"name1=test1\" , \"name2=test2\" , \"name3=test3\" ], script: this , )","title":"cloudFoundryCreateService"},{"location":"steps/cloudFoundryCreateService/#cloudfoundrycreateservice","text":"Creates one or multiple Services in Cloud Foundry","title":"cloudFoundryCreateService"},{"location":"steps/cloudFoundryCreateService/#description","text":"Creates one or multiple Cloud Foundry Services in Cloud Foundry Mandatory: * Cloud Foundry API endpoint, Organization, Space and user are available Please provide either of the following options: If you chose to create a single Service the Service Instance Name, Service Plan and Service Broker of the Service to be created have to be available. You can set the optional cfCreateServiceConfig flag to configure the Service creation with your respective JSON configuration. The JSON configuration can either be an in-line JSON string or the path a dedicated JSON configuration file containing the JSON configuration. If you chose a dedicated config file, you must store the file in the same folder as your Jenkinsfile that starts the Pipeline in order for the Pipeline to be able to find the file. Most favourable SCM is Git. If you want the service to be created from a particular broker you can set the optional cfServiceBroker flag. You can set user provided tags for the Service creation using a flat list as the value for the optional cfServiceTags flag. The optional cfServiceBroker flag can be used when the service name is ambiguous. For creating one or multiple Cloud Foundry Services at once with the Cloud Foundry Create-Service-Push Plugin using the optional serviceManifest flag. If you chose to set this flag, the Create-Service-Push Plugin will be used for all Service creations in this step and you will need to provide a serviceManifest.yml file. In that case, above described flags and options will not be used for the Service creations, since you chose to use the Create-Service-Push Plugin. Please see below examples for more information on how to make use of the plugin with the appropriate step configuation. Additionally the Plugin provides the option to make use of variable substitution for the Service creations. You can find further information regarding the functionality of the Cloud Foundry Create-Service-Push Plugin in the respective documentation: Cloud Foundry Create-Service-Push Plugin","title":"Description"},{"location":"steps/cloudFoundryCreateService/#usage","text":"We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line .","title":"Usage"},{"location":"steps/cloudFoundryCreateService/#jenkins-pipelines","text":"cloudFoundryCreateService script: this","title":"Jenkins pipelines"},{"location":"steps/cloudFoundryCreateService/#command-line","text":"piper cloudFoundryCreateService","title":"Command line"},{"location":"steps/cloudFoundryCreateService/#prerequisites","text":"You have a user for the SAP Cloud Platform Cloud Foundry Environment Credentials have been configured in Jenkins with a dedicated Id","title":"Prerequisites"},{"location":"steps/cloudFoundryCreateService/#parameters","text":"","title":"Parameters"},{"location":"steps/cloudFoundryCreateService/#overview","text":"Name Mandatory Additional information cfApiEndpoint yes cfCredentialsId yes id of credentials ( using credentials ) cfOrg yes cfSpace yes password yes pass via ENV or Jenkins credentials script yes reference to Jenkins main pipeline script username yes pass via ENV or Jenkins credentials cfCreateServiceConfig no cfService no cfServiceBroker no cfServiceInstanceName no cfServicePlan no cfServiceTags no containerCommand no containerShell no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no dockerVolumeBind no dockerWorkspace no manifestVariables no manifestVariablesFiles no serviceManifest no stashContent no verbose no activates debug output","title":"Overview"},{"location":"steps/cloudFoundryCreateService/#details","text":"","title":"Details"},{"location":"steps/cloudFoundryCreateService/#cfapiendpoint","text":"Cloud Foundry API endpoint back to overview Scope Details Aliases cloudFoundry/apiEndpoint Type string Mandatory no Default https://api.cf.eu10.hana.ondemand.com Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"cfApiEndpoint"},{"location":"steps/cloudFoundryCreateService/#cfcreateserviceconfig","text":"Path to JSON file or JSON in-line string for a Cloud Foundry Service creation back to overview Scope Details Aliases cloudFoundry/createServiceConfig Type string Mandatory no Default $PIPER_cfCreateServiceConfig (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"cfCreateServiceConfig"},{"location":"steps/cloudFoundryCreateService/#cfcredentialsid","text":"Jenkins-specific: Used for proper environment setup. Jenkins credentials ID containing user and password to authenticate to the Cloud Foundry API back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"cfCredentialsId"},{"location":"steps/cloudFoundryCreateService/#cforg","text":"Cloud Foundry org back to overview Scope Details Aliases cloudFoundry/org Type string Mandatory yes Default $PIPER_cfOrg (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"cfOrg"},{"location":"steps/cloudFoundryCreateService/#cfservice","text":"Parameter for Cloud Foundry Service to be used for creating Cloud Foundry Service back to overview Scope Details Aliases cloudFoundry/service Type string Mandatory no Default $PIPER_cfService (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"cfService"},{"location":"steps/cloudFoundryCreateService/#cfservicebroker","text":"Parameter for Service Broker to be used when creating a Cloud Foundry Service back to overview Scope Details Aliases cloudFoundry/serviceBroker Type string Mandatory no Default $PIPER_cfServiceBroker (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"cfServiceBroker"},{"location":"steps/cloudFoundryCreateService/#cfserviceinstancename","text":"Parameter for naming the Service Instance when creating a Cloud Foundry Service back to overview Scope Details Aliases cloudFoundry/serviceInstanceName Type string Mandatory no Default $PIPER_cfServiceInstanceName (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"cfServiceInstanceName"},{"location":"steps/cloudFoundryCreateService/#cfserviceplan","text":"Parameter for Cloud Foundry Service Plan to be used when creating a Cloud Foundry Service back to overview Scope Details Aliases cloudFoundry/servicePlan Type string Mandatory no Default $PIPER_cfServicePlan (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"cfServicePlan"},{"location":"steps/cloudFoundryCreateService/#cfservicetags","text":"Flat list of Tags to be used when creating a Cloud Foundry Service in a single string back to overview Scope Details Aliases cloudFoundry/serviceTags Type string Mandatory no Default $PIPER_cfServiceTags (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"cfServiceTags"},{"location":"steps/cloudFoundryCreateService/#cfspace","text":"Cloud Foundry Space back to overview Scope Details Aliases cloudFoundry/space Type string Mandatory yes Default $PIPER_cfSpace (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"cfSpace"},{"location":"steps/cloudFoundryCreateService/#containercommand","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default (/usr/bin/tail -f /dev/null). back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"containerCommand"},{"location":"steps/cloudFoundryCreateService/#containershell","text":"Jenkins-specific: Used for proper environment setup. Allows to specify the shell to be executed for container with containerName. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"containerShell"},{"location":"steps/cloudFoundryCreateService/#dockerenvvars","text":"Jenkins-specific: Used for proper environment setup. Environment variables to set in the container, e.g. [http_proxy: \"proxy:8080\"]. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerEnvVars"},{"location":"steps/cloudFoundryCreateService/#dockerimage","text":"Jenkins-specific: Used for proper environment setup. Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerImage"},{"location":"steps/cloudFoundryCreateService/#dockername","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Name of the container launching dockerImage. SideCar only: Name of the container in local network. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerName"},{"location":"steps/cloudFoundryCreateService/#dockeroptions","text":"Jenkins-specific: Used for proper environment setup. Docker options to be set when starting the container. back to overview Scope Details Aliases - Type []string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerOptions"},{"location":"steps/cloudFoundryCreateService/#dockerpullimage","text":"Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerPullImage"},{"location":"steps/cloudFoundryCreateService/#dockervolumebind","text":"Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the docker container. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerVolumeBind"},{"location":"steps/cloudFoundryCreateService/#dockerworkspace","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerWorkspace"},{"location":"steps/cloudFoundryCreateService/#manifestvariables","text":"Defines a List of variables as key-value Map objects used for variable substitution within the file given by the Manifest. Defaults to an empty list, if not specified otherwise. This can be used to set variables like it is provided by cf push --var key=value . The order of the maps of variables given in the list is relevant in case there are conflicting variable names and values between maps contained within the list. In case of conflicts, the last specified map in the list will win. Though each map entry in the list can contain more than one key-value pair for variable substitution, it is recommended to stick to one entry per map, and rather declare more maps within the list. The reason is that if a map in the list contains more than one key-value entry, and the entries are conflicting, the conflict resolution behavior is undefined (since map entries have no sequence). Variables defined via manifestVariables always win over conflicting variables defined via any file given by manifestVariablesFiles - no matter what is declared before. This is the same behavior as can be observed when using cf push --var in combination with cf push --vars-file back to overview Scope Details Aliases - cloudFoundry/manifestVariables - cfManifestVariables Type []string Mandatory no Default $PIPER_manifestVariables (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"manifestVariables"},{"location":"steps/cloudFoundryCreateService/#manifestvariablesfiles","text":"Defines the manifest variables Yaml files to be used to replace variable references in manifest. This parameter is optional and will default to manifest-variables.yml . This can be used to set variable files like it is provided by cf push --vars-file <file> . If the manifest is present and so are all variable files, a variable substitution will be triggered that uses the cfManifestSubstituteVariables step before deployment. The format of variable references follows the Cloud Foundry standard in https://docs.cloudfoundry.org/devguide/deploy-apps/manifest-attributes.html#variable-substitution back to overview Scope Details Aliases - cloudFoundry/manifestVariablesFiles - cfManifestVariablesFiles Type []string Mandatory no Default $PIPER_manifestVariablesFiles (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"manifestVariablesFiles"},{"location":"steps/cloudFoundryCreateService/#password","text":"Password for Cloud Foundry User back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_password (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"password"},{"location":"steps/cloudFoundryCreateService/#script","text":"Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none","title":"script"},{"location":"steps/cloudFoundryCreateService/#servicemanifest","text":"Path to Cloud Foundry Service Manifest in YAML format for multiple service creations that are being passed to a Create-Service-Push Cloud Foundry cli plugin back to overview Scope Details Aliases - cloudFoundry/serviceManifest - cfServiceManifest Type string Mandatory no Default service-manifest.yml Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"serviceManifest"},{"location":"steps/cloudFoundryCreateService/#stashcontent","text":"Jenkins-specific: Used for proper environment setup. Specific stashes that should be considered for the step execution. back to overview Scope Details Aliases - Type []string Mandatory no Default - deployDescriptor Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"stashContent"},{"location":"steps/cloudFoundryCreateService/#username","text":"User or E-Mail for CF back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_username (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"username"},{"location":"steps/cloudFoundryCreateService/#verbose","text":"verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"verbose"},{"location":"steps/cloudFoundryCreateService/#example","text":"","title":"Example"},{"location":"steps/cloudFoundryCreateService/#single-service-creation-in-cloud-foundry-example-with-json-configuration-in-jenkinsfile","text":"The following example creates a single Service in Cloud Foundry. It makes use of the cfCreateServiceConfig flag for passing a JSON configuration as an in-line parameter string as well as the cfServiceTags for providing user tags. You can store the credentials in Jenkins and use the cfCredentialsId parameter to authenticate to Cloud Foundry. This can be done accordingly: cloudFoundryCreateService ( cfApiEndpoint : 'https://test.server.com' , cfOrg : 'cfOrg' , cfSpace: 'cfSpace' , cfCredentialsId: 'cfCredentialsId' , cfService: 'myService' , cfServiceInstanceName: 'myServiceInstanceName' , cfServicePlan: 'myPlan' , cfCreateServiceConfig: '{\\\"example\\\":\\\"value\\\",\\\"example\\\":\\\"value\\\"}' , cfServiceTags: 'list, of, tags' , script: this , ) If you chose to having a dedicated JSON file for the JSON configuration for the cfCreateServiceConfig flag you can do so by referencing the file path accordingly. This file should be stored in the same folder as your Jenkinsfile that starts the Pipeline in order for the Pipeline to be able to find the file. Most favourable SCM is Git. Such a JSON file with the appropriate step configuration could look as follows: The JSON config file, e.g. createServiceConfig.json can look like this: { \"example\" : \"value\" , \"example\" : \"value\" } The step configuration needs to contain the path to the JSON file: cloudFoundryCreateService ( cfApiEndpoint : 'https://test.server.com' , cfOrg : 'cfOrg' , cfSpace: 'cfSpace' , cfCredentialsId: 'cfCredentialsId' , cfService: 'myService' , cfServiceInstanceName: 'myServiceInstanceName' , cfServicePlan: 'myPlan' , cfCreateServiceConfig: 'createServiceConfig.json' , cfServiceTags: 'list, of, tags' , script: this , )","title":"Single Service Creation in Cloud Foundry example with JSON-configuration in Jenkinsfile"},{"location":"steps/cloudFoundryCreateService/#multiple-service-creation-in-cloud-foundry-example-with-manifest-file-in-jenkinsfile","text":"The following example shows the option to create multiple Services in Cloud Foundry. It makes use of the Cloud Foundry Create-Service-Push Plugin. This is described in above Prerequisites, please check this section for further information regarding its usage. This plugin enables this step to create multiple Cloud Foundry Services in one step. It requires a dedicated YAML file, e.g. manifest.yml , that contains all the information for creating the services, including their names, service plan and the service broker. Such a manifest.yml file needs to have the following structure, e.g. for creating three mongoDB Services with the Service Plan v4.0-dev: --- create-services : - name : \"testDatabase1\" broker : \"mongodb\" plan : \"v4.0-dev\" - name : \"testDatabase2\" broker : \"mongodb\" plan : \"v4.0-dev\" - name : \"testDatabase3\" broker : \"mongodb\" plan : \"v4.0-dev\" The path of the manifest.yml config file needs to be passed as a parameter in the serviceManifest flag. You can store the credentials in Jenkins and use the cfCredentialsId parameter to authenticate to Cloud Foundry. This can be done accordingly: cloudFoundryCreateService ( cfApiEndpoint : 'https://test.server.com' , cfOrg : 'cfOrg' , cfSpace: 'cfSpace' , cfCredentialsId: 'cfCredentialsId' , serviceManifest: 'manifest.yml' , script: this , )","title":"Multiple Service Creation in Cloud Foundry example with manifest file in Jenkinsfile"},{"location":"steps/cloudFoundryCreateService/#multiple-service-creation-in-cloud-foundry-example-with-manifest-file-and-variable-substitution-in-jenkinsfile","text":"Additionally the Cloud Foundry Create-Service-Push Plugin offers the option to make use of variable substitution. This enables you to rename variables in the manifest.yml dynamically. It can be done either via providing the file path to a dedicated YAML file containing the information regarding the variable substitution values in the manifestVariablesFiles flag or via providing a String List in the manifestVariables flag. Either ways can be achieved as seen in below examples for creating MongoDB instances. For both ways you need to adapt the manifest.yml file to be relevant for variable substitution. This can be done according to below example: --- create-services : - name : ((name1)) broker : \"mongodb\" plan : \"v4.0-dev\" - name : ((name2)) broker : \"mongodb\" plan : \"v4.0-dev\" - name : ((name3)) broker : \"mongodb\" plan : \"v4.0-dev\" If you chose to have a dedicated file for the variable substitution values, it needs to have the following structure of the vars.yml file: name1 : test1 name2 : test2 name3 : test3 The path of the manifest.yml config file needs to be passed as a parameter in the serviceManifest flag as well as the path to the vars.yml file in the manifestVariablesFiles flag. You can store the credentials in Jenkins and use the cfCredentialsId parameter to authenticate to Cloud Foundry. This can be done accordingly: cloudFoundryCreateService ( cfApiEndpoint : 'https://test.server.com' , cfOrg : 'cfOrg' , cfSpace: 'cfSpace' , cfCredentialsId: 'cfCredentialsId' , serviceManifest: 'manifest.yml' , manifestVariablesFiles: 'vars.yml' , script: this , ) You can also pass the values for the variable substition as a string list for the manifestVariables flag. This needs to follow the pattern key=value. This can be done accordingly: cloudFoundryCreateService ( cfApiEndpoint : 'https://test.server.com' , cfOrg : 'cfOrg' , cfSpace: 'cfSpace' , cfCredentialsId: 'cfCredentialsId' , serviceManifest: 'manifest.yml' , manifestVariables: [ \"name1=test1\" , \"name2=test2\" , \"name3=test3\" ], script: this , )","title":"Multiple Service Creation in Cloud Foundry example with manifest file and variable substitution in Jenkinsfile"},{"location":"steps/cloudFoundryCreateServiceKey/","text":"cloudFoundryCreateServiceKey \u00b6 cloudFoundryCreateServiceKey Description \u00b6 Create CloudFoundryServiceKey Usage \u00b6 We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line . Jenkins pipelines \u00b6 cloudFoundryCreateServiceKey script: this Command line \u00b6 piper cloudFoundryCreateServiceKey Prerequisites \u00b6 This step is for creating a Service Key for an existing Service in Cloud Foundry. Cloud Foundry API endpoint, Organization, Space, user and Service Instance are available Credentials have been configured in Jenkins with a dedicated Id Additionally you can set the optional serviceKeyConfig flag to configure the Service Key creation with your respective JSON configuration. The JSON configuration can either be a JSON or the path a dedicated JSON configuration file containing the JSON configuration. If you chose a dedicated config file, it must be stored in a file that must be referenced in the serviceKeyConfigFile flag. You must store the file in the same folder as your Jenkinsfile that starts the Pipeline in order for the Pipeline to be able to find the file. Most favourable SCM is Git. Parameters \u00b6 Overview \u00b6 Name Mandatory Additional information cfApiEndpoint yes cfCredentialsId yes id of credentials ( using credentials ) cfOrg yes cfServiceInstance yes cfServiceKeyName yes cfSpace yes password yes pass via ENV or Jenkins credentials script yes reference to Jenkins main pipeline script username yes pass via ENV or Jenkins credentials cfServiceKeyConfig no containerCommand no containerShell no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no dockerVolumeBind no dockerWorkspace no verbose no activates debug output Details \u00b6 cfApiEndpoint \u00b6 Cloud Foundry API endpoint back to overview Scope Details Aliases cloudFoundry/apiEndpoint Type string Mandatory yes Default $PIPER_cfApiEndpoint (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none cfCredentialsId \u00b6 Jenkins-specific: Used for proper environment setup. Jenkins credentials ID containing user and password to authenticate to the Cloud Foundry API back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none cfOrg \u00b6 CF org back to overview Scope Details Aliases cloudFoundry/org Type string Mandatory yes Default $PIPER_cfOrg (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none cfServiceInstance \u00b6 Parameter for CloudFoundry Service Instance Name back to overview Scope Details Aliases cloudFoundry/serviceInstance Type string Mandatory yes Default $PIPER_cfServiceInstance (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none cfServiceKeyConfig \u00b6 Path to JSON config file path or JSON in-line string for Cloud Foundry Service Key creation back to overview Scope Details Aliases cloudFoundry/serviceKeyConfig Type string Mandatory no Default $PIPER_cfServiceKeyConfig (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none cfServiceKeyName \u00b6 Parameter for Service Key name for CloudFoundry Service Key to be created back to overview Scope Details Aliases - cloudFoundry/serviceKey - cloudFoundry/serviceKeyName - cfServiceKey Type string Mandatory yes Default $PIPER_cfServiceKeyName (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none cfSpace \u00b6 CF Space back to overview Scope Details Aliases cloudFoundry/space Type string Mandatory yes Default $PIPER_cfSpace (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none containerCommand \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default (/usr/bin/tail -f /dev/null). back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none containerShell \u00b6 Jenkins-specific: Used for proper environment setup. Allows to specify the shell to be executed for container with containerName. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerEnvVars \u00b6 Jenkins-specific: Used for proper environment setup. Environment variables to set in the container, e.g. [http_proxy: \"proxy:8080\"]. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerImage \u00b6 Jenkins-specific: Used for proper environment setup. Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerName \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Name of the container launching dockerImage. SideCar only: Name of the container in local network. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerOptions \u00b6 Jenkins-specific: Used for proper environment setup. Docker options to be set when starting the container. back to overview Scope Details Aliases - Type []string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerPullImage \u00b6 Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerVolumeBind \u00b6 Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the docker container. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerWorkspace \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none password \u00b6 User Password for CF User back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_password (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none script \u00b6 Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none username \u00b6 User or E-Mail for CF back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_username (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none verbose \u00b6 verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none \u00b6 Examples \u00b6 The following examples will create a Service Key named \"myServiceKey\" for the Service Instance \"myServiceInstance\" in the provided Cloud Foundry Organization and Space. For the Service Key creation in these example, the serviceKeyConfig parameter is used. It will show the different ways of passing the JSON configuration, either via a string or the path to a file containing the JSON configuration. If you dont want to use a special configuration simply remove the parameter since it is optional. Create Service Key with JSON config file in Jenkinsfile \u00b6 This example covers the parameters for a Jenkinsfile when using the cloudFoundryCreateServiceKey step. It uses a serviceKeaConfig.json file with valid JSON objects for creating a Cloud Foundry Service Key. cloudFoundryCreateServiceKey ( cfApiEndpoint: 'https://test.server.com' , cfCredentialsId: 'cfCredentialsId' , cfOrg: 'cfOrg' , cfSpace: 'cfSpace' , cfServiceInstance: 'myServiceInstance' , cfServiceKeyName: 'myServiceKey' , cfServiceKeyConfig: 'serviceKeyConfig.json' , script: this , ) The JSON config file, e.g. serviceKeyConfig.json can look like this: { \"example\" : \"value\" , \"example\" : \"value\" } Create Service Key with JSON string in Jenkinsfile \u00b6 The following example covers the creation of a Cloud Foundry Service Key in a Jenkinsfile with using a JSON string as a config for the Service Key creation. If you use a Jenkinsfile for passing the parameter values you need to escape the double quotes in the JSON config string. cloudFoundryCreateServiceKey ( cfApiEndpoint: 'https://test.server.com' , cfCredentialsId: 'cfCredentialsId' , cfOrg: 'cfOrg' , cfSpace: 'cfSpace' , cfServiceInstance: 'myServiceInstance' , cfServiceKeyName: 'myServiceKey' , cfServiceKeyConfig: '{\\\"example\\\":\\\"value\\\",\\\"example\\\":\\\"value\\\"}' , script: this , ) Create Service Key with JSON string as parameter in .pipeline/config.yml file \u00b6 If you chose to provide a config.yml file you can provide the parameters including the values in this file. You only need to set the script parameter when calling the step: cloudFoundryCreateServiceKey ( script: this , ) The .pipeline/config.yml has to contain the following parameters accordingly: steps : cloudFoundryCreateServiceKey : cfApiEndpoint : 'https://test.server.com' cfOrg : 'testOrg' cfSpace : 'testSpace' cfServiceInstance : 'testInstance' cfServiceKeyName : 'myServiceKey' cfServiceKeyConfig : '{\"example\":\"value\",\"example\":\"value\"}' cfCredentialsId : 'cfCredentialsId' When using a .pipeline/config.yml file you don't need to escape the double quotes in the JSON config string. You can also pass the path to a JSON config file in the cfServiceKeyConfig parameter. Example: cfServiceKeyConfig: 'serviceKeyconfig.json'","title":"cloudFoundryCreateServiceKey"},{"location":"steps/cloudFoundryCreateServiceKey/#cloudfoundrycreateservicekey","text":"cloudFoundryCreateServiceKey","title":"cloudFoundryCreateServiceKey"},{"location":"steps/cloudFoundryCreateServiceKey/#description","text":"Create CloudFoundryServiceKey","title":"Description"},{"location":"steps/cloudFoundryCreateServiceKey/#usage","text":"We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line .","title":"Usage"},{"location":"steps/cloudFoundryCreateServiceKey/#jenkins-pipelines","text":"cloudFoundryCreateServiceKey script: this","title":"Jenkins pipelines"},{"location":"steps/cloudFoundryCreateServiceKey/#command-line","text":"piper cloudFoundryCreateServiceKey","title":"Command line"},{"location":"steps/cloudFoundryCreateServiceKey/#prerequisites","text":"This step is for creating a Service Key for an existing Service in Cloud Foundry. Cloud Foundry API endpoint, Organization, Space, user and Service Instance are available Credentials have been configured in Jenkins with a dedicated Id Additionally you can set the optional serviceKeyConfig flag to configure the Service Key creation with your respective JSON configuration. The JSON configuration can either be a JSON or the path a dedicated JSON configuration file containing the JSON configuration. If you chose a dedicated config file, it must be stored in a file that must be referenced in the serviceKeyConfigFile flag. You must store the file in the same folder as your Jenkinsfile that starts the Pipeline in order for the Pipeline to be able to find the file. Most favourable SCM is Git.","title":"Prerequisites"},{"location":"steps/cloudFoundryCreateServiceKey/#parameters","text":"","title":"Parameters"},{"location":"steps/cloudFoundryCreateServiceKey/#overview","text":"Name Mandatory Additional information cfApiEndpoint yes cfCredentialsId yes id of credentials ( using credentials ) cfOrg yes cfServiceInstance yes cfServiceKeyName yes cfSpace yes password yes pass via ENV or Jenkins credentials script yes reference to Jenkins main pipeline script username yes pass via ENV or Jenkins credentials cfServiceKeyConfig no containerCommand no containerShell no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no dockerVolumeBind no dockerWorkspace no verbose no activates debug output","title":"Overview"},{"location":"steps/cloudFoundryCreateServiceKey/#details","text":"","title":"Details"},{"location":"steps/cloudFoundryCreateServiceKey/#cfapiendpoint","text":"Cloud Foundry API endpoint back to overview Scope Details Aliases cloudFoundry/apiEndpoint Type string Mandatory yes Default $PIPER_cfApiEndpoint (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"cfApiEndpoint"},{"location":"steps/cloudFoundryCreateServiceKey/#cfcredentialsid","text":"Jenkins-specific: Used for proper environment setup. Jenkins credentials ID containing user and password to authenticate to the Cloud Foundry API back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"cfCredentialsId"},{"location":"steps/cloudFoundryCreateServiceKey/#cforg","text":"CF org back to overview Scope Details Aliases cloudFoundry/org Type string Mandatory yes Default $PIPER_cfOrg (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"cfOrg"},{"location":"steps/cloudFoundryCreateServiceKey/#cfserviceinstance","text":"Parameter for CloudFoundry Service Instance Name back to overview Scope Details Aliases cloudFoundry/serviceInstance Type string Mandatory yes Default $PIPER_cfServiceInstance (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"cfServiceInstance"},{"location":"steps/cloudFoundryCreateServiceKey/#cfservicekeyconfig","text":"Path to JSON config file path or JSON in-line string for Cloud Foundry Service Key creation back to overview Scope Details Aliases cloudFoundry/serviceKeyConfig Type string Mandatory no Default $PIPER_cfServiceKeyConfig (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"cfServiceKeyConfig"},{"location":"steps/cloudFoundryCreateServiceKey/#cfservicekeyname","text":"Parameter for Service Key name for CloudFoundry Service Key to be created back to overview Scope Details Aliases - cloudFoundry/serviceKey - cloudFoundry/serviceKeyName - cfServiceKey Type string Mandatory yes Default $PIPER_cfServiceKeyName (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"cfServiceKeyName"},{"location":"steps/cloudFoundryCreateServiceKey/#cfspace","text":"CF Space back to overview Scope Details Aliases cloudFoundry/space Type string Mandatory yes Default $PIPER_cfSpace (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"cfSpace"},{"location":"steps/cloudFoundryCreateServiceKey/#containercommand","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default (/usr/bin/tail -f /dev/null). back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"containerCommand"},{"location":"steps/cloudFoundryCreateServiceKey/#containershell","text":"Jenkins-specific: Used for proper environment setup. Allows to specify the shell to be executed for container with containerName. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"containerShell"},{"location":"steps/cloudFoundryCreateServiceKey/#dockerenvvars","text":"Jenkins-specific: Used for proper environment setup. Environment variables to set in the container, e.g. [http_proxy: \"proxy:8080\"]. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerEnvVars"},{"location":"steps/cloudFoundryCreateServiceKey/#dockerimage","text":"Jenkins-specific: Used for proper environment setup. Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerImage"},{"location":"steps/cloudFoundryCreateServiceKey/#dockername","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Name of the container launching dockerImage. SideCar only: Name of the container in local network. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerName"},{"location":"steps/cloudFoundryCreateServiceKey/#dockeroptions","text":"Jenkins-specific: Used for proper environment setup. Docker options to be set when starting the container. back to overview Scope Details Aliases - Type []string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerOptions"},{"location":"steps/cloudFoundryCreateServiceKey/#dockerpullimage","text":"Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerPullImage"},{"location":"steps/cloudFoundryCreateServiceKey/#dockervolumebind","text":"Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the docker container. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerVolumeBind"},{"location":"steps/cloudFoundryCreateServiceKey/#dockerworkspace","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerWorkspace"},{"location":"steps/cloudFoundryCreateServiceKey/#password","text":"User Password for CF User back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_password (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"password"},{"location":"steps/cloudFoundryCreateServiceKey/#script","text":"Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none","title":"script"},{"location":"steps/cloudFoundryCreateServiceKey/#username","text":"User or E-Mail for CF back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_username (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"username"},{"location":"steps/cloudFoundryCreateServiceKey/#verbose","text":"verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"verbose"},{"location":"steps/cloudFoundryCreateServiceKey/#examples","text":"The following examples will create a Service Key named \"myServiceKey\" for the Service Instance \"myServiceInstance\" in the provided Cloud Foundry Organization and Space. For the Service Key creation in these example, the serviceKeyConfig parameter is used. It will show the different ways of passing the JSON configuration, either via a string or the path to a file containing the JSON configuration. If you dont want to use a special configuration simply remove the parameter since it is optional.","title":"Examples"},{"location":"steps/cloudFoundryCreateServiceKey/#create-service-key-with-json-config-file-in-jenkinsfile","text":"This example covers the parameters for a Jenkinsfile when using the cloudFoundryCreateServiceKey step. It uses a serviceKeaConfig.json file with valid JSON objects for creating a Cloud Foundry Service Key. cloudFoundryCreateServiceKey ( cfApiEndpoint: 'https://test.server.com' , cfCredentialsId: 'cfCredentialsId' , cfOrg: 'cfOrg' , cfSpace: 'cfSpace' , cfServiceInstance: 'myServiceInstance' , cfServiceKeyName: 'myServiceKey' , cfServiceKeyConfig: 'serviceKeyConfig.json' , script: this , ) The JSON config file, e.g. serviceKeyConfig.json can look like this: { \"example\" : \"value\" , \"example\" : \"value\" }","title":"Create Service Key with JSON config file in Jenkinsfile"},{"location":"steps/cloudFoundryCreateServiceKey/#create-service-key-with-json-string-in-jenkinsfile","text":"The following example covers the creation of a Cloud Foundry Service Key in a Jenkinsfile with using a JSON string as a config for the Service Key creation. If you use a Jenkinsfile for passing the parameter values you need to escape the double quotes in the JSON config string. cloudFoundryCreateServiceKey ( cfApiEndpoint: 'https://test.server.com' , cfCredentialsId: 'cfCredentialsId' , cfOrg: 'cfOrg' , cfSpace: 'cfSpace' , cfServiceInstance: 'myServiceInstance' , cfServiceKeyName: 'myServiceKey' , cfServiceKeyConfig: '{\\\"example\\\":\\\"value\\\",\\\"example\\\":\\\"value\\\"}' , script: this , )","title":"Create Service Key with JSON string in Jenkinsfile"},{"location":"steps/cloudFoundryCreateServiceKey/#create-service-key-with-json-string-as-parameter-in-pipelineconfigyml-file","text":"If you chose to provide a config.yml file you can provide the parameters including the values in this file. You only need to set the script parameter when calling the step: cloudFoundryCreateServiceKey ( script: this , ) The .pipeline/config.yml has to contain the following parameters accordingly: steps : cloudFoundryCreateServiceKey : cfApiEndpoint : 'https://test.server.com' cfOrg : 'testOrg' cfSpace : 'testSpace' cfServiceInstance : 'testInstance' cfServiceKeyName : 'myServiceKey' cfServiceKeyConfig : '{\"example\":\"value\",\"example\":\"value\"}' cfCredentialsId : 'cfCredentialsId' When using a .pipeline/config.yml file you don't need to escape the double quotes in the JSON config string. You can also pass the path to a JSON config file in the cfServiceKeyConfig parameter. Example: cfServiceKeyConfig: 'serviceKeyconfig.json'","title":"Create Service Key with JSON string as parameter in .pipeline/config.yml file"},{"location":"steps/cloudFoundryDeleteService/","text":"cloudFoundryDeleteService \u00b6 DeleteCloudFoundryService Description \u00b6 Delete CloudFoundryService Usage \u00b6 We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line . Jenkins pipelines \u00b6 cloudFoundryDeleteService script: this Command line \u00b6 piper cloudFoundryDeleteService Prerequisites \u00b6 This step is for deleting an existing service on Cloud Foundry. You need to provide the Cloud Foundry API Endpoint, the Organisation as well as the Space and the respective Service Instance Name you want to delete. Furthermore you will need to provide the Cloud Foundry Login Credentials, which must be stored in the Jenkins Configuration. Additionally you can set the cfDeleteServiceKeys flag for deleting all Service Keys that belong to the respective Service. Parameters \u00b6 Overview \u00b6 Name Mandatory Additional information cfApiEndpoint yes cfCredentialsId yes id of credentials ( using credentials ) cfOrg yes cfServiceInstance yes cfSpace yes password yes pass via ENV or Jenkins credentials script yes reference to Jenkins main pipeline script username yes pass via ENV or Jenkins credentials cfDeleteServiceKeys no containerCommand no containerShell no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no dockerVolumeBind no dockerWorkspace no verbose no activates debug output Details \u00b6 cfApiEndpoint \u00b6 Cloud Foundry API endpoint back to overview Scope Details Aliases cloudFoundry/apiEndpoint Type string Mandatory yes Default $PIPER_cfApiEndpoint (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none cfCredentialsId \u00b6 Jenkins-specific: Used for proper environment setup. Jenkins credentials ID containing user and password to authenticate to the Cloud Foundry API back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none cfDeleteServiceKeys \u00b6 Parameter to force deletion of Cloud Foundry Service Keys back to overview Scope Details Aliases cloudFoundry/cfDeleteServiceKeys Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none cfOrg \u00b6 CF org back to overview Scope Details Aliases cloudFoundry/org Type string Mandatory yes Default $PIPER_cfOrg (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none cfServiceInstance \u00b6 Parameter of ServiceInstance Name to delete CloudFoundry Service back to overview Scope Details Aliases cloudFoundry/serviceInstance Type string Mandatory yes Default $PIPER_cfServiceInstance (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none cfSpace \u00b6 CF Space back to overview Scope Details Aliases cloudFoundry/space Type string Mandatory yes Default $PIPER_cfSpace (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none containerCommand \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default (/usr/bin/tail -f /dev/null). back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none containerShell \u00b6 Jenkins-specific: Used for proper environment setup. Allows to specify the shell to be executed for container with containerName. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerEnvVars \u00b6 Jenkins-specific: Used for proper environment setup. Environment variables to set in the container, e.g. [http_proxy: \"proxy:8080\"]. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerImage \u00b6 Jenkins-specific: Used for proper environment setup. Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerName \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Name of the container launching dockerImage. SideCar only: Name of the container in local network. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerOptions \u00b6 Jenkins-specific: Used for proper environment setup. Docker options to be set when starting the container. back to overview Scope Details Aliases - Type []string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerPullImage \u00b6 Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerVolumeBind \u00b6 Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the docker container. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerWorkspace \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none password \u00b6 User Password for CF User back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_password (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none script \u00b6 Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none username \u00b6 User or E-Mail for CF back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_username (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none verbose \u00b6 verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none \u00b6 Example \u00b6 In this example, the Cloud Foundry Configuration is directly provided with the respective Credentials for the used User/Account. cloudFoundryDeleteService ( cfApiEndpoint : 'https://test.server.com' , cfOrg : 'cforg' , cfspace: 'cfspace' , cfserviceInstance: 'cfserviceInstance' , cfCredentialsId: 'cfcredentialsId' , cfDeleteServiceKeys: true , )","title":"cloudFoundryDeleteService"},{"location":"steps/cloudFoundryDeleteService/#cloudfoundrydeleteservice","text":"DeleteCloudFoundryService","title":"cloudFoundryDeleteService"},{"location":"steps/cloudFoundryDeleteService/#description","text":"Delete CloudFoundryService","title":"Description"},{"location":"steps/cloudFoundryDeleteService/#usage","text":"We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line .","title":"Usage"},{"location":"steps/cloudFoundryDeleteService/#jenkins-pipelines","text":"cloudFoundryDeleteService script: this","title":"Jenkins pipelines"},{"location":"steps/cloudFoundryDeleteService/#command-line","text":"piper cloudFoundryDeleteService","title":"Command line"},{"location":"steps/cloudFoundryDeleteService/#prerequisites","text":"This step is for deleting an existing service on Cloud Foundry. You need to provide the Cloud Foundry API Endpoint, the Organisation as well as the Space and the respective Service Instance Name you want to delete. Furthermore you will need to provide the Cloud Foundry Login Credentials, which must be stored in the Jenkins Configuration. Additionally you can set the cfDeleteServiceKeys flag for deleting all Service Keys that belong to the respective Service.","title":"Prerequisites"},{"location":"steps/cloudFoundryDeleteService/#parameters","text":"","title":"Parameters"},{"location":"steps/cloudFoundryDeleteService/#overview","text":"Name Mandatory Additional information cfApiEndpoint yes cfCredentialsId yes id of credentials ( using credentials ) cfOrg yes cfServiceInstance yes cfSpace yes password yes pass via ENV or Jenkins credentials script yes reference to Jenkins main pipeline script username yes pass via ENV or Jenkins credentials cfDeleteServiceKeys no containerCommand no containerShell no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no dockerVolumeBind no dockerWorkspace no verbose no activates debug output","title":"Overview"},{"location":"steps/cloudFoundryDeleteService/#details","text":"","title":"Details"},{"location":"steps/cloudFoundryDeleteService/#cfapiendpoint","text":"Cloud Foundry API endpoint back to overview Scope Details Aliases cloudFoundry/apiEndpoint Type string Mandatory yes Default $PIPER_cfApiEndpoint (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"cfApiEndpoint"},{"location":"steps/cloudFoundryDeleteService/#cfcredentialsid","text":"Jenkins-specific: Used for proper environment setup. Jenkins credentials ID containing user and password to authenticate to the Cloud Foundry API back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"cfCredentialsId"},{"location":"steps/cloudFoundryDeleteService/#cfdeleteservicekeys","text":"Parameter to force deletion of Cloud Foundry Service Keys back to overview Scope Details Aliases cloudFoundry/cfDeleteServiceKeys Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"cfDeleteServiceKeys"},{"location":"steps/cloudFoundryDeleteService/#cforg","text":"CF org back to overview Scope Details Aliases cloudFoundry/org Type string Mandatory yes Default $PIPER_cfOrg (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"cfOrg"},{"location":"steps/cloudFoundryDeleteService/#cfserviceinstance","text":"Parameter of ServiceInstance Name to delete CloudFoundry Service back to overview Scope Details Aliases cloudFoundry/serviceInstance Type string Mandatory yes Default $PIPER_cfServiceInstance (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"cfServiceInstance"},{"location":"steps/cloudFoundryDeleteService/#cfspace","text":"CF Space back to overview Scope Details Aliases cloudFoundry/space Type string Mandatory yes Default $PIPER_cfSpace (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"cfSpace"},{"location":"steps/cloudFoundryDeleteService/#containercommand","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default (/usr/bin/tail -f /dev/null). back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"containerCommand"},{"location":"steps/cloudFoundryDeleteService/#containershell","text":"Jenkins-specific: Used for proper environment setup. Allows to specify the shell to be executed for container with containerName. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"containerShell"},{"location":"steps/cloudFoundryDeleteService/#dockerenvvars","text":"Jenkins-specific: Used for proper environment setup. Environment variables to set in the container, e.g. [http_proxy: \"proxy:8080\"]. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerEnvVars"},{"location":"steps/cloudFoundryDeleteService/#dockerimage","text":"Jenkins-specific: Used for proper environment setup. Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerImage"},{"location":"steps/cloudFoundryDeleteService/#dockername","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Name of the container launching dockerImage. SideCar only: Name of the container in local network. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerName"},{"location":"steps/cloudFoundryDeleteService/#dockeroptions","text":"Jenkins-specific: Used for proper environment setup. Docker options to be set when starting the container. back to overview Scope Details Aliases - Type []string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerOptions"},{"location":"steps/cloudFoundryDeleteService/#dockerpullimage","text":"Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerPullImage"},{"location":"steps/cloudFoundryDeleteService/#dockervolumebind","text":"Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the docker container. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerVolumeBind"},{"location":"steps/cloudFoundryDeleteService/#dockerworkspace","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerWorkspace"},{"location":"steps/cloudFoundryDeleteService/#password","text":"User Password for CF User back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_password (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"password"},{"location":"steps/cloudFoundryDeleteService/#script","text":"Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none","title":"script"},{"location":"steps/cloudFoundryDeleteService/#username","text":"User or E-Mail for CF back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_username (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"username"},{"location":"steps/cloudFoundryDeleteService/#verbose","text":"verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"verbose"},{"location":"steps/cloudFoundryDeleteService/#example","text":"In this example, the Cloud Foundry Configuration is directly provided with the respective Credentials for the used User/Account. cloudFoundryDeleteService ( cfApiEndpoint : 'https://test.server.com' , cfOrg : 'cforg' , cfspace: 'cfspace' , cfserviceInstance: 'cfserviceInstance' , cfCredentialsId: 'cfcredentialsId' , cfDeleteServiceKeys: true , )","title":"Example"},{"location":"steps/cloudFoundryDeploy/","text":"cloudFoundryDeploy \u00b6 Description \u00b6 Deploys an application to a test or production space within Cloud Foundry. Deployment can be done in a standard way in a zero downtime manner (using a blue-green deployment approach ) Deployment supports multiple deployment tools Currently the following are supported: Standard cf push and Bluemix blue-green plugin MTA CF CLI Plugin Note Due to an incompatible change in the Cloud Foundry CLI, multiple buildpacks are not supported by this step. If your application contains a list of buildpacks instead a single buildpack , this will be automatically re-written by the step when blue-green deployment is used. Note Cloud Foundry supports the deployment of multiple applications using a single manifest file. This option is supported with Piper. In this case define appName: '' since the app name for the individual applications have to be defined via the manifest. You can find details in the Cloud Foundry Documentation Prerequisites \u00b6 Cloud Foundry organization, space and deployment user are available Credentials for deployment have been configured in Jenkins with a dedicated Id Parameters \u00b6 name mandatory default possible values apiParameters no `` buildTool no cfNativeDeployParameters no `` cloudFoundry/apiEndpoint no https://api.cf.eu10.hana.ondemand.com cloudFoundry/appName no cloudFoundry/credentialsId yes cloudFoundry/manifest no cloudFoundry/manifestVariablesFiles no cloudFoundry/org yes cloudFoundry/space yes deployDockerImage no deployTool no 'cf_native', 'mtaDeployPlugin' deployType no standard 'standard', 'blue-green' dockerCredentialsId no dockerImage no deployTool= cf_native : ppiper/cf-cli deployTool= mtaDeployPlugin : ppiper/cf-cli dockerWorkspace no deployTool= cf_native : /home/piper deployTool= mtaDeployPlugin : /home/piper keepOldInstance no false true, false loginParameters no `` manifestVariables no mtaDeployParameters no -f mtaExtensionCredentials no mtaExtensionDescriptor no `` mtaPath no `` script yes smokeTestScript no blueGreenCheckScript.sh smokeTestStatusCode no 200 stashContent no [deployDescriptor, pipelineConfigAndTests] verbose no true, false apiParameters - Addition command line options for cf api command. No escaping/quoting is performed. Not recommanded for productive environments. buildTool - cfNativeDeployParameters - Additional parameters passed to cf native deployment command. cloudFoundry/apiEndpoint - Cloud Foundry API endpoint. cloudFoundry/appName - Defines the name of the application to be deployed to the Cloud Foundry space. cloudFoundry/credentialsId - Credentials to be used for deployment. cloudFoundry/manifest - Defines the manifest to be used for deployment to Cloud Foundry. cloudFoundry/manifestVariablesFiles - Defines the manifest variables Yaml files to be used to replace variable references in manifest. This parameter is optional and will default to [\"manifest-variables.yml\"] . This can be used to set variable files like it is provided by cf push --vars-file <file> . If the manifest is present and so are all variable files, a variable substitution will be triggered that uses the cfManifestSubstituteVariables step before deployment. The format of variable references follows the Cloud Foundry standard . cloudFoundry/org - Cloud Foundry target organization. cloudFoundry/space - Cloud Foundry target space. deployDockerImage - Docker image deployments are supported (via manifest file in general)[https://docs.cloudfoundry.org/devguide/deploy-apps/manifest-attributes.html#docker]. If no manifest is used, this parameter defines the image to be deployed. The specified name of the image is passed to the --docker-image parameter of the cf CLI and must adhere it's naming pattern (e.g. REPO/IMAGE:TAG). See (cf CLI documentation)[https://docs.cloudfoundry.org/devguide/deploy-apps/push-docker.html] for details. Note: The used Docker registry must be visible for the targeted Cloud Foundry instance. deployTool - Defines the tool which should be used for deployment. If it is not set it will be inferred automatically based on the buildTool, i.e., for MTA projects mtaDeployPlugin will be used and cf_native for other types of projects. deployType - Defines the type of deployment, either standard deployment which results in a system downtime or a zero-downtime blue-green deployment. If 'cf_native' as deployType and 'blue-green' as deployTool is used in combination, your manifest.yaml may only contain one application. If this application has the option 'no-route' active the deployType will be changed to 'standard'. dockerCredentialsId - If the specified image in deployDockerImage is contained in a Docker registry, which requires authorization this defines the credentials to be used. dockerImage - Name of the docker image that should be used. Configure with empty value to execute the command directly on the Jenkins system (not using a container). Omit to use the default image (cf. default_pipeline_environment.yml ) Overwrite to use custom Docker image. dockerWorkspace - Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . keepOldInstance - In case of a blue-green deployment the old instance will be deleted by default. If this option is set to true the old instance will remain stopped in the Cloud Foundry space. loginParameters - Addition command line options for cf login command. No escaping/quoting is performed. Not recommanded for productive environments. manifestVariables - Defines a List of variables as key-value Map objects used for variable substitution within the file given by manifest . Defaults to an empty list, if not specified otherwise. This can be used to set variables like it is provided by cf push --var key=value . The order of the maps of variables given in the list is relevant in case there are conflicting variable names and values between maps contained within the list. In case of conflicts, the last specified map in the list will win. Though each map entry in the list can contain more than one key-value pair for variable substitution, it is recommended to stick to one entry per map, and rather declare more maps within the list. The reason is that if a map in the list contains more than one key-value entry, and the entries are conflicting, the conflict resolution behavior is undefined (since map entries have no sequence). Note: variables defined via manifestVariables always win over conflicting variables defined via any file given by manifestVariablesFiles - no matter what is declared before. This is the same behavior as can be observed when using cf push --var in combination with cf push --vars-file . mtaDeployParameters - Additional parameters passed to mta deployment command. mtaExtensionCredentials - Defines a map of credentials that need to be replaced in the mtaExtensionDescriptor . This map needs to be created as value-to-be-replaced : id-of-a-credential-in-jenkins mtaExtensionDescriptor - Defines additional extension descriptor file for deployment with the mtaDeployPlugin. mtaPath - Defines the path to *.mtar for deployment with the mtaDeployPlugin. If not specified, it will use the mta file created in mtaBuild or search for an mtar file in the workspace. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. smokeTestScript - Allows to specify a script which performs a check during blue-green deployment. The script gets the FQDN as parameter and returns exit code 0 in case check returned smokeTestStatusCode . More details can be found here Currently this option is only considered for deployTool cf_native . smokeTestStatusCode - Expected status code returned by the check. stashContent - Specific stashes that should be considered for the step execution. verbose - Provides more output. May reveal sensitive information. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage apiParameters X X buildTool X X cfNativeDeployParameters X X cloudFoundry/apiEndpoint X X cloudFoundry/appName X X cloudFoundry/credentialsId X X cloudFoundry/manifest X X cloudFoundry/manifestVariablesFiles X X cloudFoundry/org X X cloudFoundry/space X X deployDockerImage X X deployTool X X deployType X X dockerCredentialsId X X dockerImage X X dockerWorkspace X X keepOldInstance X X loginParameters X X manifestVariables X X mtaDeployParameters X X mtaExtensionCredentials X X mtaExtensionDescriptor X X mtaPath X X script smokeTestScript X X smokeTestStatusCode X X stashContent X X verbose X X Dependencies \u00b6 The step depends on the following Jenkins plugins credentials-binding docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Example \u00b6 cloudFoundryDeploy ( script: script , deployType: 'blue-green' , cloudFoundry: [ apiEndpoint: 'https://test.server.com' , appName: 'cfAppName' , credentialsId: 'cfCredentialsId' , manifest: 'cfManifest' , org: 'cfOrg' , space: 'cfSpace' ], deployTool: 'cf_native' )","title":"cloudFoundryDeploy"},{"location":"steps/cloudFoundryDeploy/#cloudfoundrydeploy","text":"","title":"cloudFoundryDeploy"},{"location":"steps/cloudFoundryDeploy/#description","text":"Deploys an application to a test or production space within Cloud Foundry. Deployment can be done in a standard way in a zero downtime manner (using a blue-green deployment approach ) Deployment supports multiple deployment tools Currently the following are supported: Standard cf push and Bluemix blue-green plugin MTA CF CLI Plugin Note Due to an incompatible change in the Cloud Foundry CLI, multiple buildpacks are not supported by this step. If your application contains a list of buildpacks instead a single buildpack , this will be automatically re-written by the step when blue-green deployment is used. Note Cloud Foundry supports the deployment of multiple applications using a single manifest file. This option is supported with Piper. In this case define appName: '' since the app name for the individual applications have to be defined via the manifest. You can find details in the Cloud Foundry Documentation","title":"Description"},{"location":"steps/cloudFoundryDeploy/#prerequisites","text":"Cloud Foundry organization, space and deployment user are available Credentials for deployment have been configured in Jenkins with a dedicated Id","title":"Prerequisites"},{"location":"steps/cloudFoundryDeploy/#parameters","text":"name mandatory default possible values apiParameters no `` buildTool no cfNativeDeployParameters no `` cloudFoundry/apiEndpoint no https://api.cf.eu10.hana.ondemand.com cloudFoundry/appName no cloudFoundry/credentialsId yes cloudFoundry/manifest no cloudFoundry/manifestVariablesFiles no cloudFoundry/org yes cloudFoundry/space yes deployDockerImage no deployTool no 'cf_native', 'mtaDeployPlugin' deployType no standard 'standard', 'blue-green' dockerCredentialsId no dockerImage no deployTool= cf_native : ppiper/cf-cli deployTool= mtaDeployPlugin : ppiper/cf-cli dockerWorkspace no deployTool= cf_native : /home/piper deployTool= mtaDeployPlugin : /home/piper keepOldInstance no false true, false loginParameters no `` manifestVariables no mtaDeployParameters no -f mtaExtensionCredentials no mtaExtensionDescriptor no `` mtaPath no `` script yes smokeTestScript no blueGreenCheckScript.sh smokeTestStatusCode no 200 stashContent no [deployDescriptor, pipelineConfigAndTests] verbose no true, false apiParameters - Addition command line options for cf api command. No escaping/quoting is performed. Not recommanded for productive environments. buildTool - cfNativeDeployParameters - Additional parameters passed to cf native deployment command. cloudFoundry/apiEndpoint - Cloud Foundry API endpoint. cloudFoundry/appName - Defines the name of the application to be deployed to the Cloud Foundry space. cloudFoundry/credentialsId - Credentials to be used for deployment. cloudFoundry/manifest - Defines the manifest to be used for deployment to Cloud Foundry. cloudFoundry/manifestVariablesFiles - Defines the manifest variables Yaml files to be used to replace variable references in manifest. This parameter is optional and will default to [\"manifest-variables.yml\"] . This can be used to set variable files like it is provided by cf push --vars-file <file> . If the manifest is present and so are all variable files, a variable substitution will be triggered that uses the cfManifestSubstituteVariables step before deployment. The format of variable references follows the Cloud Foundry standard . cloudFoundry/org - Cloud Foundry target organization. cloudFoundry/space - Cloud Foundry target space. deployDockerImage - Docker image deployments are supported (via manifest file in general)[https://docs.cloudfoundry.org/devguide/deploy-apps/manifest-attributes.html#docker]. If no manifest is used, this parameter defines the image to be deployed. The specified name of the image is passed to the --docker-image parameter of the cf CLI and must adhere it's naming pattern (e.g. REPO/IMAGE:TAG). See (cf CLI documentation)[https://docs.cloudfoundry.org/devguide/deploy-apps/push-docker.html] for details. Note: The used Docker registry must be visible for the targeted Cloud Foundry instance. deployTool - Defines the tool which should be used for deployment. If it is not set it will be inferred automatically based on the buildTool, i.e., for MTA projects mtaDeployPlugin will be used and cf_native for other types of projects. deployType - Defines the type of deployment, either standard deployment which results in a system downtime or a zero-downtime blue-green deployment. If 'cf_native' as deployType and 'blue-green' as deployTool is used in combination, your manifest.yaml may only contain one application. If this application has the option 'no-route' active the deployType will be changed to 'standard'. dockerCredentialsId - If the specified image in deployDockerImage is contained in a Docker registry, which requires authorization this defines the credentials to be used. dockerImage - Name of the docker image that should be used. Configure with empty value to execute the command directly on the Jenkins system (not using a container). Omit to use the default image (cf. default_pipeline_environment.yml ) Overwrite to use custom Docker image. dockerWorkspace - Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . keepOldInstance - In case of a blue-green deployment the old instance will be deleted by default. If this option is set to true the old instance will remain stopped in the Cloud Foundry space. loginParameters - Addition command line options for cf login command. No escaping/quoting is performed. Not recommanded for productive environments. manifestVariables - Defines a List of variables as key-value Map objects used for variable substitution within the file given by manifest . Defaults to an empty list, if not specified otherwise. This can be used to set variables like it is provided by cf push --var key=value . The order of the maps of variables given in the list is relevant in case there are conflicting variable names and values between maps contained within the list. In case of conflicts, the last specified map in the list will win. Though each map entry in the list can contain more than one key-value pair for variable substitution, it is recommended to stick to one entry per map, and rather declare more maps within the list. The reason is that if a map in the list contains more than one key-value entry, and the entries are conflicting, the conflict resolution behavior is undefined (since map entries have no sequence). Note: variables defined via manifestVariables always win over conflicting variables defined via any file given by manifestVariablesFiles - no matter what is declared before. This is the same behavior as can be observed when using cf push --var in combination with cf push --vars-file . mtaDeployParameters - Additional parameters passed to mta deployment command. mtaExtensionCredentials - Defines a map of credentials that need to be replaced in the mtaExtensionDescriptor . This map needs to be created as value-to-be-replaced : id-of-a-credential-in-jenkins mtaExtensionDescriptor - Defines additional extension descriptor file for deployment with the mtaDeployPlugin. mtaPath - Defines the path to *.mtar for deployment with the mtaDeployPlugin. If not specified, it will use the mta file created in mtaBuild or search for an mtar file in the workspace. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. smokeTestScript - Allows to specify a script which performs a check during blue-green deployment. The script gets the FQDN as parameter and returns exit code 0 in case check returned smokeTestStatusCode . More details can be found here Currently this option is only considered for deployTool cf_native . smokeTestStatusCode - Expected status code returned by the check. stashContent - Specific stashes that should be considered for the step execution. verbose - Provides more output. May reveal sensitive information.","title":"Parameters"},{"location":"steps/cloudFoundryDeploy/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage apiParameters X X buildTool X X cfNativeDeployParameters X X cloudFoundry/apiEndpoint X X cloudFoundry/appName X X cloudFoundry/credentialsId X X cloudFoundry/manifest X X cloudFoundry/manifestVariablesFiles X X cloudFoundry/org X X cloudFoundry/space X X deployDockerImage X X deployTool X X deployType X X dockerCredentialsId X X dockerImage X X dockerWorkspace X X keepOldInstance X X loginParameters X X manifestVariables X X mtaDeployParameters X X mtaExtensionCredentials X X mtaExtensionDescriptor X X mtaPath X X script smokeTestScript X X smokeTestStatusCode X X stashContent X X verbose X X","title":"Step configuration"},{"location":"steps/cloudFoundryDeploy/#dependencies","text":"The step depends on the following Jenkins plugins credentials-binding docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/cloudFoundryDeploy/#example","text":"cloudFoundryDeploy ( script: script , deployType: 'blue-green' , cloudFoundry: [ apiEndpoint: 'https://test.server.com' , appName: 'cfAppName' , credentialsId: 'cfCredentialsId' , manifest: 'cfManifest' , org: 'cfOrg' , space: 'cfSpace' ], deployTool: 'cf_native' )","title":"Example"},{"location":"steps/commonPipelineEnvironment/","text":"commonPipelineEnvironment \u00b6 Description \u00b6 Provides project specific settings. Prerequisites \u00b6 none Method details \u00b6 getInfluxCustomData() \u00b6 Description \u00b6 Returns the Influx custom data which can be collected during pipeline run. Parameters \u00b6 none Return value \u00b6 A Map containing the data collected. Side effects \u00b6 none Exceptions \u00b6 none Example \u00b6 def myInfluxData = commonPipelineEnvironment . getInfluxCustomData () getInfluxCustomDataMap() \u00b6 Description \u00b6 Returns the Influx custom data map which can be collected during pipeline run. It is used for example by step influxWriteData . The data map is a map of maps, like [pipeline_data: [:], my_measurement: [:]] Each map inside the map represents a dedicated measurement in the InfluxDB. Parameters \u00b6 none Return value \u00b6 A Map containing a Map s with data collected. Side effects \u00b6 none Exceptions \u00b6 none Example \u00b6 def myInfluxDataMap = commonPipelineEnvironment . getInfluxCustomDataMap () getPipelineMeasurement(measurementName) \u00b6 Description \u00b6 Returns the value of a specific pipeline measurement. The measurements are collected with step durationMeasure Parameters \u00b6 Name of the measurement Return value \u00b6 Value of the measurement Side effects \u00b6 none Exceptions \u00b6 none Example \u00b6 def myMeasurementValue = commonPipelineEnvironment . getPipelineMeasurement ( 'build_stage_duration' ) setPipelineMeasurement(measurementName, value) \u00b6 Description \u00b6 This is an internal function! Sets the value of a specific pipeline measurement. Please use the step durationMeasure in a pipeline, instead. Parameters \u00b6 Name of the measurement and its value. Return value \u00b6 none Side effects \u00b6 none Exceptions \u00b6 none Example \u00b6 commonPipelineEnvironment . setPipelineMeasurement ( 'build_stage_duration' , 2345 )","title":"commonPipelineEnvironment"},{"location":"steps/commonPipelineEnvironment/#commonpipelineenvironment","text":"","title":"commonPipelineEnvironment"},{"location":"steps/commonPipelineEnvironment/#description","text":"Provides project specific settings.","title":"Description"},{"location":"steps/commonPipelineEnvironment/#prerequisites","text":"none","title":"Prerequisites"},{"location":"steps/commonPipelineEnvironment/#method-details","text":"","title":"Method details"},{"location":"steps/commonPipelineEnvironment/#getinfluxcustomdata","text":"","title":"getInfluxCustomData()"},{"location":"steps/commonPipelineEnvironment/#description_1","text":"Returns the Influx custom data which can be collected during pipeline run.","title":"Description"},{"location":"steps/commonPipelineEnvironment/#parameters","text":"none","title":"Parameters"},{"location":"steps/commonPipelineEnvironment/#return-value","text":"A Map containing the data collected.","title":"Return value"},{"location":"steps/commonPipelineEnvironment/#side-effects","text":"none","title":"Side effects"},{"location":"steps/commonPipelineEnvironment/#exceptions","text":"none","title":"Exceptions"},{"location":"steps/commonPipelineEnvironment/#example","text":"def myInfluxData = commonPipelineEnvironment . getInfluxCustomData ()","title":"Example"},{"location":"steps/commonPipelineEnvironment/#getinfluxcustomdatamap","text":"","title":"getInfluxCustomDataMap()"},{"location":"steps/commonPipelineEnvironment/#description_2","text":"Returns the Influx custom data map which can be collected during pipeline run. It is used for example by step influxWriteData . The data map is a map of maps, like [pipeline_data: [:], my_measurement: [:]] Each map inside the map represents a dedicated measurement in the InfluxDB.","title":"Description"},{"location":"steps/commonPipelineEnvironment/#parameters_1","text":"none","title":"Parameters"},{"location":"steps/commonPipelineEnvironment/#return-value_1","text":"A Map containing a Map s with data collected.","title":"Return value"},{"location":"steps/commonPipelineEnvironment/#side-effects_1","text":"none","title":"Side effects"},{"location":"steps/commonPipelineEnvironment/#exceptions_1","text":"none","title":"Exceptions"},{"location":"steps/commonPipelineEnvironment/#example_1","text":"def myInfluxDataMap = commonPipelineEnvironment . getInfluxCustomDataMap ()","title":"Example"},{"location":"steps/commonPipelineEnvironment/#getpipelinemeasurementmeasurementname","text":"","title":"getPipelineMeasurement(measurementName)"},{"location":"steps/commonPipelineEnvironment/#description_3","text":"Returns the value of a specific pipeline measurement. The measurements are collected with step durationMeasure","title":"Description"},{"location":"steps/commonPipelineEnvironment/#parameters_2","text":"Name of the measurement","title":"Parameters"},{"location":"steps/commonPipelineEnvironment/#return-value_2","text":"Value of the measurement","title":"Return value"},{"location":"steps/commonPipelineEnvironment/#side-effects_2","text":"none","title":"Side effects"},{"location":"steps/commonPipelineEnvironment/#exceptions_2","text":"none","title":"Exceptions"},{"location":"steps/commonPipelineEnvironment/#example_2","text":"def myMeasurementValue = commonPipelineEnvironment . getPipelineMeasurement ( 'build_stage_duration' )","title":"Example"},{"location":"steps/commonPipelineEnvironment/#setpipelinemeasurementmeasurementname-value","text":"","title":"setPipelineMeasurement(measurementName, value)"},{"location":"steps/commonPipelineEnvironment/#description_4","text":"This is an internal function! Sets the value of a specific pipeline measurement. Please use the step durationMeasure in a pipeline, instead.","title":"Description"},{"location":"steps/commonPipelineEnvironment/#parameters_3","text":"Name of the measurement and its value.","title":"Parameters"},{"location":"steps/commonPipelineEnvironment/#return-value_3","text":"none","title":"Return value"},{"location":"steps/commonPipelineEnvironment/#side-effects_3","text":"none","title":"Side effects"},{"location":"steps/commonPipelineEnvironment/#exceptions_3","text":"none","title":"Exceptions"},{"location":"steps/commonPipelineEnvironment/#example_3","text":"commonPipelineEnvironment . setPipelineMeasurement ( 'build_stage_duration' , 2345 )","title":"Example"},{"location":"steps/containerExecuteStructureTests/","text":"containerExecuteStructureTests \u00b6 Description \u00b6 In this step Container Structure Tests are executed. This testing framework allows you to execute different test types against a Docker container, for example: Command tests (only if a Docker Deamon is available) File existence tests File content tests Metadata test Prerequisites \u00b6 Test configuration is available. Parameters \u00b6 name mandatory default possible values containerCommand no /busybox/tail -f /dev/null containerShell no /busybox/sh dockerImage no ppiper/container-structure-test dockerOptions no -u 0 --entrypoint='' failOnError no true true , false pullImage no true , false script yes stashContent no [tests] testConfiguration no testDriver no testImage no testReportFilePath no cst-report.json verbose no true , false containerCommand - Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default ( /usr/bin/tail -f /dev/null ). containerShell - Kubernetes only: Allows to specify the shell to be used for execution of commands. dockerImage - Name of the docker image that should be used. Configure with empty value to execute the command directly on the Jenkins system (not using a container). Omit to use the default image (cf. default_pipeline_environment.yml ) Overwrite to use custom Docker image. dockerOptions - Docker only: Docker options to be set when starting the container (List or String). failOnError - Defines the behavior, in case tests fail. pullImage - Only relevant for testDriver 'docker'. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. stashContent - Specific stashes that should be considered for the step execution. testConfiguration - Container structure test configuration in yml or json format. You can pass a pattern in order to execute multiple tests. testDriver - Container structure test driver to be used for testing, please see https://github.com/GoogleContainerTools/container-structure-test for details. testImage - Image to be tested testReportFilePath - Path and name of the test report which will be generated verbose - Print more detailed information into the log. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage containerCommand X containerShell X dockerImage X dockerOptions X failOnError X pullImage X script stashContent X testConfiguration X testDriver X testImage X testReportFilePath X verbose X X Dependencies \u00b6 The step depends on the following Jenkins plugins docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Example \u00b6 containerExecuteStructureTests( script: this, testConfiguration: 'config.yml', testImage: 'node:latest' )","title":"containerExecuteStructureTests"},{"location":"steps/containerExecuteStructureTests/#containerexecutestructuretests","text":"","title":"containerExecuteStructureTests"},{"location":"steps/containerExecuteStructureTests/#description","text":"In this step Container Structure Tests are executed. This testing framework allows you to execute different test types against a Docker container, for example: Command tests (only if a Docker Deamon is available) File existence tests File content tests Metadata test","title":"Description"},{"location":"steps/containerExecuteStructureTests/#prerequisites","text":"Test configuration is available.","title":"Prerequisites"},{"location":"steps/containerExecuteStructureTests/#parameters","text":"name mandatory default possible values containerCommand no /busybox/tail -f /dev/null containerShell no /busybox/sh dockerImage no ppiper/container-structure-test dockerOptions no -u 0 --entrypoint='' failOnError no true true , false pullImage no true , false script yes stashContent no [tests] testConfiguration no testDriver no testImage no testReportFilePath no cst-report.json verbose no true , false containerCommand - Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default ( /usr/bin/tail -f /dev/null ). containerShell - Kubernetes only: Allows to specify the shell to be used for execution of commands. dockerImage - Name of the docker image that should be used. Configure with empty value to execute the command directly on the Jenkins system (not using a container). Omit to use the default image (cf. default_pipeline_environment.yml ) Overwrite to use custom Docker image. dockerOptions - Docker only: Docker options to be set when starting the container (List or String). failOnError - Defines the behavior, in case tests fail. pullImage - Only relevant for testDriver 'docker'. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. stashContent - Specific stashes that should be considered for the step execution. testConfiguration - Container structure test configuration in yml or json format. You can pass a pattern in order to execute multiple tests. testDriver - Container structure test driver to be used for testing, please see https://github.com/GoogleContainerTools/container-structure-test for details. testImage - Image to be tested testReportFilePath - Path and name of the test report which will be generated verbose - Print more detailed information into the log.","title":"Parameters"},{"location":"steps/containerExecuteStructureTests/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage containerCommand X containerShell X dockerImage X dockerOptions X failOnError X pullImage X script stashContent X testConfiguration X testDriver X testImage X testReportFilePath X verbose X X","title":"Step configuration"},{"location":"steps/containerExecuteStructureTests/#dependencies","text":"The step depends on the following Jenkins plugins docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/containerExecuteStructureTests/#example","text":"containerExecuteStructureTests( script: this, testConfiguration: 'config.yml', testImage: 'node:latest' )","title":"Example"},{"location":"steps/containerPushToRegistry/","text":"containerPushToRegistry \u00b6 Description \u00b6 This step allows you to push a Docker image into a dedicated Container registry. By default an image available via the local Docker daemon will be pushed. In case you want to pull an existing image from a remote container registry, a source image and source registry needs to be specified. This makes it possible to move an image from one registry to another. Prerequisites \u00b6 You need to have a valid user with write permissions in the target docker registry. Credentials for the target docker registry have been configured in Jenkins with a dedicated Id. You can create the credentials in your Jenkins via Jenkins -> Credentials -> System -> Global credentials (unrestricted) -> Add Credentials -> Kind: Username with Password ID: specify id which you then use for the configuration of dockerCredentialsId (see below) Example \u00b6 Usage of pipeline step: OPTION A: To pull a Docker image from an existing docker registry and push to a different docker registry: containerPushToRegistry script: this , dockerCredentialsId: 'myTargetRegistryCredentials' , sourceRegistryUrl: 'https://mysourceRegistry.url' , sourceImage: 'path/to/mySourceImageWith:tag' , dockerRegistryUrl: 'https://my.target.docker.registry:50000' OPTION B: To push a locally build docker image into the target registry (only possible when a Docker deamon is available on your Jenkins node): containerPushToRegistry script: this , dockerCredentialsId: 'myTargetRegistryCredentials' , dockerImage: 'path/to/myImageWith:tag' , dockerRegistryUrl: 'https://my.target.docker.registry:50000' Parameters \u00b6 name mandatory default possible values dockerArchive no dockerBuildImage no dockerCredentialsId yes dockerImage no dockerRegistryUrl yes script yes skopeoImage no sourceImage no sourceRegistryUrl no tagLatest no dockerArchive - Not supported yet - Docker archive to be pushed to registry dockerBuildImage - For images built locally on the Docker Deamon, reference to the image object resulting from docker.build execution dockerCredentialsId - Defines the id of the Jenkins username/password credentials containing the credentials for the target Docker registry. dockerImage - Defines the name (incl. tag) of the target image dockerRegistryUrl - Defines the registry url where the image should be pushed to, incl. the protocol like https://my.registry.com script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. skopeoImage - Only if no Docker daemon available on your Jenkins image: Docker image to be used for Skopeo calls Unfortunately no proper image known to be available. Simple custom Dockerfile could look as follows: FROM fedora:29 RUN dnf install -y skopeo sourceImage - Defines the name (incl. tag) of the source image to be pushed to a new image defined in dockerImage . This is helpful for moving images from one location to another. sourceRegistryUrl - Defines a registry url from where the image should optionally be pulled from, incl. the protocol like https://my.registry.com tagLatest - Defines if the image should be tagged as latest Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage dockerArchive X dockerBuildImage X dockerCredentialsId X X dockerImage X dockerRegistryUrl X X script skopeoImage X sourceImage X sourceRegistryUrl X tagLatest X Dependencies \u00b6 The step depends on the following Jenkins plugins credentials-binding docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"containerPushToRegistry"},{"location":"steps/containerPushToRegistry/#containerpushtoregistry","text":"","title":"containerPushToRegistry"},{"location":"steps/containerPushToRegistry/#description","text":"This step allows you to push a Docker image into a dedicated Container registry. By default an image available via the local Docker daemon will be pushed. In case you want to pull an existing image from a remote container registry, a source image and source registry needs to be specified. This makes it possible to move an image from one registry to another.","title":"Description"},{"location":"steps/containerPushToRegistry/#prerequisites","text":"You need to have a valid user with write permissions in the target docker registry. Credentials for the target docker registry have been configured in Jenkins with a dedicated Id. You can create the credentials in your Jenkins via Jenkins -> Credentials -> System -> Global credentials (unrestricted) -> Add Credentials -> Kind: Username with Password ID: specify id which you then use for the configuration of dockerCredentialsId (see below)","title":"Prerequisites"},{"location":"steps/containerPushToRegistry/#example","text":"Usage of pipeline step: OPTION A: To pull a Docker image from an existing docker registry and push to a different docker registry: containerPushToRegistry script: this , dockerCredentialsId: 'myTargetRegistryCredentials' , sourceRegistryUrl: 'https://mysourceRegistry.url' , sourceImage: 'path/to/mySourceImageWith:tag' , dockerRegistryUrl: 'https://my.target.docker.registry:50000' OPTION B: To push a locally build docker image into the target registry (only possible when a Docker deamon is available on your Jenkins node): containerPushToRegistry script: this , dockerCredentialsId: 'myTargetRegistryCredentials' , dockerImage: 'path/to/myImageWith:tag' , dockerRegistryUrl: 'https://my.target.docker.registry:50000'","title":"Example"},{"location":"steps/containerPushToRegistry/#parameters","text":"name mandatory default possible values dockerArchive no dockerBuildImage no dockerCredentialsId yes dockerImage no dockerRegistryUrl yes script yes skopeoImage no sourceImage no sourceRegistryUrl no tagLatest no dockerArchive - Not supported yet - Docker archive to be pushed to registry dockerBuildImage - For images built locally on the Docker Deamon, reference to the image object resulting from docker.build execution dockerCredentialsId - Defines the id of the Jenkins username/password credentials containing the credentials for the target Docker registry. dockerImage - Defines the name (incl. tag) of the target image dockerRegistryUrl - Defines the registry url where the image should be pushed to, incl. the protocol like https://my.registry.com script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. skopeoImage - Only if no Docker daemon available on your Jenkins image: Docker image to be used for Skopeo calls Unfortunately no proper image known to be available. Simple custom Dockerfile could look as follows: FROM fedora:29 RUN dnf install -y skopeo sourceImage - Defines the name (incl. tag) of the source image to be pushed to a new image defined in dockerImage . This is helpful for moving images from one location to another. sourceRegistryUrl - Defines a registry url from where the image should optionally be pulled from, incl. the protocol like https://my.registry.com tagLatest - Defines if the image should be tagged as latest","title":"Parameters"},{"location":"steps/containerPushToRegistry/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage dockerArchive X dockerBuildImage X dockerCredentialsId X X dockerImage X dockerRegistryUrl X X script skopeoImage X sourceImage X sourceRegistryUrl X tagLatest X","title":"Step configuration"},{"location":"steps/containerPushToRegistry/#dependencies","text":"The step depends on the following Jenkins plugins credentials-binding docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/detectExecuteScan/","text":"detectExecuteScan \u00b6 Executes Synopsys Detect scan Description \u00b6 This step executes Synopsys Detect scans. Synopsys Detect command line utlity can be used to run various scans including BlackDuck and Polaris scans. This step allows users to run BlackDuck scans by default. Please configure your BlackDuck server Url using the serverUrl parameter and the API token of your user using the apiToken parameter for this step. Usage \u00b6 We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line . Jenkins pipelines \u00b6 detectExecuteScan script: this Command line \u00b6 piper detectExecuteScan Prerequisites \u00b6 You need to store the API token for the Detect service as 'Secret text' credential in your Jenkins system. Parameters \u00b6 Overview \u00b6 Name Mandatory Additional information apiToken yes pass via ENV or Jenkins credentials ( detectTokenCredentialsId ) detectTokenCredentialsId yes id of credentials ( using credentials ) projectName yes script yes reference to Jenkins main pipeline script serverUrl yes codeLocation no containerCommand no containerShell no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no dockerVolumeBind no dockerWorkspace no failOn no globalSettingsFile no groups no m2Path no projectSettingsFile no scanPaths no scanProperties no scanners no stashContent no verbose no activates debug output version no versioningModel no Details \u00b6 apiToken \u00b6 Api token to be used for connectivity with Synopsis Detect server. back to overview Scope Details Aliases detect/apiToken Type string Mandatory yes Default $PIPER_apiToken (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references Jenkins credential id: id: detectTokenCredentialsId reference to: `` codeLocation \u00b6 An override for the name Detect will use for the scan file it creates. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_codeLocation (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none containerCommand \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default (/usr/bin/tail -f /dev/null). back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none containerShell \u00b6 Jenkins-specific: Used for proper environment setup. Allows to specify the shell to be executed for container with containerName. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none detectTokenCredentialsId \u00b6 Jenkins-specific: Used for proper environment setup. Jenkins 'Secret text' credentials ID containing the API token used to authenticate with the Synopsis Detect (formerly BlackDuck) Server. back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerEnvVars \u00b6 Jenkins-specific: Used for proper environment setup. Environment variables to set in the container, e.g. [http_proxy: \"proxy:8080\"]. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerImage \u00b6 Jenkins-specific: Used for proper environment setup. Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerName \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Name of the container launching dockerImage. SideCar only: Name of the container in local network. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerOptions \u00b6 Jenkins-specific: Used for proper environment setup. Docker options to be set when starting the container. back to overview Scope Details Aliases - Type []string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerPullImage \u00b6 Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerVolumeBind \u00b6 Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the docker container. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerWorkspace \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none failOn \u00b6 A list of policies can be provided which will be applied after the scan is completed. These policies if violated will mark the build/scan result as failed. The list of accepted valed can be found at https://blackducksoftware.github.io/synopsys-detect/latest/properties/configuration/project/#fail-on-policy-violation-severities back to overview Scope Details Aliases detect/failOn Type []string Mandatory no Default - BLOCKER Possible values - ALL - BLOCKER - CRITICAL - MAJOR - MINOR - NONE Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none globalSettingsFile \u00b6 Path or url to the mvn settings file that should be used as global settings file back to overview Scope Details Aliases maven/globalSettingsFile Type string Mandatory no Default $PIPER_globalSettingsFile (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none groups \u00b6 Users groups to be assigned for the Project back to overview Scope Details Aliases detect/groups Type []string Mandatory no Default $PIPER_groups (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none m2Path \u00b6 Path to the location of the local repository that should be used. back to overview Scope Details Aliases maven/m2Path Type string Mandatory no Default $PIPER_m2Path (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none projectName \u00b6 Name of the Synopsis Detect (formerly BlackDuck) project. back to overview Scope Details Aliases detect/projectName Type string Mandatory yes Default $PIPER_projectName (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none projectSettingsFile \u00b6 Path or url to the mvn settings file that should be used as project settings file. back to overview Scope Details Aliases maven/projectSettingsFile Type string Mandatory no Default $PIPER_projectSettingsFile (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none scanPaths \u00b6 List of paths which should be scanned by the Synopsis Detect (formerly BlackDuck) scan. back to overview Scope Details Aliases detect/scanPaths Type []string Mandatory no Default - . Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none scanProperties \u00b6 Properties passed to the Synopsis Detect (formerly BlackDuck) scan. You can find details in the Synopsis Detect documentation back to overview Scope Details Aliases detect/scanProperties Type []string Mandatory no Default - --blackduck.signature.scanner.memory=4096 - --blackduck.timeout=6000 - --blackduck.trust.cert=true - --detect.report.timeout=4800 - --logging.level.com.synopsys.integration=DEBUG Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none scanners \u00b6 List of scanners to be used for Synopsis Detect (formerly BlackDuck) scan. back to overview Scope Details Aliases detect/scanners Type []string Mandatory no Default - signature Possible values - signature - source Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none script \u00b6 Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none serverUrl \u00b6 Server URL to the Synopsis Detect (formerly BlackDuck) Server. back to overview Scope Details Aliases detect/serverUrl Type string Mandatory yes Default $PIPER_serverUrl (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none stashContent \u00b6 Jenkins-specific: Used for proper environment setup. Specific stashes that should be considered for the step execution. back to overview Scope Details Aliases - Type []string Mandatory no Default - buildDescriptor - checkmarx Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none verbose \u00b6 verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none version \u00b6 Defines the version number of the artifact being build in the pipeline. It is used for build version creation and as source for the Detect version. Typically it is available through the pipeline run. The project version of the Detect project is calculated using the versioningModel . back to overview Scope Details Aliases - projectVersion - detect/projectVersion Type string Mandatory no Default $PIPER_version (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references commonPipelineEnvironment : reference to: artifactVersion versioningModel \u00b6 The versioning model used for result reporting (based on the artifact version). For example: the version 1.2.3 of the artifact will result in a version 1 to report into, when versioningModel: major is used and will result in a version 1.2 when versioningModel: major-minor is used. Recommendation for a Continuous Delivery process is to use versioningModel: major . back to overview Scope Details Aliases - Type string Mandatory no Default major Possible values - major - major-minor - semantic - full Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none \u00b6","title":"detectExecuteScan"},{"location":"steps/detectExecuteScan/#detectexecutescan","text":"Executes Synopsys Detect scan","title":"detectExecuteScan"},{"location":"steps/detectExecuteScan/#description","text":"This step executes Synopsys Detect scans. Synopsys Detect command line utlity can be used to run various scans including BlackDuck and Polaris scans. This step allows users to run BlackDuck scans by default. Please configure your BlackDuck server Url using the serverUrl parameter and the API token of your user using the apiToken parameter for this step.","title":"Description"},{"location":"steps/detectExecuteScan/#usage","text":"We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line .","title":"Usage"},{"location":"steps/detectExecuteScan/#jenkins-pipelines","text":"detectExecuteScan script: this","title":"Jenkins pipelines"},{"location":"steps/detectExecuteScan/#command-line","text":"piper detectExecuteScan","title":"Command line"},{"location":"steps/detectExecuteScan/#prerequisites","text":"You need to store the API token for the Detect service as 'Secret text' credential in your Jenkins system.","title":"Prerequisites"},{"location":"steps/detectExecuteScan/#parameters","text":"","title":"Parameters"},{"location":"steps/detectExecuteScan/#overview","text":"Name Mandatory Additional information apiToken yes pass via ENV or Jenkins credentials ( detectTokenCredentialsId ) detectTokenCredentialsId yes id of credentials ( using credentials ) projectName yes script yes reference to Jenkins main pipeline script serverUrl yes codeLocation no containerCommand no containerShell no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no dockerVolumeBind no dockerWorkspace no failOn no globalSettingsFile no groups no m2Path no projectSettingsFile no scanPaths no scanProperties no scanners no stashContent no verbose no activates debug output version no versioningModel no","title":"Overview"},{"location":"steps/detectExecuteScan/#details","text":"","title":"Details"},{"location":"steps/detectExecuteScan/#apitoken","text":"Api token to be used for connectivity with Synopsis Detect server. back to overview Scope Details Aliases detect/apiToken Type string Mandatory yes Default $PIPER_apiToken (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references Jenkins credential id: id: detectTokenCredentialsId reference to: ``","title":"apiToken"},{"location":"steps/detectExecuteScan/#codelocation","text":"An override for the name Detect will use for the scan file it creates. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_codeLocation (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"codeLocation"},{"location":"steps/detectExecuteScan/#containercommand","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default (/usr/bin/tail -f /dev/null). back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"containerCommand"},{"location":"steps/detectExecuteScan/#containershell","text":"Jenkins-specific: Used for proper environment setup. Allows to specify the shell to be executed for container with containerName. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"containerShell"},{"location":"steps/detectExecuteScan/#detecttokencredentialsid","text":"Jenkins-specific: Used for proper environment setup. Jenkins 'Secret text' credentials ID containing the API token used to authenticate with the Synopsis Detect (formerly BlackDuck) Server. back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"detectTokenCredentialsId"},{"location":"steps/detectExecuteScan/#dockerenvvars","text":"Jenkins-specific: Used for proper environment setup. Environment variables to set in the container, e.g. [http_proxy: \"proxy:8080\"]. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerEnvVars"},{"location":"steps/detectExecuteScan/#dockerimage","text":"Jenkins-specific: Used for proper environment setup. Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerImage"},{"location":"steps/detectExecuteScan/#dockername","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Name of the container launching dockerImage. SideCar only: Name of the container in local network. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerName"},{"location":"steps/detectExecuteScan/#dockeroptions","text":"Jenkins-specific: Used for proper environment setup. Docker options to be set when starting the container. back to overview Scope Details Aliases - Type []string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerOptions"},{"location":"steps/detectExecuteScan/#dockerpullimage","text":"Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerPullImage"},{"location":"steps/detectExecuteScan/#dockervolumebind","text":"Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the docker container. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerVolumeBind"},{"location":"steps/detectExecuteScan/#dockerworkspace","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerWorkspace"},{"location":"steps/detectExecuteScan/#failon","text":"A list of policies can be provided which will be applied after the scan is completed. These policies if violated will mark the build/scan result as failed. The list of accepted valed can be found at https://blackducksoftware.github.io/synopsys-detect/latest/properties/configuration/project/#fail-on-policy-violation-severities back to overview Scope Details Aliases detect/failOn Type []string Mandatory no Default - BLOCKER Possible values - ALL - BLOCKER - CRITICAL - MAJOR - MINOR - NONE Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"failOn"},{"location":"steps/detectExecuteScan/#globalsettingsfile","text":"Path or url to the mvn settings file that should be used as global settings file back to overview Scope Details Aliases maven/globalSettingsFile Type string Mandatory no Default $PIPER_globalSettingsFile (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"globalSettingsFile"},{"location":"steps/detectExecuteScan/#groups","text":"Users groups to be assigned for the Project back to overview Scope Details Aliases detect/groups Type []string Mandatory no Default $PIPER_groups (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"groups"},{"location":"steps/detectExecuteScan/#m2path","text":"Path to the location of the local repository that should be used. back to overview Scope Details Aliases maven/m2Path Type string Mandatory no Default $PIPER_m2Path (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"m2Path"},{"location":"steps/detectExecuteScan/#projectname","text":"Name of the Synopsis Detect (formerly BlackDuck) project. back to overview Scope Details Aliases detect/projectName Type string Mandatory yes Default $PIPER_projectName (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"projectName"},{"location":"steps/detectExecuteScan/#projectsettingsfile","text":"Path or url to the mvn settings file that should be used as project settings file. back to overview Scope Details Aliases maven/projectSettingsFile Type string Mandatory no Default $PIPER_projectSettingsFile (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"projectSettingsFile"},{"location":"steps/detectExecuteScan/#scanpaths","text":"List of paths which should be scanned by the Synopsis Detect (formerly BlackDuck) scan. back to overview Scope Details Aliases detect/scanPaths Type []string Mandatory no Default - . Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"scanPaths"},{"location":"steps/detectExecuteScan/#scanproperties","text":"Properties passed to the Synopsis Detect (formerly BlackDuck) scan. You can find details in the Synopsis Detect documentation back to overview Scope Details Aliases detect/scanProperties Type []string Mandatory no Default - --blackduck.signature.scanner.memory=4096 - --blackduck.timeout=6000 - --blackduck.trust.cert=true - --detect.report.timeout=4800 - --logging.level.com.synopsys.integration=DEBUG Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"scanProperties"},{"location":"steps/detectExecuteScan/#scanners","text":"List of scanners to be used for Synopsis Detect (formerly BlackDuck) scan. back to overview Scope Details Aliases detect/scanners Type []string Mandatory no Default - signature Possible values - signature - source Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"scanners"},{"location":"steps/detectExecuteScan/#script","text":"Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none","title":"script"},{"location":"steps/detectExecuteScan/#serverurl","text":"Server URL to the Synopsis Detect (formerly BlackDuck) Server. back to overview Scope Details Aliases detect/serverUrl Type string Mandatory yes Default $PIPER_serverUrl (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"serverUrl"},{"location":"steps/detectExecuteScan/#stashcontent","text":"Jenkins-specific: Used for proper environment setup. Specific stashes that should be considered for the step execution. back to overview Scope Details Aliases - Type []string Mandatory no Default - buildDescriptor - checkmarx Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"stashContent"},{"location":"steps/detectExecuteScan/#verbose","text":"verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"verbose"},{"location":"steps/detectExecuteScan/#version","text":"Defines the version number of the artifact being build in the pipeline. It is used for build version creation and as source for the Detect version. Typically it is available through the pipeline run. The project version of the Detect project is calculated using the versioningModel . back to overview Scope Details Aliases - projectVersion - detect/projectVersion Type string Mandatory no Default $PIPER_version (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references commonPipelineEnvironment : reference to: artifactVersion","title":"version"},{"location":"steps/detectExecuteScan/#versioningmodel","text":"The versioning model used for result reporting (based on the artifact version). For example: the version 1.2.3 of the artifact will result in a version 1 to report into, when versioningModel: major is used and will result in a version 1.2 when versioningModel: major-minor is used. Recommendation for a Continuous Delivery process is to use versioningModel: major . back to overview Scope Details Aliases - Type string Mandatory no Default major Possible values - major - major-minor - semantic - full Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"versioningModel"},{"location":"steps/dockerExecute/","text":"dockerExecute \u00b6 Description \u00b6 Executes a closure inside a docker container with the specified docker image. The workspace is mounted into the docker image. Proxy environment variables defined on the Jenkins machine are also available in the Docker container. Parameters \u00b6 name mandatory default possible values containerCommand no containerPortMappings no containerShell no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no true dockerVolumeBind no dockerWorkspace no script yes sidecarEnvVars no sidecarImage no sidecarName no sidecarOptions no sidecarPullImage no true sidecarReadyCommand no sidecarVolumeBind no sidecarWorkspace no stashContent no [] stashNoDefaultExcludes no true , false containerCommand - Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default ( /usr/bin/tail -f /dev/null ). containerPortMappings - Map which defines per docker image the port mappings, e.g. containerPortMappings: ['selenium/standalone-chrome': [[name: 'selPort', containerPort: 4444, hostPort: 4444]]] . containerShell - Kubernetes only: Allows to specify the shell to be used for execution of commands. dockerEnvVars - Environment variables to set in the container, e.g. [http_proxy: 'proxy:8080']. dockerImage - Name of the docker image that should be used. Configure with empty value to execute the command directly on the Jenkins system (not using a container). Omit to use the default image (cf. default_pipeline_environment.yml ) Overwrite to use custom Docker image. dockerName - Kubernetes only: Name of the container launching dockerImage . SideCar only: Name of the container in local network. dockerOptions - Docker only: Docker options to be set when starting the container (List or String). dockerPullImage - Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. dockerVolumeBind - Docker only: Volumes that should be mounted into the container. dockerWorkspace - Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. sidecarEnvVars - as dockerEnvVars for the sidecar container sidecarImage - as dockerImage for the sidecar container sidecarName - as dockerName for the sidecar container sidecarOptions - as dockerOptions for the sidecar container sidecarPullImage - Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. sidecarReadyCommand - Command executed inside the container which returns exit code 0 when the container is ready to be used. sidecarVolumeBind - as dockerVolumeBind for the sidecar container sidecarWorkspace - as dockerWorkspace for the sidecar container stashContent - Specific stashes that should be considered for the step execution. stashNoDefaultExcludes - In the Kubernetes case the workspace is only available to the respective Jenkins slave but not to the containers running inside the pod. This flag controls whether the stashing does not use the default exclude patterns in addition to the patterns provided in stashExcludes . Kubernetes support \u00b6 If the Jenkins is setup on a Kubernetes cluster, then you can execute the closure inside a container of a pod by setting an environment variable ON_K8S to true . However, it will ignore containerPortMappings , dockerOptions and dockerVolumeBind values. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage containerCommand X containerPortMappings X containerShell X dockerEnvVars X dockerImage X dockerName X dockerOptions X dockerPullImage X dockerVolumeBind X dockerWorkspace X script sidecarEnvVars X sidecarImage X sidecarName X sidecarOptions X sidecarPullImage X sidecarReadyCommand X sidecarVolumeBind X sidecarWorkspace X stashContent X stashNoDefaultExcludes Dependencies \u00b6 The step depends on the following Jenkins plugins docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Side effects \u00b6 none Exceptions \u00b6 none Example 1: Run closure inside a docker container \u00b6 dockerExecute ( dockerImage: 'maven:3.5-jdk-7' ){ sh \"mvn clean install\" } Example 2: Run closure inside a container in a kubernetes pod \u00b6 # set environment variable export ON_K8S = true \" dockerExecute ( script: this , dockerImage: 'maven:3.5-jdk-7' ){ sh \"mvn clean install\" } In the above example, the dockerEcecute step will internally invoke dockerExecuteOnKubernetes step and execute the closure inside a pod. Example 3: Run closure inside a container which is attached to a sidecar container (as for example used in seleniumExecuteTests \u00b6 dockerExecute ( script: script , containerPortMappings: [ containerPortMappings: 'selenium/standalone-chrome' :[ containerPort: 4444 , hostPort: 4444 ]], dockerImage: 'node:8-stretch' , dockerName: 'node' , dockerWorkspace: '/home/node' , sidecarImage: 'selenium/standalone-chrome' , sidecarName: 'selenium' , ) { git url: 'https://github.com/XXXXX/WebDriverIOTest.git' sh '''npm install node index.js ''' }","title":"dockerExecute"},{"location":"steps/dockerExecute/#dockerexecute","text":"","title":"dockerExecute"},{"location":"steps/dockerExecute/#description","text":"Executes a closure inside a docker container with the specified docker image. The workspace is mounted into the docker image. Proxy environment variables defined on the Jenkins machine are also available in the Docker container.","title":"Description"},{"location":"steps/dockerExecute/#parameters","text":"name mandatory default possible values containerCommand no containerPortMappings no containerShell no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no true dockerVolumeBind no dockerWorkspace no script yes sidecarEnvVars no sidecarImage no sidecarName no sidecarOptions no sidecarPullImage no true sidecarReadyCommand no sidecarVolumeBind no sidecarWorkspace no stashContent no [] stashNoDefaultExcludes no true , false containerCommand - Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default ( /usr/bin/tail -f /dev/null ). containerPortMappings - Map which defines per docker image the port mappings, e.g. containerPortMappings: ['selenium/standalone-chrome': [[name: 'selPort', containerPort: 4444, hostPort: 4444]]] . containerShell - Kubernetes only: Allows to specify the shell to be used for execution of commands. dockerEnvVars - Environment variables to set in the container, e.g. [http_proxy: 'proxy:8080']. dockerImage - Name of the docker image that should be used. Configure with empty value to execute the command directly on the Jenkins system (not using a container). Omit to use the default image (cf. default_pipeline_environment.yml ) Overwrite to use custom Docker image. dockerName - Kubernetes only: Name of the container launching dockerImage . SideCar only: Name of the container in local network. dockerOptions - Docker only: Docker options to be set when starting the container (List or String). dockerPullImage - Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. dockerVolumeBind - Docker only: Volumes that should be mounted into the container. dockerWorkspace - Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. sidecarEnvVars - as dockerEnvVars for the sidecar container sidecarImage - as dockerImage for the sidecar container sidecarName - as dockerName for the sidecar container sidecarOptions - as dockerOptions for the sidecar container sidecarPullImage - Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. sidecarReadyCommand - Command executed inside the container which returns exit code 0 when the container is ready to be used. sidecarVolumeBind - as dockerVolumeBind for the sidecar container sidecarWorkspace - as dockerWorkspace for the sidecar container stashContent - Specific stashes that should be considered for the step execution. stashNoDefaultExcludes - In the Kubernetes case the workspace is only available to the respective Jenkins slave but not to the containers running inside the pod. This flag controls whether the stashing does not use the default exclude patterns in addition to the patterns provided in stashExcludes .","title":"Parameters"},{"location":"steps/dockerExecute/#kubernetes-support","text":"If the Jenkins is setup on a Kubernetes cluster, then you can execute the closure inside a container of a pod by setting an environment variable ON_K8S to true . However, it will ignore containerPortMappings , dockerOptions and dockerVolumeBind values.","title":"Kubernetes support"},{"location":"steps/dockerExecute/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage containerCommand X containerPortMappings X containerShell X dockerEnvVars X dockerImage X dockerName X dockerOptions X dockerPullImage X dockerVolumeBind X dockerWorkspace X script sidecarEnvVars X sidecarImage X sidecarName X sidecarOptions X sidecarPullImage X sidecarReadyCommand X sidecarVolumeBind X sidecarWorkspace X stashContent X stashNoDefaultExcludes","title":"Step configuration"},{"location":"steps/dockerExecute/#dependencies","text":"The step depends on the following Jenkins plugins docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/dockerExecute/#side-effects","text":"none","title":"Side effects"},{"location":"steps/dockerExecute/#exceptions","text":"none","title":"Exceptions"},{"location":"steps/dockerExecute/#example-1-run-closure-inside-a-docker-container","text":"dockerExecute ( dockerImage: 'maven:3.5-jdk-7' ){ sh \"mvn clean install\" }","title":"Example 1: Run closure inside a docker container"},{"location":"steps/dockerExecute/#example-2-run-closure-inside-a-container-in-a-kubernetes-pod","text":"# set environment variable export ON_K8S = true \" dockerExecute ( script: this , dockerImage: 'maven:3.5-jdk-7' ){ sh \"mvn clean install\" } In the above example, the dockerEcecute step will internally invoke dockerExecuteOnKubernetes step and execute the closure inside a pod.","title":"Example 2: Run closure inside a container in a kubernetes pod"},{"location":"steps/dockerExecute/#example-3-run-closure-inside-a-container-which-is-attached-to-a-sidecar-container-as-for-example-used-in-seleniumexecutetests","text":"dockerExecute ( script: script , containerPortMappings: [ containerPortMappings: 'selenium/standalone-chrome' :[ containerPort: 4444 , hostPort: 4444 ]], dockerImage: 'node:8-stretch' , dockerName: 'node' , dockerWorkspace: '/home/node' , sidecarImage: 'selenium/standalone-chrome' , sidecarName: 'selenium' , ) { git url: 'https://github.com/XXXXX/WebDriverIOTest.git' sh '''npm install node index.js ''' }","title":"Example 3: Run closure inside a container which is attached to a sidecar container (as for example used in seleniumExecuteTests"},{"location":"steps/dockerExecuteOnKubernetes/","text":"dockerExecuteOnKubernetes \u00b6 Description \u00b6 Executes a closure inside a container in a kubernetes pod. Proxy environment variables defined on the Jenkins machine are also available in the container. By default jnlp agent defined for kubernetes-plugin will be used (see https://github.com/jenkinsci/kubernetes-plugin#pipeline-support ). It is possible to define a custom jnlp agent image by Defining the jnlp image via environment variable JENKINS_JNLP_IMAGE in the Kubernetes landscape Defining the image via config ( jenkinsKubernetes.jnlpAgent ) Option 1 will take precedence over option 2. Prerequisites \u00b6 The Jenkins should be running on kubernetes. An environment variable ON_K8S should be created on Jenkins and initialized to true . This could for example be done via Jenkins - Manage Jenkins - Configure System - Global properties - Environment variables Parameters \u00b6 name mandatory default possible values containerCommand no containerCommands no containerEnvVars no containerMap no containerName no containerPortMappings no containerPullImageFlags no containerShell no containerWorkspaces no dockerEnvVars no dockerImage no dockerPullImage no true dockerWorkspace no jenkinsKubernetes/inheritFrom no jenkinsKubernetes/jnlpAgent no ppiper/jenkins-agent-k8s:v8 jenkinsKubernetes/namespace no nodeSelector no script yes securityContext no sidecarEnvVars no sidecarImage no sidecarName no sidecarPullImage no true sidecarReadyCommand no sidecarWorkspace no stashContent no [] stashExcludes no [workspace:nohup.out] stashIncludes no [workspace:**/*] stashNoDefaultExcludes no true , false verbose no true , false containerCommand - Allows to specify start command for container created with dockerImage parameter to overwrite Piper default ( /usr/bin/tail -f /dev/null ). containerCommands - Specifies start command for containers to overwrite Piper default ( /usr/bin/tail -f /dev/null ). If container's defaultstart command should be used provide empty string like: ['selenium/standalone-chrome': ''] . containerEnvVars - Specifies environment variables per container. If not provided dockerEnvVars will be used. containerMap - A map of docker image to the name of the container. The pod will be created with all the images from this map and they are labled based on the value field of each map entry. Example: ['maven:3.5-jdk-8-alpine': 'mavenExecute', 'selenium/standalone-chrome': 'selenium', 'famiko/jmeter-base': 'checkJMeter', 'ppiper/cf-cli': 'cloudfoundry'] containerName - Optional configuration in combination with containerMap to define the container where the commands should be executed in. containerPortMappings - Map which defines per docker image the port mappings, e.g. containerPortMappings: ['selenium/standalone-chrome': [[name: 'selPort', containerPort: 4444, hostPort: 4444]]] . containerPullImageFlags - Specifies the pullImage flag per container. containerShell - Allows to specify the shell to be executed for container with containerName. containerWorkspaces - Specifies a dedicated user home directory per container which will be passed as value for environment variable HOME . If not provided dockerWorkspace will be used. dockerEnvVars - Environment variables to set in the container, e.g. [http_proxy:'proxy:8080']. dockerImage - Optional name of the docker image that should be used. If no docker image is provided, the closure will be executed in the jnlp agent container. dockerPullImage - Set this to 'false' to bypass a docker image pull. Useful during development process. Allows testing of images which are available in the local registry only. dockerWorkspace - Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . jenkinsKubernetes/inheritFrom - Name of the pod template that should be inherited from. The pod template can be defined in the Jenkins UI jenkinsKubernetes/jnlpAgent - Jnlp agent Docker images which should be used to create new pods. jenkinsKubernetes/namespace - Namespace that should be used to create a new pod nodeSelector - Defines the Kubernetes nodeSelector as per https://github.com/jenkinsci/kubernetes-plugin . script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. securityContext - Kubernetes Security Context used for the pod. Can be used to specify uid and fsGroup. See: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ sidecarEnvVars - as dockerEnvVars for the sidecar container sidecarImage - as dockerImage for the sidecar container sidecarName - SideCar only: Name of the container in local network. sidecarPullImage - Set this to 'false' to bypass a docker image pull. Useful during development process. Allows testing of images which are available in the local registry only. sidecarReadyCommand - Command executed inside the container which returns exit code 0 when the container is ready to be used. sidecarWorkspace - as dockerWorkspace for the sidecar container stashContent - Specific stashes that should be considered for the step execution. stashExcludes - In the Kubernetes case the workspace is only available to the respective Jenkins slave but not to the containers running inside the pod. This configuration defines exclude pattern for stashing from Jenkins workspace to working directory in container and back. Following excludes can be set: * workspace : Pattern for stashing towards container * stashBack : Pattern for bringing data from container back to Jenkins workspace. If not set: defaults to setting for workspace . stashIncludes - In the Kubernetes case the workspace is only available to the respective Jenkins slave but not to the containers running inside the pod. This configuration defines include pattern for stashing from Jenkins workspace to working directory in container and back. Following includes can be set: * workspace : Pattern for stashing towards container * stashBack : Pattern for bringing data from container back to Jenkins workspace. If not set: defaults to setting for workspace . stashNoDefaultExcludes - In the Kubernetes case the workspace is only available to the respective Jenkins slave but not to the containers running inside the pod. This configuration defines include pattern for stashing from Jenkins workspace to working directory in container and back. This flag controls whether the stashing does not use the default exclude patterns in addition to the patterns provided in stashExcludes . verbose - Print more detailed information into the log. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage containerCommand X containerCommands X containerEnvVars X containerMap X containerName X containerPortMappings X containerPullImageFlags X containerShell X containerWorkspaces X dockerEnvVars X dockerImage X dockerPullImage X dockerWorkspace X jenkinsKubernetes/inheritFrom X X jenkinsKubernetes/jnlpAgent X X jenkinsKubernetes/namespace X X nodeSelector X script securityContext X sidecarEnvVars X sidecarImage X sidecarName X sidecarPullImage X sidecarReadyCommand X sidecarWorkspace X stashContent X stashExcludes X stashIncludes X stashNoDefaultExcludes X verbose X X Dependencies \u00b6 The step depends on the following Jenkins plugins docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Side effects \u00b6 none Exceptions \u00b6 none Example 1: Run a closure in a single container pod \u00b6 # set environment variable export ON_K8S = true \" dockerExecuteOnKubernetes ( script: script , dockerImage: 'maven:3.5-jdk-7' ){ sh \"mvn clean install\" } In the above example, a pod will be created with a docker container of image maven:3.5-jdk-7 . The closure will be then executed inside the container. Example 2: Run a closure in a multi-container pod \u00b6 # set environment variable export ON_K8S = true \" dockerExecuteOnKubernetes ( script: script , containerMap: [ 'maven:3.5-jdk-8-alpine' : 'maven' , 'ppiper/cf-cli' : 'cfcli' ]){ container ( 'maven' ){ sh \"mvn clean install\" } container ( 'cfcli' ){ sh \"cf plugins\" } } In the above example, a pod will be created with multiple Docker containers that are passed as a containerMap . The containers can be chosen for executing by referring their labels as shown in the example. Example 3: Running a closure in a dedicated container of a multi-container pod \u00b6 # set environment variable export ON_K8S = true \" dockerExecuteOnKubernetes ( script: script , containerCommands: [ 'selenium/standalone-chrome' : '' ], containerMap: [ 'maven:3.5-jdk-8-alpine' : 'maven' , 'selenium/standalone-chrome' : 'selenium' ], containerName: 'maven' , containerPortMappings: [ 'selenium/standalone-chrome' : [ containerPort: 4444 , hostPort: 4444 ]] containerWorkspaces: [ 'selenium/standalone-chrome' : '' ] ){ echo \"Executing inside a Kubernetes Pod inside 'maven' container to run Selenium tests\" sh \"mvn clean install\" }","title":"dockerExecuteOnKubernetes"},{"location":"steps/dockerExecuteOnKubernetes/#dockerexecuteonkubernetes","text":"","title":"dockerExecuteOnKubernetes"},{"location":"steps/dockerExecuteOnKubernetes/#description","text":"Executes a closure inside a container in a kubernetes pod. Proxy environment variables defined on the Jenkins machine are also available in the container. By default jnlp agent defined for kubernetes-plugin will be used (see https://github.com/jenkinsci/kubernetes-plugin#pipeline-support ). It is possible to define a custom jnlp agent image by Defining the jnlp image via environment variable JENKINS_JNLP_IMAGE in the Kubernetes landscape Defining the image via config ( jenkinsKubernetes.jnlpAgent ) Option 1 will take precedence over option 2.","title":"Description"},{"location":"steps/dockerExecuteOnKubernetes/#prerequisites","text":"The Jenkins should be running on kubernetes. An environment variable ON_K8S should be created on Jenkins and initialized to true . This could for example be done via Jenkins - Manage Jenkins - Configure System - Global properties - Environment variables","title":"Prerequisites"},{"location":"steps/dockerExecuteOnKubernetes/#parameters","text":"name mandatory default possible values containerCommand no containerCommands no containerEnvVars no containerMap no containerName no containerPortMappings no containerPullImageFlags no containerShell no containerWorkspaces no dockerEnvVars no dockerImage no dockerPullImage no true dockerWorkspace no jenkinsKubernetes/inheritFrom no jenkinsKubernetes/jnlpAgent no ppiper/jenkins-agent-k8s:v8 jenkinsKubernetes/namespace no nodeSelector no script yes securityContext no sidecarEnvVars no sidecarImage no sidecarName no sidecarPullImage no true sidecarReadyCommand no sidecarWorkspace no stashContent no [] stashExcludes no [workspace:nohup.out] stashIncludes no [workspace:**/*] stashNoDefaultExcludes no true , false verbose no true , false containerCommand - Allows to specify start command for container created with dockerImage parameter to overwrite Piper default ( /usr/bin/tail -f /dev/null ). containerCommands - Specifies start command for containers to overwrite Piper default ( /usr/bin/tail -f /dev/null ). If container's defaultstart command should be used provide empty string like: ['selenium/standalone-chrome': ''] . containerEnvVars - Specifies environment variables per container. If not provided dockerEnvVars will be used. containerMap - A map of docker image to the name of the container. The pod will be created with all the images from this map and they are labled based on the value field of each map entry. Example: ['maven:3.5-jdk-8-alpine': 'mavenExecute', 'selenium/standalone-chrome': 'selenium', 'famiko/jmeter-base': 'checkJMeter', 'ppiper/cf-cli': 'cloudfoundry'] containerName - Optional configuration in combination with containerMap to define the container where the commands should be executed in. containerPortMappings - Map which defines per docker image the port mappings, e.g. containerPortMappings: ['selenium/standalone-chrome': [[name: 'selPort', containerPort: 4444, hostPort: 4444]]] . containerPullImageFlags - Specifies the pullImage flag per container. containerShell - Allows to specify the shell to be executed for container with containerName. containerWorkspaces - Specifies a dedicated user home directory per container which will be passed as value for environment variable HOME . If not provided dockerWorkspace will be used. dockerEnvVars - Environment variables to set in the container, e.g. [http_proxy:'proxy:8080']. dockerImage - Optional name of the docker image that should be used. If no docker image is provided, the closure will be executed in the jnlp agent container. dockerPullImage - Set this to 'false' to bypass a docker image pull. Useful during development process. Allows testing of images which are available in the local registry only. dockerWorkspace - Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . jenkinsKubernetes/inheritFrom - Name of the pod template that should be inherited from. The pod template can be defined in the Jenkins UI jenkinsKubernetes/jnlpAgent - Jnlp agent Docker images which should be used to create new pods. jenkinsKubernetes/namespace - Namespace that should be used to create a new pod nodeSelector - Defines the Kubernetes nodeSelector as per https://github.com/jenkinsci/kubernetes-plugin . script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. securityContext - Kubernetes Security Context used for the pod. Can be used to specify uid and fsGroup. See: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ sidecarEnvVars - as dockerEnvVars for the sidecar container sidecarImage - as dockerImage for the sidecar container sidecarName - SideCar only: Name of the container in local network. sidecarPullImage - Set this to 'false' to bypass a docker image pull. Useful during development process. Allows testing of images which are available in the local registry only. sidecarReadyCommand - Command executed inside the container which returns exit code 0 when the container is ready to be used. sidecarWorkspace - as dockerWorkspace for the sidecar container stashContent - Specific stashes that should be considered for the step execution. stashExcludes - In the Kubernetes case the workspace is only available to the respective Jenkins slave but not to the containers running inside the pod. This configuration defines exclude pattern for stashing from Jenkins workspace to working directory in container and back. Following excludes can be set: * workspace : Pattern for stashing towards container * stashBack : Pattern for bringing data from container back to Jenkins workspace. If not set: defaults to setting for workspace . stashIncludes - In the Kubernetes case the workspace is only available to the respective Jenkins slave but not to the containers running inside the pod. This configuration defines include pattern for stashing from Jenkins workspace to working directory in container and back. Following includes can be set: * workspace : Pattern for stashing towards container * stashBack : Pattern for bringing data from container back to Jenkins workspace. If not set: defaults to setting for workspace . stashNoDefaultExcludes - In the Kubernetes case the workspace is only available to the respective Jenkins slave but not to the containers running inside the pod. This configuration defines include pattern for stashing from Jenkins workspace to working directory in container and back. This flag controls whether the stashing does not use the default exclude patterns in addition to the patterns provided in stashExcludes . verbose - Print more detailed information into the log.","title":"Parameters"},{"location":"steps/dockerExecuteOnKubernetes/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage containerCommand X containerCommands X containerEnvVars X containerMap X containerName X containerPortMappings X containerPullImageFlags X containerShell X containerWorkspaces X dockerEnvVars X dockerImage X dockerPullImage X dockerWorkspace X jenkinsKubernetes/inheritFrom X X jenkinsKubernetes/jnlpAgent X X jenkinsKubernetes/namespace X X nodeSelector X script securityContext X sidecarEnvVars X sidecarImage X sidecarName X sidecarPullImage X sidecarReadyCommand X sidecarWorkspace X stashContent X stashExcludes X stashIncludes X stashNoDefaultExcludes X verbose X X","title":"Step configuration"},{"location":"steps/dockerExecuteOnKubernetes/#dependencies","text":"The step depends on the following Jenkins plugins docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/dockerExecuteOnKubernetes/#side-effects","text":"none","title":"Side effects"},{"location":"steps/dockerExecuteOnKubernetes/#exceptions","text":"none","title":"Exceptions"},{"location":"steps/dockerExecuteOnKubernetes/#example-1-run-a-closure-in-a-single-container-pod","text":"# set environment variable export ON_K8S = true \" dockerExecuteOnKubernetes ( script: script , dockerImage: 'maven:3.5-jdk-7' ){ sh \"mvn clean install\" } In the above example, a pod will be created with a docker container of image maven:3.5-jdk-7 . The closure will be then executed inside the container.","title":"Example 1: Run a closure in a single container pod"},{"location":"steps/dockerExecuteOnKubernetes/#example-2-run-a-closure-in-a-multi-container-pod","text":"# set environment variable export ON_K8S = true \" dockerExecuteOnKubernetes ( script: script , containerMap: [ 'maven:3.5-jdk-8-alpine' : 'maven' , 'ppiper/cf-cli' : 'cfcli' ]){ container ( 'maven' ){ sh \"mvn clean install\" } container ( 'cfcli' ){ sh \"cf plugins\" } } In the above example, a pod will be created with multiple Docker containers that are passed as a containerMap . The containers can be chosen for executing by referring their labels as shown in the example.","title":"Example 2: Run a closure in a multi-container pod"},{"location":"steps/dockerExecuteOnKubernetes/#example-3-running-a-closure-in-a-dedicated-container-of-a-multi-container-pod","text":"# set environment variable export ON_K8S = true \" dockerExecuteOnKubernetes ( script: script , containerCommands: [ 'selenium/standalone-chrome' : '' ], containerMap: [ 'maven:3.5-jdk-8-alpine' : 'maven' , 'selenium/standalone-chrome' : 'selenium' ], containerName: 'maven' , containerPortMappings: [ 'selenium/standalone-chrome' : [ containerPort: 4444 , hostPort: 4444 ]] containerWorkspaces: [ 'selenium/standalone-chrome' : '' ] ){ echo \"Executing inside a Kubernetes Pod inside 'maven' container to run Selenium tests\" sh \"mvn clean install\" }","title":"Example 3: Running a closure in a dedicated container of a multi-container pod"},{"location":"steps/dubExecute/","text":"dubExecute \u00b6 Parameters \u00b6 name mandatory default possible values defaultDubRegistry no dockerEnvVars no dockerImage no dlang2/dmd-ubuntu:latest dockerOptions no dockerWorkspace no dubCommand no script yes defaultDubRegistry - URL of default DUB registry dockerEnvVars - Environment variables to set in the container, e.g. [http_proxy: 'proxy:8080']. dockerImage - Name of the docker image that should be used, in which node should be installed and configured. Default value is 'dlang2/dmd-ubuntu:latest'. dockerOptions - Docker options to be set when starting the container. dockerWorkspace - Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . dubCommand - Which DUB command should be executed. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage defaultDubRegistry X dockerEnvVars X dockerImage X dockerOptions X dockerWorkspace X dubCommand X script Dependencies \u00b6 The step depends on the following Jenkins plugins docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Exceptions \u00b6 None Examples \u00b6 dubExecute script: this , dockerImage: 'dlang2/dmd-ubuntu:latest' , dubCommand: 'build'","title":"dubExecute"},{"location":"steps/dubExecute/#dubexecute","text":"","title":"dubExecute"},{"location":"steps/dubExecute/#parameters","text":"name mandatory default possible values defaultDubRegistry no dockerEnvVars no dockerImage no dlang2/dmd-ubuntu:latest dockerOptions no dockerWorkspace no dubCommand no script yes defaultDubRegistry - URL of default DUB registry dockerEnvVars - Environment variables to set in the container, e.g. [http_proxy: 'proxy:8080']. dockerImage - Name of the docker image that should be used, in which node should be installed and configured. Default value is 'dlang2/dmd-ubuntu:latest'. dockerOptions - Docker options to be set when starting the container. dockerWorkspace - Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . dubCommand - Which DUB command should be executed. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters.","title":"Parameters"},{"location":"steps/dubExecute/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage defaultDubRegistry X dockerEnvVars X dockerImage X dockerOptions X dockerWorkspace X dubCommand X script","title":"Step configuration"},{"location":"steps/dubExecute/#dependencies","text":"The step depends on the following Jenkins plugins docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/dubExecute/#exceptions","text":"None","title":"Exceptions"},{"location":"steps/dubExecute/#examples","text":"dubExecute script: this , dockerImage: 'dlang2/dmd-ubuntu:latest' , dubCommand: 'build'","title":"Examples"},{"location":"steps/durationMeasure/","text":"durationMeasure \u00b6 Description \u00b6 This step is used to measure the duration of a set of steps, e.g. a certain stage. The duration is stored in a Map. The measurement data can then be written to an Influx database using step influxWriteData . Tip Measuring for example the duration of pipeline stages helps to identify potential bottlenecks within the deployment pipeline. This then helps to counter identified issues with respective optimization measures, e.g parallelization of tests. Parameters \u00b6 name mandatory default possible values measurementName no script yes measurementName - Defines the name of the measurement which is written to the Influx database. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage measurementName script Dependencies \u00b6 The step depends on the following Jenkins plugins <none> Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Example \u00b6 durationMeasure ( script: this , measurementName: 'build_duration' ) { //execute your build }","title":"durationMeasure"},{"location":"steps/durationMeasure/#durationmeasure","text":"","title":"durationMeasure"},{"location":"steps/durationMeasure/#description","text":"This step is used to measure the duration of a set of steps, e.g. a certain stage. The duration is stored in a Map. The measurement data can then be written to an Influx database using step influxWriteData . Tip Measuring for example the duration of pipeline stages helps to identify potential bottlenecks within the deployment pipeline. This then helps to counter identified issues with respective optimization measures, e.g parallelization of tests.","title":"Description"},{"location":"steps/durationMeasure/#parameters","text":"name mandatory default possible values measurementName no script yes measurementName - Defines the name of the measurement which is written to the Influx database. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters.","title":"Parameters"},{"location":"steps/durationMeasure/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage measurementName script","title":"Step configuration"},{"location":"steps/durationMeasure/#dependencies","text":"The step depends on the following Jenkins plugins <none> Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/durationMeasure/#example","text":"durationMeasure ( script: this , measurementName: 'build_duration' ) { //execute your build }","title":"Example"},{"location":"steps/fortifyExecuteScan/","text":"fortifyExecuteScan \u00b6 This BETA step executes a Fortify scan on the specified project to perform static code analysis and check the source code for security flaws. Description \u00b6 This step executes a Fortify scan on the specified project to perform static code analysis and check the source code for security flaws. The Fortify step triggers a scan locally on your Jenkins within a docker container so finally you have to supply a docker image with a Fortify SCA and Java plus Maven or alternatively Python installed into it for being able to perform any scans. DISCLAIMER: The step has not yet been tested on a wide variaty of projects, and is therefore considered of BETA quality. Usage \u00b6 We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line . Jenkins pipelines \u00b6 fortifyExecuteScan script: this Command line \u00b6 piper fortifyExecuteScan Outputs \u00b6 Output type Details influx measurement fortify_data projectName projectVersion violations corporateTotal corporateAudited auditAllTotal auditAllAudited spotChecksTotal spotChecksAudited spotChecksGap suspicious exploitable suppressed Parameters \u00b6 Overview \u00b6 Name Mandatory Additional information authToken yes pass via ENV or Jenkins credentials fortifyCredentialsId yes id of credentials ( using credentials ) githubTokenCredentialsId yes id of credentials ( using credentials ) script yes reference to Jenkins main pipeline script serverUrl yes apiEndpoint no artifactUrl no autoCreate no autodetectClasspath no buildDescriptorFile no buildTool no commitId no commitMessage no considerSuspicious no containerCommand no containerShell no deltaMinutes no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no dockerVolumeBind no dockerWorkspace no exclude no filterSetTitle no fprDownloadEndpoint no fprUploadEndpoint no githubApiUrl no githubToken no pass via ENV or Jenkins credentials globalSettingsFile no m2Path no memory no modulePath no mustAuditIssueGroups no owner no pollingMinutes no projectName no projectSettingsFile no pullRequestMessageRegex no pullRequestMessageRegexGroup no pullRequestName no pythonAdditionalPath no pythonInstallCommand no pythonRequirementsFile no pythonRequirementsInstallSuffix no pythonVersion no quickScan no reportDownloadEndpoint no reportTemplateId no reportType no reporting no repository no spotAuditIssueGroups no spotCheckMinimum no src no stashContent no translate no updateRulePack no uploadResults no verbose no activates debug output versioningModel no Details \u00b6 apiEndpoint \u00b6 Fortify SSC endpoint used for uploading the scan results and checking the audit state back to overview Scope Details Aliases fortifyApiEndpoint Type string Mandatory no Default /api/v1 Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none artifactUrl \u00b6 Path/URL pointing to an additional artifact repository for resolution of additional artifacts during the build back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_artifactUrl (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none authToken \u00b6 The FortifyToken to use for authentication back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_authToken (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none autoCreate \u00b6 Whether Fortify project and project version shall be implicitly auto created in case they cannot be found in the backend back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none autodetectClasspath \u00b6 Whether the classpath is automatically determined via build tool i.e. maven or pip or not at all back to overview Scope Details Aliases - Type bool Mandatory no Default true Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none buildDescriptorFile \u00b6 Path to the build descriptor file addressing the module/folder to be scanned. Defaults are for buildTool= maven : ./pom.xml , buildTool= pip : ./setup.py . back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_buildDescriptorFile (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none buildTool \u00b6 Scan type used for the step which can be 'maven' , 'pip' back to overview Scope Details Aliases - Type string Mandatory no Default maven Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none commitId \u00b6 Set the Git commit ID for identifying artifacts throughout the scan. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_commitId (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references commonPipelineEnvironment : reference to: git/commitId commitMessage \u00b6 Set the Git commit message for identifying pull request merges throughout the scan. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_commitMessage (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references commonPipelineEnvironment : reference to: git/commitMessage considerSuspicious \u00b6 Whether suspicious issues should trigger the check to fail or not back to overview Scope Details Aliases - Type bool Mandatory no Default true Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none containerCommand \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default (/usr/bin/tail -f /dev/null). back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none containerShell \u00b6 Jenkins-specific: Used for proper environment setup. Allows to specify the shell to be executed for container with containerName. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none deltaMinutes \u00b6 The number of minutes for which an uploaded FPR artifact is considered to be recent and healthy, if exceeded an error will be thrown back to overview Scope Details Aliases - Type int Mandatory no Default 5 Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none dockerEnvVars \u00b6 Jenkins-specific: Used for proper environment setup. Environment variables to set in the container, e.g. [http_proxy: \"proxy:8080\"]. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerImage \u00b6 Jenkins-specific: Used for proper environment setup. Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerName \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Name of the container launching dockerImage. SideCar only: Name of the container in local network. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerOptions \u00b6 Jenkins-specific: Used for proper environment setup. Docker options to be set when starting the container. back to overview Scope Details Aliases - Type []string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerPullImage \u00b6 Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerVolumeBind \u00b6 Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the docker container. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerWorkspace \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none exclude \u00b6 A list of directories/files to be excluded from the scan. Wildcards can be used, e.g., '**/Test.java' . If translate is set, this will ignored. back to overview Scope Details Aliases - Type []string Mandatory no Default $PIPER_exclude (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none filterSetTitle \u00b6 Title of the filter set to use for analysing the results back to overview Scope Details Aliases - Type string Mandatory no Default SAP Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none fortifyCredentialsId \u00b6 Jenkins-specific: Used for proper environment setup. Jenkins 'Secret text' credentials ID containing token to authenticate to Fortify SSC. back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none fprDownloadEndpoint \u00b6 Fortify SSC endpoint for FPR downloads back to overview Scope Details Aliases fortifyFprDownloadEndpoint Type string Mandatory no Default /download/currentStateFprDownload.html Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none fprUploadEndpoint \u00b6 Fortify SSC endpoint for FPR uploads back to overview Scope Details Aliases fortifyFprUploadEndpoint Type string Mandatory no Default /upload/resultFileUpload.html Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none githubApiUrl \u00b6 Set the GitHub API URL. back to overview Scope Details Aliases - Type string Mandatory no Default https://api.github.com Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none githubToken \u00b6 GitHub personal access token as per https://help.github.com/en/github/authenticating-to-github/creating-a-personal-access-token-for-the-command-line back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_githubToken (if set) Secret yes Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none githubTokenCredentialsId \u00b6 Jenkins-specific: Used for proper environment setup. Jenkins 'Secret text' credentials ID containing token to authenticate to GitHub. back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none globalSettingsFile \u00b6 Path to the mvn settings file that should be used as global settings file. back to overview Scope Details Aliases maven/globalSettingsFile Type string Mandatory no Default $PIPER_globalSettingsFile (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none m2Path \u00b6 Path to the location of the local repository that should be used. back to overview Scope Details Aliases maven/m2Path Type string Mandatory no Default $PIPER_m2Path (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none memory \u00b6 The amount of memory granted to the translate/scan executions back to overview Scope Details Aliases - Type string Mandatory no Default -Xmx4G -Xms512M Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none modulePath \u00b6 Allows providing the path for the module to scan back to overview Scope Details Aliases - Type string Mandatory no Default ./ Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none mustAuditIssueGroups \u00b6 Comma separated list of issue groups that must be audited completely back to overview Scope Details Aliases - Type string Mandatory no Default Corporate Security Requirements, Audit All Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none owner \u00b6 Set the GitHub organization. back to overview Scope Details Aliases githubOrg Type string Mandatory no Default $PIPER_owner (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references commonPipelineEnvironment : reference to: github/owner pollingMinutes \u00b6 The number of minutes for which an uploaded FPR artifact''s status is being polled to finish queuing/processing, if exceeded polling will be stopped and an error will be thrown back to overview Scope Details Aliases - Type int Mandatory no Default 30 Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none projectName \u00b6 The project used for reporting results in SSC back to overview Scope Details Aliases fortifyProjectName Type string Mandatory no Default {{list .GroupID .ArtifactID | join \"-\" | trimAll \"-\"}} Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none projectSettingsFile \u00b6 Path to the mvn settings file that should be used as project settings file. back to overview Scope Details Aliases maven/projectSettingsFile Type string Mandatory no Default $PIPER_projectSettingsFile (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none pullRequestMessageRegex \u00b6 Regex used to identify the PR-XXX reference within the merge commit message back to overview Scope Details Aliases - Type string Mandatory no Default .*Merge pull request #(\\\\d+) from.* Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none pullRequestMessageRegexGroup \u00b6 The group number for extracting the pull request id in 'pullRequestMessageRegex' back to overview Scope Details Aliases - Type int Mandatory no Default 1 Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none pullRequestName \u00b6 The name of the pull request branch which will trigger creation of a new version in Fortify SSC based on the master branch version back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_pullRequestName (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none pythonAdditionalPath \u00b6 A list of additional paths which can be used in buildTool: 'pip' for customization purposes back to overview Scope Details Aliases - Type []string Mandatory no Default - ./lib - . Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none pythonInstallCommand \u00b6 Additional install command that can be run when buildTool: 'pip' is used which allows further customizing the execution environment of the scan back to overview Scope Details Aliases - Type string Mandatory no Default {{.Pip}} install --user . Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none pythonRequirementsFile \u00b6 The requirements file used in buildTool: 'pip' to populate the build environment with the necessary dependencies back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_pythonRequirementsFile (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none pythonRequirementsInstallSuffix \u00b6 The suffix for the command used to install the requirements file in buildTool: 'pip' to populate the build environment with the necessary dependencies back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_pythonRequirementsInstallSuffix (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none pythonVersion \u00b6 Python version to be used in buildTool: 'pip' back to overview Scope Details Aliases - Type string Mandatory no Default python3 Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none quickScan \u00b6 Whether a quick scan should be performed, please consult the related Fortify documentation on JAM on the impact of this setting back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none reportDownloadEndpoint \u00b6 Fortify SSC endpoint for Report downloads back to overview Scope Details Aliases fortifyReportDownloadEndpoint Type string Mandatory no Default /transfer/reportDownload.html Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none reportTemplateId \u00b6 Report template ID to be used for generating the Fortify report back to overview Scope Details Aliases - Type int Mandatory no Default 18 Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none reportType \u00b6 The type of report to be generated back to overview Scope Details Aliases - Type string Mandatory no Default PDF Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none reporting \u00b6 Influences whether a report is generated or not back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none repository \u00b6 Set the GitHub repository. back to overview Scope Details Aliases githubRepo Type string Mandatory no Default $PIPER_repository (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references commonPipelineEnvironment : reference to: github/repository script \u00b6 Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none serverUrl \u00b6 Fortify SSC Url to be used for accessing the APIs back to overview Scope Details Aliases - fortifyServerUrl - sscUrl ( deprecated ) Type string Mandatory yes Default $PIPER_serverUrl (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none spotAuditIssueGroups \u00b6 Comma separated list of issue groups that are spot checked and for which spotCheckMinimum audited issues are enforced back to overview Scope Details Aliases - Type string Mandatory no Default Spot Checks of Each Category Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none spotCheckMinimum \u00b6 The minimum number of issues that must be audited per category in the Spot Checks of each Category folder to avoid an error being thrown back to overview Scope Details Aliases - Type int Mandatory no Default 1 Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none src \u00b6 A list of source directories to scan. Wildcards can be used, e.g., 'src/main/java/**/*' . If 'translate' is set, this will ignored. The default value for buildTool: 'maven' is [' /*.xml', ' / .html', ' /*.jsp', ' / .js', ' /src/main/resources/ / ', ' /src/main/java/ / '], for buildTool: 'pip' it is ['./* / ']. back to overview Scope Details Aliases - Type []string Mandatory no Default $PIPER_src (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none stashContent \u00b6 Jenkins-specific: Used for proper environment setup. Specific stashes that should be considered for the step execution. back to overview Scope Details Aliases - Type []string Mandatory no Default - buildDescriptor - deployDescriptor - tests - opensourceConfiguration Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none translate \u00b6 Options for translate phase of Fortify. Most likely, you do not need to set this parameter. See src, exclude. If 'src' and 'exclude' are set they are automatically used. Technical details: It has to be a JSON string of list of maps with required key 'src' , and optional keys 'exclude' , 'libDirs' , 'aspnetcore' , and 'dotNetCoreVersion' back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_translate (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none updateRulePack \u00b6 Whether the rule pack shall be updated and pulled from Fortify SSC before scanning or not back to overview Scope Details Aliases - Type bool Mandatory no Default true Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none uploadResults \u00b6 Whether results shall be uploaded or not back to overview Scope Details Aliases - Type bool Mandatory no Default true Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none verbose \u00b6 verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none versioningModel \u00b6 The default project versioning model used for creating the version based on the build descriptor version to report results in SSC, can be one of 'major' , 'major-minor' , 'semantic' , 'full' back to overview Scope Details Aliases defaultVersioningModel ( deprecated ) Type string Mandatory no Default major Possible values - major - major-minor - semantic - full Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none \u00b6","title":"fortifyExecuteScan"},{"location":"steps/fortifyExecuteScan/#fortifyexecutescan","text":"This BETA step executes a Fortify scan on the specified project to perform static code analysis and check the source code for security flaws.","title":"fortifyExecuteScan"},{"location":"steps/fortifyExecuteScan/#description","text":"This step executes a Fortify scan on the specified project to perform static code analysis and check the source code for security flaws. The Fortify step triggers a scan locally on your Jenkins within a docker container so finally you have to supply a docker image with a Fortify SCA and Java plus Maven or alternatively Python installed into it for being able to perform any scans. DISCLAIMER: The step has not yet been tested on a wide variaty of projects, and is therefore considered of BETA quality.","title":"Description"},{"location":"steps/fortifyExecuteScan/#usage","text":"We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line .","title":"Usage"},{"location":"steps/fortifyExecuteScan/#jenkins-pipelines","text":"fortifyExecuteScan script: this","title":"Jenkins pipelines"},{"location":"steps/fortifyExecuteScan/#command-line","text":"piper fortifyExecuteScan","title":"Command line"},{"location":"steps/fortifyExecuteScan/#outputs","text":"Output type Details influx measurement fortify_data projectName projectVersion violations corporateTotal corporateAudited auditAllTotal auditAllAudited spotChecksTotal spotChecksAudited spotChecksGap suspicious exploitable suppressed","title":"Outputs"},{"location":"steps/fortifyExecuteScan/#parameters","text":"","title":"Parameters"},{"location":"steps/fortifyExecuteScan/#overview","text":"Name Mandatory Additional information authToken yes pass via ENV or Jenkins credentials fortifyCredentialsId yes id of credentials ( using credentials ) githubTokenCredentialsId yes id of credentials ( using credentials ) script yes reference to Jenkins main pipeline script serverUrl yes apiEndpoint no artifactUrl no autoCreate no autodetectClasspath no buildDescriptorFile no buildTool no commitId no commitMessage no considerSuspicious no containerCommand no containerShell no deltaMinutes no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no dockerVolumeBind no dockerWorkspace no exclude no filterSetTitle no fprDownloadEndpoint no fprUploadEndpoint no githubApiUrl no githubToken no pass via ENV or Jenkins credentials globalSettingsFile no m2Path no memory no modulePath no mustAuditIssueGroups no owner no pollingMinutes no projectName no projectSettingsFile no pullRequestMessageRegex no pullRequestMessageRegexGroup no pullRequestName no pythonAdditionalPath no pythonInstallCommand no pythonRequirementsFile no pythonRequirementsInstallSuffix no pythonVersion no quickScan no reportDownloadEndpoint no reportTemplateId no reportType no reporting no repository no spotAuditIssueGroups no spotCheckMinimum no src no stashContent no translate no updateRulePack no uploadResults no verbose no activates debug output versioningModel no","title":"Overview"},{"location":"steps/fortifyExecuteScan/#details","text":"","title":"Details"},{"location":"steps/fortifyExecuteScan/#apiendpoint","text":"Fortify SSC endpoint used for uploading the scan results and checking the audit state back to overview Scope Details Aliases fortifyApiEndpoint Type string Mandatory no Default /api/v1 Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"apiEndpoint"},{"location":"steps/fortifyExecuteScan/#artifacturl","text":"Path/URL pointing to an additional artifact repository for resolution of additional artifacts during the build back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_artifactUrl (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"artifactUrl"},{"location":"steps/fortifyExecuteScan/#authtoken","text":"The FortifyToken to use for authentication back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_authToken (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"authToken"},{"location":"steps/fortifyExecuteScan/#autocreate","text":"Whether Fortify project and project version shall be implicitly auto created in case they cannot be found in the backend back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"autoCreate"},{"location":"steps/fortifyExecuteScan/#autodetectclasspath","text":"Whether the classpath is automatically determined via build tool i.e. maven or pip or not at all back to overview Scope Details Aliases - Type bool Mandatory no Default true Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"autodetectClasspath"},{"location":"steps/fortifyExecuteScan/#builddescriptorfile","text":"Path to the build descriptor file addressing the module/folder to be scanned. Defaults are for buildTool= maven : ./pom.xml , buildTool= pip : ./setup.py . back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_buildDescriptorFile (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"buildDescriptorFile"},{"location":"steps/fortifyExecuteScan/#buildtool","text":"Scan type used for the step which can be 'maven' , 'pip' back to overview Scope Details Aliases - Type string Mandatory no Default maven Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"buildTool"},{"location":"steps/fortifyExecuteScan/#commitid","text":"Set the Git commit ID for identifying artifacts throughout the scan. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_commitId (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references commonPipelineEnvironment : reference to: git/commitId","title":"commitId"},{"location":"steps/fortifyExecuteScan/#commitmessage","text":"Set the Git commit message for identifying pull request merges throughout the scan. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_commitMessage (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references commonPipelineEnvironment : reference to: git/commitMessage","title":"commitMessage"},{"location":"steps/fortifyExecuteScan/#considersuspicious","text":"Whether suspicious issues should trigger the check to fail or not back to overview Scope Details Aliases - Type bool Mandatory no Default true Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"considerSuspicious"},{"location":"steps/fortifyExecuteScan/#containercommand","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default (/usr/bin/tail -f /dev/null). back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"containerCommand"},{"location":"steps/fortifyExecuteScan/#containershell","text":"Jenkins-specific: Used for proper environment setup. Allows to specify the shell to be executed for container with containerName. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"containerShell"},{"location":"steps/fortifyExecuteScan/#deltaminutes","text":"The number of minutes for which an uploaded FPR artifact is considered to be recent and healthy, if exceeded an error will be thrown back to overview Scope Details Aliases - Type int Mandatory no Default 5 Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"deltaMinutes"},{"location":"steps/fortifyExecuteScan/#dockerenvvars","text":"Jenkins-specific: Used for proper environment setup. Environment variables to set in the container, e.g. [http_proxy: \"proxy:8080\"]. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerEnvVars"},{"location":"steps/fortifyExecuteScan/#dockerimage","text":"Jenkins-specific: Used for proper environment setup. Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerImage"},{"location":"steps/fortifyExecuteScan/#dockername","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Name of the container launching dockerImage. SideCar only: Name of the container in local network. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerName"},{"location":"steps/fortifyExecuteScan/#dockeroptions","text":"Jenkins-specific: Used for proper environment setup. Docker options to be set when starting the container. back to overview Scope Details Aliases - Type []string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerOptions"},{"location":"steps/fortifyExecuteScan/#dockerpullimage","text":"Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerPullImage"},{"location":"steps/fortifyExecuteScan/#dockervolumebind","text":"Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the docker container. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerVolumeBind"},{"location":"steps/fortifyExecuteScan/#dockerworkspace","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerWorkspace"},{"location":"steps/fortifyExecuteScan/#exclude","text":"A list of directories/files to be excluded from the scan. Wildcards can be used, e.g., '**/Test.java' . If translate is set, this will ignored. back to overview Scope Details Aliases - Type []string Mandatory no Default $PIPER_exclude (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"exclude"},{"location":"steps/fortifyExecuteScan/#filtersettitle","text":"Title of the filter set to use for analysing the results back to overview Scope Details Aliases - Type string Mandatory no Default SAP Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"filterSetTitle"},{"location":"steps/fortifyExecuteScan/#fortifycredentialsid","text":"Jenkins-specific: Used for proper environment setup. Jenkins 'Secret text' credentials ID containing token to authenticate to Fortify SSC. back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"fortifyCredentialsId"},{"location":"steps/fortifyExecuteScan/#fprdownloadendpoint","text":"Fortify SSC endpoint for FPR downloads back to overview Scope Details Aliases fortifyFprDownloadEndpoint Type string Mandatory no Default /download/currentStateFprDownload.html Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"fprDownloadEndpoint"},{"location":"steps/fortifyExecuteScan/#fpruploadendpoint","text":"Fortify SSC endpoint for FPR uploads back to overview Scope Details Aliases fortifyFprUploadEndpoint Type string Mandatory no Default /upload/resultFileUpload.html Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"fprUploadEndpoint"},{"location":"steps/fortifyExecuteScan/#githubapiurl","text":"Set the GitHub API URL. back to overview Scope Details Aliases - Type string Mandatory no Default https://api.github.com Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"githubApiUrl"},{"location":"steps/fortifyExecuteScan/#githubtoken","text":"GitHub personal access token as per https://help.github.com/en/github/authenticating-to-github/creating-a-personal-access-token-for-the-command-line back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_githubToken (if set) Secret yes Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"githubToken"},{"location":"steps/fortifyExecuteScan/#githubtokencredentialsid","text":"Jenkins-specific: Used for proper environment setup. Jenkins 'Secret text' credentials ID containing token to authenticate to GitHub. back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"githubTokenCredentialsId"},{"location":"steps/fortifyExecuteScan/#globalsettingsfile","text":"Path to the mvn settings file that should be used as global settings file. back to overview Scope Details Aliases maven/globalSettingsFile Type string Mandatory no Default $PIPER_globalSettingsFile (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"globalSettingsFile"},{"location":"steps/fortifyExecuteScan/#m2path","text":"Path to the location of the local repository that should be used. back to overview Scope Details Aliases maven/m2Path Type string Mandatory no Default $PIPER_m2Path (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"m2Path"},{"location":"steps/fortifyExecuteScan/#memory","text":"The amount of memory granted to the translate/scan executions back to overview Scope Details Aliases - Type string Mandatory no Default -Xmx4G -Xms512M Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"memory"},{"location":"steps/fortifyExecuteScan/#modulepath","text":"Allows providing the path for the module to scan back to overview Scope Details Aliases - Type string Mandatory no Default ./ Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"modulePath"},{"location":"steps/fortifyExecuteScan/#mustauditissuegroups","text":"Comma separated list of issue groups that must be audited completely back to overview Scope Details Aliases - Type string Mandatory no Default Corporate Security Requirements, Audit All Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"mustAuditIssueGroups"},{"location":"steps/fortifyExecuteScan/#owner","text":"Set the GitHub organization. back to overview Scope Details Aliases githubOrg Type string Mandatory no Default $PIPER_owner (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references commonPipelineEnvironment : reference to: github/owner","title":"owner"},{"location":"steps/fortifyExecuteScan/#pollingminutes","text":"The number of minutes for which an uploaded FPR artifact''s status is being polled to finish queuing/processing, if exceeded polling will be stopped and an error will be thrown back to overview Scope Details Aliases - Type int Mandatory no Default 30 Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"pollingMinutes"},{"location":"steps/fortifyExecuteScan/#projectname","text":"The project used for reporting results in SSC back to overview Scope Details Aliases fortifyProjectName Type string Mandatory no Default {{list .GroupID .ArtifactID | join \"-\" | trimAll \"-\"}} Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"projectName"},{"location":"steps/fortifyExecuteScan/#projectsettingsfile","text":"Path to the mvn settings file that should be used as project settings file. back to overview Scope Details Aliases maven/projectSettingsFile Type string Mandatory no Default $PIPER_projectSettingsFile (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"projectSettingsFile"},{"location":"steps/fortifyExecuteScan/#pullrequestmessageregex","text":"Regex used to identify the PR-XXX reference within the merge commit message back to overview Scope Details Aliases - Type string Mandatory no Default .*Merge pull request #(\\\\d+) from.* Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"pullRequestMessageRegex"},{"location":"steps/fortifyExecuteScan/#pullrequestmessageregexgroup","text":"The group number for extracting the pull request id in 'pullRequestMessageRegex' back to overview Scope Details Aliases - Type int Mandatory no Default 1 Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"pullRequestMessageRegexGroup"},{"location":"steps/fortifyExecuteScan/#pullrequestname","text":"The name of the pull request branch which will trigger creation of a new version in Fortify SSC based on the master branch version back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_pullRequestName (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"pullRequestName"},{"location":"steps/fortifyExecuteScan/#pythonadditionalpath","text":"A list of additional paths which can be used in buildTool: 'pip' for customization purposes back to overview Scope Details Aliases - Type []string Mandatory no Default - ./lib - . Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"pythonAdditionalPath"},{"location":"steps/fortifyExecuteScan/#pythoninstallcommand","text":"Additional install command that can be run when buildTool: 'pip' is used which allows further customizing the execution environment of the scan back to overview Scope Details Aliases - Type string Mandatory no Default {{.Pip}} install --user . Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"pythonInstallCommand"},{"location":"steps/fortifyExecuteScan/#pythonrequirementsfile","text":"The requirements file used in buildTool: 'pip' to populate the build environment with the necessary dependencies back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_pythonRequirementsFile (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"pythonRequirementsFile"},{"location":"steps/fortifyExecuteScan/#pythonrequirementsinstallsuffix","text":"The suffix for the command used to install the requirements file in buildTool: 'pip' to populate the build environment with the necessary dependencies back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_pythonRequirementsInstallSuffix (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"pythonRequirementsInstallSuffix"},{"location":"steps/fortifyExecuteScan/#pythonversion","text":"Python version to be used in buildTool: 'pip' back to overview Scope Details Aliases - Type string Mandatory no Default python3 Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"pythonVersion"},{"location":"steps/fortifyExecuteScan/#quickscan","text":"Whether a quick scan should be performed, please consult the related Fortify documentation on JAM on the impact of this setting back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"quickScan"},{"location":"steps/fortifyExecuteScan/#reportdownloadendpoint","text":"Fortify SSC endpoint for Report downloads back to overview Scope Details Aliases fortifyReportDownloadEndpoint Type string Mandatory no Default /transfer/reportDownload.html Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"reportDownloadEndpoint"},{"location":"steps/fortifyExecuteScan/#reporttemplateid","text":"Report template ID to be used for generating the Fortify report back to overview Scope Details Aliases - Type int Mandatory no Default 18 Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"reportTemplateId"},{"location":"steps/fortifyExecuteScan/#reporttype","text":"The type of report to be generated back to overview Scope Details Aliases - Type string Mandatory no Default PDF Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"reportType"},{"location":"steps/fortifyExecuteScan/#reporting","text":"Influences whether a report is generated or not back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"reporting"},{"location":"steps/fortifyExecuteScan/#repository","text":"Set the GitHub repository. back to overview Scope Details Aliases githubRepo Type string Mandatory no Default $PIPER_repository (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references commonPipelineEnvironment : reference to: github/repository","title":"repository"},{"location":"steps/fortifyExecuteScan/#script","text":"Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none","title":"script"},{"location":"steps/fortifyExecuteScan/#serverurl","text":"Fortify SSC Url to be used for accessing the APIs back to overview Scope Details Aliases - fortifyServerUrl - sscUrl ( deprecated ) Type string Mandatory yes Default $PIPER_serverUrl (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"serverUrl"},{"location":"steps/fortifyExecuteScan/#spotauditissuegroups","text":"Comma separated list of issue groups that are spot checked and for which spotCheckMinimum audited issues are enforced back to overview Scope Details Aliases - Type string Mandatory no Default Spot Checks of Each Category Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"spotAuditIssueGroups"},{"location":"steps/fortifyExecuteScan/#spotcheckminimum","text":"The minimum number of issues that must be audited per category in the Spot Checks of each Category folder to avoid an error being thrown back to overview Scope Details Aliases - Type int Mandatory no Default 1 Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"spotCheckMinimum"},{"location":"steps/fortifyExecuteScan/#src","text":"A list of source directories to scan. Wildcards can be used, e.g., 'src/main/java/**/*' . If 'translate' is set, this will ignored. The default value for buildTool: 'maven' is [' /*.xml', ' / .html', ' /*.jsp', ' / .js', ' /src/main/resources/ / ', ' /src/main/java/ / '], for buildTool: 'pip' it is ['./* / ']. back to overview Scope Details Aliases - Type []string Mandatory no Default $PIPER_src (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"src"},{"location":"steps/fortifyExecuteScan/#stashcontent","text":"Jenkins-specific: Used for proper environment setup. Specific stashes that should be considered for the step execution. back to overview Scope Details Aliases - Type []string Mandatory no Default - buildDescriptor - deployDescriptor - tests - opensourceConfiguration Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"stashContent"},{"location":"steps/fortifyExecuteScan/#translate","text":"Options for translate phase of Fortify. Most likely, you do not need to set this parameter. See src, exclude. If 'src' and 'exclude' are set they are automatically used. Technical details: It has to be a JSON string of list of maps with required key 'src' , and optional keys 'exclude' , 'libDirs' , 'aspnetcore' , and 'dotNetCoreVersion' back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_translate (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"translate"},{"location":"steps/fortifyExecuteScan/#updaterulepack","text":"Whether the rule pack shall be updated and pulled from Fortify SSC before scanning or not back to overview Scope Details Aliases - Type bool Mandatory no Default true Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"updateRulePack"},{"location":"steps/fortifyExecuteScan/#uploadresults","text":"Whether results shall be uploaded or not back to overview Scope Details Aliases - Type bool Mandatory no Default true Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"uploadResults"},{"location":"steps/fortifyExecuteScan/#verbose","text":"verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"verbose"},{"location":"steps/fortifyExecuteScan/#versioningmodel","text":"The default project versioning model used for creating the version based on the build descriptor version to report results in SSC, can be one of 'major' , 'major-minor' , 'semantic' , 'full' back to overview Scope Details Aliases defaultVersioningModel ( deprecated ) Type string Mandatory no Default major Possible values - major - major-minor - semantic - full Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"versioningModel"},{"location":"steps/gaugeExecuteTests/","text":"gaugeExecuteTests \u00b6 Description \u00b6 In this step Gauge ( getgauge.io ) acceptance tests are executed. Using Gauge it will be possible to have a three-tier test layout: Acceptance Criteria Test implemenation layer Application driver layer This layout is propagated by Jez Humble and Dave Farley in their book \"Continuous Delivery\" as a way to create maintainable acceptance test suites (see \"Continuous Delivery\", p. 190ff). Using Gauge it is possible to write test specifications in Markdown syntax and therefore allow e.g. product owners to write the relevant acceptance test specifications. At the same time it allows the developer to implement the steps described in the specification in her development environment. You can use the sample projects of Gauge. Make sure to run against a Selenium Hub configuration In the test example of gauge-archetype-selenium please make sure to allow it to run against a Selenium hub: Please extend DriverFactory.java for example in following way: String hubUrl = System . getenv ( \"HUB_URL\" ); //when running on a Docker deamon (and not using Kubernetes plugin), Docker images will be linked //in this case hubUrl will be http://selenium:4444/wd/hub due to the linking of the containers hubUrl = ( hubUrl == null ) ? \"http://localhost:4444/wd/hub\" : hubUrl ; Capabilities chromeCapabilities = DesiredCapabilities . chrome (); System . out . println ( \"Running on Selenium Hub: \" + hubUrl ); return new RemoteWebDriver ( new URL ( hubUrl ), chromeCapabilities ); Prerequisites \u00b6 none Parameters \u00b6 name mandatory default possible values buildTool no maven maven , npm , bundler dockerEnvVars no buildTool= maven : <empty> buildTool= npm : <empty> buildTool= bundler : <empty> dockerImage no buildTool= maven : maven:3.5-jdk-8 buildTool= npm : node:lts-stretch buildTool= bundler : ruby:2.5.3-stretch dockerName no buildTool= maven : maven buildTool= npm : npm buildTool= bundler : bundler dockerOptions no buildTool= maven : <empty> buildTool= npm : <empty> buildTool= bundler : <empty> dockerWorkspace no buildTool= maven : <empty> buildTool= npm : /home/node buildTool= bundler : <empty> failOnError no false true , false gitBranch no gitSshKeyCredentialsId no `` installCommand no curl -SsL https://downloads.gauge.org/stable | sh -s -- --location=$HOME/bin/gauge languageRunner no buildTool= maven : java buildTool= npm : js buildTool= bundler : ruby runCommand no buildTool= maven : mvn test-compile gauge:execute buildTool= npm : gauge run buildTool= bundler : bundle install && bundle exec gauge run script yes stashContent no [buildDescriptor, tests] testOptions no buildTool= maven : -DspecsDir=specs buildTool= npm : specs buildTool= bundler : specs testRepository no testServerUrl no buildTool - Defines the build tool to be used for the test execution. dockerEnvVars - Environment variables to set in the container, e.g. [http_proxy: 'proxy:8080']. dockerImage - Name of the docker image that should be used. Configure with empty value to execute the command directly on the Jenkins system (not using a container). Omit to use the default image (cf. default_pipeline_environment.yml ) Overwrite to use custom Docker image. dockerName - Kubernetes only: Name of the container launching dockerImage . SideCar only: Name of the container in local network. dockerOptions - Docker only: Docker options to be set when starting the container (List or String). dockerWorkspace - Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . failOnError - Defines the behavior in case tests fail. When this is set to true test results cannot be recorded using the publishTestResults step afterwards. gitBranch - Defines the branch containing the tests, in case the test implementation is stored in a different repository and a different branch than master. gitSshKeyCredentialsId - Defines the credentials for the repository containing the tests, in case the test implementation is stored in a different and protected repository than the code itself. For protected repositories the testRepository needs to contain the ssh git url. installCommand - Defines the command for installing Gauge. In case the dockerImage already contains Gauge it can be set to empty: ``. languageRunner - Defines the Gauge language runner to be used. runCommand - Defines the command which is used for executing Gauge. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. stashContent - Defines if specific stashes should be considered for the tests. testOptions - Allows to set specific options for the Gauge execution. Details can be found for example in the Gauge Maven plugin documentation testRepository - Defines the repository containing the tests, in case the test implementation is stored in a different repository than the code itself. testServerUrl - It is passed as environment variable TARGET_SERVER_URL to the test execution. Tests running against the system should read the host information from this environment variable in order to be infrastructure agnostic. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage buildTool X dockerEnvVars X dockerImage X dockerName X dockerOptions X dockerWorkspace X failOnError X gitBranch X gitSshKeyCredentialsId X installCommand X languageRunner X runCommand X script stashContent X testOptions X testRepository X testServerUrl X We recommend to define values of step parameters via config.yml file . Dependencies \u00b6 The step depends on the following Jenkins plugins credentials-binding git pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Example \u00b6 Pipeline step: gaugeExecuteTests script: this , testServerUrl: 'http://test.url'","title":"gaugeExecuteTests"},{"location":"steps/gaugeExecuteTests/#gaugeexecutetests","text":"","title":"gaugeExecuteTests"},{"location":"steps/gaugeExecuteTests/#description","text":"In this step Gauge ( getgauge.io ) acceptance tests are executed. Using Gauge it will be possible to have a three-tier test layout: Acceptance Criteria Test implemenation layer Application driver layer This layout is propagated by Jez Humble and Dave Farley in their book \"Continuous Delivery\" as a way to create maintainable acceptance test suites (see \"Continuous Delivery\", p. 190ff). Using Gauge it is possible to write test specifications in Markdown syntax and therefore allow e.g. product owners to write the relevant acceptance test specifications. At the same time it allows the developer to implement the steps described in the specification in her development environment. You can use the sample projects of Gauge. Make sure to run against a Selenium Hub configuration In the test example of gauge-archetype-selenium please make sure to allow it to run against a Selenium hub: Please extend DriverFactory.java for example in following way: String hubUrl = System . getenv ( \"HUB_URL\" ); //when running on a Docker deamon (and not using Kubernetes plugin), Docker images will be linked //in this case hubUrl will be http://selenium:4444/wd/hub due to the linking of the containers hubUrl = ( hubUrl == null ) ? \"http://localhost:4444/wd/hub\" : hubUrl ; Capabilities chromeCapabilities = DesiredCapabilities . chrome (); System . out . println ( \"Running on Selenium Hub: \" + hubUrl ); return new RemoteWebDriver ( new URL ( hubUrl ), chromeCapabilities );","title":"Description"},{"location":"steps/gaugeExecuteTests/#prerequisites","text":"none","title":"Prerequisites"},{"location":"steps/gaugeExecuteTests/#parameters","text":"name mandatory default possible values buildTool no maven maven , npm , bundler dockerEnvVars no buildTool= maven : <empty> buildTool= npm : <empty> buildTool= bundler : <empty> dockerImage no buildTool= maven : maven:3.5-jdk-8 buildTool= npm : node:lts-stretch buildTool= bundler : ruby:2.5.3-stretch dockerName no buildTool= maven : maven buildTool= npm : npm buildTool= bundler : bundler dockerOptions no buildTool= maven : <empty> buildTool= npm : <empty> buildTool= bundler : <empty> dockerWorkspace no buildTool= maven : <empty> buildTool= npm : /home/node buildTool= bundler : <empty> failOnError no false true , false gitBranch no gitSshKeyCredentialsId no `` installCommand no curl -SsL https://downloads.gauge.org/stable | sh -s -- --location=$HOME/bin/gauge languageRunner no buildTool= maven : java buildTool= npm : js buildTool= bundler : ruby runCommand no buildTool= maven : mvn test-compile gauge:execute buildTool= npm : gauge run buildTool= bundler : bundle install && bundle exec gauge run script yes stashContent no [buildDescriptor, tests] testOptions no buildTool= maven : -DspecsDir=specs buildTool= npm : specs buildTool= bundler : specs testRepository no testServerUrl no buildTool - Defines the build tool to be used for the test execution. dockerEnvVars - Environment variables to set in the container, e.g. [http_proxy: 'proxy:8080']. dockerImage - Name of the docker image that should be used. Configure with empty value to execute the command directly on the Jenkins system (not using a container). Omit to use the default image (cf. default_pipeline_environment.yml ) Overwrite to use custom Docker image. dockerName - Kubernetes only: Name of the container launching dockerImage . SideCar only: Name of the container in local network. dockerOptions - Docker only: Docker options to be set when starting the container (List or String). dockerWorkspace - Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . failOnError - Defines the behavior in case tests fail. When this is set to true test results cannot be recorded using the publishTestResults step afterwards. gitBranch - Defines the branch containing the tests, in case the test implementation is stored in a different repository and a different branch than master. gitSshKeyCredentialsId - Defines the credentials for the repository containing the tests, in case the test implementation is stored in a different and protected repository than the code itself. For protected repositories the testRepository needs to contain the ssh git url. installCommand - Defines the command for installing Gauge. In case the dockerImage already contains Gauge it can be set to empty: ``. languageRunner - Defines the Gauge language runner to be used. runCommand - Defines the command which is used for executing Gauge. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. stashContent - Defines if specific stashes should be considered for the tests. testOptions - Allows to set specific options for the Gauge execution. Details can be found for example in the Gauge Maven plugin documentation testRepository - Defines the repository containing the tests, in case the test implementation is stored in a different repository than the code itself. testServerUrl - It is passed as environment variable TARGET_SERVER_URL to the test execution. Tests running against the system should read the host information from this environment variable in order to be infrastructure agnostic.","title":"Parameters"},{"location":"steps/gaugeExecuteTests/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage buildTool X dockerEnvVars X dockerImage X dockerName X dockerOptions X dockerWorkspace X failOnError X gitBranch X gitSshKeyCredentialsId X installCommand X languageRunner X runCommand X script stashContent X testOptions X testRepository X testServerUrl X We recommend to define values of step parameters via config.yml file .","title":"Step configuration"},{"location":"steps/gaugeExecuteTests/#dependencies","text":"The step depends on the following Jenkins plugins credentials-binding git pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/gaugeExecuteTests/#example","text":"Pipeline step: gaugeExecuteTests script: this , testServerUrl: 'http://test.url'","title":"Example"},{"location":"steps/gctsCloneRepository/","text":"gctsCloneRepository \u00b6 Clones a Git repository Description \u00b6 Clones a Git repository from a remote repository to a local repository on an ABAP system. To be able to execute this step, the corresponding local repository has to exist on the local ABAP system. Usage \u00b6 We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line . Jenkins pipelines \u00b6 gctsCloneRepository script: this Command line \u00b6 piper gctsCloneRepository Prerequisites \u00b6 With this step you can clone a remote Git repository to a local repository on an ABAP server. To be able to execute this step, the corresponding local repository has to exist on the local ABAP system. Learn more about the SAP Git-enabled Change & Transport Sytem (gCTS) here . With gCTS, ABAP developments on ABAP servers can be maintained in Git repositories. Parameters \u00b6 Overview \u00b6 Name Mandatory Additional information abapCredentialsId yes id of credentials ( using credentials ) client yes host yes password yes pass via ENV or Jenkins credentials repository yes script yes reference to Jenkins main pipeline script username yes pass via ENV or Jenkins credentials verbose no activates debug output Details \u00b6 abapCredentialsId \u00b6 Jenkins-specific: Used for proper environment setup. Jenkins credentials ID containing username and password for authentication to the ABAP system on which you want to clone the repository back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none client \u00b6 Specifies the client of the ABAP system to be adressed back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_client (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none host \u00b6 Specifies the protocol and host adress, including the port. Please provide in the format <protocol>://<host>:<port> . Supported protocols are http and https . back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_host (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none password \u00b6 Password to authenticate to the ABAP system back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_password (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none repository \u00b6 Specifies the name (ID) of the local repsitory on the ABAP system back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_repository (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none script \u00b6 Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none username \u00b6 User to authenticate to the ABAP system back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_username (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none verbose \u00b6 verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none \u00b6 Example \u00b6 Example configuration for the use in a Jenkinsfile . gctsCloneRepository ( script: this , host: 'https://abap.server.com:port' , client: '000' , abapCredentialsId: 'ABAPUserPasswordCredentialsId' , repository: 'myrepo' ) Example for the use in a YAML configuration file (such as .pipeline/config.yaml ). steps : <...> gctsCloneRepository : host : 'https://abap.server.com:port' client : '000' abapCredentialsId : 'ABAPUserPasswordCredentialsId' repository : 'myrepo'","title":"gctsCloneRepository"},{"location":"steps/gctsCloneRepository/#gctsclonerepository","text":"Clones a Git repository","title":"gctsCloneRepository"},{"location":"steps/gctsCloneRepository/#description","text":"Clones a Git repository from a remote repository to a local repository on an ABAP system. To be able to execute this step, the corresponding local repository has to exist on the local ABAP system.","title":"Description"},{"location":"steps/gctsCloneRepository/#usage","text":"We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line .","title":"Usage"},{"location":"steps/gctsCloneRepository/#jenkins-pipelines","text":"gctsCloneRepository script: this","title":"Jenkins pipelines"},{"location":"steps/gctsCloneRepository/#command-line","text":"piper gctsCloneRepository","title":"Command line"},{"location":"steps/gctsCloneRepository/#prerequisites","text":"With this step you can clone a remote Git repository to a local repository on an ABAP server. To be able to execute this step, the corresponding local repository has to exist on the local ABAP system. Learn more about the SAP Git-enabled Change & Transport Sytem (gCTS) here . With gCTS, ABAP developments on ABAP servers can be maintained in Git repositories.","title":"Prerequisites"},{"location":"steps/gctsCloneRepository/#parameters","text":"","title":"Parameters"},{"location":"steps/gctsCloneRepository/#overview","text":"Name Mandatory Additional information abapCredentialsId yes id of credentials ( using credentials ) client yes host yes password yes pass via ENV or Jenkins credentials repository yes script yes reference to Jenkins main pipeline script username yes pass via ENV or Jenkins credentials verbose no activates debug output","title":"Overview"},{"location":"steps/gctsCloneRepository/#details","text":"","title":"Details"},{"location":"steps/gctsCloneRepository/#abapcredentialsid","text":"Jenkins-specific: Used for proper environment setup. Jenkins credentials ID containing username and password for authentication to the ABAP system on which you want to clone the repository back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"abapCredentialsId"},{"location":"steps/gctsCloneRepository/#client","text":"Specifies the client of the ABAP system to be adressed back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_client (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"client"},{"location":"steps/gctsCloneRepository/#host","text":"Specifies the protocol and host adress, including the port. Please provide in the format <protocol>://<host>:<port> . Supported protocols are http and https . back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_host (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"host"},{"location":"steps/gctsCloneRepository/#password","text":"Password to authenticate to the ABAP system back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_password (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"password"},{"location":"steps/gctsCloneRepository/#repository","text":"Specifies the name (ID) of the local repsitory on the ABAP system back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_repository (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"repository"},{"location":"steps/gctsCloneRepository/#script","text":"Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none","title":"script"},{"location":"steps/gctsCloneRepository/#username","text":"User to authenticate to the ABAP system back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_username (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"username"},{"location":"steps/gctsCloneRepository/#verbose","text":"verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"verbose"},{"location":"steps/gctsCloneRepository/#example","text":"Example configuration for the use in a Jenkinsfile . gctsCloneRepository ( script: this , host: 'https://abap.server.com:port' , client: '000' , abapCredentialsId: 'ABAPUserPasswordCredentialsId' , repository: 'myrepo' ) Example for the use in a YAML configuration file (such as .pipeline/config.yaml ). steps : <...> gctsCloneRepository : host : 'https://abap.server.com:port' client : '000' abapCredentialsId : 'ABAPUserPasswordCredentialsId' repository : 'myrepo'","title":"Example"},{"location":"steps/gctsCreateRepository/","text":"gctsCreateRepository \u00b6 Creates a Git repository on an ABAP system Description \u00b6 Creates a local Git repository on an ABAP system if it does not already exist. Usage \u00b6 We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line . Jenkins pipelines \u00b6 gctsCreateRepository script: this Command line \u00b6 piper gctsCreateRepository Prerequisites \u00b6 With this step you can create a local git-enabled CTS (gCTS) repository on an ABAP server. Learn more about the SAP Git-enabled Change & Transport Sytem (gCTS) here . With gCTS, ABAP developments on ABAP servers can be maintained in Git repositories. Parameters \u00b6 Overview \u00b6 Name Mandatory Additional information abapCredentialsId yes id of credentials ( using credentials ) client yes host yes password yes pass via ENV or Jenkins credentials repository yes script yes reference to Jenkins main pipeline script username yes pass via ENV or Jenkins credentials remoteRepositoryURL no role no type no vSID no verbose no activates debug output Details \u00b6 abapCredentialsId \u00b6 Jenkins-specific: Used for proper environment setup. Jenkins credentials ID containing username and password for authentication to the ABAP system on which you want to create the repository back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none client \u00b6 Specifies the client of the ABAP system to be adressed back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_client (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none host \u00b6 Specifies the protocol and host adress, including the port. Please provide in the format <protocol>://<host>:<port> . Supported protocols are http and https . back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_host (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none password \u00b6 Password to authenticate to the ABAP system back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_password (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none remoteRepositoryURL \u00b6 URL of the corresponding remote repository back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_remoteRepositoryURL (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none repository \u00b6 Specifies the name (ID) of the local repository on the ABAP system back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_repository (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none role \u00b6 Role of the local repository. Choose between 'TARGET' and 'SOURCE'. Local repositories with a TARGET role will NOT be able to be the source of code changes back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_role (if set) Possible values - SOURCE - TARGET Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none script \u00b6 Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none type \u00b6 Type of the used source code management tool back to overview Scope Details Aliases - Type string Mandatory no Default GIT Possible values - GIT Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none username \u00b6 Username to authenticate to the ABAP system back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_username (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none vSID \u00b6 Virtual SID of the local repository. The vSID corresponds to the transport route that delivers content to the remote Git repository back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_vSID (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none verbose \u00b6 verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none \u00b6 Example \u00b6 Example configuration for the use in a Jenkinsfile . gctsCreateRepository ( script: this , host: 'https://abap.server.com:port' , client: '000' , abapCredentialsId: 'ABAPUserPasswordCredentialsId' , repository: 'myrepo' , remoteRepositoryURL: 'https://github.com/user/myrepo' , role: 'SOURCE' , vSID: 'ABC' ) Example for the use in a YAML configuration file (such as .pipeline/config.yaml ). steps : <...> gctsCreateRepository : host : 'https://abap.server.com:port' client : '000' abapCredentialsId : 'ABAPUserPasswordCredentialsId' repository : 'myrepo' remoteRepositoryURL : 'https://github.com/user/myrepo' role : 'SOURCE' vSID : 'ABC'","title":"gctsCreateRepository"},{"location":"steps/gctsCreateRepository/#gctscreaterepository","text":"Creates a Git repository on an ABAP system","title":"gctsCreateRepository"},{"location":"steps/gctsCreateRepository/#description","text":"Creates a local Git repository on an ABAP system if it does not already exist.","title":"Description"},{"location":"steps/gctsCreateRepository/#usage","text":"We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line .","title":"Usage"},{"location":"steps/gctsCreateRepository/#jenkins-pipelines","text":"gctsCreateRepository script: this","title":"Jenkins pipelines"},{"location":"steps/gctsCreateRepository/#command-line","text":"piper gctsCreateRepository","title":"Command line"},{"location":"steps/gctsCreateRepository/#prerequisites","text":"With this step you can create a local git-enabled CTS (gCTS) repository on an ABAP server. Learn more about the SAP Git-enabled Change & Transport Sytem (gCTS) here . With gCTS, ABAP developments on ABAP servers can be maintained in Git repositories.","title":"Prerequisites"},{"location":"steps/gctsCreateRepository/#parameters","text":"","title":"Parameters"},{"location":"steps/gctsCreateRepository/#overview","text":"Name Mandatory Additional information abapCredentialsId yes id of credentials ( using credentials ) client yes host yes password yes pass via ENV or Jenkins credentials repository yes script yes reference to Jenkins main pipeline script username yes pass via ENV or Jenkins credentials remoteRepositoryURL no role no type no vSID no verbose no activates debug output","title":"Overview"},{"location":"steps/gctsCreateRepository/#details","text":"","title":"Details"},{"location":"steps/gctsCreateRepository/#abapcredentialsid","text":"Jenkins-specific: Used for proper environment setup. Jenkins credentials ID containing username and password for authentication to the ABAP system on which you want to create the repository back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"abapCredentialsId"},{"location":"steps/gctsCreateRepository/#client","text":"Specifies the client of the ABAP system to be adressed back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_client (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"client"},{"location":"steps/gctsCreateRepository/#host","text":"Specifies the protocol and host adress, including the port. Please provide in the format <protocol>://<host>:<port> . Supported protocols are http and https . back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_host (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"host"},{"location":"steps/gctsCreateRepository/#password","text":"Password to authenticate to the ABAP system back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_password (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"password"},{"location":"steps/gctsCreateRepository/#remoterepositoryurl","text":"URL of the corresponding remote repository back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_remoteRepositoryURL (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"remoteRepositoryURL"},{"location":"steps/gctsCreateRepository/#repository","text":"Specifies the name (ID) of the local repository on the ABAP system back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_repository (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"repository"},{"location":"steps/gctsCreateRepository/#role","text":"Role of the local repository. Choose between 'TARGET' and 'SOURCE'. Local repositories with a TARGET role will NOT be able to be the source of code changes back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_role (if set) Possible values - SOURCE - TARGET Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"role"},{"location":"steps/gctsCreateRepository/#script","text":"Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none","title":"script"},{"location":"steps/gctsCreateRepository/#type","text":"Type of the used source code management tool back to overview Scope Details Aliases - Type string Mandatory no Default GIT Possible values - GIT Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"type"},{"location":"steps/gctsCreateRepository/#username","text":"Username to authenticate to the ABAP system back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_username (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"username"},{"location":"steps/gctsCreateRepository/#vsid","text":"Virtual SID of the local repository. The vSID corresponds to the transport route that delivers content to the remote Git repository back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_vSID (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"vSID"},{"location":"steps/gctsCreateRepository/#verbose","text":"verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"verbose"},{"location":"steps/gctsCreateRepository/#example","text":"Example configuration for the use in a Jenkinsfile . gctsCreateRepository ( script: this , host: 'https://abap.server.com:port' , client: '000' , abapCredentialsId: 'ABAPUserPasswordCredentialsId' , repository: 'myrepo' , remoteRepositoryURL: 'https://github.com/user/myrepo' , role: 'SOURCE' , vSID: 'ABC' ) Example for the use in a YAML configuration file (such as .pipeline/config.yaml ). steps : <...> gctsCreateRepository : host : 'https://abap.server.com:port' client : '000' abapCredentialsId : 'ABAPUserPasswordCredentialsId' repository : 'myrepo' remoteRepositoryURL : 'https://github.com/user/myrepo' role : 'SOURCE' vSID : 'ABC'","title":"Example"},{"location":"steps/gctsDeploy/","text":"gctsDeploy \u00b6 Pulls a commit from the remote Git repository to a local repository Description \u00b6 Pulls a commit from the corresponding remote Git repository to a specified local repository on an ABAP system. If no parameter is specified, this step will pull the latest commit available on the remote repository. Usage \u00b6 We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line . Jenkins pipelines \u00b6 gctsDeploy script: this Command line \u00b6 piper gctsDeploy Prerequisites \u00b6 With this step you can deploy a commit from a remote Git repository to a local repository on an ABAP server. If no commit parameter is specified, this step will pull the latest commit available on the remote repository. Learn more about the SAP Git-enabled Change & Transport Sytem (gCTS) here . With gCTS, ABAP developments on ABAP servers can be maintained in Git repositories. Parameters \u00b6 Overview \u00b6 Name Mandatory Additional information abapCredentialsId yes id of credentials ( using credentials ) client yes host yes password yes pass via ENV or Jenkins credentials repository yes script yes reference to Jenkins main pipeline script username yes pass via ENV or Jenkins credentials commit no verbose no activates debug output Details \u00b6 abapCredentialsId \u00b6 Jenkins-specific: Used for proper environment setup. Jenkins credentials ID containing username and password for authentication to the ABAP system on which you want to deploy a commit back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none client \u00b6 Specifies the client of the ABAP system to be adressed back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_client (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none commit \u00b6 Specifies the commit to be deployed back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_commit (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none host \u00b6 Specifies the protocol and host adress, including the port. Please provide in the format <protocol>://<host>:<port> . Supported protocols are http and https . back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_host (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none password \u00b6 Password to authenticate to the ABAP system back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_password (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none repository \u00b6 Specifies the name (ID) of the local repsitory on the ABAP system back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_repository (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none script \u00b6 Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none username \u00b6 User to authenticate to the ABAP system back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_username (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none verbose \u00b6 verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none \u00b6 Example \u00b6 Example configuration for the use in a Jenkinsfile . gctsDeploy ( script: this , host: 'https://abap.server.com:port' , client: '000' , abapCredentialsId: 'ABAPUserPasswordCredentialsId' , repository: 'myrepo' ) Example for the use in a YAML configuration file (such as .pipeline/config.yaml ). steps : <...> gctsDeploy : host : 'https://abap.server.com:port' client : '000' abapCredentialsId : 'ABAPUserPasswordCredentialsId' repository : 'myrepo'","title":"gctsDeploy"},{"location":"steps/gctsDeploy/#gctsdeploy","text":"Pulls a commit from the remote Git repository to a local repository","title":"gctsDeploy"},{"location":"steps/gctsDeploy/#description","text":"Pulls a commit from the corresponding remote Git repository to a specified local repository on an ABAP system. If no parameter is specified, this step will pull the latest commit available on the remote repository.","title":"Description"},{"location":"steps/gctsDeploy/#usage","text":"We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line .","title":"Usage"},{"location":"steps/gctsDeploy/#jenkins-pipelines","text":"gctsDeploy script: this","title":"Jenkins pipelines"},{"location":"steps/gctsDeploy/#command-line","text":"piper gctsDeploy","title":"Command line"},{"location":"steps/gctsDeploy/#prerequisites","text":"With this step you can deploy a commit from a remote Git repository to a local repository on an ABAP server. If no commit parameter is specified, this step will pull the latest commit available on the remote repository. Learn more about the SAP Git-enabled Change & Transport Sytem (gCTS) here . With gCTS, ABAP developments on ABAP servers can be maintained in Git repositories.","title":"Prerequisites"},{"location":"steps/gctsDeploy/#parameters","text":"","title":"Parameters"},{"location":"steps/gctsDeploy/#overview","text":"Name Mandatory Additional information abapCredentialsId yes id of credentials ( using credentials ) client yes host yes password yes pass via ENV or Jenkins credentials repository yes script yes reference to Jenkins main pipeline script username yes pass via ENV or Jenkins credentials commit no verbose no activates debug output","title":"Overview"},{"location":"steps/gctsDeploy/#details","text":"","title":"Details"},{"location":"steps/gctsDeploy/#abapcredentialsid","text":"Jenkins-specific: Used for proper environment setup. Jenkins credentials ID containing username and password for authentication to the ABAP system on which you want to deploy a commit back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"abapCredentialsId"},{"location":"steps/gctsDeploy/#client","text":"Specifies the client of the ABAP system to be adressed back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_client (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"client"},{"location":"steps/gctsDeploy/#commit","text":"Specifies the commit to be deployed back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_commit (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"commit"},{"location":"steps/gctsDeploy/#host","text":"Specifies the protocol and host adress, including the port. Please provide in the format <protocol>://<host>:<port> . Supported protocols are http and https . back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_host (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"host"},{"location":"steps/gctsDeploy/#password","text":"Password to authenticate to the ABAP system back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_password (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"password"},{"location":"steps/gctsDeploy/#repository","text":"Specifies the name (ID) of the local repsitory on the ABAP system back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_repository (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"repository"},{"location":"steps/gctsDeploy/#script","text":"Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none","title":"script"},{"location":"steps/gctsDeploy/#username","text":"User to authenticate to the ABAP system back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_username (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"username"},{"location":"steps/gctsDeploy/#verbose","text":"verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"verbose"},{"location":"steps/gctsDeploy/#example","text":"Example configuration for the use in a Jenkinsfile . gctsDeploy ( script: this , host: 'https://abap.server.com:port' , client: '000' , abapCredentialsId: 'ABAPUserPasswordCredentialsId' , repository: 'myrepo' ) Example for the use in a YAML configuration file (such as .pipeline/config.yaml ). steps : <...> gctsDeploy : host : 'https://abap.server.com:port' client : '000' abapCredentialsId : 'ABAPUserPasswordCredentialsId' repository : 'myrepo'","title":"Example"},{"location":"steps/gctsExecuteABAPUnitTests/","text":"gctsExecuteABAPUnitTests \u00b6 Runs ABAP unit tests for all packages of the specified repository Description \u00b6 This step will execute every unit test associated with a package belonging to the specified local repository on an ABAP system. Usage \u00b6 We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line . Jenkins pipelines \u00b6 gctsExecuteABAPUnitTests script: this Command line \u00b6 piper gctsExecuteABAPUnitTests Prerequisites \u00b6 You have gCTS installed and configured on your ABAP systems. Learn more about the SAP Git-enabled Change & Transport Sytem (gCTS) here . With gCTS, ABAP developments on ABAP servers can be maintained in Git repositories. Parameters \u00b6 Overview \u00b6 Name Mandatory Additional information abapCredentialsId yes id of credentials ( using credentials ) client yes host yes password yes pass via ENV or Jenkins credentials repository yes script yes reference to Jenkins main pipeline script username yes pass via ENV or Jenkins credentials verbose no activates debug output Details \u00b6 abapCredentialsId \u00b6 Jenkins-specific: Used for proper environment setup. Jenkins credentials ID containing username and password for authentication to the ABAP system on which you want to perform the unit tests back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none client \u00b6 Specifies the client of the ABAP system to be adressed back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_client (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none host \u00b6 Specifies the protocol and host adress, including the port. Please provide in the format <protocol>://<host>:<port> . Supported protocols are http and https . back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_host (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none password \u00b6 Password to authenticate to the ABAP system back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_password (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none repository \u00b6 Specifies the name (ID) of the local repsitory on the ABAP system back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_repository (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none script \u00b6 Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none username \u00b6 User to authenticate to the ABAP system back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_username (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none verbose \u00b6 verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none \u00b6 Example \u00b6 Example configuration for the use in a Jenkinsfile. gctsExecuteABAPUnitTests ( script: this , host: 'https://abap.server.com:port' , client: '000' , abapCredentialsId: 'ABAPUserPasswordCredentialsId' , repository: 'myrepo' ) Example configuration for the use in a yaml config file (such as .pipeline/config.yaml ). steps : <...> gctsExecuteABAPUnitTests : host : 'https://abap.server.com:port' client : '000' abapCredentialsId : 'ABAPUserPasswordCredentialsId' repository : 'myrepo'","title":"gctsExecuteABAPUnitTests"},{"location":"steps/gctsExecuteABAPUnitTests/#gctsexecuteabapunittests","text":"Runs ABAP unit tests for all packages of the specified repository","title":"gctsExecuteABAPUnitTests"},{"location":"steps/gctsExecuteABAPUnitTests/#description","text":"This step will execute every unit test associated with a package belonging to the specified local repository on an ABAP system.","title":"Description"},{"location":"steps/gctsExecuteABAPUnitTests/#usage","text":"We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line .","title":"Usage"},{"location":"steps/gctsExecuteABAPUnitTests/#jenkins-pipelines","text":"gctsExecuteABAPUnitTests script: this","title":"Jenkins pipelines"},{"location":"steps/gctsExecuteABAPUnitTests/#command-line","text":"piper gctsExecuteABAPUnitTests","title":"Command line"},{"location":"steps/gctsExecuteABAPUnitTests/#prerequisites","text":"You have gCTS installed and configured on your ABAP systems. Learn more about the SAP Git-enabled Change & Transport Sytem (gCTS) here . With gCTS, ABAP developments on ABAP servers can be maintained in Git repositories.","title":"Prerequisites"},{"location":"steps/gctsExecuteABAPUnitTests/#parameters","text":"","title":"Parameters"},{"location":"steps/gctsExecuteABAPUnitTests/#overview","text":"Name Mandatory Additional information abapCredentialsId yes id of credentials ( using credentials ) client yes host yes password yes pass via ENV or Jenkins credentials repository yes script yes reference to Jenkins main pipeline script username yes pass via ENV or Jenkins credentials verbose no activates debug output","title":"Overview"},{"location":"steps/gctsExecuteABAPUnitTests/#details","text":"","title":"Details"},{"location":"steps/gctsExecuteABAPUnitTests/#abapcredentialsid","text":"Jenkins-specific: Used for proper environment setup. Jenkins credentials ID containing username and password for authentication to the ABAP system on which you want to perform the unit tests back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"abapCredentialsId"},{"location":"steps/gctsExecuteABAPUnitTests/#client","text":"Specifies the client of the ABAP system to be adressed back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_client (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"client"},{"location":"steps/gctsExecuteABAPUnitTests/#host","text":"Specifies the protocol and host adress, including the port. Please provide in the format <protocol>://<host>:<port> . Supported protocols are http and https . back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_host (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"host"},{"location":"steps/gctsExecuteABAPUnitTests/#password","text":"Password to authenticate to the ABAP system back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_password (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"password"},{"location":"steps/gctsExecuteABAPUnitTests/#repository","text":"Specifies the name (ID) of the local repsitory on the ABAP system back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_repository (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"repository"},{"location":"steps/gctsExecuteABAPUnitTests/#script","text":"Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none","title":"script"},{"location":"steps/gctsExecuteABAPUnitTests/#username","text":"User to authenticate to the ABAP system back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_username (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"username"},{"location":"steps/gctsExecuteABAPUnitTests/#verbose","text":"verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"verbose"},{"location":"steps/gctsExecuteABAPUnitTests/#example","text":"Example configuration for the use in a Jenkinsfile. gctsExecuteABAPUnitTests ( script: this , host: 'https://abap.server.com:port' , client: '000' , abapCredentialsId: 'ABAPUserPasswordCredentialsId' , repository: 'myrepo' ) Example configuration for the use in a yaml config file (such as .pipeline/config.yaml ). steps : <...> gctsExecuteABAPUnitTests : host : 'https://abap.server.com:port' client : '000' abapCredentialsId : 'ABAPUserPasswordCredentialsId' repository : 'myrepo'","title":"Example"},{"location":"steps/gctsRollback/","text":"gctsRollback \u00b6 Perfoms roll back of one (default) or several commit(s) Description \u00b6 This step performs a rollback of commit(s) in a local ABAP system repository. If a parameter is specified, it will be used as the target commit for the rollback. If no parameter is specified and the remote repository domain is 'github.com', the last commit with status 'success' will be used for the rollback. Otherwise, gctsRollback will rollback to the previously active commit in the local repository. Usage \u00b6 We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line . Jenkins pipelines \u00b6 gctsRollback script: this Command line \u00b6 piper gctsRollback Prerequisites \u00b6 This step performs a rollback of commit(s) in a local ABAP system repository. If a commit parameter is specified, it will be used as the target commit for the rollback. If no commit parameter is specified and the remote repository domain is 'github.com', the last commit with status 'success' will be used for the rollback. Otherwise, gctsRollback will rollback to the previously active commit in the local repository. Learn more about the SAP git-enabled Central Transport Sytem (gCTS) here . With gCTS, ABAP developments on ABAP servers can be maintained in Git repositories. Parameters \u00b6 Overview \u00b6 Name Mandatory Additional information abapCredentialsId yes id of credentials ( using credentials ) client yes githubPersonalAccessTokenId yes id of credentials ( using credentials ) host yes password yes pass via ENV or Jenkins credentials repository yes script yes reference to Jenkins main pipeline script username yes pass via ENV or Jenkins credentials commit no githubPersonalAccessToken no pass via ENV or Jenkins credentials verbose no activates debug output Details \u00b6 abapCredentialsId \u00b6 Jenkins-specific: Used for proper environment setup. Jenkins credentials ID containing username and password for authentication to the ABAP system on which you want to perform the rollback back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none client \u00b6 Specifies the client of the ABAP system to be adressed back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_client (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none commit \u00b6 Specifies the commit to deploy back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_commit (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none githubPersonalAccessToken \u00b6 GitHub personal access token with at least read permissions for the remote repository back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_githubPersonalAccessToken (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none githubPersonalAccessTokenId \u00b6 Jenkins-specific: Used for proper environment setup. GitHub personal access token with at least read permissions for the remote repository back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none host \u00b6 Specifies the protocol and host adress, including the port. Please provide in the format ' :// : ' back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_host (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none password \u00b6 Password to authenticate to the ABAP system back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_password (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none repository \u00b6 Specifies the name (ID) of the local repsitory on the ABAP system back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_repository (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none script \u00b6 Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none username \u00b6 User to authenticate to the ABAP system back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_username (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none verbose \u00b6 verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none \u00b6 Example \u00b6 Example configuration for the use in a Jenkinsfile. gctsRollback ( script: this , host: \"https://abap.server.com:port\" , client: \"000\" , abapCredentialsId: 'ABAPUserPasswordCredentialsId' , repository: \"myrepo\" ) Example for the use in a YAML configuration file (such as .pipeline/config.yaml ). steps : <...> gctsRollback : host : \"https://abap.server.com:port\" client : \"000\" abapCredentialsId : 'ABAPUserPasswordCredentialsId' repository : \"myrepo\"","title":"gctsRollback"},{"location":"steps/gctsRollback/#gctsrollback","text":"Perfoms roll back of one (default) or several commit(s)","title":"gctsRollback"},{"location":"steps/gctsRollback/#description","text":"This step performs a rollback of commit(s) in a local ABAP system repository. If a parameter is specified, it will be used as the target commit for the rollback. If no parameter is specified and the remote repository domain is 'github.com', the last commit with status 'success' will be used for the rollback. Otherwise, gctsRollback will rollback to the previously active commit in the local repository.","title":"Description"},{"location":"steps/gctsRollback/#usage","text":"We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line .","title":"Usage"},{"location":"steps/gctsRollback/#jenkins-pipelines","text":"gctsRollback script: this","title":"Jenkins pipelines"},{"location":"steps/gctsRollback/#command-line","text":"piper gctsRollback","title":"Command line"},{"location":"steps/gctsRollback/#prerequisites","text":"This step performs a rollback of commit(s) in a local ABAP system repository. If a commit parameter is specified, it will be used as the target commit for the rollback. If no commit parameter is specified and the remote repository domain is 'github.com', the last commit with status 'success' will be used for the rollback. Otherwise, gctsRollback will rollback to the previously active commit in the local repository. Learn more about the SAP git-enabled Central Transport Sytem (gCTS) here . With gCTS, ABAP developments on ABAP servers can be maintained in Git repositories.","title":"Prerequisites"},{"location":"steps/gctsRollback/#parameters","text":"","title":"Parameters"},{"location":"steps/gctsRollback/#overview","text":"Name Mandatory Additional information abapCredentialsId yes id of credentials ( using credentials ) client yes githubPersonalAccessTokenId yes id of credentials ( using credentials ) host yes password yes pass via ENV or Jenkins credentials repository yes script yes reference to Jenkins main pipeline script username yes pass via ENV or Jenkins credentials commit no githubPersonalAccessToken no pass via ENV or Jenkins credentials verbose no activates debug output","title":"Overview"},{"location":"steps/gctsRollback/#details","text":"","title":"Details"},{"location":"steps/gctsRollback/#abapcredentialsid","text":"Jenkins-specific: Used for proper environment setup. Jenkins credentials ID containing username and password for authentication to the ABAP system on which you want to perform the rollback back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"abapCredentialsId"},{"location":"steps/gctsRollback/#client","text":"Specifies the client of the ABAP system to be adressed back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_client (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"client"},{"location":"steps/gctsRollback/#commit","text":"Specifies the commit to deploy back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_commit (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"commit"},{"location":"steps/gctsRollback/#githubpersonalaccesstoken","text":"GitHub personal access token with at least read permissions for the remote repository back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_githubPersonalAccessToken (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"githubPersonalAccessToken"},{"location":"steps/gctsRollback/#githubpersonalaccesstokenid","text":"Jenkins-specific: Used for proper environment setup. GitHub personal access token with at least read permissions for the remote repository back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"githubPersonalAccessTokenId"},{"location":"steps/gctsRollback/#host","text":"Specifies the protocol and host adress, including the port. Please provide in the format ' :// : ' back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_host (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"host"},{"location":"steps/gctsRollback/#password","text":"Password to authenticate to the ABAP system back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_password (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"password"},{"location":"steps/gctsRollback/#repository","text":"Specifies the name (ID) of the local repsitory on the ABAP system back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_repository (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"repository"},{"location":"steps/gctsRollback/#script","text":"Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none","title":"script"},{"location":"steps/gctsRollback/#username","text":"User to authenticate to the ABAP system back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_username (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"username"},{"location":"steps/gctsRollback/#verbose","text":"verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"verbose"},{"location":"steps/gctsRollback/#example","text":"Example configuration for the use in a Jenkinsfile. gctsRollback ( script: this , host: \"https://abap.server.com:port\" , client: \"000\" , abapCredentialsId: 'ABAPUserPasswordCredentialsId' , repository: \"myrepo\" ) Example for the use in a YAML configuration file (such as .pipeline/config.yaml ). steps : <...> gctsRollback : host : \"https://abap.server.com:port\" client : \"000\" abapCredentialsId : 'ABAPUserPasswordCredentialsId' repository : \"myrepo\"","title":"Example"},{"location":"steps/githubPublishRelease/","text":"githubPublishRelease \u00b6 Publish a release in GitHub Prerequisites \u00b6 You need to create a personal access token within GitHub and add this to the Jenkins credentials store. Please see GitHub documentation for details about creating the personal access token . Parameters \u00b6 Overview \u00b6 Name Mandatory Additional information apiUrl yes githubTokenCredentialsId yes id of credentials ( using credentials ) owner yes repository yes script yes reference to Jenkins main pipeline script serverUrl yes token yes pass via ENV or Jenkins credentials uploadUrl yes version yes addClosedIssues no addDeltaToLastRelease no assetPath no commitish no excludeLabels no labels no preRelease no releaseBodyHeader no verbose no activates debug output Details \u00b6 addClosedIssues \u00b6 If set to true , closed issues and merged pull-requests since the last release will added below the releaseBodyHeader back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none addDeltaToLastRelease \u00b6 If set to true , a link will be added to the relese information that brings up all commits since the last release. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none apiUrl \u00b6 Set the GitHub API url. back to overview Scope Details Aliases githubApiUrl Type string Mandatory no Default https://api.github.com Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none assetPath \u00b6 Path to a release asset which should be uploaded to the list of release assets. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_assetPath (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none commitish \u00b6 Target git commitish for the release back to overview Scope Details Aliases - Type string Mandatory no Default master Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none excludeLabels \u00b6 Allows to exclude issues with dedicated list of labels. back to overview Scope Details Aliases - Type []string Mandatory no Default $PIPER_excludeLabels (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none githubTokenCredentialsId \u00b6 Jenkins-specific: Used for proper environment setup. Jenkins 'Secret text' credentials ID containing token to authenticate to GitHub. back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none labels \u00b6 Labels to include in issue search. back to overview Scope Details Aliases - Type []string Mandatory no Default $PIPER_labels (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none owner \u00b6 Set the GitHub organization. back to overview Scope Details Aliases githubOrg Type string Mandatory yes Default $PIPER_owner (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references commonPipelineEnvironment : reference to: github/owner preRelease \u00b6 If set to true the release will be marked as Pre-release. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none releaseBodyHeader \u00b6 Content which will appear for the release. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_releaseBodyHeader (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none repository \u00b6 Set the GitHub repository. back to overview Scope Details Aliases githubRepo Type string Mandatory yes Default $PIPER_repository (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references commonPipelineEnvironment : reference to: github/repository script \u00b6 Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none serverUrl \u00b6 GitHub server url for end-user access. back to overview Scope Details Aliases githubServerUrl Type string Mandatory no Default https://github.com Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none token \u00b6 GitHub personal access token as per https://help.github.com/en/github/authenticating-to-github/creating-a-personal-access-token-for-the-command-line back to overview Scope Details Aliases githubToken Type string Mandatory yes Default $PIPER_token (if set) Secret yes Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none uploadUrl \u00b6 Set the GitHub API url. back to overview Scope Details Aliases githubUploadUrl Type string Mandatory no Default https://uploads.github.com Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none verbose \u00b6 verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none version \u00b6 Define the version number which will be written as tag as well as release name. back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_version (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references commonPipelineEnvironment : reference to: artifactVersion \u00b6 Description \u00b6 This step creates a tag in your GitHub repository together with a release. The release can be filled with text plus additional information like: Closed pull request since last release Closed issues since last release Link to delta information showing all commits since last release The result looks like Usage \u00b6 We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line . Jenkins pipelines \u00b6 githubPublishRelease script: this Command line \u00b6 piper githubPublishRelease Example \u00b6 Usage of pipeline step: githubPublishRelease script: this , releaseBodyHeader: \"**This is the latest success!**<br />\"","title":"githubPublishRelease"},{"location":"steps/githubPublishRelease/#githubpublishrelease","text":"Publish a release in GitHub","title":"githubPublishRelease"},{"location":"steps/githubPublishRelease/#prerequisites","text":"You need to create a personal access token within GitHub and add this to the Jenkins credentials store. Please see GitHub documentation for details about creating the personal access token .","title":"Prerequisites"},{"location":"steps/githubPublishRelease/#parameters","text":"","title":"Parameters"},{"location":"steps/githubPublishRelease/#overview","text":"Name Mandatory Additional information apiUrl yes githubTokenCredentialsId yes id of credentials ( using credentials ) owner yes repository yes script yes reference to Jenkins main pipeline script serverUrl yes token yes pass via ENV or Jenkins credentials uploadUrl yes version yes addClosedIssues no addDeltaToLastRelease no assetPath no commitish no excludeLabels no labels no preRelease no releaseBodyHeader no verbose no activates debug output","title":"Overview"},{"location":"steps/githubPublishRelease/#details","text":"","title":"Details"},{"location":"steps/githubPublishRelease/#addclosedissues","text":"If set to true , closed issues and merged pull-requests since the last release will added below the releaseBodyHeader back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"addClosedIssues"},{"location":"steps/githubPublishRelease/#adddeltatolastrelease","text":"If set to true , a link will be added to the relese information that brings up all commits since the last release. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"addDeltaToLastRelease"},{"location":"steps/githubPublishRelease/#apiurl","text":"Set the GitHub API url. back to overview Scope Details Aliases githubApiUrl Type string Mandatory no Default https://api.github.com Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"apiUrl"},{"location":"steps/githubPublishRelease/#assetpath","text":"Path to a release asset which should be uploaded to the list of release assets. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_assetPath (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"assetPath"},{"location":"steps/githubPublishRelease/#commitish","text":"Target git commitish for the release back to overview Scope Details Aliases - Type string Mandatory no Default master Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"commitish"},{"location":"steps/githubPublishRelease/#excludelabels","text":"Allows to exclude issues with dedicated list of labels. back to overview Scope Details Aliases - Type []string Mandatory no Default $PIPER_excludeLabels (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"excludeLabels"},{"location":"steps/githubPublishRelease/#githubtokencredentialsid","text":"Jenkins-specific: Used for proper environment setup. Jenkins 'Secret text' credentials ID containing token to authenticate to GitHub. back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"githubTokenCredentialsId"},{"location":"steps/githubPublishRelease/#labels","text":"Labels to include in issue search. back to overview Scope Details Aliases - Type []string Mandatory no Default $PIPER_labels (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"labels"},{"location":"steps/githubPublishRelease/#owner","text":"Set the GitHub organization. back to overview Scope Details Aliases githubOrg Type string Mandatory yes Default $PIPER_owner (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references commonPipelineEnvironment : reference to: github/owner","title":"owner"},{"location":"steps/githubPublishRelease/#prerelease","text":"If set to true the release will be marked as Pre-release. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"preRelease"},{"location":"steps/githubPublishRelease/#releasebodyheader","text":"Content which will appear for the release. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_releaseBodyHeader (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"releaseBodyHeader"},{"location":"steps/githubPublishRelease/#repository","text":"Set the GitHub repository. back to overview Scope Details Aliases githubRepo Type string Mandatory yes Default $PIPER_repository (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references commonPipelineEnvironment : reference to: github/repository","title":"repository"},{"location":"steps/githubPublishRelease/#script","text":"Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none","title":"script"},{"location":"steps/githubPublishRelease/#serverurl","text":"GitHub server url for end-user access. back to overview Scope Details Aliases githubServerUrl Type string Mandatory no Default https://github.com Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"serverUrl"},{"location":"steps/githubPublishRelease/#token","text":"GitHub personal access token as per https://help.github.com/en/github/authenticating-to-github/creating-a-personal-access-token-for-the-command-line back to overview Scope Details Aliases githubToken Type string Mandatory yes Default $PIPER_token (if set) Secret yes Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"token"},{"location":"steps/githubPublishRelease/#uploadurl","text":"Set the GitHub API url. back to overview Scope Details Aliases githubUploadUrl Type string Mandatory no Default https://uploads.github.com Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"uploadUrl"},{"location":"steps/githubPublishRelease/#verbose","text":"verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"verbose"},{"location":"steps/githubPublishRelease/#version","text":"Define the version number which will be written as tag as well as release name. back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_version (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references commonPipelineEnvironment : reference to: artifactVersion","title":"version"},{"location":"steps/githubPublishRelease/#description","text":"This step creates a tag in your GitHub repository together with a release. The release can be filled with text plus additional information like: Closed pull request since last release Closed issues since last release Link to delta information showing all commits since last release The result looks like","title":"Description"},{"location":"steps/githubPublishRelease/#usage","text":"We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line .","title":"Usage"},{"location":"steps/githubPublishRelease/#jenkins-pipelines","text":"githubPublishRelease script: this","title":"Jenkins pipelines"},{"location":"steps/githubPublishRelease/#command-line","text":"piper githubPublishRelease","title":"Command line"},{"location":"steps/githubPublishRelease/#example","text":"Usage of pipeline step: githubPublishRelease script: this , releaseBodyHeader: \"**This is the latest success!**<br />\"","title":"Example"},{"location":"steps/hadolintExecute/","text":"hadolintExecute \u00b6 Description \u00b6 Executes the Haskell Dockerfile Linter which is a smarter Dockerfile linter that helps you build best practice Docker images. The linter is parsing the Dockerfile into an abstract syntax tree (AST) and performs rules on top of the AST. Parameters \u00b6 name mandatory default possible values configurationFile no .hadolint.yaml configurationUrl no `` dockerFile no ./Dockerfile dockerImage no hadolint/hadolint:latest-debian dockerOptions no qualityGates no [[threshold:1, type:TOTAL_ERROR, unstable:false]] reportFile no hadolint.xml reportName no HaDoLint script yes configurationFile - Name of the configuration file used locally within the step. If a file with this name is detected as part of your repo downloading the central configuration via configurationUrl will be skipped. If you change the file's name make sure your stashing configuration also reflects this. configurationUrl - URL pointing to the .hadolint.yaml exclude configuration to be used for linting. Also have a look at configurationFile which could avoid central configuration download in case the file is part of your repository. dockerFile - Dockerfile to be used for the assessment. dockerImage - Name of the docker image that should be used, in which node should be installed and configured. Default value is 'hadolint/hadolint:latest-debian'. dockerOptions - Docker options to be set when starting the container. qualityGates - Quality Gates to fail the build, see warnings-ng plugin documentation . reportFile - Name of the result file used locally within the step. reportName - Name of the checkstyle report being generated our of the results. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage configurationFile X configurationUrl X dockerFile X X dockerImage X X dockerOptions X qualityGates X reportFile X reportName X script Exceptions \u00b6 None Examples \u00b6 hadolintExecute script: this","title":"hadolintExecute"},{"location":"steps/hadolintExecute/#hadolintexecute","text":"","title":"hadolintExecute"},{"location":"steps/hadolintExecute/#description","text":"Executes the Haskell Dockerfile Linter which is a smarter Dockerfile linter that helps you build best practice Docker images. The linter is parsing the Dockerfile into an abstract syntax tree (AST) and performs rules on top of the AST.","title":"Description"},{"location":"steps/hadolintExecute/#parameters","text":"name mandatory default possible values configurationFile no .hadolint.yaml configurationUrl no `` dockerFile no ./Dockerfile dockerImage no hadolint/hadolint:latest-debian dockerOptions no qualityGates no [[threshold:1, type:TOTAL_ERROR, unstable:false]] reportFile no hadolint.xml reportName no HaDoLint script yes configurationFile - Name of the configuration file used locally within the step. If a file with this name is detected as part of your repo downloading the central configuration via configurationUrl will be skipped. If you change the file's name make sure your stashing configuration also reflects this. configurationUrl - URL pointing to the .hadolint.yaml exclude configuration to be used for linting. Also have a look at configurationFile which could avoid central configuration download in case the file is part of your repository. dockerFile - Dockerfile to be used for the assessment. dockerImage - Name of the docker image that should be used, in which node should be installed and configured. Default value is 'hadolint/hadolint:latest-debian'. dockerOptions - Docker options to be set when starting the container. qualityGates - Quality Gates to fail the build, see warnings-ng plugin documentation . reportFile - Name of the result file used locally within the step. reportName - Name of the checkstyle report being generated our of the results. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters.","title":"Parameters"},{"location":"steps/hadolintExecute/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage configurationFile X configurationUrl X dockerFile X X dockerImage X X dockerOptions X qualityGates X reportFile X reportName X script","title":"Step configuration"},{"location":"steps/hadolintExecute/#exceptions","text":"None","title":"Exceptions"},{"location":"steps/hadolintExecute/#examples","text":"hadolintExecute script: this","title":"Examples"},{"location":"steps/handlePipelineStepErrors/","text":"handlePipelineStepErrors \u00b6 Description \u00b6 Used by other steps to make error analysis easier. Lists parameters and other data available to the step in which the error occurs. Prerequisites \u00b6 none Parameters \u00b6 name mandatory default possible values echoDetails no true true , false failOnError no true true , false libraryDocumentationUrl no https://sap.github.io/jenkins-library/ libraryRepositoryUrl no https://github.com/SAP/jenkins-library/ mandatorySteps no [] script yes stepName yes stepNameDoc no stepParameters yes stepTimeouts no [:] echoDetails - If it is set to true details will be output to the console. See example below. failOnError - Defines the behavior, in case an error occurs which is handled by this step. When set to false an error results in an \"UNSTABLE\" build result and the pipeline can continue. libraryDocumentationUrl - Defines the url of the library's documentation that will be used to generate the corresponding links to the step documentation. libraryRepositoryUrl - Defines the url of the library's repository that will be used to generate the corresponding links to the step implementation. mandatorySteps - Defines a list of mandatory steps (step names) which have to be successful (=stop the pipeline), even if failOnError: false script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. stepName - Defines the name of the step for which the error handling is active. It will be shown in the console log. stepNameDoc - Defines the documented step, in case the documentation reference should point to a different step. stepParameters - Passes the parameters of the step which uses the error handling onto the error handling. The list of parameters is then shown in the console output. The simplest case looks like this: [ script: this ] stepTimeouts - Defines a Map containing step name as key and timout in minutes in order to stop an execution after a certain timeout. This helps to make pipeline runs more resilient with respect to long running steps. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage echoDetails failOnError X libraryDocumentationUrl X libraryRepositoryUrl X mandatorySteps X script stepName stepNameDoc stepParameters stepTimeouts X Dependencies \u00b6 The step depends on the following Jenkins plugins pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Example \u00b6 handlePipelineStepErrors ( stepName: 'executeHealthCheck' , stepParameters: parameters ) { // The code you want to get controlled by the error handler goes right here into the closure def url = new Utils (). getMandatoryParameter ( parameters , 'url' , null ) def statusCode = curl ( url ) if ( statusCode != '200' ) error \"Health Check failed: ${statusCode}\" } Example console output \u00b6 If echoDetails is set to true the following information will be output to the console: Step beginning: --- Begin library step: ${stepName}.groovy --- Step end: --- End library step: ${stepName}.groovy --- Step errors: ---------------------------------------------------------- --- An error occurred in the library step: ${stepName} ---------------------------------------------------------- The following parameters were available to the step: *** ${stepParameters} *** The error was: *** ${err} *** Further information: * Documentation of step ${stepName}: .../${stepName}/ * Pipeline documentation: https://... * GitHub repository for pipeline steps: https://... ----------------------------------------------------------","title":"handlePipelineStepErrors"},{"location":"steps/handlePipelineStepErrors/#handlepipelinesteperrors","text":"","title":"handlePipelineStepErrors"},{"location":"steps/handlePipelineStepErrors/#description","text":"Used by other steps to make error analysis easier. Lists parameters and other data available to the step in which the error occurs.","title":"Description"},{"location":"steps/handlePipelineStepErrors/#prerequisites","text":"none","title":"Prerequisites"},{"location":"steps/handlePipelineStepErrors/#parameters","text":"name mandatory default possible values echoDetails no true true , false failOnError no true true , false libraryDocumentationUrl no https://sap.github.io/jenkins-library/ libraryRepositoryUrl no https://github.com/SAP/jenkins-library/ mandatorySteps no [] script yes stepName yes stepNameDoc no stepParameters yes stepTimeouts no [:] echoDetails - If it is set to true details will be output to the console. See example below. failOnError - Defines the behavior, in case an error occurs which is handled by this step. When set to false an error results in an \"UNSTABLE\" build result and the pipeline can continue. libraryDocumentationUrl - Defines the url of the library's documentation that will be used to generate the corresponding links to the step documentation. libraryRepositoryUrl - Defines the url of the library's repository that will be used to generate the corresponding links to the step implementation. mandatorySteps - Defines a list of mandatory steps (step names) which have to be successful (=stop the pipeline), even if failOnError: false script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. stepName - Defines the name of the step for which the error handling is active. It will be shown in the console log. stepNameDoc - Defines the documented step, in case the documentation reference should point to a different step. stepParameters - Passes the parameters of the step which uses the error handling onto the error handling. The list of parameters is then shown in the console output. The simplest case looks like this: [ script: this ] stepTimeouts - Defines a Map containing step name as key and timout in minutes in order to stop an execution after a certain timeout. This helps to make pipeline runs more resilient with respect to long running steps.","title":"Parameters"},{"location":"steps/handlePipelineStepErrors/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage echoDetails failOnError X libraryDocumentationUrl X libraryRepositoryUrl X mandatorySteps X script stepName stepNameDoc stepParameters stepTimeouts X","title":"Step configuration"},{"location":"steps/handlePipelineStepErrors/#dependencies","text":"The step depends on the following Jenkins plugins pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/handlePipelineStepErrors/#example","text":"handlePipelineStepErrors ( stepName: 'executeHealthCheck' , stepParameters: parameters ) { // The code you want to get controlled by the error handler goes right here into the closure def url = new Utils (). getMandatoryParameter ( parameters , 'url' , null ) def statusCode = curl ( url ) if ( statusCode != '200' ) error \"Health Check failed: ${statusCode}\" }","title":"Example"},{"location":"steps/handlePipelineStepErrors/#example-console-output","text":"If echoDetails is set to true the following information will be output to the console: Step beginning: --- Begin library step: ${stepName}.groovy --- Step end: --- End library step: ${stepName}.groovy --- Step errors: ---------------------------------------------------------- --- An error occurred in the library step: ${stepName} ---------------------------------------------------------- The following parameters were available to the step: *** ${stepParameters} *** The error was: *** ${err} *** Further information: * Documentation of step ${stepName}: .../${stepName}/ * Pipeline documentation: https://... * GitHub repository for pipeline steps: https://... ----------------------------------------------------------","title":"Example console output"},{"location":"steps/healthExecuteCheck/","text":"healthExecuteCheck \u00b6 Description \u00b6 Calls the health endpoint url of the application. The intention of the check is to verify that a suitable health endpoint is available. Such a health endpoint is required for operation purposes. This check is used as a real-life test for your productive health endpoints. Check Depth Typically, tools performing simple health checks are not too smart. Therefore it is important to choose an endpoint for checking wisely. This check therefore only checks if the application/service url returns HTTP 200 . This is in line with health check capabilities of platforms which are used for example in load balancing scenarios. Here you can find an example for Amazon AWS . Prerequisites \u00b6 Endpoint for health check is configured. Warning The health endpoint needs to be available without authentication! Tip If using Spring Boot framework, ideally the provided /health endpoint is used and extended by development. Further information can be found in the Spring Boot documenation for Endpoints Parameters \u00b6 name mandatory default possible values healthEndpoint no `` script yes testServerUrl yes healthEndpoint - Optionally with healthEndpoint the health function is called if endpoint is not the standard url. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. testServerUrl - Health check function is called providing full qualified testServerUrl to the health check. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage healthEndpoint X script testServerUrl X Dependencies \u00b6 The step depends on the following Jenkins plugins pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Example \u00b6 Pipeline step: healthExecuteCheck testServerUrl: 'https://testserver.com'","title":"healthExecuteCheck"},{"location":"steps/healthExecuteCheck/#healthexecutecheck","text":"","title":"healthExecuteCheck"},{"location":"steps/healthExecuteCheck/#description","text":"Calls the health endpoint url of the application. The intention of the check is to verify that a suitable health endpoint is available. Such a health endpoint is required for operation purposes. This check is used as a real-life test for your productive health endpoints. Check Depth Typically, tools performing simple health checks are not too smart. Therefore it is important to choose an endpoint for checking wisely. This check therefore only checks if the application/service url returns HTTP 200 . This is in line with health check capabilities of platforms which are used for example in load balancing scenarios. Here you can find an example for Amazon AWS .","title":"Description"},{"location":"steps/healthExecuteCheck/#prerequisites","text":"Endpoint for health check is configured. Warning The health endpoint needs to be available without authentication! Tip If using Spring Boot framework, ideally the provided /health endpoint is used and extended by development. Further information can be found in the Spring Boot documenation for Endpoints","title":"Prerequisites"},{"location":"steps/healthExecuteCheck/#parameters","text":"name mandatory default possible values healthEndpoint no `` script yes testServerUrl yes healthEndpoint - Optionally with healthEndpoint the health function is called if endpoint is not the standard url. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. testServerUrl - Health check function is called providing full qualified testServerUrl to the health check.","title":"Parameters"},{"location":"steps/healthExecuteCheck/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage healthEndpoint X script testServerUrl X","title":"Step configuration"},{"location":"steps/healthExecuteCheck/#dependencies","text":"The step depends on the following Jenkins plugins pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/healthExecuteCheck/#example","text":"Pipeline step: healthExecuteCheck testServerUrl: 'https://testserver.com'","title":"Example"},{"location":"steps/influxWriteData/","text":"influxWriteData \u00b6 Description \u00b6 Since your Continuous Delivery Pipeline in Jenkins provides your productive development and delivery infrastructure you should monitor the pipeline to ensure it runs as expected. How to setup this monitoring is described in the following. You basically need three components: The InfluxDB Jenkins plugin which allows you to send build metrics to InfluxDB servers The InfluxDB to store this data (Docker available) A Grafana dashboard to visualize the data stored in InfluxDB (Docker available) no InfluxDB available? If you don't have an InfluxDB available yet this step will still provide you some benefit. It will create following files for you and archive them into your build: jenkins_data.json : This file gives you build-specific information, like e.g. build result, stage where the build failed influx_data.json : This file gives you detailed information about your pipeline, e.g. stage durations, steps executed, ... Prerequisites \u00b6 Setting up InfluxDB with Grafana \u00b6 The easiest way to start with is using the available official docker images. You can either run these docker containers on the same host on which you run your Jenkins or each docker on individual VMs (hosts). Very basic setup can be done like that (with user \"admin\" and password \"adminPwd\" for both InfluxDB and Grafana): docker run -d -p 8083:8083 -p 8086:8086 --restart=always --name influxdb -v /var/influx_data:/var/lib/influxdb influxdb docker run -d -p 3000:3000 --name grafana --restart=always --link influxdb:influxdb -e \"GF_SECURITY_ADMIN_PASSWORD=adminPwd\" grafana/grafana For more advanced setup please reach out to the respective documentation: InfluxDB ( Docker Hub GitHub ) Grafana ( Docker Hub GitHub ) After you have started your InfluxDB docker you need to create a database: in a Webbrowser open the InfluxDB Web-UI using the following URL: <host of your docker>:8083 (port 8083 is used for access via Web-UI, for Jenkins you use port 8086 to access the DB) create new DB (the name of this DB you need to provide later to Jenkins) create Admin user (this user you need to provide later to Jenkins) With InfluxDB version 1.1 the InfluxDB Web-UI is deprecated You can perform the above steps via commandline: The following command will create a database with name <databasename> curl -i -XPOST http://localhost:8086/query --data-urlencode \"q=CREATE DATABASE \\<databasename\\>\" The admin user with the name <adminusername> and the password <adminuserpwd> can be created with curl -i -XPOST http://localhost:8086/query --data-urlencode \"q=CREATE USER \\<adminusername\\> WITH PASSWORD '\\<adminuserpwd\\>' WITH ALL PRIVILEGES\" Once you have started both docker containers and Influx and Grafana are running you need to configure the Jenkins Plugin according to your settings. Pipeline configuration \u00b6 To setup your Jenkins you need to do two configuration steps: Configure Jenkins (via Manage Jenkins) Adapt pipeline configuration Configure Jenkins \u00b6 Once the plugin is available in your Jenkins: go to \"Manage Jenkins\" > \"Configure System\" > scroll down to section \"influxdb target\" maintain Influx data Jenkins as a Service For Jenkins as a Service instances this is already preset to the local InfluxDB with the name jenkins . In this case there is not need to do any additional configuration. Adapt pipeline configuration \u00b6 You need to define the influxDB server in your pipeline as it is defined in the InfluxDb plugin configuration (see above). influxDBServer = jenkins Parameters \u00b6 name mandatory default possible values artifactVersion no customData no customDataMap no customDataMapTags no customDataTags no influxPrefix no influxServer no `` script yes sonarTokenCredentialsId no wrapInNode no artifactVersion - Defines the version of the current artifact. Defaults to commonPipelineEnvironment.getArtifactVersion() customData - Defines custom data (map of key-value pairs) to be written to Influx into measurement jenkins_custom_data . Defaults to commonPipelineEnvironment.getInfluxCustomData() customDataMap - Defines a map of measurement names containing custom data (map of key-value pairs) to be written to Influx. Defaults to commonPipelineEnvironment.getInfluxCustomDataMap() customDataMapTags - Defines a map of measurement names containing tags (map of key-value pairs) to be written to Influx. Defaults to commonPipelineEnvironment.getInfluxCustomDataTags() customDataTags - Defines tags (map of key-value pairs) to be written to Influx into measurement jenkins_custom_data . Defaults to commonPipelineEnvironment.getInfluxCustomDataTags() influxPrefix - Defines a custom prefix. For example in multi branch pipelines, where every build is named after the branch built and thus you have different builds called 'master' that report different metrics. influxServer - Defines the name of the Influx server as configured in Jenkins global configuration. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. sonarTokenCredentialsId - wrapInNode - Defines if a dedicated node/executor should be created in the pipeline run. This is especially relevant when running the step in a declarative POST stage where by default no executor is available. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage artifactVersion X customData X customDataMap X customDataMapTags X customDataTags X influxPrefix X influxServer X script sonarTokenCredentialsId X wrapInNode X Dependencies \u00b6 The step depends on the following Jenkins plugins credentials-binding pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Example \u00b6 influxWriteData script: this Work with InfluxDB and Grafana \u00b6 You can access your Grafana via Web-UI: <host of your grafana(-docker)>:<port3000> (or another port in case you have defined another one when starting your docker) As a first step you need to add your InfluxDB as Data source to your Grafana: Login as user admin (PW as defined when starting your docker) in the navigation go to data sources -> add data source: name type: InfluxDB Url: http://<host of your InfluxDB server>:<port> Access: direct (not via proxy) database: <name of the DB as specified above> User: <name of the admin user as specified in step above> Password: <password of the admin user as specified in step above> Jenkins as a Service For Jenkins as a Service the data source configuration is already available. Therefore no need to go through the data source configuration step unless you want to add addtional data sources. Data collected in InfluxDB \u00b6 The Influx plugin collects following data in the Piper context: All data as per default InfluxDB plugin capabilities Additional data collected via InfluxData.addField(measurement, key, value) Add custom information to your InfluxDB You can simply add custom data collected during your pipeline runs via available data objects. Example: //add data to measurement jenkins_custom_data - value can be a String or a Number commonPipelineEnvironment . setInfluxCustomDataProperty ( 'myProperty' , 2018 ) Collected InfluxDB measurements \u00b6 Measurements are potentially pre-fixed - see parameter influxPrefix above. Measurement name data column description All measurements build_number project_name All below measurements will have these columns. Details see InfluxDB plugin documentation jenkins_data build_result build_time last_successful_build tests_failed tests_skipped tests_total ... Details see InfluxDB plugin documentation cobertura_data cobertura_branch_coverage_rate cobertura_class_coverage_rate cobertura_line_coverage_rate cobertura_package_coverage_rate ... Details see InfluxDB plugin documentation jacoco_data jacoco_branch_coverage_rate jacoco_class_coverage_rate jacoco_instruction_coverage_rate jacoco_line_coverage_rate jacoco_method_coverage_rate Details see InfluxDB plugin documentation performance_data 90Percentile average max median min error_count error_percent ... Details see InfluxDB plugin documentation sonarqube_data blocker_issues critical_issues info_issues major_issues minor_issues lines_of_code ... Details see InfluxDB plugin documentation jenkins_custom_data Piper fills following colums by default: build_result build_result_key build_step (->step in case of error) build_error (->error message in case of error) filled by commonPipelineEnvironment.setInfluxCustomDataProperty() pipeline_data Examples from the Piper templates: build_duration opa_duration deploy_test_duration deploy_test_duration fortify_duration release_duration ... filled by step measureDuration using parameter measurementName step_data Considered, e.g.: build_url bats checkmarx fortify gauge nsp snyk sonar ... filled by InfluxData.addField('step_data', key, value) Examples for InfluxDB queries which can be used in Grafana \u00b6 Project Names containing dashes (-) The InfluxDB plugin replaces dashes (-) with underscores (_). Please keep this in mind when specifying your project_name for a InfluxDB query. Example 1: Select last 10 successful builds \u00b6 select top ( build_number , 10 ), build_result from jenkins_data WHERE build_result = 'SUCCESS' Example 2: Select last 10 step names of failed builds \u00b6 select top ( build_number , 10 ), build_result , build_step from jenkins_custom_data WHERE build_result = 'FAILURE' Example 3: Select build duration of step for a specific project \u00b6 select build_duration / 1000 from \"pipeline_data\" WHERE project_name = 'PiperTestOrg_piper_test_master' Example 4: Get transparency about successful/failed steps for a specific project \u00b6 select top ( build_number , 10 ) AS \"Build\" , build_url , build_quality , fortify , gauge , vulas , opa from step_data WHERE project_name = 'PiperTestOrg_piper_test_master' Note With this query you can create transparency about which steps ran successfully / not successfully in your pipeline and which ones were not executed at all. By specifying all the steps you consider relevant in your select statement it is very easy to create this transparency.","title":"influxWriteData"},{"location":"steps/influxWriteData/#influxwritedata","text":"","title":"influxWriteData"},{"location":"steps/influxWriteData/#description","text":"Since your Continuous Delivery Pipeline in Jenkins provides your productive development and delivery infrastructure you should monitor the pipeline to ensure it runs as expected. How to setup this monitoring is described in the following. You basically need three components: The InfluxDB Jenkins plugin which allows you to send build metrics to InfluxDB servers The InfluxDB to store this data (Docker available) A Grafana dashboard to visualize the data stored in InfluxDB (Docker available) no InfluxDB available? If you don't have an InfluxDB available yet this step will still provide you some benefit. It will create following files for you and archive them into your build: jenkins_data.json : This file gives you build-specific information, like e.g. build result, stage where the build failed influx_data.json : This file gives you detailed information about your pipeline, e.g. stage durations, steps executed, ...","title":"Description"},{"location":"steps/influxWriteData/#prerequisites","text":"","title":"Prerequisites"},{"location":"steps/influxWriteData/#setting-up-influxdb-with-grafana","text":"The easiest way to start with is using the available official docker images. You can either run these docker containers on the same host on which you run your Jenkins or each docker on individual VMs (hosts). Very basic setup can be done like that (with user \"admin\" and password \"adminPwd\" for both InfluxDB and Grafana): docker run -d -p 8083:8083 -p 8086:8086 --restart=always --name influxdb -v /var/influx_data:/var/lib/influxdb influxdb docker run -d -p 3000:3000 --name grafana --restart=always --link influxdb:influxdb -e \"GF_SECURITY_ADMIN_PASSWORD=adminPwd\" grafana/grafana For more advanced setup please reach out to the respective documentation: InfluxDB ( Docker Hub GitHub ) Grafana ( Docker Hub GitHub ) After you have started your InfluxDB docker you need to create a database: in a Webbrowser open the InfluxDB Web-UI using the following URL: <host of your docker>:8083 (port 8083 is used for access via Web-UI, for Jenkins you use port 8086 to access the DB) create new DB (the name of this DB you need to provide later to Jenkins) create Admin user (this user you need to provide later to Jenkins) With InfluxDB version 1.1 the InfluxDB Web-UI is deprecated You can perform the above steps via commandline: The following command will create a database with name <databasename> curl -i -XPOST http://localhost:8086/query --data-urlencode \"q=CREATE DATABASE \\<databasename\\>\" The admin user with the name <adminusername> and the password <adminuserpwd> can be created with curl -i -XPOST http://localhost:8086/query --data-urlencode \"q=CREATE USER \\<adminusername\\> WITH PASSWORD '\\<adminuserpwd\\>' WITH ALL PRIVILEGES\" Once you have started both docker containers and Influx and Grafana are running you need to configure the Jenkins Plugin according to your settings.","title":"Setting up InfluxDB with Grafana"},{"location":"steps/influxWriteData/#pipeline-configuration","text":"To setup your Jenkins you need to do two configuration steps: Configure Jenkins (via Manage Jenkins) Adapt pipeline configuration","title":"Pipeline configuration"},{"location":"steps/influxWriteData/#configure-jenkins","text":"Once the plugin is available in your Jenkins: go to \"Manage Jenkins\" > \"Configure System\" > scroll down to section \"influxdb target\" maintain Influx data Jenkins as a Service For Jenkins as a Service instances this is already preset to the local InfluxDB with the name jenkins . In this case there is not need to do any additional configuration.","title":"Configure Jenkins"},{"location":"steps/influxWriteData/#adapt-pipeline-configuration","text":"You need to define the influxDB server in your pipeline as it is defined in the InfluxDb plugin configuration (see above). influxDBServer = jenkins","title":"Adapt pipeline configuration"},{"location":"steps/influxWriteData/#parameters","text":"name mandatory default possible values artifactVersion no customData no customDataMap no customDataMapTags no customDataTags no influxPrefix no influxServer no `` script yes sonarTokenCredentialsId no wrapInNode no artifactVersion - Defines the version of the current artifact. Defaults to commonPipelineEnvironment.getArtifactVersion() customData - Defines custom data (map of key-value pairs) to be written to Influx into measurement jenkins_custom_data . Defaults to commonPipelineEnvironment.getInfluxCustomData() customDataMap - Defines a map of measurement names containing custom data (map of key-value pairs) to be written to Influx. Defaults to commonPipelineEnvironment.getInfluxCustomDataMap() customDataMapTags - Defines a map of measurement names containing tags (map of key-value pairs) to be written to Influx. Defaults to commonPipelineEnvironment.getInfluxCustomDataTags() customDataTags - Defines tags (map of key-value pairs) to be written to Influx into measurement jenkins_custom_data . Defaults to commonPipelineEnvironment.getInfluxCustomDataTags() influxPrefix - Defines a custom prefix. For example in multi branch pipelines, where every build is named after the branch built and thus you have different builds called 'master' that report different metrics. influxServer - Defines the name of the Influx server as configured in Jenkins global configuration. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. sonarTokenCredentialsId - wrapInNode - Defines if a dedicated node/executor should be created in the pipeline run. This is especially relevant when running the step in a declarative POST stage where by default no executor is available.","title":"Parameters"},{"location":"steps/influxWriteData/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage artifactVersion X customData X customDataMap X customDataMapTags X customDataTags X influxPrefix X influxServer X script sonarTokenCredentialsId X wrapInNode X","title":"Step configuration"},{"location":"steps/influxWriteData/#dependencies","text":"The step depends on the following Jenkins plugins credentials-binding pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/influxWriteData/#example","text":"influxWriteData script: this","title":"Example"},{"location":"steps/influxWriteData/#work-with-influxdb-and-grafana","text":"You can access your Grafana via Web-UI: <host of your grafana(-docker)>:<port3000> (or another port in case you have defined another one when starting your docker) As a first step you need to add your InfluxDB as Data source to your Grafana: Login as user admin (PW as defined when starting your docker) in the navigation go to data sources -> add data source: name type: InfluxDB Url: http://<host of your InfluxDB server>:<port> Access: direct (not via proxy) database: <name of the DB as specified above> User: <name of the admin user as specified in step above> Password: <password of the admin user as specified in step above> Jenkins as a Service For Jenkins as a Service the data source configuration is already available. Therefore no need to go through the data source configuration step unless you want to add addtional data sources.","title":"Work with InfluxDB and Grafana"},{"location":"steps/influxWriteData/#data-collected-in-influxdb","text":"The Influx plugin collects following data in the Piper context: All data as per default InfluxDB plugin capabilities Additional data collected via InfluxData.addField(measurement, key, value) Add custom information to your InfluxDB You can simply add custom data collected during your pipeline runs via available data objects. Example: //add data to measurement jenkins_custom_data - value can be a String or a Number commonPipelineEnvironment . setInfluxCustomDataProperty ( 'myProperty' , 2018 )","title":"Data collected in InfluxDB"},{"location":"steps/influxWriteData/#collected-influxdb-measurements","text":"Measurements are potentially pre-fixed - see parameter influxPrefix above. Measurement name data column description All measurements build_number project_name All below measurements will have these columns. Details see InfluxDB plugin documentation jenkins_data build_result build_time last_successful_build tests_failed tests_skipped tests_total ... Details see InfluxDB plugin documentation cobertura_data cobertura_branch_coverage_rate cobertura_class_coverage_rate cobertura_line_coverage_rate cobertura_package_coverage_rate ... Details see InfluxDB plugin documentation jacoco_data jacoco_branch_coverage_rate jacoco_class_coverage_rate jacoco_instruction_coverage_rate jacoco_line_coverage_rate jacoco_method_coverage_rate Details see InfluxDB plugin documentation performance_data 90Percentile average max median min error_count error_percent ... Details see InfluxDB plugin documentation sonarqube_data blocker_issues critical_issues info_issues major_issues minor_issues lines_of_code ... Details see InfluxDB plugin documentation jenkins_custom_data Piper fills following colums by default: build_result build_result_key build_step (->step in case of error) build_error (->error message in case of error) filled by commonPipelineEnvironment.setInfluxCustomDataProperty() pipeline_data Examples from the Piper templates: build_duration opa_duration deploy_test_duration deploy_test_duration fortify_duration release_duration ... filled by step measureDuration using parameter measurementName step_data Considered, e.g.: build_url bats checkmarx fortify gauge nsp snyk sonar ... filled by InfluxData.addField('step_data', key, value)","title":"Collected InfluxDB measurements"},{"location":"steps/influxWriteData/#examples-for-influxdb-queries-which-can-be-used-in-grafana","text":"Project Names containing dashes (-) The InfluxDB plugin replaces dashes (-) with underscores (_). Please keep this in mind when specifying your project_name for a InfluxDB query.","title":"Examples for InfluxDB queries which can be used in Grafana"},{"location":"steps/influxWriteData/#example-1-select-last-10-successful-builds","text":"select top ( build_number , 10 ), build_result from jenkins_data WHERE build_result = 'SUCCESS'","title":"Example 1: Select last 10 successful builds"},{"location":"steps/influxWriteData/#example-2-select-last-10-step-names-of-failed-builds","text":"select top ( build_number , 10 ), build_result , build_step from jenkins_custom_data WHERE build_result = 'FAILURE'","title":"Example 2: Select last 10 step names of failed builds"},{"location":"steps/influxWriteData/#example-3-select-build-duration-of-step-for-a-specific-project","text":"select build_duration / 1000 from \"pipeline_data\" WHERE project_name = 'PiperTestOrg_piper_test_master'","title":"Example 3: Select build duration of step for a specific project"},{"location":"steps/influxWriteData/#example-4-get-transparency-about-successfulfailed-steps-for-a-specific-project","text":"select top ( build_number , 10 ) AS \"Build\" , build_url , build_quality , fortify , gauge , vulas , opa from step_data WHERE project_name = 'PiperTestOrg_piper_test_master' Note With this query you can create transparency about which steps ran successfully / not successfully in your pipeline and which ones were not executed at all. By specifying all the steps you consider relevant in your select statement it is very easy to create this transparency.","title":"Example 4: Get transparency about successful/failed steps for a specific project"},{"location":"steps/jenkinsMaterializeLog/","text":"jenkinsMaterializeLog \u00b6 Description \u00b6 This step allows you to materialize the Jenkins log file of the running build. It acts as a wrapper executing the passed function body. Note: the file that has been created during step execution will be removed automatically. Prerequisites \u00b6 None Example \u00b6 jenkinsMaterializeLog script: this , { name -> println \"log file: \" + name } Parameters \u00b6 name mandatory default possible values script yes script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage script Dependencies \u00b6 The step depends on the following Jenkins plugins pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"jenkinsMaterializeLog"},{"location":"steps/jenkinsMaterializeLog/#jenkinsmaterializelog","text":"","title":"jenkinsMaterializeLog"},{"location":"steps/jenkinsMaterializeLog/#description","text":"This step allows you to materialize the Jenkins log file of the running build. It acts as a wrapper executing the passed function body. Note: the file that has been created during step execution will be removed automatically.","title":"Description"},{"location":"steps/jenkinsMaterializeLog/#prerequisites","text":"None","title":"Prerequisites"},{"location":"steps/jenkinsMaterializeLog/#example","text":"jenkinsMaterializeLog script: this , { name -> println \"log file: \" + name }","title":"Example"},{"location":"steps/jenkinsMaterializeLog/#parameters","text":"name mandatory default possible values script yes script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters.","title":"Parameters"},{"location":"steps/jenkinsMaterializeLog/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage script","title":"Step configuration"},{"location":"steps/jenkinsMaterializeLog/#dependencies","text":"The step depends on the following Jenkins plugins pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/kanikoExecute/","text":"kanikoExecute \u00b6 Executes a Kaniko build for creating a Docker container. Description \u00b6 Executes a Kaniko build for creating a Docker container. Usage \u00b6 We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line . Jenkins pipelines \u00b6 kanikoExecute script: this Command line \u00b6 piper kanikoExecute Prerequisites \u00b6 When pushing to a container registry, you need to maintain the respective credentials in your Jenkins credentials store: Kaniko expects a Docker config.json file containing the credential information for registries. You can create it like explained in the Docker Success Center in the article about How to generate a new auth in the config.json file . Please copy this file and upload it to your Jenkins for example via Jenkins -> Credentials -> System -> Global credentials (unrestricted) -> Add Credentials -> Kind: Secret file File: upload your config.json file ID: specify id which you then use for the configuration of dockerConfigJsonCredentialsId (see below) Example \u00b6 kanikoExecute script: this Parameters \u00b6 Overview \u00b6 Name Mandatory Additional information dockerConfigJsonCredentialsId yes id of credentials ( using credentials ) script yes reference to Jenkins main pipeline script buildOptions no containerBuildOptions no containerCommand no containerImage no containerPreparationCommand no containerShell no customTlsCertificateLinks no dockerConfigJSON no pass via ENV or Jenkins credentials dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no dockerVolumeBind no dockerWorkspace no dockerfilePath no verbose no activates debug output Details \u00b6 buildOptions \u00b6 Defines a list of build options for the kaniko build. back to overview Scope Details Aliases - Type []string Mandatory no Default - --skip-tls-verify-pull Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none containerBuildOptions \u00b6 Deprected, please use buildOptions. Defines the build options for the kaniko build. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_containerBuildOptions (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none containerCommand \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default (/usr/bin/tail -f /dev/null). back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none containerImage \u00b6 Defines the full name of the Docker image to be created including registry, image name and tag like my.docker.registry/path/myImageName:myTag . If left empty, image will not be pushed. back to overview Scope Details Aliases containerImageNameAndTag ( deprecated ) Type string Mandatory no Default $PIPER_containerImage (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references commonPipelineEnvironment : reference to: container/imageNameTag containerPreparationCommand \u00b6 Defines the command to prepare the Kaniko container. By default the contained credentials are removed in order to allow anonymous access to container registries. back to overview Scope Details Aliases - Type string Mandatory no Default rm -f /kaniko/.docker/config.json Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none containerShell \u00b6 Jenkins-specific: Used for proper environment setup. Allows to specify the shell to be executed for container with containerName. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none customTlsCertificateLinks \u00b6 List containing download links of custom TLS certificates. This is required to ensure trusted connections to registries with custom certificates. back to overview Scope Details Aliases - Type []string Mandatory no Default $PIPER_customTlsCertificateLinks (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none dockerConfigJSON \u00b6 Path to the file .docker/config.json - this is typically provided by your CI/CD system. You can find more details about the Docker credentials in the Docker documentation . back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_dockerConfigJSON (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none dockerConfigJsonCredentialsId \u00b6 Jenkins-specific: Used for proper environment setup. back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerEnvVars \u00b6 Jenkins-specific: Used for proper environment setup. Environment variables to set in the container, e.g. [http_proxy: \"proxy:8080\"]. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerImage \u00b6 Jenkins-specific: Used for proper environment setup. Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerName \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Name of the container launching dockerImage. SideCar only: Name of the container in local network. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerOptions \u00b6 Jenkins-specific: Used for proper environment setup. Docker options to be set when starting the container. back to overview Scope Details Aliases - Type []string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerPullImage \u00b6 Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerVolumeBind \u00b6 Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the docker container. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerWorkspace \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerfilePath \u00b6 Defines the location of the Dockerfile relative to the Jenkins workspace. back to overview Scope Details Aliases dockerfile Type string Mandatory no Default Dockerfile Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none script \u00b6 Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none verbose \u00b6 verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none \u00b6","title":"kanikoExecute"},{"location":"steps/kanikoExecute/#kanikoexecute","text":"Executes a Kaniko build for creating a Docker container.","title":"kanikoExecute"},{"location":"steps/kanikoExecute/#description","text":"Executes a Kaniko build for creating a Docker container.","title":"Description"},{"location":"steps/kanikoExecute/#usage","text":"We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line .","title":"Usage"},{"location":"steps/kanikoExecute/#jenkins-pipelines","text":"kanikoExecute script: this","title":"Jenkins pipelines"},{"location":"steps/kanikoExecute/#command-line","text":"piper kanikoExecute","title":"Command line"},{"location":"steps/kanikoExecute/#prerequisites","text":"When pushing to a container registry, you need to maintain the respective credentials in your Jenkins credentials store: Kaniko expects a Docker config.json file containing the credential information for registries. You can create it like explained in the Docker Success Center in the article about How to generate a new auth in the config.json file . Please copy this file and upload it to your Jenkins for example via Jenkins -> Credentials -> System -> Global credentials (unrestricted) -> Add Credentials -> Kind: Secret file File: upload your config.json file ID: specify id which you then use for the configuration of dockerConfigJsonCredentialsId (see below)","title":"Prerequisites"},{"location":"steps/kanikoExecute/#example","text":"kanikoExecute script: this","title":"Example"},{"location":"steps/kanikoExecute/#parameters","text":"","title":"Parameters"},{"location":"steps/kanikoExecute/#overview","text":"Name Mandatory Additional information dockerConfigJsonCredentialsId yes id of credentials ( using credentials ) script yes reference to Jenkins main pipeline script buildOptions no containerBuildOptions no containerCommand no containerImage no containerPreparationCommand no containerShell no customTlsCertificateLinks no dockerConfigJSON no pass via ENV or Jenkins credentials dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no dockerVolumeBind no dockerWorkspace no dockerfilePath no verbose no activates debug output","title":"Overview"},{"location":"steps/kanikoExecute/#details","text":"","title":"Details"},{"location":"steps/kanikoExecute/#buildoptions","text":"Defines a list of build options for the kaniko build. back to overview Scope Details Aliases - Type []string Mandatory no Default - --skip-tls-verify-pull Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"buildOptions"},{"location":"steps/kanikoExecute/#containerbuildoptions","text":"Deprected, please use buildOptions. Defines the build options for the kaniko build. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_containerBuildOptions (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"containerBuildOptions"},{"location":"steps/kanikoExecute/#containercommand","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default (/usr/bin/tail -f /dev/null). back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"containerCommand"},{"location":"steps/kanikoExecute/#containerimage","text":"Defines the full name of the Docker image to be created including registry, image name and tag like my.docker.registry/path/myImageName:myTag . If left empty, image will not be pushed. back to overview Scope Details Aliases containerImageNameAndTag ( deprecated ) Type string Mandatory no Default $PIPER_containerImage (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references commonPipelineEnvironment : reference to: container/imageNameTag","title":"containerImage"},{"location":"steps/kanikoExecute/#containerpreparationcommand","text":"Defines the command to prepare the Kaniko container. By default the contained credentials are removed in order to allow anonymous access to container registries. back to overview Scope Details Aliases - Type string Mandatory no Default rm -f /kaniko/.docker/config.json Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"containerPreparationCommand"},{"location":"steps/kanikoExecute/#containershell","text":"Jenkins-specific: Used for proper environment setup. Allows to specify the shell to be executed for container with containerName. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"containerShell"},{"location":"steps/kanikoExecute/#customtlscertificatelinks","text":"List containing download links of custom TLS certificates. This is required to ensure trusted connections to registries with custom certificates. back to overview Scope Details Aliases - Type []string Mandatory no Default $PIPER_customTlsCertificateLinks (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"customTlsCertificateLinks"},{"location":"steps/kanikoExecute/#dockerconfigjson","text":"Path to the file .docker/config.json - this is typically provided by your CI/CD system. You can find more details about the Docker credentials in the Docker documentation . back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_dockerConfigJSON (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"dockerConfigJSON"},{"location":"steps/kanikoExecute/#dockerconfigjsoncredentialsid","text":"Jenkins-specific: Used for proper environment setup. back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerConfigJsonCredentialsId"},{"location":"steps/kanikoExecute/#dockerenvvars","text":"Jenkins-specific: Used for proper environment setup. Environment variables to set in the container, e.g. [http_proxy: \"proxy:8080\"]. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerEnvVars"},{"location":"steps/kanikoExecute/#dockerimage","text":"Jenkins-specific: Used for proper environment setup. Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerImage"},{"location":"steps/kanikoExecute/#dockername","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Name of the container launching dockerImage. SideCar only: Name of the container in local network. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerName"},{"location":"steps/kanikoExecute/#dockeroptions","text":"Jenkins-specific: Used for proper environment setup. Docker options to be set when starting the container. back to overview Scope Details Aliases - Type []string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerOptions"},{"location":"steps/kanikoExecute/#dockerpullimage","text":"Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerPullImage"},{"location":"steps/kanikoExecute/#dockervolumebind","text":"Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the docker container. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerVolumeBind"},{"location":"steps/kanikoExecute/#dockerworkspace","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerWorkspace"},{"location":"steps/kanikoExecute/#dockerfilepath","text":"Defines the location of the Dockerfile relative to the Jenkins workspace. back to overview Scope Details Aliases dockerfile Type string Mandatory no Default Dockerfile Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"dockerfilePath"},{"location":"steps/kanikoExecute/#script","text":"Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none","title":"script"},{"location":"steps/kanikoExecute/#verbose","text":"verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"verbose"},{"location":"steps/karmaExecuteTests/","text":"karmaExecuteTests \u00b6 Description \u00b6 In this step the ( Karma test runner ) is executed. The step is using the seleniumExecuteTest step to spin up two containers in a Docker network: a Selenium/Chrome container ( selenium/standalone-chrome ) a NodeJS container ( node:lts-stretch ) In the Docker network, the containers can be referenced by the values provided in dockerName and sidecarName , the default values are karma and selenium . These values must be used in the hostname properties of the test configuration ( Karma and WebDriver ). Note In a Kubernetes environment, the containers both need to be referenced with localhost . Prerequisites \u00b6 running Karma tests - have a NPM module with running tests executed with Karma configured WebDriver - have the karma-webdriver-launcher package installed and a custom, WebDriver-based browser configured in Karma Dependencies \u00b6 The step depends on the following Jenkins plugins credentials-binding git pipeline-utility-steps workflow-basic-steps workflow-cps workflow-cps-global-lib workflow-durable-task-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Parameters \u00b6 name mandatory default possible values containerPortMappings no [node:lts-stretch:[[containerPort:9876, hostPort:9876]]] dockerEnvVars no [NO_PROXY:localhost,selenium,$NO_PROXY, no_proxy:localhost,selenium,$no_proxy] dockerImage no node:lts-stretch dockerName no karma dockerOptions no dockerWorkspace no /home/node failOnError no true , false installCommand no npm install --quiet modules no [.] runCommand no npm run karma script yes seleniumHubCredentialsId no sidecarEnvVars no [NO_PROXY:localhost,karma,$NO_PROXY, no_proxy:localhost,karma,$no_proxy] sidecarImage no sidecarName no sidecarVolumeBind no stashContent no [buildDescriptor, tests] containerPortMappings - Map which defines per docker image the port mappings, e.g. containerPortMappings: ['selenium/standalone-chrome': [[name: 'selPort', containerPort: 4444, hostPort: 4444]]] . dockerEnvVars - A map of environment variables to set in the container, e.g. [http_proxy:'proxy:8080']. dockerImage - The name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. dockerName - Kubernetes only: Name of the container launching dockerImage . SideCar only: Name of the container in local network. dockerOptions - Docker only: Docker options to be set when starting the container (List or String). dockerWorkspace - Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . failOnError - With failOnError the behavior in case tests fail can be defined. installCommand - The command that is executed to install the test tool. modules - Define the paths of the modules to execute tests on. runCommand - The command that is executed to start the tests. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. seleniumHubCredentialsId - Defines the id of the user/password credentials to be used to connect to a Selenium Hub. The credentials are provided in the environment variables PIPER_SELENIUM_HUB_USER and PIPER_SELENIUM_HUB_PASSWORD . sidecarEnvVars - A map of environment variables to set in the sidecar container, similar to dockerEnvVars . sidecarImage - The name of the docker image of the sidecar container. If empty, no sidecar container is started. sidecarName - as dockerName for the sidecar container sidecarVolumeBind - Volumes that should be mounted into the sidecar container. stashContent - If specific stashes should be considered for the tests, their names need to be passed via the parameter stashContent . Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage containerPortMappings X X dockerEnvVars X X dockerImage X X dockerName X X dockerOptions X X dockerWorkspace X X failOnError X X installCommand X X modules X X runCommand X X script seleniumHubCredentialsId X X sidecarEnvVars X X sidecarImage X X sidecarName X X sidecarVolumeBind X X stashContent X X Side effects \u00b6 Step uses seleniumExecuteTest & dockerExecute inside. Exceptions \u00b6 none Example \u00b6 karmaExecuteTests script: this , modules: [ './shoppinglist' , './catalog' ]","title":"karmaExecuteTests"},{"location":"steps/karmaExecuteTests/#karmaexecutetests","text":"","title":"karmaExecuteTests"},{"location":"steps/karmaExecuteTests/#description","text":"In this step the ( Karma test runner ) is executed. The step is using the seleniumExecuteTest step to spin up two containers in a Docker network: a Selenium/Chrome container ( selenium/standalone-chrome ) a NodeJS container ( node:lts-stretch ) In the Docker network, the containers can be referenced by the values provided in dockerName and sidecarName , the default values are karma and selenium . These values must be used in the hostname properties of the test configuration ( Karma and WebDriver ). Note In a Kubernetes environment, the containers both need to be referenced with localhost .","title":"Description"},{"location":"steps/karmaExecuteTests/#prerequisites","text":"running Karma tests - have a NPM module with running tests executed with Karma configured WebDriver - have the karma-webdriver-launcher package installed and a custom, WebDriver-based browser configured in Karma","title":"Prerequisites"},{"location":"steps/karmaExecuteTests/#dependencies","text":"The step depends on the following Jenkins plugins credentials-binding git pipeline-utility-steps workflow-basic-steps workflow-cps workflow-cps-global-lib workflow-durable-task-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/karmaExecuteTests/#parameters","text":"name mandatory default possible values containerPortMappings no [node:lts-stretch:[[containerPort:9876, hostPort:9876]]] dockerEnvVars no [NO_PROXY:localhost,selenium,$NO_PROXY, no_proxy:localhost,selenium,$no_proxy] dockerImage no node:lts-stretch dockerName no karma dockerOptions no dockerWorkspace no /home/node failOnError no true , false installCommand no npm install --quiet modules no [.] runCommand no npm run karma script yes seleniumHubCredentialsId no sidecarEnvVars no [NO_PROXY:localhost,karma,$NO_PROXY, no_proxy:localhost,karma,$no_proxy] sidecarImage no sidecarName no sidecarVolumeBind no stashContent no [buildDescriptor, tests] containerPortMappings - Map which defines per docker image the port mappings, e.g. containerPortMappings: ['selenium/standalone-chrome': [[name: 'selPort', containerPort: 4444, hostPort: 4444]]] . dockerEnvVars - A map of environment variables to set in the container, e.g. [http_proxy:'proxy:8080']. dockerImage - The name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. dockerName - Kubernetes only: Name of the container launching dockerImage . SideCar only: Name of the container in local network. dockerOptions - Docker only: Docker options to be set when starting the container (List or String). dockerWorkspace - Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . failOnError - With failOnError the behavior in case tests fail can be defined. installCommand - The command that is executed to install the test tool. modules - Define the paths of the modules to execute tests on. runCommand - The command that is executed to start the tests. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. seleniumHubCredentialsId - Defines the id of the user/password credentials to be used to connect to a Selenium Hub. The credentials are provided in the environment variables PIPER_SELENIUM_HUB_USER and PIPER_SELENIUM_HUB_PASSWORD . sidecarEnvVars - A map of environment variables to set in the sidecar container, similar to dockerEnvVars . sidecarImage - The name of the docker image of the sidecar container. If empty, no sidecar container is started. sidecarName - as dockerName for the sidecar container sidecarVolumeBind - Volumes that should be mounted into the sidecar container. stashContent - If specific stashes should be considered for the tests, their names need to be passed via the parameter stashContent .","title":"Parameters"},{"location":"steps/karmaExecuteTests/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage containerPortMappings X X dockerEnvVars X X dockerImage X X dockerName X X dockerOptions X X dockerWorkspace X X failOnError X X installCommand X X modules X X runCommand X X script seleniumHubCredentialsId X X sidecarEnvVars X X sidecarImage X X sidecarName X X sidecarVolumeBind X X stashContent X X","title":"Step configuration"},{"location":"steps/karmaExecuteTests/#side-effects","text":"Step uses seleniumExecuteTest & dockerExecute inside.","title":"Side effects"},{"location":"steps/karmaExecuteTests/#exceptions","text":"none","title":"Exceptions"},{"location":"steps/karmaExecuteTests/#example","text":"karmaExecuteTests script: this , modules: [ './shoppinglist' , './catalog' ]","title":"Example"},{"location":"steps/kubernetesDeploy/","text":"kubernetesDeploy \u00b6 Deployment to Kubernetes test or production namespace within the specified Kubernetes cluster. Description \u00b6 Deployment to Kubernetes test or production namespace within the specified Kubernetes cluster. Deployment supports multiple deployment tools Currently the following are supported: Helm command line tool and Helm Charts . kubectl and kubectl apply command. Helm \u00b6 Following helm command will be executed by default: helm upgrade <deploymentName> <chartPath> --install --force --namespace <namespace> --wait --timeout <helmDeployWaitSeconds> --set \"image.repository=<yourRegistry>/<yourImageName>,image.tag=<yourImageTag>,secret.dockerconfigjson=<dockerSecret>,ingress.hosts[0]=<ingressHosts[0]>,,ingress.hosts[1]=<ingressHosts[1]>,... yourRegistry will be retrieved from containerRegistryUrl yourImageName , yourImageTag will be retrieved from image dockerSecret will be calculated with a call to kubectl create secret docker-registry regsecret --docker-server=<yourRegistry> --docker-username=<containerRegistryUser> --docker-password=<containerRegistryPassword> --dry-run=true --output=json' Usage \u00b6 We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line . Jenkins pipelines \u00b6 kubernetesDeploy script: this Command line \u00b6 piper kubernetesDeploy Parameters \u00b6 Overview \u00b6 Name Mandatory Additional information chartPath yes containerRegistryUrl yes deployTool yes deploymentName yes dockerCredentialsId yes id of credentials ( using credentials ) image yes kubeConfigFileCredentialsId yes id of credentials ( using credentials ) kubeTokenCredentialsId yes id of credentials ( using credentials ) script yes reference to Jenkins main pipeline script additionalParameters no apiServer no appTemplate no containerCommand no containerRegistryPassword no pass via ENV or Jenkins credentials containerRegistrySecret no containerRegistryUser no pass via ENV or Jenkins credentials containerShell no createDockerRegistrySecret no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no dockerVolumeBind no dockerWorkspace no helmDeployWaitSeconds no helmValues no ingressHosts no kubeConfig no kubeContext no kubeToken no pass via ENV or Jenkins credentials namespace no stashContent no tillerNamespace no verbose no activates debug output Details \u00b6 additionalParameters \u00b6 Defines additional parameters for \\\"helm install\\\" or \\\"kubectl apply\\\" command. back to overview Scope Details Aliases helmDeploymentParameters Type []string Mandatory no Default $PIPER_additionalParameters (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none apiServer \u00b6 Defines the Url of the API Server of the Kubernetes cluster. back to overview Scope Details Aliases k8sAPIServer Type string Mandatory no Default $PIPER_apiServer (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none appTemplate \u00b6 Defines the filename for the kubernetes app template (e.g. k8s_apptemplate.yaml) back to overview Scope Details Aliases k8sAppTemplate Type string Mandatory no Default $PIPER_appTemplate (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none chartPath \u00b6 Defines the chart path for deployments using helm. back to overview Scope Details Aliases helmChartPath Type string Mandatory yes Default $PIPER_chartPath (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none containerCommand \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default (/usr/bin/tail -f /dev/null). back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none containerRegistryPassword \u00b6 Password for container registry access - typically provided by the CI/CD environment. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_containerRegistryPassword (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none containerRegistrySecret \u00b6 Name of the container registry secret used for pulling containers from the registry. For deployTool: helm/helm3 : If containerRegistryUser and containerRegistryPassword are provided, a secret is created on the fly and the information is passed to the helm template. Note: the secret will not be persisted in the Kubernetes cluster. If neither containerRegistryUser nor containerRegistryPassword are provided, it is expected that a secret with the configured name exists in the target Kubernetes cluster. For deployTool: kubectl : If createDockerRegistrySecret: true and containerRegistryUser and containerRegistryPassword are provided, a secret with the given name will be created in the Kubernetes cluster unless a secret with the name already exists. back to overview Scope Details Aliases - Type string Mandatory no Default regsecret Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none containerRegistryUrl \u00b6 http(s) url of the Container registry where the image to deploy is located. back to overview Scope Details Aliases dockerRegistryUrl Type string Mandatory yes Default $PIPER_containerRegistryUrl (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references commonPipelineEnvironment : reference to: container/registryUrl containerRegistryUser \u00b6 Username for container registry access - typically provided by the CI/CD environment. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_containerRegistryUser (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none containerShell \u00b6 Jenkins-specific: Used for proper environment setup. Allows to specify the shell to be executed for container with containerName. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none createDockerRegistrySecret \u00b6 Only for deployTool:kubectl : Toggle to turn on containerRegistrySecret creation. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none deployTool \u00b6 Defines the tool which should be used for deployment. back to overview Scope Details Aliases - Type string Mandatory no Default kubectl Possible values - kubectl - helm - helm3 Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none deploymentName \u00b6 Defines the name of the deployment. back to overview Scope Details Aliases helmDeploymentName Type string Mandatory yes Default $PIPER_deploymentName (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none dockerCredentialsId \u00b6 Jenkins-specific: Used for proper environment setup. back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerEnvVars \u00b6 Jenkins-specific: Used for proper environment setup. Environment variables to set in the container, e.g. [http_proxy: \"proxy:8080\"]. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerImage \u00b6 Jenkins-specific: Used for proper environment setup. Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. back to overview Scope Details Aliases - Type string Mandatory no Default deployTool= helm3 : dtzar/helm-kubectl:3.1.2 deployTool= helm : dtzar/helm-kubectl:2.12.1 deployTool= kubectl : dtzar/helm-kubectl:2.12.1 Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerName \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Name of the container launching dockerImage. SideCar only: Name of the container in local network. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerOptions \u00b6 Jenkins-specific: Used for proper environment setup. Docker options to be set when starting the container. back to overview Scope Details Aliases - Type []string Mandatory no Default deployTool= helm3 : [{-u 0}] deployTool= helm : [{-u 0}] deployTool= kubectl : [{-u 0}] Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerPullImage \u00b6 Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default deployTool= helm3 : true deployTool= helm : true deployTool= kubectl : true Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerVolumeBind \u00b6 Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the docker container. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerWorkspace \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . back to overview Scope Details Aliases - Type string Mandatory no Default deployTool= helm3 : /config deployTool= helm : /config deployTool= kubectl : /config Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none helmDeployWaitSeconds \u00b6 Number of seconds before helm deploy returns. back to overview Scope Details Aliases - Type int Mandatory no Default 300 Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none helmValues \u00b6 List of helm values as YAML file reference or URL (as per helm parameter description for -f / --values ) back to overview Scope Details Aliases - Type []string Mandatory no Default $PIPER_helmValues (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none image \u00b6 Full name of the image to be deployed. back to overview Scope Details Aliases deployImage Type string Mandatory yes Default $PIPER_image (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references commonPipelineEnvironment : reference to: container/imageNameTag ingressHosts \u00b6 DEPRECATED List of ingress hosts to be exposed via helm deployment. Host names are passed to helm template via ingress configuration. This requires a modification to the default helm template, thus it is not recommended. Recommendation is to use custom values and pass them via parameter helmValues . Since helm supports multiple files on top of the values.yaml , landscape-specific attributes can be passed via a specific file. back to overview Scope Details Aliases - Type []string Mandatory no Default $PIPER_ingressHosts (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none kubeConfig \u00b6 Defines the path to the \\\"kubeconfig\\\" file. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_kubeConfig (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none kubeConfigFileCredentialsId \u00b6 Jenkins-specific: Used for proper environment setup. back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none kubeContext \u00b6 Defines the context to use from the \\\"kubeconfig\\\" file. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_kubeContext (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none kubeToken \u00b6 Contains the id_token used by kubectl for authentication. Consider using kubeConfig parameter instead. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_kubeToken (if set) Secret yes Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none kubeTokenCredentialsId \u00b6 Jenkins-specific: Used for proper environment setup. back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none namespace \u00b6 Defines the target Kubernetes namespace for the deployment. back to overview Scope Details Aliases - helmDeploymentNamespace - k8sDeploymentNamespace Type string Mandatory no Default default Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none script \u00b6 Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none stashContent \u00b6 Jenkins-specific: Used for proper environment setup. Specific stashes that should be considered for the step execution. back to overview Scope Details Aliases - Type []string Mandatory no Default - deployDescriptor Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none tillerNamespace \u00b6 Defines optional tiller namespace for deployments using helm. back to overview Scope Details Aliases helmTillerNamespace Type string Mandatory no Default $PIPER_tillerNamespace (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none verbose \u00b6 verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none \u00b6 Exceptions \u00b6 None Examples \u00b6 kubernetesDeploy script: this // Deploy a helm chart called \"myChart\" using Helm 3 kubernetesDeploy script: this , deployTool: 'helm3' , chartPath: 'myChart' , deploymentName: 'myRelease' , image: 'nginx' , containerRegistryUrl: 'https://docker.io'","title":"kubernetesDeploy"},{"location":"steps/kubernetesDeploy/#kubernetesdeploy","text":"Deployment to Kubernetes test or production namespace within the specified Kubernetes cluster.","title":"kubernetesDeploy"},{"location":"steps/kubernetesDeploy/#description","text":"Deployment to Kubernetes test or production namespace within the specified Kubernetes cluster. Deployment supports multiple deployment tools Currently the following are supported: Helm command line tool and Helm Charts . kubectl and kubectl apply command.","title":"Description"},{"location":"steps/kubernetesDeploy/#helm","text":"Following helm command will be executed by default: helm upgrade <deploymentName> <chartPath> --install --force --namespace <namespace> --wait --timeout <helmDeployWaitSeconds> --set \"image.repository=<yourRegistry>/<yourImageName>,image.tag=<yourImageTag>,secret.dockerconfigjson=<dockerSecret>,ingress.hosts[0]=<ingressHosts[0]>,,ingress.hosts[1]=<ingressHosts[1]>,... yourRegistry will be retrieved from containerRegistryUrl yourImageName , yourImageTag will be retrieved from image dockerSecret will be calculated with a call to kubectl create secret docker-registry regsecret --docker-server=<yourRegistry> --docker-username=<containerRegistryUser> --docker-password=<containerRegistryPassword> --dry-run=true --output=json'","title":"Helm"},{"location":"steps/kubernetesDeploy/#usage","text":"We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line .","title":"Usage"},{"location":"steps/kubernetesDeploy/#jenkins-pipelines","text":"kubernetesDeploy script: this","title":"Jenkins pipelines"},{"location":"steps/kubernetesDeploy/#command-line","text":"piper kubernetesDeploy","title":"Command line"},{"location":"steps/kubernetesDeploy/#parameters","text":"","title":"Parameters"},{"location":"steps/kubernetesDeploy/#overview","text":"Name Mandatory Additional information chartPath yes containerRegistryUrl yes deployTool yes deploymentName yes dockerCredentialsId yes id of credentials ( using credentials ) image yes kubeConfigFileCredentialsId yes id of credentials ( using credentials ) kubeTokenCredentialsId yes id of credentials ( using credentials ) script yes reference to Jenkins main pipeline script additionalParameters no apiServer no appTemplate no containerCommand no containerRegistryPassword no pass via ENV or Jenkins credentials containerRegistrySecret no containerRegistryUser no pass via ENV or Jenkins credentials containerShell no createDockerRegistrySecret no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no dockerVolumeBind no dockerWorkspace no helmDeployWaitSeconds no helmValues no ingressHosts no kubeConfig no kubeContext no kubeToken no pass via ENV or Jenkins credentials namespace no stashContent no tillerNamespace no verbose no activates debug output","title":"Overview"},{"location":"steps/kubernetesDeploy/#details","text":"","title":"Details"},{"location":"steps/kubernetesDeploy/#additionalparameters","text":"Defines additional parameters for \\\"helm install\\\" or \\\"kubectl apply\\\" command. back to overview Scope Details Aliases helmDeploymentParameters Type []string Mandatory no Default $PIPER_additionalParameters (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"additionalParameters"},{"location":"steps/kubernetesDeploy/#apiserver","text":"Defines the Url of the API Server of the Kubernetes cluster. back to overview Scope Details Aliases k8sAPIServer Type string Mandatory no Default $PIPER_apiServer (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"apiServer"},{"location":"steps/kubernetesDeploy/#apptemplate","text":"Defines the filename for the kubernetes app template (e.g. k8s_apptemplate.yaml) back to overview Scope Details Aliases k8sAppTemplate Type string Mandatory no Default $PIPER_appTemplate (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"appTemplate"},{"location":"steps/kubernetesDeploy/#chartpath","text":"Defines the chart path for deployments using helm. back to overview Scope Details Aliases helmChartPath Type string Mandatory yes Default $PIPER_chartPath (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"chartPath"},{"location":"steps/kubernetesDeploy/#containercommand","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default (/usr/bin/tail -f /dev/null). back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"containerCommand"},{"location":"steps/kubernetesDeploy/#containerregistrypassword","text":"Password for container registry access - typically provided by the CI/CD environment. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_containerRegistryPassword (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"containerRegistryPassword"},{"location":"steps/kubernetesDeploy/#containerregistrysecret","text":"Name of the container registry secret used for pulling containers from the registry. For deployTool: helm/helm3 : If containerRegistryUser and containerRegistryPassword are provided, a secret is created on the fly and the information is passed to the helm template. Note: the secret will not be persisted in the Kubernetes cluster. If neither containerRegistryUser nor containerRegistryPassword are provided, it is expected that a secret with the configured name exists in the target Kubernetes cluster. For deployTool: kubectl : If createDockerRegistrySecret: true and containerRegistryUser and containerRegistryPassword are provided, a secret with the given name will be created in the Kubernetes cluster unless a secret with the name already exists. back to overview Scope Details Aliases - Type string Mandatory no Default regsecret Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"containerRegistrySecret"},{"location":"steps/kubernetesDeploy/#containerregistryurl","text":"http(s) url of the Container registry where the image to deploy is located. back to overview Scope Details Aliases dockerRegistryUrl Type string Mandatory yes Default $PIPER_containerRegistryUrl (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references commonPipelineEnvironment : reference to: container/registryUrl","title":"containerRegistryUrl"},{"location":"steps/kubernetesDeploy/#containerregistryuser","text":"Username for container registry access - typically provided by the CI/CD environment. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_containerRegistryUser (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"containerRegistryUser"},{"location":"steps/kubernetesDeploy/#containershell","text":"Jenkins-specific: Used for proper environment setup. Allows to specify the shell to be executed for container with containerName. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"containerShell"},{"location":"steps/kubernetesDeploy/#createdockerregistrysecret","text":"Only for deployTool:kubectl : Toggle to turn on containerRegistrySecret creation. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"createDockerRegistrySecret"},{"location":"steps/kubernetesDeploy/#deploytool","text":"Defines the tool which should be used for deployment. back to overview Scope Details Aliases - Type string Mandatory no Default kubectl Possible values - kubectl - helm - helm3 Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"deployTool"},{"location":"steps/kubernetesDeploy/#deploymentname","text":"Defines the name of the deployment. back to overview Scope Details Aliases helmDeploymentName Type string Mandatory yes Default $PIPER_deploymentName (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"deploymentName"},{"location":"steps/kubernetesDeploy/#dockercredentialsid","text":"Jenkins-specific: Used for proper environment setup. back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerCredentialsId"},{"location":"steps/kubernetesDeploy/#dockerenvvars","text":"Jenkins-specific: Used for proper environment setup. Environment variables to set in the container, e.g. [http_proxy: \"proxy:8080\"]. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerEnvVars"},{"location":"steps/kubernetesDeploy/#dockerimage","text":"Jenkins-specific: Used for proper environment setup. Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. back to overview Scope Details Aliases - Type string Mandatory no Default deployTool= helm3 : dtzar/helm-kubectl:3.1.2 deployTool= helm : dtzar/helm-kubectl:2.12.1 deployTool= kubectl : dtzar/helm-kubectl:2.12.1 Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerImage"},{"location":"steps/kubernetesDeploy/#dockername","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Name of the container launching dockerImage. SideCar only: Name of the container in local network. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerName"},{"location":"steps/kubernetesDeploy/#dockeroptions","text":"Jenkins-specific: Used for proper environment setup. Docker options to be set when starting the container. back to overview Scope Details Aliases - Type []string Mandatory no Default deployTool= helm3 : [{-u 0}] deployTool= helm : [{-u 0}] deployTool= kubectl : [{-u 0}] Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerOptions"},{"location":"steps/kubernetesDeploy/#dockerpullimage","text":"Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default deployTool= helm3 : true deployTool= helm : true deployTool= kubectl : true Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerPullImage"},{"location":"steps/kubernetesDeploy/#dockervolumebind","text":"Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the docker container. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerVolumeBind"},{"location":"steps/kubernetesDeploy/#dockerworkspace","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . back to overview Scope Details Aliases - Type string Mandatory no Default deployTool= helm3 : /config deployTool= helm : /config deployTool= kubectl : /config Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerWorkspace"},{"location":"steps/kubernetesDeploy/#helmdeploywaitseconds","text":"Number of seconds before helm deploy returns. back to overview Scope Details Aliases - Type int Mandatory no Default 300 Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"helmDeployWaitSeconds"},{"location":"steps/kubernetesDeploy/#helmvalues","text":"List of helm values as YAML file reference or URL (as per helm parameter description for -f / --values ) back to overview Scope Details Aliases - Type []string Mandatory no Default $PIPER_helmValues (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"helmValues"},{"location":"steps/kubernetesDeploy/#image","text":"Full name of the image to be deployed. back to overview Scope Details Aliases deployImage Type string Mandatory yes Default $PIPER_image (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references commonPipelineEnvironment : reference to: container/imageNameTag","title":"image"},{"location":"steps/kubernetesDeploy/#ingresshosts","text":"DEPRECATED List of ingress hosts to be exposed via helm deployment. Host names are passed to helm template via ingress configuration. This requires a modification to the default helm template, thus it is not recommended. Recommendation is to use custom values and pass them via parameter helmValues . Since helm supports multiple files on top of the values.yaml , landscape-specific attributes can be passed via a specific file. back to overview Scope Details Aliases - Type []string Mandatory no Default $PIPER_ingressHosts (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"ingressHosts"},{"location":"steps/kubernetesDeploy/#kubeconfig","text":"Defines the path to the \\\"kubeconfig\\\" file. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_kubeConfig (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"kubeConfig"},{"location":"steps/kubernetesDeploy/#kubeconfigfilecredentialsid","text":"Jenkins-specific: Used for proper environment setup. back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"kubeConfigFileCredentialsId"},{"location":"steps/kubernetesDeploy/#kubecontext","text":"Defines the context to use from the \\\"kubeconfig\\\" file. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_kubeContext (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"kubeContext"},{"location":"steps/kubernetesDeploy/#kubetoken","text":"Contains the id_token used by kubectl for authentication. Consider using kubeConfig parameter instead. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_kubeToken (if set) Secret yes Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"kubeToken"},{"location":"steps/kubernetesDeploy/#kubetokencredentialsid","text":"Jenkins-specific: Used for proper environment setup. back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"kubeTokenCredentialsId"},{"location":"steps/kubernetesDeploy/#namespace","text":"Defines the target Kubernetes namespace for the deployment. back to overview Scope Details Aliases - helmDeploymentNamespace - k8sDeploymentNamespace Type string Mandatory no Default default Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"namespace"},{"location":"steps/kubernetesDeploy/#script","text":"Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none","title":"script"},{"location":"steps/kubernetesDeploy/#stashcontent","text":"Jenkins-specific: Used for proper environment setup. Specific stashes that should be considered for the step execution. back to overview Scope Details Aliases - Type []string Mandatory no Default - deployDescriptor Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"stashContent"},{"location":"steps/kubernetesDeploy/#tillernamespace","text":"Defines optional tiller namespace for deployments using helm. back to overview Scope Details Aliases helmTillerNamespace Type string Mandatory no Default $PIPER_tillerNamespace (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"tillerNamespace"},{"location":"steps/kubernetesDeploy/#verbose","text":"verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"verbose"},{"location":"steps/kubernetesDeploy/#exceptions","text":"None","title":"Exceptions"},{"location":"steps/kubernetesDeploy/#examples","text":"kubernetesDeploy script: this // Deploy a helm chart called \"myChart\" using Helm 3 kubernetesDeploy script: this , deployTool: 'helm3' , chartPath: 'myChart' , deploymentName: 'myRelease' , image: 'nginx' , containerRegistryUrl: 'https://docker.io'","title":"Examples"},{"location":"steps/mailSendNotification/","text":"mailSendNotification \u00b6 Description \u00b6 Sends notifications to all potential culprits of a current or previous build failure and to fixed list of recipients. It will attach the current build log to the email. Notifications are sent in following cases: current build failed or is unstable current build is successful and previous build failed or was unstable Prerequisites \u00b6 none Example \u00b6 Usage of pipeline step: mailSendNotification script: this Parameters \u00b6 name mandatory default possible values buildResult no gitCommitId no gitSshKeyCredentialsId no `` Jenkins credentials id gitUrl no notificationAttachment no true true , false notificationRecipients no notifyCulprits no true true , false numLogLinesInBody no 100 projectName no script yes wrapInNode no false true , false buildResult - Set the build result used to determine the mail template. default currentBuild.result gitCommitId - Only if notifyCulprits is set: Defines a dedicated git commitId for culprit retrieval. default commonPipelineEnvironment.getGitCommitId() gitSshKeyCredentialsId - Only if notifyCulprits is set: Credentials if the repository is protected. gitUrl - Only if notifyCulprits is set: Repository url used to retrieve culprit information. default commonPipelineEnvironment.getGitSshUrl() notificationAttachment - defines if the console log file should be attached to the notification mail. notificationRecipients - A space-separated list of recipients that always get the notification. notifyCulprits - Notify all committers since the last successful build. numLogLinesInBody - Number of log line which are included in the email body. projectName - The project name used in the email subject. default currentBuild.fullProjectName script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. wrapInNode - Needs to be set to true if step is used outside of a node context, e.g. post actions in a declarative pipeline script. default false Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage buildResult X gitCommitId X gitSshKeyCredentialsId X X gitUrl X notificationAttachment X notificationRecipients X notifyCulprits X numLogLinesInBody X projectName X script wrapInNode X Dependencies \u00b6 The step depends on the following Jenkins plugins email-ext pipeline-utility-steps ssh-agent workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Side effects \u00b6 none Exceptions \u00b6 none","title":"mailSendNotification"},{"location":"steps/mailSendNotification/#mailsendnotification","text":"","title":"mailSendNotification"},{"location":"steps/mailSendNotification/#description","text":"Sends notifications to all potential culprits of a current or previous build failure and to fixed list of recipients. It will attach the current build log to the email. Notifications are sent in following cases: current build failed or is unstable current build is successful and previous build failed or was unstable","title":"Description"},{"location":"steps/mailSendNotification/#prerequisites","text":"none","title":"Prerequisites"},{"location":"steps/mailSendNotification/#example","text":"Usage of pipeline step: mailSendNotification script: this","title":"Example"},{"location":"steps/mailSendNotification/#parameters","text":"name mandatory default possible values buildResult no gitCommitId no gitSshKeyCredentialsId no `` Jenkins credentials id gitUrl no notificationAttachment no true true , false notificationRecipients no notifyCulprits no true true , false numLogLinesInBody no 100 projectName no script yes wrapInNode no false true , false buildResult - Set the build result used to determine the mail template. default currentBuild.result gitCommitId - Only if notifyCulprits is set: Defines a dedicated git commitId for culprit retrieval. default commonPipelineEnvironment.getGitCommitId() gitSshKeyCredentialsId - Only if notifyCulprits is set: Credentials if the repository is protected. gitUrl - Only if notifyCulprits is set: Repository url used to retrieve culprit information. default commonPipelineEnvironment.getGitSshUrl() notificationAttachment - defines if the console log file should be attached to the notification mail. notificationRecipients - A space-separated list of recipients that always get the notification. notifyCulprits - Notify all committers since the last successful build. numLogLinesInBody - Number of log line which are included in the email body. projectName - The project name used in the email subject. default currentBuild.fullProjectName script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. wrapInNode - Needs to be set to true if step is used outside of a node context, e.g. post actions in a declarative pipeline script. default false","title":"Parameters"},{"location":"steps/mailSendNotification/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage buildResult X gitCommitId X gitSshKeyCredentialsId X X gitUrl X notificationAttachment X notificationRecipients X notifyCulprits X numLogLinesInBody X projectName X script wrapInNode X","title":"Step configuration"},{"location":"steps/mailSendNotification/#dependencies","text":"The step depends on the following Jenkins plugins email-ext pipeline-utility-steps ssh-agent workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/mailSendNotification/#side-effects","text":"none","title":"Side effects"},{"location":"steps/mailSendNotification/#exceptions","text":"none","title":"Exceptions"},{"location":"steps/malwareExecuteScan/","text":"malwareExecuteScan \u00b6 Performs a malware scan Parameters \u00b6 Overview \u00b6 Name Mandatory Additional information file yes host yes malwareScanCredentialsId yes id of credentials ( using credentials ) password yes pass via ENV or Jenkins credentials script yes reference to Jenkins main pipeline script username yes pass via ENV or Jenkins credentials timeout no verbose no activates debug output Details \u00b6 file \u00b6 The file which is scanned for malware back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_file (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none host \u00b6 malware scanning host. back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_host (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none malwareScanCredentialsId \u00b6 Jenkins-specific: Used for proper environment setup. The technical user/password credential used to communicate with the malwarescanning service back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none password \u00b6 Password back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_password (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none script \u00b6 Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none timeout \u00b6 timeout for http layer in seconds back to overview Scope Details Aliases - Type string Mandatory no Default 600 Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none username \u00b6 User back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_username (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none verbose \u00b6 verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none \u00b6 Exceptions \u00b6 None Examples \u00b6 malwareExecuteScan script: this configuration steps: malwareExecuteScan: file: myFile.zip host: https://malwarescanner.example.sap.com malwareScanCredentialsId: MALWARESCAN","title":"malwareExecuteScan"},{"location":"steps/malwareExecuteScan/#malwareexecutescan","text":"Performs a malware scan","title":"malwareExecuteScan"},{"location":"steps/malwareExecuteScan/#parameters","text":"","title":"Parameters"},{"location":"steps/malwareExecuteScan/#overview","text":"Name Mandatory Additional information file yes host yes malwareScanCredentialsId yes id of credentials ( using credentials ) password yes pass via ENV or Jenkins credentials script yes reference to Jenkins main pipeline script username yes pass via ENV or Jenkins credentials timeout no verbose no activates debug output","title":"Overview"},{"location":"steps/malwareExecuteScan/#details","text":"","title":"Details"},{"location":"steps/malwareExecuteScan/#file","text":"The file which is scanned for malware back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_file (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"file"},{"location":"steps/malwareExecuteScan/#host","text":"malware scanning host. back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_host (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"host"},{"location":"steps/malwareExecuteScan/#malwarescancredentialsid","text":"Jenkins-specific: Used for proper environment setup. The technical user/password credential used to communicate with the malwarescanning service back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"malwareScanCredentialsId"},{"location":"steps/malwareExecuteScan/#password","text":"Password back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_password (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"password"},{"location":"steps/malwareExecuteScan/#script","text":"Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none","title":"script"},{"location":"steps/malwareExecuteScan/#timeout","text":"timeout for http layer in seconds back to overview Scope Details Aliases - Type string Mandatory no Default 600 Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"timeout"},{"location":"steps/malwareExecuteScan/#username","text":"User back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_username (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"username"},{"location":"steps/malwareExecuteScan/#verbose","text":"verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"verbose"},{"location":"steps/malwareExecuteScan/#exceptions","text":"None","title":"Exceptions"},{"location":"steps/malwareExecuteScan/#examples","text":"malwareExecuteScan script: this configuration steps: malwareExecuteScan: file: myFile.zip host: https://malwarescanner.example.sap.com malwareScanCredentialsId: MALWARESCAN","title":"Examples"},{"location":"steps/mavenBuild/","text":"mavenBuild \u00b6 This step will install the maven project into the local maven repository. Description \u00b6 This step will install the maven project into the local maven repository. It will also prepare jacoco to record the code coverage and supports ci friendly versioning by flattening the pom before installing. Usage \u00b6 We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line . Jenkins pipelines \u00b6 mavenBuild script: this Command line \u00b6 piper mavenBuild Parameters \u00b6 Overview \u00b6 Name Mandatory Additional information script yes reference to Jenkins main pipeline script containerCommand no containerShell no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no dockerVolumeBind no dockerWorkspace no flatten no globalSettingsFile no logSuccessfulMavenTransfers no m2Path no pomPath no projectSettingsFile no verbose no activates debug output verify no Details \u00b6 containerCommand \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default (/usr/bin/tail -f /dev/null). back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none containerShell \u00b6 Jenkins-specific: Used for proper environment setup. Allows to specify the shell to be executed for container with containerName. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerEnvVars \u00b6 Jenkins-specific: Used for proper environment setup. Environment variables to set in the container, e.g. [http_proxy: \"proxy:8080\"]. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerImage \u00b6 Jenkins-specific: Used for proper environment setup. Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerName \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Name of the container launching dockerImage. SideCar only: Name of the container in local network. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerOptions \u00b6 Jenkins-specific: Used for proper environment setup. Docker options to be set when starting the container. back to overview Scope Details Aliases - Type []string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerPullImage \u00b6 Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerVolumeBind \u00b6 Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the docker container. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerWorkspace \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none flatten \u00b6 Defines if the pom files should be flattened to support ci friendly maven versioning. back to overview Scope Details Aliases - Type bool Mandatory no Default true Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2610 steps \u2610 stages Resource references none globalSettingsFile \u00b6 Path to the mvn settings file that should be used as global settings file. back to overview Scope Details Aliases maven/globalSettingsFile Type string Mandatory no Default $PIPER_globalSettingsFile (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none logSuccessfulMavenTransfers \u00b6 Configures maven to log successful downloads. This is set to false by default to reduce the noise in build logs. back to overview Scope Details Aliases maven/logSuccessfulMavenTransfers Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none m2Path \u00b6 Path to the location of the local repository that should be used. back to overview Scope Details Aliases maven/m2Path Type string Mandatory no Default $PIPER_m2Path (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none pomPath \u00b6 Path to the pom file which should be installed including all children. back to overview Scope Details Aliases - Type string Mandatory no Default pom.xml Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2610 stages Resource references none projectSettingsFile \u00b6 Path to the mvn settings file that should be used as project settings file. back to overview Scope Details Aliases maven/projectSettingsFile Type string Mandatory no Default $PIPER_projectSettingsFile (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none script \u00b6 Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none verbose \u00b6 verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none verify \u00b6 Instead of installing the artifact only the verify lifecycle phase is executed. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2610 steps \u2610 stages Resource references none \u00b6","title":"mavenBuild"},{"location":"steps/mavenBuild/#mavenbuild","text":"This step will install the maven project into the local maven repository.","title":"mavenBuild"},{"location":"steps/mavenBuild/#description","text":"This step will install the maven project into the local maven repository. It will also prepare jacoco to record the code coverage and supports ci friendly versioning by flattening the pom before installing.","title":"Description"},{"location":"steps/mavenBuild/#usage","text":"We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line .","title":"Usage"},{"location":"steps/mavenBuild/#jenkins-pipelines","text":"mavenBuild script: this","title":"Jenkins pipelines"},{"location":"steps/mavenBuild/#command-line","text":"piper mavenBuild","title":"Command line"},{"location":"steps/mavenBuild/#parameters","text":"","title":"Parameters"},{"location":"steps/mavenBuild/#overview","text":"Name Mandatory Additional information script yes reference to Jenkins main pipeline script containerCommand no containerShell no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no dockerVolumeBind no dockerWorkspace no flatten no globalSettingsFile no logSuccessfulMavenTransfers no m2Path no pomPath no projectSettingsFile no verbose no activates debug output verify no","title":"Overview"},{"location":"steps/mavenBuild/#details","text":"","title":"Details"},{"location":"steps/mavenBuild/#containercommand","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default (/usr/bin/tail -f /dev/null). back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"containerCommand"},{"location":"steps/mavenBuild/#containershell","text":"Jenkins-specific: Used for proper environment setup. Allows to specify the shell to be executed for container with containerName. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"containerShell"},{"location":"steps/mavenBuild/#dockerenvvars","text":"Jenkins-specific: Used for proper environment setup. Environment variables to set in the container, e.g. [http_proxy: \"proxy:8080\"]. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerEnvVars"},{"location":"steps/mavenBuild/#dockerimage","text":"Jenkins-specific: Used for proper environment setup. Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerImage"},{"location":"steps/mavenBuild/#dockername","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Name of the container launching dockerImage. SideCar only: Name of the container in local network. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerName"},{"location":"steps/mavenBuild/#dockeroptions","text":"Jenkins-specific: Used for proper environment setup. Docker options to be set when starting the container. back to overview Scope Details Aliases - Type []string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerOptions"},{"location":"steps/mavenBuild/#dockerpullimage","text":"Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerPullImage"},{"location":"steps/mavenBuild/#dockervolumebind","text":"Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the docker container. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerVolumeBind"},{"location":"steps/mavenBuild/#dockerworkspace","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerWorkspace"},{"location":"steps/mavenBuild/#flatten","text":"Defines if the pom files should be flattened to support ci friendly maven versioning. back to overview Scope Details Aliases - Type bool Mandatory no Default true Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2610 steps \u2610 stages Resource references none","title":"flatten"},{"location":"steps/mavenBuild/#globalsettingsfile","text":"Path to the mvn settings file that should be used as global settings file. back to overview Scope Details Aliases maven/globalSettingsFile Type string Mandatory no Default $PIPER_globalSettingsFile (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"globalSettingsFile"},{"location":"steps/mavenBuild/#logsuccessfulmaventransfers","text":"Configures maven to log successful downloads. This is set to false by default to reduce the noise in build logs. back to overview Scope Details Aliases maven/logSuccessfulMavenTransfers Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"logSuccessfulMavenTransfers"},{"location":"steps/mavenBuild/#m2path","text":"Path to the location of the local repository that should be used. back to overview Scope Details Aliases maven/m2Path Type string Mandatory no Default $PIPER_m2Path (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"m2Path"},{"location":"steps/mavenBuild/#pompath","text":"Path to the pom file which should be installed including all children. back to overview Scope Details Aliases - Type string Mandatory no Default pom.xml Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2610 stages Resource references none","title":"pomPath"},{"location":"steps/mavenBuild/#projectsettingsfile","text":"Path to the mvn settings file that should be used as project settings file. back to overview Scope Details Aliases maven/projectSettingsFile Type string Mandatory no Default $PIPER_projectSettingsFile (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"projectSettingsFile"},{"location":"steps/mavenBuild/#script","text":"Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none","title":"script"},{"location":"steps/mavenBuild/#verbose","text":"verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"verbose"},{"location":"steps/mavenBuild/#verify","text":"Instead of installing the artifact only the verify lifecycle phase is executed. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2610 steps \u2610 stages Resource references none","title":"verify"},{"location":"steps/mavenExecute/","text":"mavenExecute \u00b6 This step allows to run maven commands Description \u00b6 This step runs a maven command based on the parameters provided to the step. Usage \u00b6 We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line . Jenkins pipelines \u00b6 mavenExecute script: this Command line \u00b6 piper mavenExecute Parameters \u00b6 Overview \u00b6 Name Mandatory Additional information goals yes script yes reference to Jenkins main pipeline script containerCommand no containerShell no defines no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no dockerVolumeBind no dockerWorkspace no flags no globalSettingsFile no logSuccessfulMavenTransfers no m2Path no pomPath no projectSettingsFile no returnStdout no verbose no activates debug output Details \u00b6 containerCommand \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default (/usr/bin/tail -f /dev/null). back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none containerShell \u00b6 Jenkins-specific: Used for proper environment setup. Allows to specify the shell to be executed for container with containerName. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none defines \u00b6 Additional properties in form of -Dkey=value. back to overview Scope Details Aliases - Type []string Mandatory no Default $PIPER_defines (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2610 steps \u2610 stages Resource references none dockerEnvVars \u00b6 Jenkins-specific: Used for proper environment setup. Environment variables to set in the container, e.g. [http_proxy: \"proxy:8080\"]. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerImage \u00b6 Jenkins-specific: Used for proper environment setup. Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerName \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Name of the container launching dockerImage. SideCar only: Name of the container in local network. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerOptions \u00b6 Jenkins-specific: Used for proper environment setup. Docker options to be set when starting the container. back to overview Scope Details Aliases - Type []string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerPullImage \u00b6 Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerVolumeBind \u00b6 Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the docker container. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerWorkspace \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none flags \u00b6 Flags to provide when running mvn. back to overview Scope Details Aliases - Type []string Mandatory no Default $PIPER_flags (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2610 stages Resource references none globalSettingsFile \u00b6 Path to the mvn settings file that should be used as global settings file. back to overview Scope Details Aliases maven/globalSettingsFile Type string Mandatory no Default $PIPER_globalSettingsFile (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none goals \u00b6 Maven goals that should be executed. back to overview Scope Details Aliases - Type []string Mandatory yes Default $PIPER_goals (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2610 steps \u2610 stages Resource references none logSuccessfulMavenTransfers \u00b6 Configures maven to log successful downloads. This is set to false by default to reduce the noise in build logs. back to overview Scope Details Aliases maven/logSuccessfulMavenTransfers Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none m2Path \u00b6 Path to the location of the local repository that should be used. back to overview Scope Details Aliases maven/m2Path Type string Mandatory no Default $PIPER_m2Path (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none pomPath \u00b6 Path to the pom file that should be used. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_pomPath (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2610 stages Resource references none projectSettingsFile \u00b6 Path to the mvn settings file that should be used as project settings file. back to overview Scope Details Aliases maven/projectSettingsFile Type string Mandatory no Default $PIPER_projectSettingsFile (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none returnStdout \u00b6 Returns the output of the maven command for further processing. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2610 steps \u2610 stages Resource references none script \u00b6 Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none verbose \u00b6 verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none Breaking change in goals , defines and flags parameters The goals , defines and flags parameters of the step need to be lists of strings with each element being one item. As an example consider this diff, showing the old api deleted and the new api inserted: -goals: 'org.apache.maven.plugins:maven-help-plugin:3.1.0:evaluate', -defines: \"-Dexpression=$pomPathExpression -DforceStdout -q\", +goals: ['org.apache.maven.plugins:maven-help-plugin:3.1.0:evaluate'], +defines: [\"-Dexpression=$pomPathExpression\", \"-DforceStdout\", \"-q\"], Additionally please note that in the parameters must not be shell quoted/escaped . What you pass in is literally passed to Maven without any shell interpreter inbetween. The old behavior is still available in version v1.23.0 and before of project \"Piper\". \u00b6 Exceptions \u00b6 None Example \u00b6 mavenExecute script: this , goals: [ 'clean' , 'install' ] Example for the correct usage of goals , defines and flags in version v1.24.0 and newer: mavenExecute ( script: script , goals: [ 'org.apache.maven.plugins:maven-help-plugin:3.1.0:evaluate' ], defines: [ \"-Dexpression=$pomPathExpression\" , \"-DforceStdout\" , \"-q\" ], returnStdout: true ) Note that it does not work to put multiple arguments into one element of a list, so defines: [\"-Dexpression=$pomPathExpression -DforceStdout -q\"] does not work.","title":"mavenExecute"},{"location":"steps/mavenExecute/#mavenexecute","text":"This step allows to run maven commands","title":"mavenExecute"},{"location":"steps/mavenExecute/#description","text":"This step runs a maven command based on the parameters provided to the step.","title":"Description"},{"location":"steps/mavenExecute/#usage","text":"We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line .","title":"Usage"},{"location":"steps/mavenExecute/#jenkins-pipelines","text":"mavenExecute script: this","title":"Jenkins pipelines"},{"location":"steps/mavenExecute/#command-line","text":"piper mavenExecute","title":"Command line"},{"location":"steps/mavenExecute/#parameters","text":"","title":"Parameters"},{"location":"steps/mavenExecute/#overview","text":"Name Mandatory Additional information goals yes script yes reference to Jenkins main pipeline script containerCommand no containerShell no defines no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no dockerVolumeBind no dockerWorkspace no flags no globalSettingsFile no logSuccessfulMavenTransfers no m2Path no pomPath no projectSettingsFile no returnStdout no verbose no activates debug output","title":"Overview"},{"location":"steps/mavenExecute/#details","text":"","title":"Details"},{"location":"steps/mavenExecute/#containercommand","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default (/usr/bin/tail -f /dev/null). back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"containerCommand"},{"location":"steps/mavenExecute/#containershell","text":"Jenkins-specific: Used for proper environment setup. Allows to specify the shell to be executed for container with containerName. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"containerShell"},{"location":"steps/mavenExecute/#defines","text":"Additional properties in form of -Dkey=value. back to overview Scope Details Aliases - Type []string Mandatory no Default $PIPER_defines (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2610 steps \u2610 stages Resource references none","title":"defines"},{"location":"steps/mavenExecute/#dockerenvvars","text":"Jenkins-specific: Used for proper environment setup. Environment variables to set in the container, e.g. [http_proxy: \"proxy:8080\"]. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerEnvVars"},{"location":"steps/mavenExecute/#dockerimage","text":"Jenkins-specific: Used for proper environment setup. Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerImage"},{"location":"steps/mavenExecute/#dockername","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Name of the container launching dockerImage. SideCar only: Name of the container in local network. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerName"},{"location":"steps/mavenExecute/#dockeroptions","text":"Jenkins-specific: Used for proper environment setup. Docker options to be set when starting the container. back to overview Scope Details Aliases - Type []string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerOptions"},{"location":"steps/mavenExecute/#dockerpullimage","text":"Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerPullImage"},{"location":"steps/mavenExecute/#dockervolumebind","text":"Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the docker container. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerVolumeBind"},{"location":"steps/mavenExecute/#dockerworkspace","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerWorkspace"},{"location":"steps/mavenExecute/#flags","text":"Flags to provide when running mvn. back to overview Scope Details Aliases - Type []string Mandatory no Default $PIPER_flags (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2610 stages Resource references none","title":"flags"},{"location":"steps/mavenExecute/#globalsettingsfile","text":"Path to the mvn settings file that should be used as global settings file. back to overview Scope Details Aliases maven/globalSettingsFile Type string Mandatory no Default $PIPER_globalSettingsFile (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"globalSettingsFile"},{"location":"steps/mavenExecute/#goals","text":"Maven goals that should be executed. back to overview Scope Details Aliases - Type []string Mandatory yes Default $PIPER_goals (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2610 steps \u2610 stages Resource references none","title":"goals"},{"location":"steps/mavenExecute/#logsuccessfulmaventransfers","text":"Configures maven to log successful downloads. This is set to false by default to reduce the noise in build logs. back to overview Scope Details Aliases maven/logSuccessfulMavenTransfers Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"logSuccessfulMavenTransfers"},{"location":"steps/mavenExecute/#m2path","text":"Path to the location of the local repository that should be used. back to overview Scope Details Aliases maven/m2Path Type string Mandatory no Default $PIPER_m2Path (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"m2Path"},{"location":"steps/mavenExecute/#pompath","text":"Path to the pom file that should be used. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_pomPath (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2610 stages Resource references none","title":"pomPath"},{"location":"steps/mavenExecute/#projectsettingsfile","text":"Path to the mvn settings file that should be used as project settings file. back to overview Scope Details Aliases maven/projectSettingsFile Type string Mandatory no Default $PIPER_projectSettingsFile (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"projectSettingsFile"},{"location":"steps/mavenExecute/#returnstdout","text":"Returns the output of the maven command for further processing. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2610 steps \u2610 stages Resource references none","title":"returnStdout"},{"location":"steps/mavenExecute/#script","text":"Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none","title":"script"},{"location":"steps/mavenExecute/#verbose","text":"verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none Breaking change in goals , defines and flags parameters The goals , defines and flags parameters of the step need to be lists of strings with each element being one item. As an example consider this diff, showing the old api deleted and the new api inserted: -goals: 'org.apache.maven.plugins:maven-help-plugin:3.1.0:evaluate', -defines: \"-Dexpression=$pomPathExpression -DforceStdout -q\", +goals: ['org.apache.maven.plugins:maven-help-plugin:3.1.0:evaluate'], +defines: [\"-Dexpression=$pomPathExpression\", \"-DforceStdout\", \"-q\"], Additionally please note that in the parameters must not be shell quoted/escaped . What you pass in is literally passed to Maven without any shell interpreter inbetween. The old behavior is still available in version v1.23.0 and before of project \"Piper\".","title":"verbose"},{"location":"steps/mavenExecute/#exceptions","text":"None","title":"Exceptions"},{"location":"steps/mavenExecute/#example","text":"mavenExecute script: this , goals: [ 'clean' , 'install' ] Example for the correct usage of goals , defines and flags in version v1.24.0 and newer: mavenExecute ( script: script , goals: [ 'org.apache.maven.plugins:maven-help-plugin:3.1.0:evaluate' ], defines: [ \"-Dexpression=$pomPathExpression\" , \"-DforceStdout\" , \"-q\" ], returnStdout: true ) Note that it does not work to put multiple arguments into one element of a list, so defines: [\"-Dexpression=$pomPathExpression -DforceStdout -q\"] does not work.","title":"Example"},{"location":"steps/mavenExecuteIntegration/","text":"mavenExecuteIntegration \u00b6 This step will execute backend integration tests via the Jacoco Maven-plugin. Description \u00b6 If the project contains a Maven module named \"integration-tests\", this step will execute the integration tests via the Jacoco Maven-plugin. Usage \u00b6 We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line . Jenkins pipelines \u00b6 mavenExecuteIntegration script: this Command line \u00b6 piper mavenExecuteIntegration Parameters \u00b6 Overview \u00b6 Name Mandatory Additional information script yes reference to Jenkins main pipeline script containerCommand no containerName no containerShell no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no dockerVolumeBind no dockerWorkspace no forkCount no globalSettingsFile no logSuccessfulMavenTransfers no m2Path no projectSettingsFile no retry no sidecarEnvVars no sidecarImage no sidecarName no sidecarOptions no sidecarPullImage no sidecarReadyCommand no sidecarVolumeBind no sidecarWorkspace no verbose no activates debug output Details \u00b6 containerCommand \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default (/usr/bin/tail -f /dev/null). back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none containerName \u00b6 Jenkins-specific: Used for proper environment setup. Optional configuration in combination with containerMap to define the container where the commands should be executed in. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none containerShell \u00b6 Jenkins-specific: Used for proper environment setup. Allows to specify the shell to be executed for container with containerName. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerEnvVars \u00b6 Jenkins-specific: Used for proper environment setup. Environment variables to set in the container, e.g. [http_proxy: \"proxy:8080\"]. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerImage \u00b6 Jenkins-specific: Used for proper environment setup. Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerName \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Name of the container launching dockerImage. SideCar only: Name of the container in local network. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerOptions \u00b6 Jenkins-specific: Used for proper environment setup. Docker options to be set when starting the container. back to overview Scope Details Aliases - Type []string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerPullImage \u00b6 Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerVolumeBind \u00b6 Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the docker container. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerWorkspace \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none forkCount \u00b6 The number of JVM processes that are spawned to run the tests in parallel in case of using a maven based project structure. For more details visit the Surefire documentation at https://maven.apache.org/surefire/maven-surefire-plugin/test-mojo.html#forkCount. back to overview Scope Details Aliases - Type string Mandatory no Default 1C Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none globalSettingsFile \u00b6 Path to the mvn settings file that should be used as global settings file. back to overview Scope Details Aliases maven/globalSettingsFile Type string Mandatory no Default $PIPER_globalSettingsFile (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none logSuccessfulMavenTransfers \u00b6 Configures maven to log successful downloads. This is set to false by default to reduce the noise in build logs. back to overview Scope Details Aliases maven/logSuccessfulMavenTransfers Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none m2Path \u00b6 Path to the location of the local repository that should be used. back to overview Scope Details Aliases maven/m2Path Type string Mandatory no Default $PIPER_m2Path (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none projectSettingsFile \u00b6 Path to the mvn settings file that should be used as project settings file. back to overview Scope Details Aliases maven/projectSettingsFile Type string Mandatory no Default $PIPER_projectSettingsFile (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none retry \u00b6 The number of times that integration tests will be retried before failing the step. Note: This will consume more time for the step execution. back to overview Scope Details Aliases - Type int Mandatory no Default 1 Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none script \u00b6 Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none sidecarEnvVars \u00b6 Jenkins-specific: Used for proper environment setup. A map of environment variables to set in the sidecar container, similar to dockerEnvVars . back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none sidecarImage \u00b6 Jenkins-specific: Used for proper environment setup. The name of the docker image of the sidecar container. If empty, no sidecar container is started. Similar to dockerImage . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none sidecarName \u00b6 Jenkins-specific: Used for proper environment setup. Name of the sidecar container. Similar to dockerName . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none sidecarOptions \u00b6 Jenkins-specific: Used for proper environment setup. Options to be set when starting the sidecar container. Similar to dockerOptions . back to overview Scope Details Aliases - Type []string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none sidecarPullImage \u00b6 Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Useful during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none sidecarReadyCommand \u00b6 Jenkins-specific: Used for proper environment setup. Command executed inside the container which returns exit code 0 when the container is ready to be used. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none sidecarVolumeBind \u00b6 Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the sidecar container. Similar to dockerVolumeBind . back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none sidecarWorkspace \u00b6 Jenkins-specific: Used for proper environment setup. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none verbose \u00b6 verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none \u00b6","title":"mavenExecuteIntegration"},{"location":"steps/mavenExecuteIntegration/#mavenexecuteintegration","text":"This step will execute backend integration tests via the Jacoco Maven-plugin.","title":"mavenExecuteIntegration"},{"location":"steps/mavenExecuteIntegration/#description","text":"If the project contains a Maven module named \"integration-tests\", this step will execute the integration tests via the Jacoco Maven-plugin.","title":"Description"},{"location":"steps/mavenExecuteIntegration/#usage","text":"We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line .","title":"Usage"},{"location":"steps/mavenExecuteIntegration/#jenkins-pipelines","text":"mavenExecuteIntegration script: this","title":"Jenkins pipelines"},{"location":"steps/mavenExecuteIntegration/#command-line","text":"piper mavenExecuteIntegration","title":"Command line"},{"location":"steps/mavenExecuteIntegration/#parameters","text":"","title":"Parameters"},{"location":"steps/mavenExecuteIntegration/#overview","text":"Name Mandatory Additional information script yes reference to Jenkins main pipeline script containerCommand no containerName no containerShell no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no dockerVolumeBind no dockerWorkspace no forkCount no globalSettingsFile no logSuccessfulMavenTransfers no m2Path no projectSettingsFile no retry no sidecarEnvVars no sidecarImage no sidecarName no sidecarOptions no sidecarPullImage no sidecarReadyCommand no sidecarVolumeBind no sidecarWorkspace no verbose no activates debug output","title":"Overview"},{"location":"steps/mavenExecuteIntegration/#details","text":"","title":"Details"},{"location":"steps/mavenExecuteIntegration/#containercommand","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default (/usr/bin/tail -f /dev/null). back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"containerCommand"},{"location":"steps/mavenExecuteIntegration/#containername","text":"Jenkins-specific: Used for proper environment setup. Optional configuration in combination with containerMap to define the container where the commands should be executed in. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"containerName"},{"location":"steps/mavenExecuteIntegration/#containershell","text":"Jenkins-specific: Used for proper environment setup. Allows to specify the shell to be executed for container with containerName. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"containerShell"},{"location":"steps/mavenExecuteIntegration/#dockerenvvars","text":"Jenkins-specific: Used for proper environment setup. Environment variables to set in the container, e.g. [http_proxy: \"proxy:8080\"]. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerEnvVars"},{"location":"steps/mavenExecuteIntegration/#dockerimage","text":"Jenkins-specific: Used for proper environment setup. Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerImage"},{"location":"steps/mavenExecuteIntegration/#dockername","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Name of the container launching dockerImage. SideCar only: Name of the container in local network. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerName"},{"location":"steps/mavenExecuteIntegration/#dockeroptions","text":"Jenkins-specific: Used for proper environment setup. Docker options to be set when starting the container. back to overview Scope Details Aliases - Type []string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerOptions"},{"location":"steps/mavenExecuteIntegration/#dockerpullimage","text":"Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerPullImage"},{"location":"steps/mavenExecuteIntegration/#dockervolumebind","text":"Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the docker container. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerVolumeBind"},{"location":"steps/mavenExecuteIntegration/#dockerworkspace","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerWorkspace"},{"location":"steps/mavenExecuteIntegration/#forkcount","text":"The number of JVM processes that are spawned to run the tests in parallel in case of using a maven based project structure. For more details visit the Surefire documentation at https://maven.apache.org/surefire/maven-surefire-plugin/test-mojo.html#forkCount. back to overview Scope Details Aliases - Type string Mandatory no Default 1C Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"forkCount"},{"location":"steps/mavenExecuteIntegration/#globalsettingsfile","text":"Path to the mvn settings file that should be used as global settings file. back to overview Scope Details Aliases maven/globalSettingsFile Type string Mandatory no Default $PIPER_globalSettingsFile (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"globalSettingsFile"},{"location":"steps/mavenExecuteIntegration/#logsuccessfulmaventransfers","text":"Configures maven to log successful downloads. This is set to false by default to reduce the noise in build logs. back to overview Scope Details Aliases maven/logSuccessfulMavenTransfers Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"logSuccessfulMavenTransfers"},{"location":"steps/mavenExecuteIntegration/#m2path","text":"Path to the location of the local repository that should be used. back to overview Scope Details Aliases maven/m2Path Type string Mandatory no Default $PIPER_m2Path (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"m2Path"},{"location":"steps/mavenExecuteIntegration/#projectsettingsfile","text":"Path to the mvn settings file that should be used as project settings file. back to overview Scope Details Aliases maven/projectSettingsFile Type string Mandatory no Default $PIPER_projectSettingsFile (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"projectSettingsFile"},{"location":"steps/mavenExecuteIntegration/#retry","text":"The number of times that integration tests will be retried before failing the step. Note: This will consume more time for the step execution. back to overview Scope Details Aliases - Type int Mandatory no Default 1 Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"retry"},{"location":"steps/mavenExecuteIntegration/#script","text":"Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none","title":"script"},{"location":"steps/mavenExecuteIntegration/#sidecarenvvars","text":"Jenkins-specific: Used for proper environment setup. A map of environment variables to set in the sidecar container, similar to dockerEnvVars . back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"sidecarEnvVars"},{"location":"steps/mavenExecuteIntegration/#sidecarimage","text":"Jenkins-specific: Used for proper environment setup. The name of the docker image of the sidecar container. If empty, no sidecar container is started. Similar to dockerImage . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"sidecarImage"},{"location":"steps/mavenExecuteIntegration/#sidecarname","text":"Jenkins-specific: Used for proper environment setup. Name of the sidecar container. Similar to dockerName . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"sidecarName"},{"location":"steps/mavenExecuteIntegration/#sidecaroptions","text":"Jenkins-specific: Used for proper environment setup. Options to be set when starting the sidecar container. Similar to dockerOptions . back to overview Scope Details Aliases - Type []string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"sidecarOptions"},{"location":"steps/mavenExecuteIntegration/#sidecarpullimage","text":"Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Useful during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"sidecarPullImage"},{"location":"steps/mavenExecuteIntegration/#sidecarreadycommand","text":"Jenkins-specific: Used for proper environment setup. Command executed inside the container which returns exit code 0 when the container is ready to be used. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"sidecarReadyCommand"},{"location":"steps/mavenExecuteIntegration/#sidecarvolumebind","text":"Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the sidecar container. Similar to dockerVolumeBind . back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"sidecarVolumeBind"},{"location":"steps/mavenExecuteIntegration/#sidecarworkspace","text":"Jenkins-specific: Used for proper environment setup. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"sidecarWorkspace"},{"location":"steps/mavenExecuteIntegration/#verbose","text":"verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"verbose"},{"location":"steps/mavenExecuteStaticCodeChecks/","text":"mavenExecuteStaticCodeChecks \u00b6 Execute static code checks for Maven based projects. The plugins SpotBugs and PMD are used. Description \u00b6 Executes Spotbugs Maven plugin as well as Pmd Maven plugin for static code checks. SpotBugs is a program to find bugs in Java programs. It looks for instances of \u201cbug patterns\u201d \u2014 code instances that are likely to be errors. For more information please visit https://spotbugs.readthedocs.io/en/latest/maven.html PMD is a source code analyzer. It finds common programming flaws like unused variables, empty catch blocks, unnecessary object creation, and so forth. It supports Java, JavaScript, Salesforce.com Apex and Visualforce, PLSQL, Apache Velocity, XML, XSL. For more information please visit https://pmd.github.io/. The plugins should be configured in the respective pom.xml. For SpotBugs include- and exclude filters as well as maximum allowed violations are conifgurable via .pipeline/config.yml. For PMD the failure priority and the max allowed violations are configurable via .pipeline/config.yml. Usage \u00b6 We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line . Jenkins pipelines \u00b6 mavenExecuteStaticCodeChecks script: this Command line \u00b6 piper mavenExecuteStaticCodeChecks Parameters \u00b6 Overview \u00b6 Name Mandatory Additional information script yes reference to Jenkins main pipeline script containerCommand no containerShell no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no dockerVolumeBind no dockerWorkspace no globalSettingsFile no logSuccessfulMavenTransfers no m2Path no mavenModulesExcludes no pmd no pmdFailurePriority no pmdMaxAllowedViolations no projectSettingsFile no spotBugs no spotBugsExcludeFilterFile no spotBugsIncludeFilterFile no spotBugsMaxAllowedViolations no verbose no activates debug output Details \u00b6 containerCommand \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default (/usr/bin/tail -f /dev/null). back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none containerShell \u00b6 Jenkins-specific: Used for proper environment setup. Allows to specify the shell to be executed for container with containerName. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerEnvVars \u00b6 Jenkins-specific: Used for proper environment setup. Environment variables to set in the container, e.g. [http_proxy: \"proxy:8080\"]. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerImage \u00b6 Jenkins-specific: Used for proper environment setup. Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerName \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Name of the container launching dockerImage. SideCar only: Name of the container in local network. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerOptions \u00b6 Jenkins-specific: Used for proper environment setup. Docker options to be set when starting the container. back to overview Scope Details Aliases - Type []string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerPullImage \u00b6 Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerVolumeBind \u00b6 Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the docker container. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerWorkspace \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none globalSettingsFile \u00b6 Path to the mvn settings file that should be used as global settings file. back to overview Scope Details Aliases maven/globalSettingsFile Type string Mandatory no Default $PIPER_globalSettingsFile (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none logSuccessfulMavenTransfers \u00b6 Configures maven to log successful downloads. This is set to false by default to reduce the noise in build logs. back to overview Scope Details Aliases maven/logSuccessfulMavenTransfers Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none m2Path \u00b6 Path to the location of the local repository that should be used. back to overview Scope Details Aliases maven/m2Path Type string Mandatory no Default $PIPER_m2Path (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none mavenModulesExcludes \u00b6 Maven modules which should be excluded by the static code checks. By default the modules 'unit-tests' and 'integration-tests' will be excluded. back to overview Scope Details Aliases - Type []string Mandatory no Default $PIPER_mavenModulesExcludes (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none pmd \u00b6 Parameter to turn off PMD. back to overview Scope Details Aliases - Type bool Mandatory no Default true Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none pmdFailurePriority \u00b6 What priority level to fail the build on. PMD violations are assigned a priority from 1 (most severe) to 5 (least severe) according the the rule's priority. Violations at or less than this priority level are considered failures and will fail the build if failOnViolation=true and the count exceeds maxAllowedViolations. The other violations will be regarded as warnings and will be displayed in the build output if verbose=true. Setting a value of 5 will treat all violations as failures, which may cause the build to fail. Setting a value of 1 will treat all violations as warnings. Only values from 1 to 5 are valid. back to overview Scope Details Aliases pmd/failurePriority Type int Mandatory no Default 0 Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none pmdMaxAllowedViolations \u00b6 The maximum number of failures allowed before execution fails. Used in conjunction with failOnViolation=true and utilizes failurePriority. This value has no meaning if failOnViolation=false. If the number of failures is greater than this number, the build will be failed. If the number of failures is less than or equal to this value, then the build will not be failed. back to overview Scope Details Aliases pmd/maxAllowedViolations Type int Mandatory no Default 0 Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none projectSettingsFile \u00b6 Path to the mvn settings file that should be used as project settings file. back to overview Scope Details Aliases maven/projectSettingsFile Type string Mandatory no Default $PIPER_projectSettingsFile (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none script \u00b6 Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none spotBugs \u00b6 Parameter to turn off SpotBugs. back to overview Scope Details Aliases - Type bool Mandatory no Default true Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none spotBugsExcludeFilterFile \u00b6 Path to a filter file with bug definitions which should be excluded. back to overview Scope Details Aliases spotBugs/excludeFilterFile Type string Mandatory no Default $PIPER_spotBugsExcludeFilterFile (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none spotBugsIncludeFilterFile \u00b6 Path to a filter file with bug definitions which should be included. back to overview Scope Details Aliases spotBugs/includeFilterFile Type string Mandatory no Default $PIPER_spotBugsIncludeFilterFile (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none spotBugsMaxAllowedViolations \u00b6 The maximum number of failures allowed before execution fails. back to overview Scope Details Aliases spotBugs/maxAllowedViolations Type int Mandatory no Default 0 Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none verbose \u00b6 verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none \u00b6","title":"mavenExecuteStaticCodeChecks"},{"location":"steps/mavenExecuteStaticCodeChecks/#mavenexecutestaticcodechecks","text":"Execute static code checks for Maven based projects. The plugins SpotBugs and PMD are used.","title":"mavenExecuteStaticCodeChecks"},{"location":"steps/mavenExecuteStaticCodeChecks/#description","text":"Executes Spotbugs Maven plugin as well as Pmd Maven plugin for static code checks. SpotBugs is a program to find bugs in Java programs. It looks for instances of \u201cbug patterns\u201d \u2014 code instances that are likely to be errors. For more information please visit https://spotbugs.readthedocs.io/en/latest/maven.html PMD is a source code analyzer. It finds common programming flaws like unused variables, empty catch blocks, unnecessary object creation, and so forth. It supports Java, JavaScript, Salesforce.com Apex and Visualforce, PLSQL, Apache Velocity, XML, XSL. For more information please visit https://pmd.github.io/. The plugins should be configured in the respective pom.xml. For SpotBugs include- and exclude filters as well as maximum allowed violations are conifgurable via .pipeline/config.yml. For PMD the failure priority and the max allowed violations are configurable via .pipeline/config.yml.","title":"Description"},{"location":"steps/mavenExecuteStaticCodeChecks/#usage","text":"We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line .","title":"Usage"},{"location":"steps/mavenExecuteStaticCodeChecks/#jenkins-pipelines","text":"mavenExecuteStaticCodeChecks script: this","title":"Jenkins pipelines"},{"location":"steps/mavenExecuteStaticCodeChecks/#command-line","text":"piper mavenExecuteStaticCodeChecks","title":"Command line"},{"location":"steps/mavenExecuteStaticCodeChecks/#parameters","text":"","title":"Parameters"},{"location":"steps/mavenExecuteStaticCodeChecks/#overview","text":"Name Mandatory Additional information script yes reference to Jenkins main pipeline script containerCommand no containerShell no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no dockerVolumeBind no dockerWorkspace no globalSettingsFile no logSuccessfulMavenTransfers no m2Path no mavenModulesExcludes no pmd no pmdFailurePriority no pmdMaxAllowedViolations no projectSettingsFile no spotBugs no spotBugsExcludeFilterFile no spotBugsIncludeFilterFile no spotBugsMaxAllowedViolations no verbose no activates debug output","title":"Overview"},{"location":"steps/mavenExecuteStaticCodeChecks/#details","text":"","title":"Details"},{"location":"steps/mavenExecuteStaticCodeChecks/#containercommand","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default (/usr/bin/tail -f /dev/null). back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"containerCommand"},{"location":"steps/mavenExecuteStaticCodeChecks/#containershell","text":"Jenkins-specific: Used for proper environment setup. Allows to specify the shell to be executed for container with containerName. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"containerShell"},{"location":"steps/mavenExecuteStaticCodeChecks/#dockerenvvars","text":"Jenkins-specific: Used for proper environment setup. Environment variables to set in the container, e.g. [http_proxy: \"proxy:8080\"]. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerEnvVars"},{"location":"steps/mavenExecuteStaticCodeChecks/#dockerimage","text":"Jenkins-specific: Used for proper environment setup. Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerImage"},{"location":"steps/mavenExecuteStaticCodeChecks/#dockername","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Name of the container launching dockerImage. SideCar only: Name of the container in local network. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerName"},{"location":"steps/mavenExecuteStaticCodeChecks/#dockeroptions","text":"Jenkins-specific: Used for proper environment setup. Docker options to be set when starting the container. back to overview Scope Details Aliases - Type []string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerOptions"},{"location":"steps/mavenExecuteStaticCodeChecks/#dockerpullimage","text":"Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerPullImage"},{"location":"steps/mavenExecuteStaticCodeChecks/#dockervolumebind","text":"Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the docker container. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerVolumeBind"},{"location":"steps/mavenExecuteStaticCodeChecks/#dockerworkspace","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerWorkspace"},{"location":"steps/mavenExecuteStaticCodeChecks/#globalsettingsfile","text":"Path to the mvn settings file that should be used as global settings file. back to overview Scope Details Aliases maven/globalSettingsFile Type string Mandatory no Default $PIPER_globalSettingsFile (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"globalSettingsFile"},{"location":"steps/mavenExecuteStaticCodeChecks/#logsuccessfulmaventransfers","text":"Configures maven to log successful downloads. This is set to false by default to reduce the noise in build logs. back to overview Scope Details Aliases maven/logSuccessfulMavenTransfers Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"logSuccessfulMavenTransfers"},{"location":"steps/mavenExecuteStaticCodeChecks/#m2path","text":"Path to the location of the local repository that should be used. back to overview Scope Details Aliases maven/m2Path Type string Mandatory no Default $PIPER_m2Path (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"m2Path"},{"location":"steps/mavenExecuteStaticCodeChecks/#mavenmodulesexcludes","text":"Maven modules which should be excluded by the static code checks. By default the modules 'unit-tests' and 'integration-tests' will be excluded. back to overview Scope Details Aliases - Type []string Mandatory no Default $PIPER_mavenModulesExcludes (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"mavenModulesExcludes"},{"location":"steps/mavenExecuteStaticCodeChecks/#pmd","text":"Parameter to turn off PMD. back to overview Scope Details Aliases - Type bool Mandatory no Default true Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"pmd"},{"location":"steps/mavenExecuteStaticCodeChecks/#pmdfailurepriority","text":"What priority level to fail the build on. PMD violations are assigned a priority from 1 (most severe) to 5 (least severe) according the the rule's priority. Violations at or less than this priority level are considered failures and will fail the build if failOnViolation=true and the count exceeds maxAllowedViolations. The other violations will be regarded as warnings and will be displayed in the build output if verbose=true. Setting a value of 5 will treat all violations as failures, which may cause the build to fail. Setting a value of 1 will treat all violations as warnings. Only values from 1 to 5 are valid. back to overview Scope Details Aliases pmd/failurePriority Type int Mandatory no Default 0 Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"pmdFailurePriority"},{"location":"steps/mavenExecuteStaticCodeChecks/#pmdmaxallowedviolations","text":"The maximum number of failures allowed before execution fails. Used in conjunction with failOnViolation=true and utilizes failurePriority. This value has no meaning if failOnViolation=false. If the number of failures is greater than this number, the build will be failed. If the number of failures is less than or equal to this value, then the build will not be failed. back to overview Scope Details Aliases pmd/maxAllowedViolations Type int Mandatory no Default 0 Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"pmdMaxAllowedViolations"},{"location":"steps/mavenExecuteStaticCodeChecks/#projectsettingsfile","text":"Path to the mvn settings file that should be used as project settings file. back to overview Scope Details Aliases maven/projectSettingsFile Type string Mandatory no Default $PIPER_projectSettingsFile (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"projectSettingsFile"},{"location":"steps/mavenExecuteStaticCodeChecks/#script","text":"Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none","title":"script"},{"location":"steps/mavenExecuteStaticCodeChecks/#spotbugs","text":"Parameter to turn off SpotBugs. back to overview Scope Details Aliases - Type bool Mandatory no Default true Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"spotBugs"},{"location":"steps/mavenExecuteStaticCodeChecks/#spotbugsexcludefilterfile","text":"Path to a filter file with bug definitions which should be excluded. back to overview Scope Details Aliases spotBugs/excludeFilterFile Type string Mandatory no Default $PIPER_spotBugsExcludeFilterFile (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"spotBugsExcludeFilterFile"},{"location":"steps/mavenExecuteStaticCodeChecks/#spotbugsincludefilterfile","text":"Path to a filter file with bug definitions which should be included. back to overview Scope Details Aliases spotBugs/includeFilterFile Type string Mandatory no Default $PIPER_spotBugsIncludeFilterFile (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"spotBugsIncludeFilterFile"},{"location":"steps/mavenExecuteStaticCodeChecks/#spotbugsmaxallowedviolations","text":"The maximum number of failures allowed before execution fails. back to overview Scope Details Aliases spotBugs/maxAllowedViolations Type int Mandatory no Default 0 Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"spotBugsMaxAllowedViolations"},{"location":"steps/mavenExecuteStaticCodeChecks/#verbose","text":"verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"verbose"},{"location":"steps/mtaBuild/","text":"mtaBuild \u00b6 Performs an mta build Description \u00b6 Executes the SAP Multitarget Application Archive Builder to create an mtar archive of the application. Usage \u00b6 We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line . Jenkins pipelines \u00b6 mtaBuild script: this Command line \u00b6 piper mtaBuild Outputs \u00b6 Output type Details commonPipelineEnvironment mtarFilePath Prerequisites \u00b6 While using a custom docker file, ensure that the following tools are installed: SAP MTA Archive Builder 1.0.6 or compatible version - can be downloaded from SAP Development Tools . Java 8 or compatible version - necessary to run the MTA Archive Builder itself and to build Java modules. NodeJS installed - the MTA Builder uses npm to download node module dependencies such as grunt . Parameters \u00b6 Overview \u00b6 Name Mandatory Additional information script yes reference to Jenkins main pipeline script applicationName no buildTarget no containerCommand no containerShell no defaultNpmRegistry no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no dockerVolumeBind no dockerWorkspace no extensions no globalSettingsFile no installArtifacts no m2Path no mtaBuildTool no mtaJarLocation no mtarName no platform no projectSettingsFile no verbose no activates debug output Details \u00b6 applicationName \u00b6 The name of the application which is being built. If the parameter has been provided and no mta.yaml exists, the mta.yaml will be automatically generated using this parameter and the information ( name and version ) from 'package.json` before the actual build starts. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_applicationName (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none buildTarget \u00b6 mtaBuildTool 'classic' only: The target platform to which the mtar can be deployed. Valid values: 'CF', 'NEO', 'XSA'. back to overview Scope Details Aliases - Type string Mandatory no Default NEO Possible values - CF - NEO - XSA Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none containerCommand \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default (/usr/bin/tail -f /dev/null). back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none containerShell \u00b6 Jenkins-specific: Used for proper environment setup. Allows to specify the shell to be executed for container with containerName. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none defaultNpmRegistry \u00b6 Url to the npm registry that should be used for installing npm dependencies. back to overview Scope Details Aliases npm/defaultNpmRegistry Type string Mandatory no Default $PIPER_defaultNpmRegistry (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerEnvVars \u00b6 Jenkins-specific: Used for proper environment setup. Environment variables to set in the container, e.g. [http_proxy: \"proxy:8080\"]. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerImage \u00b6 Jenkins-specific: Used for proper environment setup. Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. back to overview Scope Details Aliases - Type string Mandatory no Default mtaBuildTool= cloudMbt : devxci/mbtci:1.0.14.1 mtaBuildTool= classic : ppiper/mta-archive-builder:v1 Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerName \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Name of the container launching dockerImage. SideCar only: Name of the container in local network. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerOptions \u00b6 Jenkins-specific: Used for proper environment setup. Docker options to be set when starting the container. back to overview Scope Details Aliases - Type []string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerPullImage \u00b6 Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default mtaBuildTool= cloudMbt : true mtaBuildTool= classic : true Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerVolumeBind \u00b6 Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the docker container. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerWorkspace \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none extensions \u00b6 The path to the extension descriptor file. back to overview Scope Details Aliases extension Type string Mandatory no Default $PIPER_extensions (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none globalSettingsFile \u00b6 Path or url to the mvn settings file that should be used as global settings file back to overview Scope Details Aliases maven/globalSettingsFile Type string Mandatory no Default $PIPER_globalSettingsFile (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none installArtifacts \u00b6 If enabled, for npm packages this step will install all depedencies including dev dependencies. For maven it will install all artifacts to the local maven repository. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none m2Path \u00b6 Path to the location of the local repository that should be used. back to overview Scope Details Aliases maven/m2Path Type string Mandatory no Default $PIPER_m2Path (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none mtaBuildTool \u00b6 Tool to use when building the MTA. Valid values: 'classic', 'cloudMbt'. back to overview Scope Details Aliases - Type string Mandatory no Default cloudMbt Possible values - cloudMbt - classic Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none mtaJarLocation \u00b6 mtaBuildTool 'classic' only: The location of the SAP Multitarget Application Archive Builder jar file, including file name and extension. If you run on Docker, this must match the location of the jar file in the container as well. back to overview Scope Details Aliases - Type string Mandatory no Default /opt/sap/mta/lib/mta.jar Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none mtarName \u00b6 The name of the generated mtar file including its extension. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_mtarName (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none platform \u00b6 mtaBuildTool 'cloudMbt' only: The target platform to which the mtar can be deployed. back to overview Scope Details Aliases - Type string Mandatory no Default CF Possible values - CF - NEO - XSA Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none projectSettingsFile \u00b6 Path or url to the mvn settings file that should be used as project settings file. back to overview Scope Details Aliases maven/projectSettingsFile Type string Mandatory no Default $PIPER_projectSettingsFile (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none script \u00b6 Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none verbose \u00b6 verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none \u00b6 Side effects \u00b6 The file name of the resulting archive is written to the commonPipelineEnvironment with variable name mtarFileName . Exceptions \u00b6 AbortException : If there is an invalid buildTarget . If there is no key ID inside the mta.yaml file. Example \u00b6 dir ( '/path/to/FioriApp' ){ mtaBuild script: this , buildTarget: 'NEO' } def mtarFilePath = commonPipelineEnvironment . getMtarFilePath ()","title":"mtaBuild"},{"location":"steps/mtaBuild/#mtabuild","text":"Performs an mta build","title":"mtaBuild"},{"location":"steps/mtaBuild/#description","text":"Executes the SAP Multitarget Application Archive Builder to create an mtar archive of the application.","title":"Description"},{"location":"steps/mtaBuild/#usage","text":"We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line .","title":"Usage"},{"location":"steps/mtaBuild/#jenkins-pipelines","text":"mtaBuild script: this","title":"Jenkins pipelines"},{"location":"steps/mtaBuild/#command-line","text":"piper mtaBuild","title":"Command line"},{"location":"steps/mtaBuild/#outputs","text":"Output type Details commonPipelineEnvironment mtarFilePath","title":"Outputs"},{"location":"steps/mtaBuild/#prerequisites","text":"While using a custom docker file, ensure that the following tools are installed: SAP MTA Archive Builder 1.0.6 or compatible version - can be downloaded from SAP Development Tools . Java 8 or compatible version - necessary to run the MTA Archive Builder itself and to build Java modules. NodeJS installed - the MTA Builder uses npm to download node module dependencies such as grunt .","title":"Prerequisites"},{"location":"steps/mtaBuild/#parameters","text":"","title":"Parameters"},{"location":"steps/mtaBuild/#overview","text":"Name Mandatory Additional information script yes reference to Jenkins main pipeline script applicationName no buildTarget no containerCommand no containerShell no defaultNpmRegistry no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no dockerVolumeBind no dockerWorkspace no extensions no globalSettingsFile no installArtifacts no m2Path no mtaBuildTool no mtaJarLocation no mtarName no platform no projectSettingsFile no verbose no activates debug output","title":"Overview"},{"location":"steps/mtaBuild/#details","text":"","title":"Details"},{"location":"steps/mtaBuild/#applicationname","text":"The name of the application which is being built. If the parameter has been provided and no mta.yaml exists, the mta.yaml will be automatically generated using this parameter and the information ( name and version ) from 'package.json` before the actual build starts. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_applicationName (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"applicationName"},{"location":"steps/mtaBuild/#buildtarget","text":"mtaBuildTool 'classic' only: The target platform to which the mtar can be deployed. Valid values: 'CF', 'NEO', 'XSA'. back to overview Scope Details Aliases - Type string Mandatory no Default NEO Possible values - CF - NEO - XSA Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"buildTarget"},{"location":"steps/mtaBuild/#containercommand","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default (/usr/bin/tail -f /dev/null). back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"containerCommand"},{"location":"steps/mtaBuild/#containershell","text":"Jenkins-specific: Used for proper environment setup. Allows to specify the shell to be executed for container with containerName. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"containerShell"},{"location":"steps/mtaBuild/#defaultnpmregistry","text":"Url to the npm registry that should be used for installing npm dependencies. back to overview Scope Details Aliases npm/defaultNpmRegistry Type string Mandatory no Default $PIPER_defaultNpmRegistry (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"defaultNpmRegistry"},{"location":"steps/mtaBuild/#dockerenvvars","text":"Jenkins-specific: Used for proper environment setup. Environment variables to set in the container, e.g. [http_proxy: \"proxy:8080\"]. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerEnvVars"},{"location":"steps/mtaBuild/#dockerimage","text":"Jenkins-specific: Used for proper environment setup. Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. back to overview Scope Details Aliases - Type string Mandatory no Default mtaBuildTool= cloudMbt : devxci/mbtci:1.0.14.1 mtaBuildTool= classic : ppiper/mta-archive-builder:v1 Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerImage"},{"location":"steps/mtaBuild/#dockername","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Name of the container launching dockerImage. SideCar only: Name of the container in local network. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerName"},{"location":"steps/mtaBuild/#dockeroptions","text":"Jenkins-specific: Used for proper environment setup. Docker options to be set when starting the container. back to overview Scope Details Aliases - Type []string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerOptions"},{"location":"steps/mtaBuild/#dockerpullimage","text":"Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default mtaBuildTool= cloudMbt : true mtaBuildTool= classic : true Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerPullImage"},{"location":"steps/mtaBuild/#dockervolumebind","text":"Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the docker container. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerVolumeBind"},{"location":"steps/mtaBuild/#dockerworkspace","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerWorkspace"},{"location":"steps/mtaBuild/#extensions","text":"The path to the extension descriptor file. back to overview Scope Details Aliases extension Type string Mandatory no Default $PIPER_extensions (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"extensions"},{"location":"steps/mtaBuild/#globalsettingsfile","text":"Path or url to the mvn settings file that should be used as global settings file back to overview Scope Details Aliases maven/globalSettingsFile Type string Mandatory no Default $PIPER_globalSettingsFile (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"globalSettingsFile"},{"location":"steps/mtaBuild/#installartifacts","text":"If enabled, for npm packages this step will install all depedencies including dev dependencies. For maven it will install all artifacts to the local maven repository. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"installArtifacts"},{"location":"steps/mtaBuild/#m2path","text":"Path to the location of the local repository that should be used. back to overview Scope Details Aliases maven/m2Path Type string Mandatory no Default $PIPER_m2Path (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"m2Path"},{"location":"steps/mtaBuild/#mtabuildtool","text":"Tool to use when building the MTA. Valid values: 'classic', 'cloudMbt'. back to overview Scope Details Aliases - Type string Mandatory no Default cloudMbt Possible values - cloudMbt - classic Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"mtaBuildTool"},{"location":"steps/mtaBuild/#mtajarlocation","text":"mtaBuildTool 'classic' only: The location of the SAP Multitarget Application Archive Builder jar file, including file name and extension. If you run on Docker, this must match the location of the jar file in the container as well. back to overview Scope Details Aliases - Type string Mandatory no Default /opt/sap/mta/lib/mta.jar Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"mtaJarLocation"},{"location":"steps/mtaBuild/#mtarname","text":"The name of the generated mtar file including its extension. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_mtarName (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"mtarName"},{"location":"steps/mtaBuild/#platform","text":"mtaBuildTool 'cloudMbt' only: The target platform to which the mtar can be deployed. back to overview Scope Details Aliases - Type string Mandatory no Default CF Possible values - CF - NEO - XSA Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"platform"},{"location":"steps/mtaBuild/#projectsettingsfile","text":"Path or url to the mvn settings file that should be used as project settings file. back to overview Scope Details Aliases maven/projectSettingsFile Type string Mandatory no Default $PIPER_projectSettingsFile (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"projectSettingsFile"},{"location":"steps/mtaBuild/#script","text":"Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none","title":"script"},{"location":"steps/mtaBuild/#verbose","text":"verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"verbose"},{"location":"steps/mtaBuild/#side-effects","text":"The file name of the resulting archive is written to the commonPipelineEnvironment with variable name mtarFileName .","title":"Side effects"},{"location":"steps/mtaBuild/#exceptions","text":"AbortException : If there is an invalid buildTarget . If there is no key ID inside the mta.yaml file.","title":"Exceptions"},{"location":"steps/mtaBuild/#example","text":"dir ( '/path/to/FioriApp' ){ mtaBuild script: this , buildTarget: 'NEO' } def mtarFilePath = commonPipelineEnvironment . getMtarFilePath ()","title":"Example"},{"location":"steps/multicloudDeploy/","text":"multicloudDeploy \u00b6 Parameters \u00b6 name mandatory default possible values cfCreateServices no cfTargets no [] enableZeroDowntimeDeployment no false neoTargets no [] parallelExecution no false script yes source no cfCreateServices - Defines Cloud Foundry service instances to create as part of the deployment. This is a list of objects with the following properties each: - apiEndpoint - credentialsId - serviceManifest - manifestVariablesFiles - org - space cfTargets - Defines the targets to deploy on Cloud Foundry. enableZeroDowntimeDeployment - Defines the deployment type. neoTargets - Defines the targets to deploy on neo. parallelExecution - Executes the deployments in parallel. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. source - The source file to deploy to SAP Cloud Platform. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage cfCreateServices X cfTargets X X enableZeroDowntimeDeployment X neoTargets X X parallelExecution X X script source Dependencies \u00b6 The step depends on the following Jenkins plugins credentials-binding docker kubernetes lockable-resources pipeline-utility-steps workflow-basic-steps workflow-cps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Examples \u00b6 multicloudDeploy ( script: script , cfTargets: [[ apiEndpoint: 'https://test.server.com' , appName: 'cfAppName' , credentialsId: 'cfCredentialsId' , manifest: 'cfManifest' , org: 'cfOrg' , space: 'cfSpace' ]], neoTargets: [[ credentialsId: 'my-credentials-id' , host: hana . example . org , account: 'trialuser1' ]], enableZeroDowntimeDeployment: 'true' )","title":"multicloudDeploy"},{"location":"steps/multicloudDeploy/#multiclouddeploy","text":"","title":"multicloudDeploy"},{"location":"steps/multicloudDeploy/#parameters","text":"name mandatory default possible values cfCreateServices no cfTargets no [] enableZeroDowntimeDeployment no false neoTargets no [] parallelExecution no false script yes source no cfCreateServices - Defines Cloud Foundry service instances to create as part of the deployment. This is a list of objects with the following properties each: - apiEndpoint - credentialsId - serviceManifest - manifestVariablesFiles - org - space cfTargets - Defines the targets to deploy on Cloud Foundry. enableZeroDowntimeDeployment - Defines the deployment type. neoTargets - Defines the targets to deploy on neo. parallelExecution - Executes the deployments in parallel. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. source - The source file to deploy to SAP Cloud Platform.","title":"Parameters"},{"location":"steps/multicloudDeploy/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage cfCreateServices X cfTargets X X enableZeroDowntimeDeployment X neoTargets X X parallelExecution X X script source","title":"Step configuration"},{"location":"steps/multicloudDeploy/#dependencies","text":"The step depends on the following Jenkins plugins credentials-binding docker kubernetes lockable-resources pipeline-utility-steps workflow-basic-steps workflow-cps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/multicloudDeploy/#examples","text":"multicloudDeploy ( script: script , cfTargets: [[ apiEndpoint: 'https://test.server.com' , appName: 'cfAppName' , credentialsId: 'cfCredentialsId' , manifest: 'cfManifest' , org: 'cfOrg' , space: 'cfSpace' ]], neoTargets: [[ credentialsId: 'my-credentials-id' , host: hana . example . org , account: 'trialuser1' ]], enableZeroDowntimeDeployment: 'true' )","title":"Examples"},{"location":"steps/neoDeploy/","text":"neoDeploy \u00b6 Description \u00b6 Deploys an Application to SAP Cloud Platform (SAP CP) using the SAP Cloud Platform Console Client (Neo Java Web SDK). Prerequisites \u00b6 SAP CP account - the account to where the application is deployed. To deploy MTA ( deployMode: mta ) an over existing Java application, free Java Quota of at least 1 is required, which means that this will not work on trial accounts. SAP CP user for deployment - a user with deployment permissions in the given account. Jenkins credentials for deployment - must be configured in Jenkins credentials with a dedicated Id. Neo Java Web SDK 3.39.10 or compatible version - can be downloaded from Maven Central . This step is capable of triggering the neo deploy tool provided inside a docker image. We provide docker image ppiper/neo-cli . neo.sh needs to be contained in path, e.g by adding a symbolic link to /usr/local/bin . Java 8 or compatible version - needed by the Neo-Java-Web-SDK . Java environment needs to be properly configured (JAVA_HOME, java exectutable contained in path). Parameters \u00b6 name mandatory default possible values deployMode no mta 'mta', 'warParams', 'warPropertiesFile' dockerEnvVars no dockerImage no ppiper/neo-cli dockerOptions no extensions no [] mavenDeploymentModule no . neo/account for deployMode=warParams neo/application for deployMode=warParams neo/credentialsId no CI_CREDENTIALS_ID neo/environment no neo/host for deployMode=warParams neo/propertiesFile for deployMode=warPropertiesFile neo/runtime for deployMode=warParams neo/runtimeVersion for deployMode=warParams neo/size no lite neo/vmArguments no script yes source yes warAction no deploy 'deploy', 'rolling-update' deployMode - The deployment mode which should be used. Available options are: 'mta' - default, 'warParams' - deploying WAR file and passing all the deployment parameters via the function call, * 'warPropertiesFile' - deploying WAR file and putting all the deployment parameters in a .properties file. dockerEnvVars - Environment variables to set in the container, e.g. [http_proxy: 'proxy:8080']. dockerImage - Name of the docker image that should be used. Configure with empty value to execute the command directly on the Jenkins system (not using a container). Omit to use the default image (cf. default_pipeline_environment.yml ) Overwrite to use custom Docker image. dockerOptions - Docker only: Docker options to be set when starting the container (List or String). extensions - Extension files. Provided to the neo command via parameter --extensions ( -e ). Only valid for deploy mode mta . mavenDeploymentModule - Path to the maven module which contains the deployment artifact. neo/account - The SAP Cloud Platform account to deploy to. neo/application - Name of the application you want to manage, configure, or deploy. neo/credentialsId - The Jenkins credentials containing user and password used for SAP CP deployment. neo/environment - Map of environment variables in the form of KEY: VALUE. neo/host - The SAP Cloud Platform host to deploy to. neo/propertiesFile - The path to the .properties file in which all necessary deployment properties for the application are defined. neo/runtime - Name of SAP Cloud Platform application runtime. neo/runtimeVersion - Version of SAP Cloud Platform application runtime. neo/size - Compute unit (VM) size. Acceptable values: lite, pro, prem, prem-plus. neo/vmArguments - String of VM arguments passed to the JVM. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. source - The path to the archive for deployment to SAP CP. If not provided the following defaults are used based on the deployMode: 'mta' - The mtarFilePath from common pipeline environment is used instead. 'warParams' and 'warPropertiesFile' - The following template will be used \" /target/ . \" warAction - Action mode when using WAR file mode. Available options are deploy (default) and rolling-update which performs update of an application without downtime in one go. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage deployMode X dockerEnvVars X dockerImage X dockerOptions X extensions X mavenDeploymentModule X neo/account X X neo/application X X neo/credentialsId X X neo/environment X X neo/host X X neo/propertiesFile X X neo/runtime X X neo/runtimeVersion X X neo/size X X neo/vmArguments X X script source X warAction Dependencies \u00b6 The step depends on the following Jenkins plugins credentials-binding docker kubernetes lockable-resources pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Side effects \u00b6 none Exceptions \u00b6 Exception : If source is not provided. If propertiesFile is not provided (when using 'WAR_PROPERTIESFILE' deployment mode). If application is not provided (when using 'WAR_PARAMS' deployment mode). If runtime is not provided (when using 'WAR_PARAMS' deployment mode). If runtimeVersion is not provided (when using 'WAR_PARAMS' deployment mode). AbortException : If neo-java-web-sdk is not properly installed. CredentialNotFoundException : If the credentials cannot be resolved. Example \u00b6 neoDeploy script: this , source: 'path/to/archiveFile.mtar' , neo: [ credentialsId: 'my-credentials-id' , host: hana . example . org ] Example configuration: steps : <...> neoDeploy : deployMode : mta neo : account : <myDeployAccount> host : hana.example.org","title":"neoDeploy"},{"location":"steps/neoDeploy/#neodeploy","text":"","title":"neoDeploy"},{"location":"steps/neoDeploy/#description","text":"Deploys an Application to SAP Cloud Platform (SAP CP) using the SAP Cloud Platform Console Client (Neo Java Web SDK).","title":"Description"},{"location":"steps/neoDeploy/#prerequisites","text":"SAP CP account - the account to where the application is deployed. To deploy MTA ( deployMode: mta ) an over existing Java application, free Java Quota of at least 1 is required, which means that this will not work on trial accounts. SAP CP user for deployment - a user with deployment permissions in the given account. Jenkins credentials for deployment - must be configured in Jenkins credentials with a dedicated Id. Neo Java Web SDK 3.39.10 or compatible version - can be downloaded from Maven Central . This step is capable of triggering the neo deploy tool provided inside a docker image. We provide docker image ppiper/neo-cli . neo.sh needs to be contained in path, e.g by adding a symbolic link to /usr/local/bin . Java 8 or compatible version - needed by the Neo-Java-Web-SDK . Java environment needs to be properly configured (JAVA_HOME, java exectutable contained in path).","title":"Prerequisites"},{"location":"steps/neoDeploy/#parameters","text":"name mandatory default possible values deployMode no mta 'mta', 'warParams', 'warPropertiesFile' dockerEnvVars no dockerImage no ppiper/neo-cli dockerOptions no extensions no [] mavenDeploymentModule no . neo/account for deployMode=warParams neo/application for deployMode=warParams neo/credentialsId no CI_CREDENTIALS_ID neo/environment no neo/host for deployMode=warParams neo/propertiesFile for deployMode=warPropertiesFile neo/runtime for deployMode=warParams neo/runtimeVersion for deployMode=warParams neo/size no lite neo/vmArguments no script yes source yes warAction no deploy 'deploy', 'rolling-update' deployMode - The deployment mode which should be used. Available options are: 'mta' - default, 'warParams' - deploying WAR file and passing all the deployment parameters via the function call, * 'warPropertiesFile' - deploying WAR file and putting all the deployment parameters in a .properties file. dockerEnvVars - Environment variables to set in the container, e.g. [http_proxy: 'proxy:8080']. dockerImage - Name of the docker image that should be used. Configure with empty value to execute the command directly on the Jenkins system (not using a container). Omit to use the default image (cf. default_pipeline_environment.yml ) Overwrite to use custom Docker image. dockerOptions - Docker only: Docker options to be set when starting the container (List or String). extensions - Extension files. Provided to the neo command via parameter --extensions ( -e ). Only valid for deploy mode mta . mavenDeploymentModule - Path to the maven module which contains the deployment artifact. neo/account - The SAP Cloud Platform account to deploy to. neo/application - Name of the application you want to manage, configure, or deploy. neo/credentialsId - The Jenkins credentials containing user and password used for SAP CP deployment. neo/environment - Map of environment variables in the form of KEY: VALUE. neo/host - The SAP Cloud Platform host to deploy to. neo/propertiesFile - The path to the .properties file in which all necessary deployment properties for the application are defined. neo/runtime - Name of SAP Cloud Platform application runtime. neo/runtimeVersion - Version of SAP Cloud Platform application runtime. neo/size - Compute unit (VM) size. Acceptable values: lite, pro, prem, prem-plus. neo/vmArguments - String of VM arguments passed to the JVM. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. source - The path to the archive for deployment to SAP CP. If not provided the following defaults are used based on the deployMode: 'mta' - The mtarFilePath from common pipeline environment is used instead. 'warParams' and 'warPropertiesFile' - The following template will be used \" /target/ . \" warAction - Action mode when using WAR file mode. Available options are deploy (default) and rolling-update which performs update of an application without downtime in one go.","title":"Parameters"},{"location":"steps/neoDeploy/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage deployMode X dockerEnvVars X dockerImage X dockerOptions X extensions X mavenDeploymentModule X neo/account X X neo/application X X neo/credentialsId X X neo/environment X X neo/host X X neo/propertiesFile X X neo/runtime X X neo/runtimeVersion X X neo/size X X neo/vmArguments X X script source X warAction","title":"Step configuration"},{"location":"steps/neoDeploy/#dependencies","text":"The step depends on the following Jenkins plugins credentials-binding docker kubernetes lockable-resources pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/neoDeploy/#side-effects","text":"none","title":"Side effects"},{"location":"steps/neoDeploy/#exceptions","text":"Exception : If source is not provided. If propertiesFile is not provided (when using 'WAR_PROPERTIESFILE' deployment mode). If application is not provided (when using 'WAR_PARAMS' deployment mode). If runtime is not provided (when using 'WAR_PARAMS' deployment mode). If runtimeVersion is not provided (when using 'WAR_PARAMS' deployment mode). AbortException : If neo-java-web-sdk is not properly installed. CredentialNotFoundException : If the credentials cannot be resolved.","title":"Exceptions"},{"location":"steps/neoDeploy/#example","text":"neoDeploy script: this , source: 'path/to/archiveFile.mtar' , neo: [ credentialsId: 'my-credentials-id' , host: hana . example . org ] Example configuration: steps : <...> neoDeploy : deployMode : mta neo : account : <myDeployAccount> host : hana.example.org","title":"Example"},{"location":"steps/newmanExecute/","text":"newmanExecute \u00b6 Description \u00b6 This script executes Postman tests from a collection via the Newman command line tool. Prerequisites \u00b6 prepared Postman with a test collection Parameters \u00b6 name mandatory default possible values cfAppsWithSecrets no cloudFoundry/apiEndpoint no cloudFoundry/credentialsId no cloudFoundry/org no cloudFoundry/space no dockerEnvVars no dockerImage no node:lts-stretch dockerOptions no dockerWorkspace no failOnError no true true , false gitBranch no gitSshKeyCredentialsId no `` Jenkins credentials id newmanCollection no **/*.postman_collection.json newmanEnvironment no `` newmanGlobals no `` newmanInstallCommand no npm install newman newman-reporter-html --global --quiet newmanRunCommand no run '${config.newmanCollection}' --environment '${config.newmanEnvironment}' --globals '${config.newmanGlobals}' --reporters junit,html --reporter-junit-export 'target/newman/TEST-${collectionDisplayName}.xml' --reporter-html-export 'target/newman/TEST-${collectionDisplayName}.html' script yes stashContent no [tests] testRepository no verbose no true , false cfAppsWithSecrets - Define name array of cloud foundry apps deployed for which secrets (clientid and clientsecret) will be appended to the newman command that overrides the environment json entries (--env-var =${clientid} & --env-var =${clientsecret}) cloudFoundry/apiEndpoint - Cloud Foundry API endpoint. cloudFoundry/credentialsId - Credentials to be used for deployment. cloudFoundry/org - Cloud Foundry target organization. cloudFoundry/space - Cloud Foundry target space. dockerEnvVars - Environment variables to set in the container, e.g. [http_proxy: 'proxy:8080']. dockerImage - Name of the docker image that should be used. Configure with empty value to execute the command directly on the Jenkins system (not using a container). Omit to use the default image (cf. default_pipeline_environment.yml ) Overwrite to use custom Docker image. dockerOptions - Docker only: Docker options to be set when starting the container (List or String). dockerWorkspace - Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . failOnError - Defines the behavior, in case tests fail. gitBranch - Only if testRepository is provided: Branch of testRepository, defaults to master. gitSshKeyCredentialsId - Only if testRepository is provided: Credentials for a protected testRepository newmanCollection - The test collection that should be executed. This could also be a file pattern. newmanEnvironment - Specify an environment file path or URL. Environments provide a set of variables that one can use within collections. see also Newman docs newmanGlobals - Specify the file path or URL for global variables. Global variables are similar to environment variables but have a lower precedence and can be overridden by environment variables having the same name. see also Newman docs newmanInstallCommand - The shell command that will be executed inside the docker container to install Newman. newmanRunCommand - The newman command that will be executed inside the docker container. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. stashContent - If specific stashes should be considered for the tests, you can pass this via this parameter. testRepository - Define an additional repository where the test implementation is located. For protected repositories the testRepository needs to contain the ssh git url. verbose - Print more detailed information into the log. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage cfAppsWithSecrets X cloudFoundry/apiEndpoint X cloudFoundry/credentialsId X cloudFoundry/org X cloudFoundry/space X dockerEnvVars X dockerImage X dockerOptions X dockerWorkspace X failOnError X gitBranch X gitSshKeyCredentialsId X newmanCollection X newmanEnvironment X newmanGlobals X newmanInstallCommand X newmanRunCommand X script stashContent X testRepository X verbose X Side effects \u00b6 Step uses dockerExecute inside. Dependencies \u00b6 The step depends on the following Jenkins plugins credentials-binding docker git http_request kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Exceptions \u00b6 none Example \u00b6 Pipeline step: newmanExecute script: this This step should be used in combination with testsPublishResults : newmanExecute script: this , failOnError: false testsPublishResults script: this , junit: [ pattern: '**/newman/TEST-*.xml' ]","title":"newmanExecute"},{"location":"steps/newmanExecute/#newmanexecute","text":"","title":"newmanExecute"},{"location":"steps/newmanExecute/#description","text":"This script executes Postman tests from a collection via the Newman command line tool.","title":"Description"},{"location":"steps/newmanExecute/#prerequisites","text":"prepared Postman with a test collection","title":"Prerequisites"},{"location":"steps/newmanExecute/#parameters","text":"name mandatory default possible values cfAppsWithSecrets no cloudFoundry/apiEndpoint no cloudFoundry/credentialsId no cloudFoundry/org no cloudFoundry/space no dockerEnvVars no dockerImage no node:lts-stretch dockerOptions no dockerWorkspace no failOnError no true true , false gitBranch no gitSshKeyCredentialsId no `` Jenkins credentials id newmanCollection no **/*.postman_collection.json newmanEnvironment no `` newmanGlobals no `` newmanInstallCommand no npm install newman newman-reporter-html --global --quiet newmanRunCommand no run '${config.newmanCollection}' --environment '${config.newmanEnvironment}' --globals '${config.newmanGlobals}' --reporters junit,html --reporter-junit-export 'target/newman/TEST-${collectionDisplayName}.xml' --reporter-html-export 'target/newman/TEST-${collectionDisplayName}.html' script yes stashContent no [tests] testRepository no verbose no true , false cfAppsWithSecrets - Define name array of cloud foundry apps deployed for which secrets (clientid and clientsecret) will be appended to the newman command that overrides the environment json entries (--env-var =${clientid} & --env-var =${clientsecret}) cloudFoundry/apiEndpoint - Cloud Foundry API endpoint. cloudFoundry/credentialsId - Credentials to be used for deployment. cloudFoundry/org - Cloud Foundry target organization. cloudFoundry/space - Cloud Foundry target space. dockerEnvVars - Environment variables to set in the container, e.g. [http_proxy: 'proxy:8080']. dockerImage - Name of the docker image that should be used. Configure with empty value to execute the command directly on the Jenkins system (not using a container). Omit to use the default image (cf. default_pipeline_environment.yml ) Overwrite to use custom Docker image. dockerOptions - Docker only: Docker options to be set when starting the container (List or String). dockerWorkspace - Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . failOnError - Defines the behavior, in case tests fail. gitBranch - Only if testRepository is provided: Branch of testRepository, defaults to master. gitSshKeyCredentialsId - Only if testRepository is provided: Credentials for a protected testRepository newmanCollection - The test collection that should be executed. This could also be a file pattern. newmanEnvironment - Specify an environment file path or URL. Environments provide a set of variables that one can use within collections. see also Newman docs newmanGlobals - Specify the file path or URL for global variables. Global variables are similar to environment variables but have a lower precedence and can be overridden by environment variables having the same name. see also Newman docs newmanInstallCommand - The shell command that will be executed inside the docker container to install Newman. newmanRunCommand - The newman command that will be executed inside the docker container. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. stashContent - If specific stashes should be considered for the tests, you can pass this via this parameter. testRepository - Define an additional repository where the test implementation is located. For protected repositories the testRepository needs to contain the ssh git url. verbose - Print more detailed information into the log.","title":"Parameters"},{"location":"steps/newmanExecute/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage cfAppsWithSecrets X cloudFoundry/apiEndpoint X cloudFoundry/credentialsId X cloudFoundry/org X cloudFoundry/space X dockerEnvVars X dockerImage X dockerOptions X dockerWorkspace X failOnError X gitBranch X gitSshKeyCredentialsId X newmanCollection X newmanEnvironment X newmanGlobals X newmanInstallCommand X newmanRunCommand X script stashContent X testRepository X verbose X","title":"Step configuration"},{"location":"steps/newmanExecute/#side-effects","text":"Step uses dockerExecute inside.","title":"Side effects"},{"location":"steps/newmanExecute/#dependencies","text":"The step depends on the following Jenkins plugins credentials-binding docker git http_request kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/newmanExecute/#exceptions","text":"none","title":"Exceptions"},{"location":"steps/newmanExecute/#example","text":"Pipeline step: newmanExecute script: this This step should be used in combination with testsPublishResults : newmanExecute script: this , failOnError: false testsPublishResults script: this , junit: [ pattern: '**/newman/TEST-*.xml' ]","title":"Example"},{"location":"steps/nexusUpload/","text":"nexusUpload \u00b6 Upload artifacts to Nexus Repository Manager Description \u00b6 Upload build artifacts to a Nexus Repository Manager. Supports MTA, npm and (multi-module) Maven projects. MTA files will be uploaded to a Maven repository. The uploaded file-type depends on your project structure and step configuration. To upload Maven projects, you need a pom.xml in the project root and set the mavenRepository option. To upload MTA projects, you need a mta.yaml in the project root and set the mavenRepository option. To upload npm projects, you need a package.json in the project root and set the npmRepository option. npm: Publishing npm projects makes use of npm's \"publish\" command. It requires a \"package.json\" file in the project's root directory which has \"version\" set and is not delared as \"private\". To find out what will be published, run \"npm publish --dry-run\" in the project's root folder. It will use your gitignore file to exclude the mached files from publishing. Note: npm's gitignore parser might yield different results from your git client, to ignore a \"foo\" directory globally use the glob pattern \"**/foo\". If an image for mavenExecute is configured, and npm packages are to be published, the image must have npm installed. Usage \u00b6 We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line . Jenkins pipelines \u00b6 nexusUpload script: this Command line \u00b6 piper nexusUpload Parameters \u00b6 Overview \u00b6 Name Mandatory Additional information nexusCredentialsId yes id of credentials ( using credentials ) script yes reference to Jenkins main pipeline script url yes artifactId no containerCommand no containerShell no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no dockerVolumeBind no dockerWorkspace no globalSettingsFile no groupId no m2Path no mavenRepository no npmRepository no password no pass via ENV or Jenkins credentials user no pass via ENV or Jenkins credentials verbose no activates debug output version no Details \u00b6 artifactId \u00b6 The artifact ID used for both the .mtar and mta.yaml files deployed for MTA projects, ignored for Maven. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_artifactId (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2610 steps \u2610 stages Resource references none containerCommand \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default (/usr/bin/tail -f /dev/null). back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none containerShell \u00b6 Jenkins-specific: Used for proper environment setup. Allows to specify the shell to be executed for container with containerName. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerEnvVars \u00b6 Jenkins-specific: Used for proper environment setup. Environment variables to set in the container, e.g. [http_proxy: \"proxy:8080\"]. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerImage \u00b6 Jenkins-specific: Used for proper environment setup. Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerName \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Name of the container launching dockerImage. SideCar only: Name of the container in local network. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerOptions \u00b6 Jenkins-specific: Used for proper environment setup. Docker options to be set when starting the container. back to overview Scope Details Aliases - Type []string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerPullImage \u00b6 Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerVolumeBind \u00b6 Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the docker container. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerWorkspace \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none globalSettingsFile \u00b6 Path to the mvn settings file that should be used as global settings file. back to overview Scope Details Aliases maven/globalSettingsFile Type string Mandatory no Default $PIPER_globalSettingsFile (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none groupId \u00b6 Group ID of the artifacts. Only used in MTA projects, ignored for Maven. back to overview Scope Details Aliases nexus/groupId Type string Mandatory no Default $PIPER_groupId (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none m2Path \u00b6 The path to the local .m2 directory, only used for Maven projects. back to overview Scope Details Aliases maven/m2Path Type string Mandatory no Default $PIPER_m2Path (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none mavenRepository \u00b6 Name of the nexus repository for Maven and MTA deployments. If this is not provided, Maven and MTA deployment is implicitly disabled. back to overview Scope Details Aliases - nexus/mavenRepository - nexus/repository ( deprecated ) Type string Mandatory no Default $PIPER_mavenRepository (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none nexusCredentialsId \u00b6 Jenkins-specific: Used for proper environment setup. The technical username/password credential for accessing the nexus endpoint. back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none npmRepository \u00b6 Name of the nexus repository for npm deployments. If this is not provided, npm deployment is implicitly disabled. back to overview Scope Details Aliases nexus/npmRepository Type string Mandatory no Default $PIPER_npmRepository (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none password \u00b6 Password for accessing the Nexus endpoint. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_password (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2610 steps \u2610 stages Resource references none script \u00b6 Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none url \u00b6 URL of the nexus. The scheme part of the URL will not be considered, because only http is supported. back to overview Scope Details Aliases nexus/url Type string Mandatory yes Default $PIPER_url (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none user \u00b6 Username for accessing the Nexus endpoint. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_user (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2610 steps \u2610 stages Resource references none verbose \u00b6 verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none version \u00b6 The Nexus Repository Manager version. Currently supported are 'nexus2' and 'nexus3'. back to overview Scope Details Aliases nexus/version Type string Mandatory no Default nexus3 Possible values - nexus2 - nexus3 Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none \u00b6","title":"nexusUpload"},{"location":"steps/nexusUpload/#nexusupload","text":"Upload artifacts to Nexus Repository Manager","title":"nexusUpload"},{"location":"steps/nexusUpload/#description","text":"Upload build artifacts to a Nexus Repository Manager. Supports MTA, npm and (multi-module) Maven projects. MTA files will be uploaded to a Maven repository. The uploaded file-type depends on your project structure and step configuration. To upload Maven projects, you need a pom.xml in the project root and set the mavenRepository option. To upload MTA projects, you need a mta.yaml in the project root and set the mavenRepository option. To upload npm projects, you need a package.json in the project root and set the npmRepository option. npm: Publishing npm projects makes use of npm's \"publish\" command. It requires a \"package.json\" file in the project's root directory which has \"version\" set and is not delared as \"private\". To find out what will be published, run \"npm publish --dry-run\" in the project's root folder. It will use your gitignore file to exclude the mached files from publishing. Note: npm's gitignore parser might yield different results from your git client, to ignore a \"foo\" directory globally use the glob pattern \"**/foo\". If an image for mavenExecute is configured, and npm packages are to be published, the image must have npm installed.","title":"Description"},{"location":"steps/nexusUpload/#usage","text":"We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line .","title":"Usage"},{"location":"steps/nexusUpload/#jenkins-pipelines","text":"nexusUpload script: this","title":"Jenkins pipelines"},{"location":"steps/nexusUpload/#command-line","text":"piper nexusUpload","title":"Command line"},{"location":"steps/nexusUpload/#parameters","text":"","title":"Parameters"},{"location":"steps/nexusUpload/#overview","text":"Name Mandatory Additional information nexusCredentialsId yes id of credentials ( using credentials ) script yes reference to Jenkins main pipeline script url yes artifactId no containerCommand no containerShell no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no dockerVolumeBind no dockerWorkspace no globalSettingsFile no groupId no m2Path no mavenRepository no npmRepository no password no pass via ENV or Jenkins credentials user no pass via ENV or Jenkins credentials verbose no activates debug output version no","title":"Overview"},{"location":"steps/nexusUpload/#details","text":"","title":"Details"},{"location":"steps/nexusUpload/#artifactid","text":"The artifact ID used for both the .mtar and mta.yaml files deployed for MTA projects, ignored for Maven. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_artifactId (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2610 steps \u2610 stages Resource references none","title":"artifactId"},{"location":"steps/nexusUpload/#containercommand","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default (/usr/bin/tail -f /dev/null). back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"containerCommand"},{"location":"steps/nexusUpload/#containershell","text":"Jenkins-specific: Used for proper environment setup. Allows to specify the shell to be executed for container with containerName. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"containerShell"},{"location":"steps/nexusUpload/#dockerenvvars","text":"Jenkins-specific: Used for proper environment setup. Environment variables to set in the container, e.g. [http_proxy: \"proxy:8080\"]. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerEnvVars"},{"location":"steps/nexusUpload/#dockerimage","text":"Jenkins-specific: Used for proper environment setup. Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerImage"},{"location":"steps/nexusUpload/#dockername","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Name of the container launching dockerImage. SideCar only: Name of the container in local network. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerName"},{"location":"steps/nexusUpload/#dockeroptions","text":"Jenkins-specific: Used for proper environment setup. Docker options to be set when starting the container. back to overview Scope Details Aliases - Type []string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerOptions"},{"location":"steps/nexusUpload/#dockerpullimage","text":"Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerPullImage"},{"location":"steps/nexusUpload/#dockervolumebind","text":"Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the docker container. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerVolumeBind"},{"location":"steps/nexusUpload/#dockerworkspace","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerWorkspace"},{"location":"steps/nexusUpload/#globalsettingsfile","text":"Path to the mvn settings file that should be used as global settings file. back to overview Scope Details Aliases maven/globalSettingsFile Type string Mandatory no Default $PIPER_globalSettingsFile (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"globalSettingsFile"},{"location":"steps/nexusUpload/#groupid","text":"Group ID of the artifacts. Only used in MTA projects, ignored for Maven. back to overview Scope Details Aliases nexus/groupId Type string Mandatory no Default $PIPER_groupId (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"groupId"},{"location":"steps/nexusUpload/#m2path","text":"The path to the local .m2 directory, only used for Maven projects. back to overview Scope Details Aliases maven/m2Path Type string Mandatory no Default $PIPER_m2Path (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"m2Path"},{"location":"steps/nexusUpload/#mavenrepository","text":"Name of the nexus repository for Maven and MTA deployments. If this is not provided, Maven and MTA deployment is implicitly disabled. back to overview Scope Details Aliases - nexus/mavenRepository - nexus/repository ( deprecated ) Type string Mandatory no Default $PIPER_mavenRepository (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"mavenRepository"},{"location":"steps/nexusUpload/#nexuscredentialsid","text":"Jenkins-specific: Used for proper environment setup. The technical username/password credential for accessing the nexus endpoint. back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"nexusCredentialsId"},{"location":"steps/nexusUpload/#npmrepository","text":"Name of the nexus repository for npm deployments. If this is not provided, npm deployment is implicitly disabled. back to overview Scope Details Aliases nexus/npmRepository Type string Mandatory no Default $PIPER_npmRepository (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"npmRepository"},{"location":"steps/nexusUpload/#password","text":"Password for accessing the Nexus endpoint. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_password (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2610 steps \u2610 stages Resource references none","title":"password"},{"location":"steps/nexusUpload/#script","text":"Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none","title":"script"},{"location":"steps/nexusUpload/#url","text":"URL of the nexus. The scheme part of the URL will not be considered, because only http is supported. back to overview Scope Details Aliases nexus/url Type string Mandatory yes Default $PIPER_url (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"url"},{"location":"steps/nexusUpload/#user","text":"Username for accessing the Nexus endpoint. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_user (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2610 steps \u2610 stages Resource references none","title":"user"},{"location":"steps/nexusUpload/#verbose","text":"verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"verbose"},{"location":"steps/nexusUpload/#version","text":"The Nexus Repository Manager version. Currently supported are 'nexus2' and 'nexus3'. back to overview Scope Details Aliases nexus/version Type string Mandatory no Default nexus3 Possible values - nexus2 - nexus3 Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"version"},{"location":"steps/npmExecute/","text":"npmExecute \u00b6 Parameters \u00b6 name mandatory default possible values defaultNpmRegistry no dockerEnvVars no dockerImage no node:lts-stretch dockerOptions no dockerWorkspace no npmCommand no script yes defaultNpmRegistry - URL of default NPM registry dockerEnvVars - Environment variables to set in the container, e.g. [http_proxy: 'proxy:8080']. dockerImage - Name of the docker image that should be used, in which node should be installed and configured. dockerOptions - Docker options to be set when starting the container. dockerWorkspace - Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . npmCommand - Which NPM command should be executed. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage defaultNpmRegistry X dockerEnvVars X dockerImage X dockerOptions X dockerWorkspace X npmCommand X script Dependencies \u00b6 The step depends on the following Jenkins plugins docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Exceptions \u00b6 None Examples \u00b6 npmExecute script: this , dockerImage: 'node:8-stretch' , npmCommand: 'run build'","title":"npmExecute"},{"location":"steps/npmExecute/#npmexecute","text":"","title":"npmExecute"},{"location":"steps/npmExecute/#parameters","text":"name mandatory default possible values defaultNpmRegistry no dockerEnvVars no dockerImage no node:lts-stretch dockerOptions no dockerWorkspace no npmCommand no script yes defaultNpmRegistry - URL of default NPM registry dockerEnvVars - Environment variables to set in the container, e.g. [http_proxy: 'proxy:8080']. dockerImage - Name of the docker image that should be used, in which node should be installed and configured. dockerOptions - Docker options to be set when starting the container. dockerWorkspace - Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . npmCommand - Which NPM command should be executed. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters.","title":"Parameters"},{"location":"steps/npmExecute/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage defaultNpmRegistry X dockerEnvVars X dockerImage X dockerOptions X dockerWorkspace X npmCommand X script","title":"Step configuration"},{"location":"steps/npmExecute/#dependencies","text":"The step depends on the following Jenkins plugins docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/npmExecute/#exceptions","text":"None","title":"Exceptions"},{"location":"steps/npmExecute/#examples","text":"npmExecute script: this , dockerImage: 'node:8-stretch' , npmCommand: 'run build'","title":"Examples"},{"location":"steps/npmExecuteEndToEndTests/","text":"npmExecuteEndToEndTests \u00b6 Description \u00b6 Executes end to end tests by running the npm script configured via the runScript property. Parameters \u00b6 name mandatory default possible values appUrls no buildDescriptorExcludeList no parallelExecution no runScript no script yes appUrls - The URLs under which the app is available after deployment. Each element of appUrls must be a map containing a property url, an optional property credentialId, and an optional property parameters. The optional property parameters can be used to pass additional parameters to the end-to-end test deployment reachable via the given application URL. These parameters must be a list of strings, where each string corresponds to one element of the parameters. For example, if the parameter --tag scenario1 should be passed to the test, specify parameters: [\"--tag\", \"scenario1\"]. These parameters are appended to the npm command during execution. buildDescriptorExcludeList - List of build descriptors and therefore modules to exclude from execution of the npm scripts. The elements of the list can either be a path to the build descriptor or a pattern. parallelExecution - Executes the deployments in parallel. runScript - Script to be executed from package.json. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage appUrls X buildDescriptorExcludeList X parallelExecution X X runScript X script","title":"npmExecuteEndToEndTests"},{"location":"steps/npmExecuteEndToEndTests/#npmexecuteendtoendtests","text":"","title":"npmExecuteEndToEndTests"},{"location":"steps/npmExecuteEndToEndTests/#description","text":"Executes end to end tests by running the npm script configured via the runScript property.","title":"Description"},{"location":"steps/npmExecuteEndToEndTests/#parameters","text":"name mandatory default possible values appUrls no buildDescriptorExcludeList no parallelExecution no runScript no script yes appUrls - The URLs under which the app is available after deployment. Each element of appUrls must be a map containing a property url, an optional property credentialId, and an optional property parameters. The optional property parameters can be used to pass additional parameters to the end-to-end test deployment reachable via the given application URL. These parameters must be a list of strings, where each string corresponds to one element of the parameters. For example, if the parameter --tag scenario1 should be passed to the test, specify parameters: [\"--tag\", \"scenario1\"]. These parameters are appended to the npm command during execution. buildDescriptorExcludeList - List of build descriptors and therefore modules to exclude from execution of the npm scripts. The elements of the list can either be a path to the build descriptor or a pattern. parallelExecution - Executes the deployments in parallel. runScript - Script to be executed from package.json. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters.","title":"Parameters"},{"location":"steps/npmExecuteEndToEndTests/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage appUrls X buildDescriptorExcludeList X parallelExecution X X runScript X script","title":"Step configuration"},{"location":"steps/npmExecuteLint/","text":"npmExecuteLint \u00b6 Execute ci-lint script on all npm packages in a project or execute default linting Description \u00b6 Execute ci-lint script for all package json files, if they implement the script. If no ci-lint script is defined, either use ESLint configurations present in the project or use the provided general purpose configuration to run ESLint. Usage \u00b6 We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line . Jenkins pipelines \u00b6 npmExecuteLint script: this Command line \u00b6 piper npmExecuteLint Parameters \u00b6 Overview \u00b6 Name Mandatory Additional information script yes reference to Jenkins main pipeline script containerCommand no containerShell no defaultNpmRegistry no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no dockerVolumeBind no dockerWorkspace no failOnError no verbose no activates debug output Details \u00b6 containerCommand \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default (/usr/bin/tail -f /dev/null). back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none containerShell \u00b6 Jenkins-specific: Used for proper environment setup. Allows to specify the shell to be executed for container with containerName. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none defaultNpmRegistry \u00b6 URL of the npm registry to use. Defaults to https://registry.npmjs.org/ back to overview Scope Details Aliases npm/defaultNpmRegistry Type string Mandatory no Default $PIPER_defaultNpmRegistry (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerEnvVars \u00b6 Jenkins-specific: Used for proper environment setup. Environment variables to set in the container, e.g. [http_proxy: \"proxy:8080\"]. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerImage \u00b6 Jenkins-specific: Used for proper environment setup. Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerName \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Name of the container launching dockerImage. SideCar only: Name of the container in local network. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerOptions \u00b6 Jenkins-specific: Used for proper environment setup. Docker options to be set when starting the container. back to overview Scope Details Aliases - Type []string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerPullImage \u00b6 Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerVolumeBind \u00b6 Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the docker container. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerWorkspace \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none failOnError \u00b6 Defines the behavior in case linting errors are found. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none script \u00b6 Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none verbose \u00b6 verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none \u00b6","title":"npmExecuteLint"},{"location":"steps/npmExecuteLint/#npmexecutelint","text":"Execute ci-lint script on all npm packages in a project or execute default linting","title":"npmExecuteLint"},{"location":"steps/npmExecuteLint/#description","text":"Execute ci-lint script for all package json files, if they implement the script. If no ci-lint script is defined, either use ESLint configurations present in the project or use the provided general purpose configuration to run ESLint.","title":"Description"},{"location":"steps/npmExecuteLint/#usage","text":"We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line .","title":"Usage"},{"location":"steps/npmExecuteLint/#jenkins-pipelines","text":"npmExecuteLint script: this","title":"Jenkins pipelines"},{"location":"steps/npmExecuteLint/#command-line","text":"piper npmExecuteLint","title":"Command line"},{"location":"steps/npmExecuteLint/#parameters","text":"","title":"Parameters"},{"location":"steps/npmExecuteLint/#overview","text":"Name Mandatory Additional information script yes reference to Jenkins main pipeline script containerCommand no containerShell no defaultNpmRegistry no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no dockerVolumeBind no dockerWorkspace no failOnError no verbose no activates debug output","title":"Overview"},{"location":"steps/npmExecuteLint/#details","text":"","title":"Details"},{"location":"steps/npmExecuteLint/#containercommand","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default (/usr/bin/tail -f /dev/null). back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"containerCommand"},{"location":"steps/npmExecuteLint/#containershell","text":"Jenkins-specific: Used for proper environment setup. Allows to specify the shell to be executed for container with containerName. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"containerShell"},{"location":"steps/npmExecuteLint/#defaultnpmregistry","text":"URL of the npm registry to use. Defaults to https://registry.npmjs.org/ back to overview Scope Details Aliases npm/defaultNpmRegistry Type string Mandatory no Default $PIPER_defaultNpmRegistry (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"defaultNpmRegistry"},{"location":"steps/npmExecuteLint/#dockerenvvars","text":"Jenkins-specific: Used for proper environment setup. Environment variables to set in the container, e.g. [http_proxy: \"proxy:8080\"]. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerEnvVars"},{"location":"steps/npmExecuteLint/#dockerimage","text":"Jenkins-specific: Used for proper environment setup. Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerImage"},{"location":"steps/npmExecuteLint/#dockername","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Name of the container launching dockerImage. SideCar only: Name of the container in local network. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerName"},{"location":"steps/npmExecuteLint/#dockeroptions","text":"Jenkins-specific: Used for proper environment setup. Docker options to be set when starting the container. back to overview Scope Details Aliases - Type []string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerOptions"},{"location":"steps/npmExecuteLint/#dockerpullimage","text":"Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerPullImage"},{"location":"steps/npmExecuteLint/#dockervolumebind","text":"Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the docker container. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerVolumeBind"},{"location":"steps/npmExecuteLint/#dockerworkspace","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerWorkspace"},{"location":"steps/npmExecuteLint/#failonerror","text":"Defines the behavior in case linting errors are found. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"failOnError"},{"location":"steps/npmExecuteLint/#script","text":"Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none","title":"script"},{"location":"steps/npmExecuteLint/#verbose","text":"verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"verbose"},{"location":"steps/npmExecuteScripts/","text":"npmExecuteScripts \u00b6 Execute npm run scripts on all npm packages in a project Description \u00b6 Execute npm run scripts in all package json files, if they implement the scripts. Usage \u00b6 We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line . Jenkins pipelines \u00b6 npmExecuteScripts script: this Command line \u00b6 piper npmExecuteScripts Parameters \u00b6 Overview \u00b6 Name Mandatory Additional information script yes reference to Jenkins main pipeline script buildDescriptorExcludeList no containerCommand no containerShell no defaultNpmRegistry no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no dockerVolumeBind no dockerWorkspace no install no runScripts no scriptOptions no verbose no activates debug output virtualFrameBuffer no Details \u00b6 buildDescriptorExcludeList \u00b6 List of build descriptors and therefore modules to exclude from execution of the npm scripts. The elements can either be a path to the build descriptor or a pattern. back to overview Scope Details Aliases - Type []string Mandatory no Default - deployment/** Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none containerCommand \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default (/usr/bin/tail -f /dev/null). back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none containerShell \u00b6 Jenkins-specific: Used for proper environment setup. Allows to specify the shell to be executed for container with containerName. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none defaultNpmRegistry \u00b6 URL of the npm registry to use. Defaults to https://registry.npmjs.org/ back to overview Scope Details Aliases npm/defaultNpmRegistry Type string Mandatory no Default $PIPER_defaultNpmRegistry (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerEnvVars \u00b6 Jenkins-specific: Used for proper environment setup. Environment variables to set in the container, e.g. [http_proxy: \"proxy:8080\"]. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerImage \u00b6 Jenkins-specific: Used for proper environment setup. Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerName \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Name of the container launching dockerImage. SideCar only: Name of the container in local network. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerOptions \u00b6 Jenkins-specific: Used for proper environment setup. Docker options to be set when starting the container. back to overview Scope Details Aliases - Type []string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerPullImage \u00b6 Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerVolumeBind \u00b6 Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the docker container. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerWorkspace \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none install \u00b6 Run npm install or similar commands depending on the project structure. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none runScripts \u00b6 List of additional run scripts to execute from package.json. back to overview Scope Details Aliases - Type []string Mandatory no Default $PIPER_runScripts (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none script \u00b6 Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none scriptOptions \u00b6 Options are passed to all runScripts calls separated by a '--'. './piper npmExecuteScripts --runScripts ci-e2e --scriptOptions '--tag1' will correspond to 'npm run ci-e2e -- --tag1' back to overview Scope Details Aliases - Type []string Mandatory no Default $PIPER_scriptOptions (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none verbose \u00b6 verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none virtualFrameBuffer \u00b6 (Linux only) Start a virtual frame buffer in the background. This allows you to run a web browser without the need for an X server. Note that xvfb needs to be installed in the execution environment. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none \u00b6","title":"npmExecuteScripts"},{"location":"steps/npmExecuteScripts/#npmexecutescripts","text":"Execute npm run scripts on all npm packages in a project","title":"npmExecuteScripts"},{"location":"steps/npmExecuteScripts/#description","text":"Execute npm run scripts in all package json files, if they implement the scripts.","title":"Description"},{"location":"steps/npmExecuteScripts/#usage","text":"We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line .","title":"Usage"},{"location":"steps/npmExecuteScripts/#jenkins-pipelines","text":"npmExecuteScripts script: this","title":"Jenkins pipelines"},{"location":"steps/npmExecuteScripts/#command-line","text":"piper npmExecuteScripts","title":"Command line"},{"location":"steps/npmExecuteScripts/#parameters","text":"","title":"Parameters"},{"location":"steps/npmExecuteScripts/#overview","text":"Name Mandatory Additional information script yes reference to Jenkins main pipeline script buildDescriptorExcludeList no containerCommand no containerShell no defaultNpmRegistry no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no dockerVolumeBind no dockerWorkspace no install no runScripts no scriptOptions no verbose no activates debug output virtualFrameBuffer no","title":"Overview"},{"location":"steps/npmExecuteScripts/#details","text":"","title":"Details"},{"location":"steps/npmExecuteScripts/#builddescriptorexcludelist","text":"List of build descriptors and therefore modules to exclude from execution of the npm scripts. The elements can either be a path to the build descriptor or a pattern. back to overview Scope Details Aliases - Type []string Mandatory no Default - deployment/** Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"buildDescriptorExcludeList"},{"location":"steps/npmExecuteScripts/#containercommand","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default (/usr/bin/tail -f /dev/null). back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"containerCommand"},{"location":"steps/npmExecuteScripts/#containershell","text":"Jenkins-specific: Used for proper environment setup. Allows to specify the shell to be executed for container with containerName. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"containerShell"},{"location":"steps/npmExecuteScripts/#defaultnpmregistry","text":"URL of the npm registry to use. Defaults to https://registry.npmjs.org/ back to overview Scope Details Aliases npm/defaultNpmRegistry Type string Mandatory no Default $PIPER_defaultNpmRegistry (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"defaultNpmRegistry"},{"location":"steps/npmExecuteScripts/#dockerenvvars","text":"Jenkins-specific: Used for proper environment setup. Environment variables to set in the container, e.g. [http_proxy: \"proxy:8080\"]. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerEnvVars"},{"location":"steps/npmExecuteScripts/#dockerimage","text":"Jenkins-specific: Used for proper environment setup. Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerImage"},{"location":"steps/npmExecuteScripts/#dockername","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Name of the container launching dockerImage. SideCar only: Name of the container in local network. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerName"},{"location":"steps/npmExecuteScripts/#dockeroptions","text":"Jenkins-specific: Used for proper environment setup. Docker options to be set when starting the container. back to overview Scope Details Aliases - Type []string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerOptions"},{"location":"steps/npmExecuteScripts/#dockerpullimage","text":"Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerPullImage"},{"location":"steps/npmExecuteScripts/#dockervolumebind","text":"Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the docker container. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerVolumeBind"},{"location":"steps/npmExecuteScripts/#dockerworkspace","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerWorkspace"},{"location":"steps/npmExecuteScripts/#install","text":"Run npm install or similar commands depending on the project structure. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"install"},{"location":"steps/npmExecuteScripts/#runscripts","text":"List of additional run scripts to execute from package.json. back to overview Scope Details Aliases - Type []string Mandatory no Default $PIPER_runScripts (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"runScripts"},{"location":"steps/npmExecuteScripts/#script","text":"Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none","title":"script"},{"location":"steps/npmExecuteScripts/#scriptoptions","text":"Options are passed to all runScripts calls separated by a '--'. './piper npmExecuteScripts --runScripts ci-e2e --scriptOptions '--tag1' will correspond to 'npm run ci-e2e -- --tag1' back to overview Scope Details Aliases - Type []string Mandatory no Default $PIPER_scriptOptions (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"scriptOptions"},{"location":"steps/npmExecuteScripts/#verbose","text":"verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"verbose"},{"location":"steps/npmExecuteScripts/#virtualframebuffer","text":"(Linux only) Start a virtual frame buffer in the background. This allows you to run a web browser without the need for an X server. Note that xvfb needs to be installed in the execution environment. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"virtualFrameBuffer"},{"location":"steps/pipelineExecute/","text":"pipelineExecute \u00b6 Description \u00b6 Loads and executes a pipeline from another git repository. The idea is to set up a pipeline job in Jenkins that loads a minimal pipeline, which in turn loads the shared library and then uses this step to load the actual pipeline. A centrally maintained pipeline script (Jenkinsfile) can be re-used by several projects using pipelineExecute as outlined in the example below. Prerequisites \u00b6 none Parameters \u00b6 name mandatory default possible values branch no master credentialsId no `` path no Jenkinsfile repoUrl yes script yes branch - The branch of the git repository from which the pipeline should be checked out. credentialsId - The Jenkins credentials containing user and password needed to access a private git repository. In case access to the repository containing the pipeline script is restricted the credentialsId of the credentials used for accessing the repository needs to be provided. The corresponding credentials needs to be configured in Jenkins accordingly. path - The path to the Jenkinsfile, inside the repository, to be loaded. repoUrl - The url to the git repository of the pipeline to be loaded. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage branch credentialsId path repoUrl script Dependencies \u00b6 The step depends on the following Jenkins plugins pipeline-utility-steps workflow-basic-steps workflow-cps workflow-cps-global-lib workflow-durable-task-step workflow-scm-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Side effects \u00b6 none Exceptions \u00b6 Exception If repoUrl is not provided. Example \u00b6 pipelineExecute repoUrl: \"https://github.com/MyOrg/MyPipelineRepo.git\" , branch: 'feature1' , path: 'path/to/Jenkinsfile' , credentialsId: 'MY_REPO_CREDENTIALS'","title":"pipelineExecute"},{"location":"steps/pipelineExecute/#pipelineexecute","text":"","title":"pipelineExecute"},{"location":"steps/pipelineExecute/#description","text":"Loads and executes a pipeline from another git repository. The idea is to set up a pipeline job in Jenkins that loads a minimal pipeline, which in turn loads the shared library and then uses this step to load the actual pipeline. A centrally maintained pipeline script (Jenkinsfile) can be re-used by several projects using pipelineExecute as outlined in the example below.","title":"Description"},{"location":"steps/pipelineExecute/#prerequisites","text":"none","title":"Prerequisites"},{"location":"steps/pipelineExecute/#parameters","text":"name mandatory default possible values branch no master credentialsId no `` path no Jenkinsfile repoUrl yes script yes branch - The branch of the git repository from which the pipeline should be checked out. credentialsId - The Jenkins credentials containing user and password needed to access a private git repository. In case access to the repository containing the pipeline script is restricted the credentialsId of the credentials used for accessing the repository needs to be provided. The corresponding credentials needs to be configured in Jenkins accordingly. path - The path to the Jenkinsfile, inside the repository, to be loaded. repoUrl - The url to the git repository of the pipeline to be loaded. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters.","title":"Parameters"},{"location":"steps/pipelineExecute/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage branch credentialsId path repoUrl script","title":"Step configuration"},{"location":"steps/pipelineExecute/#dependencies","text":"The step depends on the following Jenkins plugins pipeline-utility-steps workflow-basic-steps workflow-cps workflow-cps-global-lib workflow-durable-task-step workflow-scm-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/pipelineExecute/#side-effects","text":"none","title":"Side effects"},{"location":"steps/pipelineExecute/#exceptions","text":"Exception If repoUrl is not provided.","title":"Exceptions"},{"location":"steps/pipelineExecute/#example","text":"pipelineExecute repoUrl: \"https://github.com/MyOrg/MyPipelineRepo.git\" , branch: 'feature1' , path: 'path/to/Jenkinsfile' , credentialsId: 'MY_REPO_CREDENTIALS'","title":"Example"},{"location":"steps/pipelineRestartSteps/","text":"pipelineRestartSteps \u00b6 Description \u00b6 Support of restarting failed stages or steps in a pipeline is limited in Jenkins. This has been documented in the Jenkins Jira issue JENKINS-33846 . For declarative pipelines there is a solution available which partially addresses this topic: https://jenkins.io/doc/book/pipeline/running-pipelines/#restart-from-a-stage. Nonetheless, still features are missing, so it can't be used in all cases. The more complex Piper pipelines which share a state via commonPipelineEnvironment will for example not work with the standard restart-from-stage . The step pipelineRestartSteps aims to address this gap and allows individual parts of a pipeline (e.g. a failed deployment) to be restarted. This is done in a way that the pipeline waits for user input to restart the pipeline in case of a failure. In case this user input is not provided the pipeline stops after a timeout which can be configured. Prerequisites \u00b6 none Parameters \u00b6 name mandatory default possible values script yes sendMail no true timeoutInSeconds no 900 script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. sendMail - If it is set to true the step mailSendNotification will be triggered in case of an error. timeoutInSeconds - Defines the time period where the job waits for input. Default is 15 minutes. Once this time is passed the job enters state FAILED . Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage script sendMail X timeoutInSeconds X Example \u00b6 Usage of pipeline step: pipelineRestartSteps ( script: this ) { node { //your steps ... } } Caution Use node inside the step. If a node exists outside the step context, the input step which is triggered in the process will block a Jenkins executor. In case you cannot use node inside this step, please choose the parameter timeoutInSeconds carefully! Side effects \u00b6 none Dependencies \u00b6 The step depends on the following Jenkins plugins email-ext pipeline-input-step pipeline-utility-steps ssh-agent workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Exceptions \u00b6 none","title":"pipelineRestartSteps"},{"location":"steps/pipelineRestartSteps/#pipelinerestartsteps","text":"","title":"pipelineRestartSteps"},{"location":"steps/pipelineRestartSteps/#description","text":"Support of restarting failed stages or steps in a pipeline is limited in Jenkins. This has been documented in the Jenkins Jira issue JENKINS-33846 . For declarative pipelines there is a solution available which partially addresses this topic: https://jenkins.io/doc/book/pipeline/running-pipelines/#restart-from-a-stage. Nonetheless, still features are missing, so it can't be used in all cases. The more complex Piper pipelines which share a state via commonPipelineEnvironment will for example not work with the standard restart-from-stage . The step pipelineRestartSteps aims to address this gap and allows individual parts of a pipeline (e.g. a failed deployment) to be restarted. This is done in a way that the pipeline waits for user input to restart the pipeline in case of a failure. In case this user input is not provided the pipeline stops after a timeout which can be configured.","title":"Description"},{"location":"steps/pipelineRestartSteps/#prerequisites","text":"none","title":"Prerequisites"},{"location":"steps/pipelineRestartSteps/#parameters","text":"name mandatory default possible values script yes sendMail no true timeoutInSeconds no 900 script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. sendMail - If it is set to true the step mailSendNotification will be triggered in case of an error. timeoutInSeconds - Defines the time period where the job waits for input. Default is 15 minutes. Once this time is passed the job enters state FAILED .","title":"Parameters"},{"location":"steps/pipelineRestartSteps/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage script sendMail X timeoutInSeconds X","title":"Step configuration"},{"location":"steps/pipelineRestartSteps/#example","text":"Usage of pipeline step: pipelineRestartSteps ( script: this ) { node { //your steps ... } } Caution Use node inside the step. If a node exists outside the step context, the input step which is triggered in the process will block a Jenkins executor. In case you cannot use node inside this step, please choose the parameter timeoutInSeconds carefully!","title":"Example"},{"location":"steps/pipelineRestartSteps/#side-effects","text":"none","title":"Side effects"},{"location":"steps/pipelineRestartSteps/#dependencies","text":"The step depends on the following Jenkins plugins email-ext pipeline-input-step pipeline-utility-steps ssh-agent workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/pipelineRestartSteps/#exceptions","text":"none","title":"Exceptions"},{"location":"steps/pipelineStashFiles/","text":"pipelineStashFiles \u00b6 Description \u00b6 This step stashes files that are needed in other build steps (on other nodes). Prerequisites \u00b6 none Parameters \u00b6 name mandatory default possible values script yes stashExcludes no stashIncludes no script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. stashExcludes - Can be used to overwrite the default behavior of existing stashes as well as to define additional stashes. This parameter handles the excludes and can be defined as a map of stash name and exclude patterns. Exclude pattern has to be a string with comma separated patterns as per Pipeline basic step stash stashIncludes - Can be used to overwrite the default behavior of existing stashes as well as to define additional stashes. This parameter handles the includes and can be defined as a map of stash name and include patterns. Include pattern has to be a string with comma separated patterns as per Pipeline basic step stash Details: The step is stashing files before and after the build. This is due to the fact, that some of the code that needs to be stashed, is generated during the build (TypeScript for NPM). stash name mandatory prerequisite pattern buildDescriptor no includes: **/pom.xml, **/.mvn/**, **/assembly.xml, **/.swagger-codegen-ignore, **/package.json, **/requirements.txt, **/setup.py, **/whitesource_config.py, **/mta*.y*ml, **/.npmrc, **/whitesource.*.json, **/whitesource-fs-agent.config, Dockerfile, **/VERSION, **/version.txt, **/Gopkg.*, **/dub.json, **/dub.sdl, **/build.sbt, **/sbtDescriptor.json, **/project/* excludes: **/node_modules/**/package.json checkmarx no Checkmarx is enabled includes: **/*.js, **/*.scala, **/*.go, **/*.d, **/*.di excludes: **/*.mockserver.js, node_modules/**/*.js classFiles no includes: **/target/classes/**/*.class, **/target/test-classes/**/*.class excludes: '' deployDescriptor no includes: **/manifest*.y*ml, **/*.mtaext.y*ml, **/*.mtaext, **/xs-app.json, helm/**, *.y*ml exclude: '' git no includes: **/gitmetadata/** exludes: '' opensourceConfiguration no includes: **/srcclr.yml, **/vulas-custom.properties, **/.nsprc, **/.retireignore, **/.retireignore.json, **/.snyk excludes: '' pipelineConfigAndTests no includes: .pipeline/*.* excludes: '' securityDescriptor no includes: **/xs-security.json exludes: '' sonar no includes: **/jacoco*.exec, **/sonar-project.properties exludes: '' tests no includes: **/pom.xml, **/*.json, **/*.xml, **/src/**, **/node_modules/**, **/specs/**, **/env/**, **/*.js excludes: '' Overwriting default stashing behavior It is possible to overwrite the default behavior of the stashes using the parameters stashIncludes and stashExcludes , e.g. stashIncludes: [buildDescriptor: '**/mybuild.yml] stashExcludes: [tests: '**/NOTRELEVANT.*] Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage script stashExcludes stashIncludes Dependencies \u00b6 The step depends on the following Jenkins plugins <none> Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Explanation of pipeline step \u00b6 Usage of pipeline step: pipelineStashFiles script: this { mavenExecute script: this , ... }","title":"pipelineStashFiles"},{"location":"steps/pipelineStashFiles/#pipelinestashfiles","text":"","title":"pipelineStashFiles"},{"location":"steps/pipelineStashFiles/#description","text":"This step stashes files that are needed in other build steps (on other nodes).","title":"Description"},{"location":"steps/pipelineStashFiles/#prerequisites","text":"none","title":"Prerequisites"},{"location":"steps/pipelineStashFiles/#parameters","text":"name mandatory default possible values script yes stashExcludes no stashIncludes no script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. stashExcludes - Can be used to overwrite the default behavior of existing stashes as well as to define additional stashes. This parameter handles the excludes and can be defined as a map of stash name and exclude patterns. Exclude pattern has to be a string with comma separated patterns as per Pipeline basic step stash stashIncludes - Can be used to overwrite the default behavior of existing stashes as well as to define additional stashes. This parameter handles the includes and can be defined as a map of stash name and include patterns. Include pattern has to be a string with comma separated patterns as per Pipeline basic step stash Details: The step is stashing files before and after the build. This is due to the fact, that some of the code that needs to be stashed, is generated during the build (TypeScript for NPM). stash name mandatory prerequisite pattern buildDescriptor no includes: **/pom.xml, **/.mvn/**, **/assembly.xml, **/.swagger-codegen-ignore, **/package.json, **/requirements.txt, **/setup.py, **/whitesource_config.py, **/mta*.y*ml, **/.npmrc, **/whitesource.*.json, **/whitesource-fs-agent.config, Dockerfile, **/VERSION, **/version.txt, **/Gopkg.*, **/dub.json, **/dub.sdl, **/build.sbt, **/sbtDescriptor.json, **/project/* excludes: **/node_modules/**/package.json checkmarx no Checkmarx is enabled includes: **/*.js, **/*.scala, **/*.go, **/*.d, **/*.di excludes: **/*.mockserver.js, node_modules/**/*.js classFiles no includes: **/target/classes/**/*.class, **/target/test-classes/**/*.class excludes: '' deployDescriptor no includes: **/manifest*.y*ml, **/*.mtaext.y*ml, **/*.mtaext, **/xs-app.json, helm/**, *.y*ml exclude: '' git no includes: **/gitmetadata/** exludes: '' opensourceConfiguration no includes: **/srcclr.yml, **/vulas-custom.properties, **/.nsprc, **/.retireignore, **/.retireignore.json, **/.snyk excludes: '' pipelineConfigAndTests no includes: .pipeline/*.* excludes: '' securityDescriptor no includes: **/xs-security.json exludes: '' sonar no includes: **/jacoco*.exec, **/sonar-project.properties exludes: '' tests no includes: **/pom.xml, **/*.json, **/*.xml, **/src/**, **/node_modules/**, **/specs/**, **/env/**, **/*.js excludes: '' Overwriting default stashing behavior It is possible to overwrite the default behavior of the stashes using the parameters stashIncludes and stashExcludes , e.g. stashIncludes: [buildDescriptor: '**/mybuild.yml] stashExcludes: [tests: '**/NOTRELEVANT.*]","title":"Parameters"},{"location":"steps/pipelineStashFiles/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage script stashExcludes stashIncludes","title":"Step configuration"},{"location":"steps/pipelineStashFiles/#dependencies","text":"The step depends on the following Jenkins plugins <none> Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/pipelineStashFiles/#explanation-of-pipeline-step","text":"Usage of pipeline step: pipelineStashFiles script: this { mavenExecute script: this , ... }","title":"Explanation of pipeline step"},{"location":"steps/pipelineStashFilesAfterBuild/","text":"pipelineStashFilesAfterBuild \u00b6 Prerequisites \u00b6 none Parameters \u00b6 name mandatory default possible values noDefaultExludes no [] script yes stashExcludes no [buildResult:, checkmarx:**/*.mockserver.js, node_modules/**/*.js, classFiles:, sonar:] stashIncludes no [buildResult:**/target/*.jar, **/*.mtar, checkmarx:**/*.js, **/*.scala, **/*.py, **/*.go, **/*.d, **/*.di, **/*.xml, **/*.html, classFiles:**/target/classes/**/*.class, **/target/test-classes/**/*.class, sonar:**/jacoco*.exec, **/sonar-project.properties] noDefaultExludes - By default certain files are excluded from stashing (e.g. .git folder). Details can be found as per [Pipeline basic step stash](https://jenkins.io/doc/pipeline/steps/workflow-basic-steps/#stash-stash-some-files-to-be-used-later-in-the-build). This parameter allows to provide a list of stash names for which the standard exclude behavior should be switched off. This will allow you to also stash directories like .git`. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. stashExcludes - Can be used to overwrite the default behavior of existing stashes as well as to define additional stashes. This parameter handles the excludes and can be defined as a map of stash name and exclude patterns. Exclude pattern has to be a string with comma separated patterns as per Pipeline basic step stash stashIncludes - Can be used to overwrite the default behavior of existing stashes as well as to define additional stashes. This parameter handles the includes and can be defined as a map of stash name and include patterns. Include pattern has to be a string with comma separated patterns as per Pipeline basic step stash Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage noDefaultExludes X script stashExcludes X stashIncludes X Dependencies \u00b6 The step depends on the following Jenkins plugins pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"pipelineStashFilesAfterBuild"},{"location":"steps/pipelineStashFilesAfterBuild/#pipelinestashfilesafterbuild","text":"","title":"pipelineStashFilesAfterBuild"},{"location":"steps/pipelineStashFilesAfterBuild/#prerequisites","text":"none","title":"Prerequisites"},{"location":"steps/pipelineStashFilesAfterBuild/#parameters","text":"name mandatory default possible values noDefaultExludes no [] script yes stashExcludes no [buildResult:, checkmarx:**/*.mockserver.js, node_modules/**/*.js, classFiles:, sonar:] stashIncludes no [buildResult:**/target/*.jar, **/*.mtar, checkmarx:**/*.js, **/*.scala, **/*.py, **/*.go, **/*.d, **/*.di, **/*.xml, **/*.html, classFiles:**/target/classes/**/*.class, **/target/test-classes/**/*.class, sonar:**/jacoco*.exec, **/sonar-project.properties] noDefaultExludes - By default certain files are excluded from stashing (e.g. .git folder). Details can be found as per [Pipeline basic step stash](https://jenkins.io/doc/pipeline/steps/workflow-basic-steps/#stash-stash-some-files-to-be-used-later-in-the-build). This parameter allows to provide a list of stash names for which the standard exclude behavior should be switched off. This will allow you to also stash directories like .git`. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. stashExcludes - Can be used to overwrite the default behavior of existing stashes as well as to define additional stashes. This parameter handles the excludes and can be defined as a map of stash name and exclude patterns. Exclude pattern has to be a string with comma separated patterns as per Pipeline basic step stash stashIncludes - Can be used to overwrite the default behavior of existing stashes as well as to define additional stashes. This parameter handles the includes and can be defined as a map of stash name and include patterns. Include pattern has to be a string with comma separated patterns as per Pipeline basic step stash","title":"Parameters"},{"location":"steps/pipelineStashFilesAfterBuild/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage noDefaultExludes X script stashExcludes X stashIncludes X","title":"Step configuration"},{"location":"steps/pipelineStashFilesAfterBuild/#dependencies","text":"The step depends on the following Jenkins plugins pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/pipelineStashFilesBeforeBuild/","text":"pipelineStashFilesBeforeBuild \u00b6 Description \u00b6 This step stashes files that are needed in other build steps (on other nodes). Prerequisites \u00b6 none Parameters \u00b6 name mandatory default possible values noDefaultExludes no [git] script yes stashExcludes no [buildDescriptor:**/node_modules/**/package.json, deployDescriptor:, git:, opensourceConfiguration:, pipelineConfigAndTests:, securityDescriptor:, tests:] stashIncludes no [buildDescriptor:**/pom.xml, **/.mvn/**, **/assembly.xml, **/.swagger-codegen-ignore, **/package.json, **/requirements.txt, **/setup.py, **/mta*.y*ml, **/.npmrc, **/Dockerfile, .hadolint.yaml, **/VERSION, **/version.txt, **/Gopkg.*, **/dub.json, **/dub.sdl, **/build.sbt, **/sbtDescriptor.json, **/project/*, **/ui5.yaml, **/ui5.yml, deployDescriptor:**/manifest*.y*ml, **/*.mtaext.y*ml, **/*.mtaext, **/xs-app.json, helm/**, *.y*ml, git:.git/**, opensourceConfiguration:**/srcclr.yml, **/vulas-custom.properties, **/.nsprc, **/.retireignore, **/.retireignore.json, **/.snyk, **/wss-unified-agent.config, **/vendor/**/*, pipelineConfigAndTests:.pipeline/**, securityDescriptor:**/xs-security.json, tests:**/pom.xml, **/*.json, **/*.xml, **/src/**, **/node_modules/**, **/specs/**, **/env/**, **/*.js, **/tests/**, **/*.html, **/*.css, **/*.properties] noDefaultExludes - By default certain files are excluded from stashing (e.g. .git folder). Details can be found as per [Pipeline basic step stash](https://jenkins.io/doc/pipeline/steps/workflow-basic-steps/#stash-stash-some-files-to-be-used-later-in-the-build). This parameter allows to provide a list of stash names for which the standard exclude behavior should be switched off. This will allow you to also stash directories like .git`. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. stashExcludes - Can be used to overwrite the default behavior of existing stashes as well as to define additional stashes. This parameter handles the excludes and can be defined as a map of stash name and exclude patterns. Exclude pattern has to be a string with comma separated patterns as per Pipeline basic step stash stashIncludes - Can be used to overwrite the default behavior of existing stashes as well as to define additional stashes. This parameter handles the includes and can be defined as a map of stash name and include patterns. Include pattern has to be a string with comma separated patterns as per Pipeline basic step stash Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage noDefaultExludes X script stashExcludes X stashIncludes X Dependencies \u00b6 The step depends on the following Jenkins plugins pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"pipelineStashFilesBeforeBuild"},{"location":"steps/pipelineStashFilesBeforeBuild/#pipelinestashfilesbeforebuild","text":"","title":"pipelineStashFilesBeforeBuild"},{"location":"steps/pipelineStashFilesBeforeBuild/#description","text":"This step stashes files that are needed in other build steps (on other nodes).","title":"Description"},{"location":"steps/pipelineStashFilesBeforeBuild/#prerequisites","text":"none","title":"Prerequisites"},{"location":"steps/pipelineStashFilesBeforeBuild/#parameters","text":"name mandatory default possible values noDefaultExludes no [git] script yes stashExcludes no [buildDescriptor:**/node_modules/**/package.json, deployDescriptor:, git:, opensourceConfiguration:, pipelineConfigAndTests:, securityDescriptor:, tests:] stashIncludes no [buildDescriptor:**/pom.xml, **/.mvn/**, **/assembly.xml, **/.swagger-codegen-ignore, **/package.json, **/requirements.txt, **/setup.py, **/mta*.y*ml, **/.npmrc, **/Dockerfile, .hadolint.yaml, **/VERSION, **/version.txt, **/Gopkg.*, **/dub.json, **/dub.sdl, **/build.sbt, **/sbtDescriptor.json, **/project/*, **/ui5.yaml, **/ui5.yml, deployDescriptor:**/manifest*.y*ml, **/*.mtaext.y*ml, **/*.mtaext, **/xs-app.json, helm/**, *.y*ml, git:.git/**, opensourceConfiguration:**/srcclr.yml, **/vulas-custom.properties, **/.nsprc, **/.retireignore, **/.retireignore.json, **/.snyk, **/wss-unified-agent.config, **/vendor/**/*, pipelineConfigAndTests:.pipeline/**, securityDescriptor:**/xs-security.json, tests:**/pom.xml, **/*.json, **/*.xml, **/src/**, **/node_modules/**, **/specs/**, **/env/**, **/*.js, **/tests/**, **/*.html, **/*.css, **/*.properties] noDefaultExludes - By default certain files are excluded from stashing (e.g. .git folder). Details can be found as per [Pipeline basic step stash](https://jenkins.io/doc/pipeline/steps/workflow-basic-steps/#stash-stash-some-files-to-be-used-later-in-the-build). This parameter allows to provide a list of stash names for which the standard exclude behavior should be switched off. This will allow you to also stash directories like .git`. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. stashExcludes - Can be used to overwrite the default behavior of existing stashes as well as to define additional stashes. This parameter handles the excludes and can be defined as a map of stash name and exclude patterns. Exclude pattern has to be a string with comma separated patterns as per Pipeline basic step stash stashIncludes - Can be used to overwrite the default behavior of existing stashes as well as to define additional stashes. This parameter handles the includes and can be defined as a map of stash name and include patterns. Include pattern has to be a string with comma separated patterns as per Pipeline basic step stash","title":"Parameters"},{"location":"steps/pipelineStashFilesBeforeBuild/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage noDefaultExludes X script stashExcludes X stashIncludes X","title":"Step configuration"},{"location":"steps/pipelineStashFilesBeforeBuild/#dependencies","text":"The step depends on the following Jenkins plugins pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/piperLoadGlobalExtensions/","text":"piperLoadGlobalExtensions \u00b6 Description \u00b6 This step is part of the step setupCommonPipelineEnvironment and should not be used outside independently in a custom pipeline. This step allows users to define extensions (https://sap.github.io/jenkins-library/extensibility/#1-extend-individual-stages) globally instead of in each repository. Instead of defining the extensions in the .pipeline folder the extensions are defined in another repository. You can also place a file called extension_configuration.yml in this repository. Configuration defined in this file will be treated as default values with a lower precedence then custom defaults defined in the project configuration. You can also define additional Jenkins libraries these extensions depend on using a yaml file called sharedLibraries.yml: Example: - name: my-extension-dependency version: git-tag Parameters \u00b6 name mandatory default possible values customDefaults no customDefaultsFromFiles no globalExtensionsDirectory no .pipeline/tmp/global_extensions/ globalExtensionsRepository no globalExtensionsRepositoryCredentialsId no globalExtensionsVersion no script yes customDefaults - This step will reinitialize the defaults. Make sure to pass the same customDefaults as to the step setupCommonPipelineEnvironment customDefaultsFromFiles - This step will reinitialize the defaults. Make sure to pass the same customDefaultsFromFiles as to the step setupCommonPipelineEnvironment globalExtensionsDirectory - Directory where the extensions are cloned to globalExtensionsRepository - Git url of the repository containing the extensions globalExtensionsRepositoryCredentialsId - Credentials required to clone the repository globalExtensionsVersion - Version of the extensions which should be used, e.g. the tag name script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage customDefaults customDefaultsFromFiles globalExtensionsDirectory X globalExtensionsRepository X globalExtensionsRepositoryCredentialsId X globalExtensionsVersion X script Dependencies \u00b6 The step depends on the following Jenkins plugins pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-scm-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"piperLoadGlobalExtensions"},{"location":"steps/piperLoadGlobalExtensions/#piperloadglobalextensions","text":"","title":"piperLoadGlobalExtensions"},{"location":"steps/piperLoadGlobalExtensions/#description","text":"This step is part of the step setupCommonPipelineEnvironment and should not be used outside independently in a custom pipeline. This step allows users to define extensions (https://sap.github.io/jenkins-library/extensibility/#1-extend-individual-stages) globally instead of in each repository. Instead of defining the extensions in the .pipeline folder the extensions are defined in another repository. You can also place a file called extension_configuration.yml in this repository. Configuration defined in this file will be treated as default values with a lower precedence then custom defaults defined in the project configuration. You can also define additional Jenkins libraries these extensions depend on using a yaml file called sharedLibraries.yml: Example: - name: my-extension-dependency version: git-tag","title":"Description"},{"location":"steps/piperLoadGlobalExtensions/#parameters","text":"name mandatory default possible values customDefaults no customDefaultsFromFiles no globalExtensionsDirectory no .pipeline/tmp/global_extensions/ globalExtensionsRepository no globalExtensionsRepositoryCredentialsId no globalExtensionsVersion no script yes customDefaults - This step will reinitialize the defaults. Make sure to pass the same customDefaults as to the step setupCommonPipelineEnvironment customDefaultsFromFiles - This step will reinitialize the defaults. Make sure to pass the same customDefaultsFromFiles as to the step setupCommonPipelineEnvironment globalExtensionsDirectory - Directory where the extensions are cloned to globalExtensionsRepository - Git url of the repository containing the extensions globalExtensionsRepositoryCredentialsId - Credentials required to clone the repository globalExtensionsVersion - Version of the extensions which should be used, e.g. the tag name script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters.","title":"Parameters"},{"location":"steps/piperLoadGlobalExtensions/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage customDefaults customDefaultsFromFiles globalExtensionsDirectory X globalExtensionsRepository X globalExtensionsRepositoryCredentialsId X globalExtensionsVersion X script","title":"Step configuration"},{"location":"steps/piperLoadGlobalExtensions/#dependencies","text":"The step depends on the following Jenkins plugins pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-scm-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/piperPublishWarnings/","text":"piperPublishWarnings \u00b6 Description \u00b6 This step scans the current build log for messages produces by the Piper library steps and publishes them on the Jenkins job run as Piper warnings via the warnings-ng plugin. The default parser detects log entries with the following pattern: [<SEVERITY>] <MESSAGE> (<LIBRARY>/<STEP>) Parameters \u00b6 name mandatory default possible values parserId no piper parserName no Piper parserPattern no \\[(INFO|WARNING|ERROR)\\] (.*) \\(([^) ]*)\\/([^) ]*)\\) parserScript no return builder.guessSeverity(matcher.group(1)).setMessage(matcher.group(2)).setModuleName(matcher.group(3)).setType(matcher.group(4)).buildOptional() recordIssuesSettings no [blameDisabled:true, enabledForFailure:true] script yes parserId - The id of the Groovy script parser. If the id is not present in the current Jenkins configuration it is created. parserName - The display name for the warnings parsed by the parser. Only considered if a new parser is created. parserPattern - The pattern used to parse the log file. Only considered if a new parser is created. parserScript - The script used to parse the matches produced by the pattern into issues. Only considered if a new parser is created. see https://github.com/jenkinsci/analysis-model/blob/master/src/main/java/edu/hm/hafner/analysis/IssueBuilder.java recordIssuesSettings - Settings that are passed to the recordIssues step of the warnings-ng plugin. see https://github.com/jenkinsci/warnings-ng-plugin/blob/master/doc/Documentation.md#configuration script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage parserId X parserName X parserPattern X parserScript X recordIssuesSettings X script Dependencies \u00b6 The step depends on the following Jenkins plugins pipeline-utility-steps warnings-ng workflow-basic-steps workflow-cps-global-lib Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"piperPublishWarnings"},{"location":"steps/piperPublishWarnings/#piperpublishwarnings","text":"","title":"piperPublishWarnings"},{"location":"steps/piperPublishWarnings/#description","text":"This step scans the current build log for messages produces by the Piper library steps and publishes them on the Jenkins job run as Piper warnings via the warnings-ng plugin. The default parser detects log entries with the following pattern: [<SEVERITY>] <MESSAGE> (<LIBRARY>/<STEP>)","title":"Description"},{"location":"steps/piperPublishWarnings/#parameters","text":"name mandatory default possible values parserId no piper parserName no Piper parserPattern no \\[(INFO|WARNING|ERROR)\\] (.*) \\(([^) ]*)\\/([^) ]*)\\) parserScript no return builder.guessSeverity(matcher.group(1)).setMessage(matcher.group(2)).setModuleName(matcher.group(3)).setType(matcher.group(4)).buildOptional() recordIssuesSettings no [blameDisabled:true, enabledForFailure:true] script yes parserId - The id of the Groovy script parser. If the id is not present in the current Jenkins configuration it is created. parserName - The display name for the warnings parsed by the parser. Only considered if a new parser is created. parserPattern - The pattern used to parse the log file. Only considered if a new parser is created. parserScript - The script used to parse the matches produced by the pattern into issues. Only considered if a new parser is created. see https://github.com/jenkinsci/analysis-model/blob/master/src/main/java/edu/hm/hafner/analysis/IssueBuilder.java recordIssuesSettings - Settings that are passed to the recordIssues step of the warnings-ng plugin. see https://github.com/jenkinsci/warnings-ng-plugin/blob/master/doc/Documentation.md#configuration script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters.","title":"Parameters"},{"location":"steps/piperPublishWarnings/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage parserId X parserName X parserPattern X parserScript X recordIssuesSettings X script","title":"Step configuration"},{"location":"steps/piperPublishWarnings/#dependencies","text":"The step depends on the following Jenkins plugins pipeline-utility-steps warnings-ng workflow-basic-steps workflow-cps-global-lib Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/prepareDefaultValues/","text":"prepareDefaultValues \u00b6 Description \u00b6 Loads the pipeline library default values from the file resources/default_pipeline_environment.yml . Afterwards the values can be loaded by the method: ConfigurationLoader.defaultStepConfiguration Parameters \u00b6 name mandatory default possible values script yes script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage script Exceptions \u00b6 None Dependencies \u00b6 The step depends on the following Jenkins plugins pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Example \u00b6 prepareDefaultValues ()","title":"prepareDefaultValues"},{"location":"steps/prepareDefaultValues/#preparedefaultvalues","text":"","title":"prepareDefaultValues"},{"location":"steps/prepareDefaultValues/#description","text":"Loads the pipeline library default values from the file resources/default_pipeline_environment.yml . Afterwards the values can be loaded by the method: ConfigurationLoader.defaultStepConfiguration","title":"Description"},{"location":"steps/prepareDefaultValues/#parameters","text":"name mandatory default possible values script yes script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters.","title":"Parameters"},{"location":"steps/prepareDefaultValues/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage script","title":"Step configuration"},{"location":"steps/prepareDefaultValues/#exceptions","text":"None","title":"Exceptions"},{"location":"steps/prepareDefaultValues/#dependencies","text":"The step depends on the following Jenkins plugins pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/prepareDefaultValues/#example","text":"prepareDefaultValues ()","title":"Example"},{"location":"steps/protecodeExecuteScan/","text":"protecodeExecuteScan \u00b6 Protecode is an Open Source Vulnerability Scanner that is capable of scanning binaries. It can be used to scan docker images but is supports many other programming languages especially those of the C family. Description \u00b6 Protecode is an Open Source Vulnerability Scanner that is capable of scanning binaries. It can be used to scan docker images but is supports many other programming languages especially those of the C family. Auditing findings (Triaging) Triaging is now supported by the Protecode backend and also Piper does consider this information during the analysis of the scan results though product versions are not supported by Protecode. Therefore please make sure that the fileName you are providing does either contain a stable version or that it does not contain one at all. By ensuring that you are able to triage CVEs globally on the upload file's name without affecting any other artifacts scanned in the same Protecode group and as such triaged vulnerabilities will be considered during the next scan and will not fail the build anymore. Usage \u00b6 We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line . Jenkins pipelines \u00b6 protecodeExecuteScan script: this Command line \u00b6 piper protecodeExecuteScan Outputs \u00b6 Output type Details influx measurement protecode_data historical_vulnerabilities triaged_vulnerabilities excluded_vulnerabilities minor_vulnerabilities major_vulnerabilities vulnerabilities Prerequisites \u00b6 Create a Username / Password credential with the Protecode user in your Jenkins credential store Lookup your Group ID using REST API via curl -u <username> \"https://<protecode host>/api/groups/\" . If the image is on a protected registry you can provide a Docker config.json file containing the credential information for the registry. You can create it like explained in the Docker Success Center in the article about how to generate a new auth in the config.json file . Parameters \u00b6 Overview \u00b6 Name Mandatory Additional information dockerConfigJsonCredentialsId yes id of credentials ( using credentials ) group yes password yes pass via ENV or Jenkins credentials protecodeCredentialsId yes id of credentials ( using credentials ) script yes reference to Jenkins main pipeline script serverUrl yes username yes pass via ENV or Jenkins credentials artifactVersion no cleanupMode no dockerConfigJSON no pass via ENV or Jenkins credentials ( dockerConfigJsonCredentialsId ) dockerRegistryUrl no excludeCVEs no failOnSevereVulnerabilities no fetchUrl no filePath no includeLayers no pullRequestName no reportFileName no reuseExisting no scanImage no timeoutMinutes no verbose no activates debug output Details \u00b6 artifactVersion \u00b6 The version of the artifact to allow identification in protecode backend back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_artifactVersion (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references commonPipelineEnvironment : reference to: artifactVersion cleanupMode \u00b6 Decides which parts are removed from the Protecode backend after the scan back to overview Scope Details Aliases - Type string Mandatory no Default binary Possible values - none - binary - complete Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none dockerConfigJSON \u00b6 Path to the file .docker/config.json - this is typically provided by your CI/CD system. You can find more details about the Docker credentials in the Docker documentation . back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_dockerConfigJSON (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references Jenkins credential id: id: dockerConfigJsonCredentialsId reference to: `` dockerConfigJsonCredentialsId \u00b6 Jenkins-specific: Used for proper environment setup. back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerRegistryUrl \u00b6 The reference to the docker registry to scan with Protecode back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_dockerRegistryUrl (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references commonPipelineEnvironment : reference to: container/registryUrl excludeCVEs \u00b6 DEPRECATED: Do use triaging within the Protecode UI instead back to overview Scope Details Aliases protecodeExcludeCVEs Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none failOnSevereVulnerabilities \u00b6 Whether to fail the job on severe vulnerabilties or not back to overview Scope Details Aliases protecodeFailOnSevereVulnerabilities Type bool Mandatory no Default true Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none fetchUrl \u00b6 The URL to fetch the file to scan with Protecode which must be accessible via public HTTP GET request back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_fetchUrl (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none filePath \u00b6 The path to the file from local workspace to scan with Protecode back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_filePath (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none group \u00b6 The Protecode group ID of your team back to overview Scope Details Aliases protecodeGroup Type string Mandatory yes Default $PIPER_group (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none includeLayers \u00b6 Flag if the docker layers should be included back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none password \u00b6 Password which is used for the user back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_password (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none protecodeCredentialsId \u00b6 Jenkins-specific: Used for proper environment setup. back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none pullRequestName \u00b6 The name of the pull request back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_pullRequestName (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none reportFileName \u00b6 The file name of the report to be created back to overview Scope Details Aliases - Type string Mandatory no Default protecode_report.pdf Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none reuseExisting \u00b6 Whether to reuse an existing product instead of creating a new one back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none scanImage \u00b6 The reference to the docker image to scan with Protecode back to overview Scope Details Aliases dockerImage Type string Mandatory no Default $PIPER_scanImage (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references commonPipelineEnvironment : reference to: container/imageNameTag script \u00b6 Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none serverUrl \u00b6 The URL to the Protecode backend back to overview Scope Details Aliases protecodeServerUrl Type string Mandatory yes Default $PIPER_serverUrl (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none timeoutMinutes \u00b6 The timeout to wait for the scan to finish back to overview Scope Details Aliases protecodeTimeoutMinutes Type string Mandatory no Default 60 Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none username \u00b6 User which is used for the protecode scan back to overview Scope Details Aliases user ( deprecated ) Type string Mandatory yes Default $PIPER_username (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none verbose \u00b6 verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none Details \u00b6 The Protecode scan step is able to send a file addressed via parameter filePath to the backend for scanning it for known vulnerabilities. Alternatively an HTTP URL can be specified via fetchUrl . Protecode will then download the artifact from there and scan it. To support docker image scanning please provide scanImage with a docker like URL poiting to the image tag within the docker registry being used. To receive the result it polls until the job completes. Once the job has completed a PDF report is pulled from the backend and archived in the build Finally the scan result is being analysed for critical findings with a CVSS v3 score >= 7.0 and if such findings are detected the build is failed based on the configuration setting failOnSevereVulnerabilities . During the analysis all CVEs which are triaged are ignored and will not provoke the build to fail. \u00b6","title":"protecodeExecuteScan"},{"location":"steps/protecodeExecuteScan/#protecodeexecutescan","text":"Protecode is an Open Source Vulnerability Scanner that is capable of scanning binaries. It can be used to scan docker images but is supports many other programming languages especially those of the C family.","title":"protecodeExecuteScan"},{"location":"steps/protecodeExecuteScan/#description","text":"Protecode is an Open Source Vulnerability Scanner that is capable of scanning binaries. It can be used to scan docker images but is supports many other programming languages especially those of the C family. Auditing findings (Triaging) Triaging is now supported by the Protecode backend and also Piper does consider this information during the analysis of the scan results though product versions are not supported by Protecode. Therefore please make sure that the fileName you are providing does either contain a stable version or that it does not contain one at all. By ensuring that you are able to triage CVEs globally on the upload file's name without affecting any other artifacts scanned in the same Protecode group and as such triaged vulnerabilities will be considered during the next scan and will not fail the build anymore.","title":"Description"},{"location":"steps/protecodeExecuteScan/#usage","text":"We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line .","title":"Usage"},{"location":"steps/protecodeExecuteScan/#jenkins-pipelines","text":"protecodeExecuteScan script: this","title":"Jenkins pipelines"},{"location":"steps/protecodeExecuteScan/#command-line","text":"piper protecodeExecuteScan","title":"Command line"},{"location":"steps/protecodeExecuteScan/#outputs","text":"Output type Details influx measurement protecode_data historical_vulnerabilities triaged_vulnerabilities excluded_vulnerabilities minor_vulnerabilities major_vulnerabilities vulnerabilities","title":"Outputs"},{"location":"steps/protecodeExecuteScan/#prerequisites","text":"Create a Username / Password credential with the Protecode user in your Jenkins credential store Lookup your Group ID using REST API via curl -u <username> \"https://<protecode host>/api/groups/\" . If the image is on a protected registry you can provide a Docker config.json file containing the credential information for the registry. You can create it like explained in the Docker Success Center in the article about how to generate a new auth in the config.json file .","title":"Prerequisites"},{"location":"steps/protecodeExecuteScan/#parameters","text":"","title":"Parameters"},{"location":"steps/protecodeExecuteScan/#overview","text":"Name Mandatory Additional information dockerConfigJsonCredentialsId yes id of credentials ( using credentials ) group yes password yes pass via ENV or Jenkins credentials protecodeCredentialsId yes id of credentials ( using credentials ) script yes reference to Jenkins main pipeline script serverUrl yes username yes pass via ENV or Jenkins credentials artifactVersion no cleanupMode no dockerConfigJSON no pass via ENV or Jenkins credentials ( dockerConfigJsonCredentialsId ) dockerRegistryUrl no excludeCVEs no failOnSevereVulnerabilities no fetchUrl no filePath no includeLayers no pullRequestName no reportFileName no reuseExisting no scanImage no timeoutMinutes no verbose no activates debug output","title":"Overview"},{"location":"steps/protecodeExecuteScan/#details","text":"","title":"Details"},{"location":"steps/protecodeExecuteScan/#artifactversion","text":"The version of the artifact to allow identification in protecode backend back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_artifactVersion (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references commonPipelineEnvironment : reference to: artifactVersion","title":"artifactVersion"},{"location":"steps/protecodeExecuteScan/#cleanupmode","text":"Decides which parts are removed from the Protecode backend after the scan back to overview Scope Details Aliases - Type string Mandatory no Default binary Possible values - none - binary - complete Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"cleanupMode"},{"location":"steps/protecodeExecuteScan/#dockerconfigjson","text":"Path to the file .docker/config.json - this is typically provided by your CI/CD system. You can find more details about the Docker credentials in the Docker documentation . back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_dockerConfigJSON (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references Jenkins credential id: id: dockerConfigJsonCredentialsId reference to: ``","title":"dockerConfigJSON"},{"location":"steps/protecodeExecuteScan/#dockerconfigjsoncredentialsid","text":"Jenkins-specific: Used for proper environment setup. back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerConfigJsonCredentialsId"},{"location":"steps/protecodeExecuteScan/#dockerregistryurl","text":"The reference to the docker registry to scan with Protecode back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_dockerRegistryUrl (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references commonPipelineEnvironment : reference to: container/registryUrl","title":"dockerRegistryUrl"},{"location":"steps/protecodeExecuteScan/#excludecves","text":"DEPRECATED: Do use triaging within the Protecode UI instead back to overview Scope Details Aliases protecodeExcludeCVEs Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"excludeCVEs"},{"location":"steps/protecodeExecuteScan/#failonseverevulnerabilities","text":"Whether to fail the job on severe vulnerabilties or not back to overview Scope Details Aliases protecodeFailOnSevereVulnerabilities Type bool Mandatory no Default true Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"failOnSevereVulnerabilities"},{"location":"steps/protecodeExecuteScan/#fetchurl","text":"The URL to fetch the file to scan with Protecode which must be accessible via public HTTP GET request back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_fetchUrl (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"fetchUrl"},{"location":"steps/protecodeExecuteScan/#filepath","text":"The path to the file from local workspace to scan with Protecode back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_filePath (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"filePath"},{"location":"steps/protecodeExecuteScan/#group","text":"The Protecode group ID of your team back to overview Scope Details Aliases protecodeGroup Type string Mandatory yes Default $PIPER_group (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"group"},{"location":"steps/protecodeExecuteScan/#includelayers","text":"Flag if the docker layers should be included back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"includeLayers"},{"location":"steps/protecodeExecuteScan/#password","text":"Password which is used for the user back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_password (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"password"},{"location":"steps/protecodeExecuteScan/#protecodecredentialsid","text":"Jenkins-specific: Used for proper environment setup. back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"protecodeCredentialsId"},{"location":"steps/protecodeExecuteScan/#pullrequestname","text":"The name of the pull request back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_pullRequestName (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"pullRequestName"},{"location":"steps/protecodeExecuteScan/#reportfilename","text":"The file name of the report to be created back to overview Scope Details Aliases - Type string Mandatory no Default protecode_report.pdf Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"reportFileName"},{"location":"steps/protecodeExecuteScan/#reuseexisting","text":"Whether to reuse an existing product instead of creating a new one back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"reuseExisting"},{"location":"steps/protecodeExecuteScan/#scanimage","text":"The reference to the docker image to scan with Protecode back to overview Scope Details Aliases dockerImage Type string Mandatory no Default $PIPER_scanImage (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references commonPipelineEnvironment : reference to: container/imageNameTag","title":"scanImage"},{"location":"steps/protecodeExecuteScan/#script","text":"Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none","title":"script"},{"location":"steps/protecodeExecuteScan/#serverurl","text":"The URL to the Protecode backend back to overview Scope Details Aliases protecodeServerUrl Type string Mandatory yes Default $PIPER_serverUrl (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"serverUrl"},{"location":"steps/protecodeExecuteScan/#timeoutminutes","text":"The timeout to wait for the scan to finish back to overview Scope Details Aliases protecodeTimeoutMinutes Type string Mandatory no Default 60 Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"timeoutMinutes"},{"location":"steps/protecodeExecuteScan/#username","text":"User which is used for the protecode scan back to overview Scope Details Aliases user ( deprecated ) Type string Mandatory yes Default $PIPER_username (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"username"},{"location":"steps/protecodeExecuteScan/#verbose","text":"verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"verbose"},{"location":"steps/protecodeExecuteScan/#details_1","text":"The Protecode scan step is able to send a file addressed via parameter filePath to the backend for scanning it for known vulnerabilities. Alternatively an HTTP URL can be specified via fetchUrl . Protecode will then download the artifact from there and scan it. To support docker image scanning please provide scanImage with a docker like URL poiting to the image tag within the docker registry being used. To receive the result it polls until the job completes. Once the job has completed a PDF report is pulled from the backend and archived in the build Finally the scan result is being analysed for critical findings with a CVSS v3 score >= 7.0 and if such findings are detected the build is failed based on the configuration setting failOnSevereVulnerabilities . During the analysis all CVEs which are triaged are ignored and will not provoke the build to fail.","title":"Details"},{"location":"steps/seleniumExecuteTests/","text":"seleniumExecuteTests \u00b6 Description \u00b6 Enables UI test execution with Selenium in a sidecar container. The step executes a closure (see example below) connecting to a sidecar container with a Selenium Server. When executing in a local Docker environment, please make sure to set Selenium host to selenium in your tests. Kubernetes environment, plese make sure to set Seleniums host to localhost in your tests. Proxy Environments If work in an environment containing a proxy, please make sure that localhost / selenium is added to your proxy exclusion list, e.g. via environment variable NO_PROXY & no_proxy . You can pass those via parameters dockerEnvVars and sidecarEnvVars directly to the containers if required. Prerequisites \u00b6 none Example \u00b6 seleniumExecuteTests ( script: this ) { git url: 'https://github.com/xxxxx/WebDriverIOTest.git' sh '''npm install node index.js''' } Example test using WebdriverIO \u00b6 Example based on http://webdriver.io/guide/getstarted/modes.html and http://webdriver.io/guide.html Configuration for Local Docker Environment \u00b6 var webdriverio = require ( 'webdriverio' ); var options = { host : 'selenium' , port : 4444 , desiredCapabilities : { browserName : 'chrome' } }; Configuration for Kubernetes Environment \u00b6 var webdriverio = require ( 'webdriverio' ); var options = { host : 'localhost' , port : 4444 , desiredCapabilities : { browserName : 'chrome' } }; Test Code (index.js) \u00b6 // ToDo: add configuration from above webdriverio . remote ( options ) . init () . url ( 'http://www.google.com' ) . getTitle (). then ( function ( title ) { console . log ( 'Title was: ' + title ); }) . end () . catch ( function ( err ) { console . log ( err ); }); Parameters \u00b6 name mandatory default possible values buildTool no npm maven , npm , bundler containerPortMappings no [selenium/standalone-chrome:[[containerPort:4444, hostPort:4444]]] dockerEnvVars no dockerImage no buildTool= maven : maven:3.5-jdk-8 buildTool= npm : node:lts-stretch buildTool= bundler : ruby:2.5.3-stretch dockerName no buildTool= maven : maven buildTool= npm : npm buildTool= bundler : bundler dockerOptions no dockerWorkspace no buildTool= maven : <empty> buildTool= npm : /home/node buildTool= bundler : <empty> failOnError no true true , false gitBranch no gitSshKeyCredentialsId no `` Jenkins credentials id script yes seleniumHubCredentialsId no sidecarEnvVars no sidecarImage no selenium/standalone-chrome sidecarName no selenium sidecarVolumeBind no [/dev/shm:/dev/shm] stashContent no [tests] testRepository no buildTool - Defines the tool which is used for executing the tests containerPortMappings - Map which defines per docker image the port mappings, e.g. containerPortMappings: ['selenium/standalone-chrome': [[name: 'selPort', containerPort: 4444, hostPort: 4444]]] . dockerEnvVars - Environment variables to set in the container, e.g. [http_proxy: 'proxy:8080']. dockerImage - Name of the docker image that should be used. Configure with empty value to execute the command directly on the Jenkins system (not using a container). Omit to use the default image (cf. default_pipeline_environment.yml ) Overwrite to use custom Docker image. dockerName - Kubernetes only: Name of the container launching dockerImage . SideCar only: Name of the container in local network. dockerOptions - Docker only: Docker options to be set when starting the container (List or String). dockerWorkspace - Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . failOnError - With failOnError the behavior in case tests fail can be defined. gitBranch - Only if testRepository is provided: Branch of testRepository, defaults to master. gitSshKeyCredentialsId - Only if testRepository is provided: Credentials for a protected testRepository script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. seleniumHubCredentialsId - Defines the id of the user/password credentials to be used to connect to a Selenium Hub. The credentials are provided in the environment variables PIPER_SELENIUM_HUB_USER and PIPER_SELENIUM_HUB_PASSWORD . sidecarEnvVars - as dockerEnvVars for the sidecar container sidecarImage - as dockerImage for the sidecar container sidecarName - as dockerName for the sidecar container sidecarVolumeBind - as dockerVolumeBind for the sidecar container stashContent - Specific stashes that should be considered for the step execution. testRepository - Define an additional repository where the test implementation is located. For protected repositories the testRepository needs to contain the ssh git url. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage buildTool X X containerPortMappings X X dockerEnvVars X X dockerImage X X dockerName X X dockerOptions X X dockerWorkspace X X failOnError X X gitBranch X X gitSshKeyCredentialsId X X script seleniumHubCredentialsId X X sidecarEnvVars X X sidecarImage X X sidecarName X X sidecarVolumeBind X X stashContent X X testRepository X X Dependencies \u00b6 The step depends on the following Jenkins plugins credentials-binding docker git kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Side effects \u00b6 none Exceptions \u00b6 none","title":"seleniumExecuteTests"},{"location":"steps/seleniumExecuteTests/#seleniumexecutetests","text":"","title":"seleniumExecuteTests"},{"location":"steps/seleniumExecuteTests/#description","text":"Enables UI test execution with Selenium in a sidecar container. The step executes a closure (see example below) connecting to a sidecar container with a Selenium Server. When executing in a local Docker environment, please make sure to set Selenium host to selenium in your tests. Kubernetes environment, plese make sure to set Seleniums host to localhost in your tests. Proxy Environments If work in an environment containing a proxy, please make sure that localhost / selenium is added to your proxy exclusion list, e.g. via environment variable NO_PROXY & no_proxy . You can pass those via parameters dockerEnvVars and sidecarEnvVars directly to the containers if required.","title":"Description"},{"location":"steps/seleniumExecuteTests/#prerequisites","text":"none","title":"Prerequisites"},{"location":"steps/seleniumExecuteTests/#example","text":"seleniumExecuteTests ( script: this ) { git url: 'https://github.com/xxxxx/WebDriverIOTest.git' sh '''npm install node index.js''' }","title":"Example"},{"location":"steps/seleniumExecuteTests/#example-test-using-webdriverio","text":"Example based on http://webdriver.io/guide/getstarted/modes.html and http://webdriver.io/guide.html","title":"Example test using WebdriverIO"},{"location":"steps/seleniumExecuteTests/#configuration-for-local-docker-environment","text":"var webdriverio = require ( 'webdriverio' ); var options = { host : 'selenium' , port : 4444 , desiredCapabilities : { browserName : 'chrome' } };","title":"Configuration for Local Docker Environment"},{"location":"steps/seleniumExecuteTests/#configuration-for-kubernetes-environment","text":"var webdriverio = require ( 'webdriverio' ); var options = { host : 'localhost' , port : 4444 , desiredCapabilities : { browserName : 'chrome' } };","title":"Configuration for Kubernetes Environment"},{"location":"steps/seleniumExecuteTests/#test-code-indexjs","text":"// ToDo: add configuration from above webdriverio . remote ( options ) . init () . url ( 'http://www.google.com' ) . getTitle (). then ( function ( title ) { console . log ( 'Title was: ' + title ); }) . end () . catch ( function ( err ) { console . log ( err ); });","title":"Test Code (index.js)"},{"location":"steps/seleniumExecuteTests/#parameters","text":"name mandatory default possible values buildTool no npm maven , npm , bundler containerPortMappings no [selenium/standalone-chrome:[[containerPort:4444, hostPort:4444]]] dockerEnvVars no dockerImage no buildTool= maven : maven:3.5-jdk-8 buildTool= npm : node:lts-stretch buildTool= bundler : ruby:2.5.3-stretch dockerName no buildTool= maven : maven buildTool= npm : npm buildTool= bundler : bundler dockerOptions no dockerWorkspace no buildTool= maven : <empty> buildTool= npm : /home/node buildTool= bundler : <empty> failOnError no true true , false gitBranch no gitSshKeyCredentialsId no `` Jenkins credentials id script yes seleniumHubCredentialsId no sidecarEnvVars no sidecarImage no selenium/standalone-chrome sidecarName no selenium sidecarVolumeBind no [/dev/shm:/dev/shm] stashContent no [tests] testRepository no buildTool - Defines the tool which is used for executing the tests containerPortMappings - Map which defines per docker image the port mappings, e.g. containerPortMappings: ['selenium/standalone-chrome': [[name: 'selPort', containerPort: 4444, hostPort: 4444]]] . dockerEnvVars - Environment variables to set in the container, e.g. [http_proxy: 'proxy:8080']. dockerImage - Name of the docker image that should be used. Configure with empty value to execute the command directly on the Jenkins system (not using a container). Omit to use the default image (cf. default_pipeline_environment.yml ) Overwrite to use custom Docker image. dockerName - Kubernetes only: Name of the container launching dockerImage . SideCar only: Name of the container in local network. dockerOptions - Docker only: Docker options to be set when starting the container (List or String). dockerWorkspace - Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . failOnError - With failOnError the behavior in case tests fail can be defined. gitBranch - Only if testRepository is provided: Branch of testRepository, defaults to master. gitSshKeyCredentialsId - Only if testRepository is provided: Credentials for a protected testRepository script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. seleniumHubCredentialsId - Defines the id of the user/password credentials to be used to connect to a Selenium Hub. The credentials are provided in the environment variables PIPER_SELENIUM_HUB_USER and PIPER_SELENIUM_HUB_PASSWORD . sidecarEnvVars - as dockerEnvVars for the sidecar container sidecarImage - as dockerImage for the sidecar container sidecarName - as dockerName for the sidecar container sidecarVolumeBind - as dockerVolumeBind for the sidecar container stashContent - Specific stashes that should be considered for the step execution. testRepository - Define an additional repository where the test implementation is located. For protected repositories the testRepository needs to contain the ssh git url.","title":"Parameters"},{"location":"steps/seleniumExecuteTests/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage buildTool X X containerPortMappings X X dockerEnvVars X X dockerImage X X dockerName X X dockerOptions X X dockerWorkspace X X failOnError X X gitBranch X X gitSshKeyCredentialsId X X script seleniumHubCredentialsId X X sidecarEnvVars X X sidecarImage X X sidecarName X X sidecarVolumeBind X X stashContent X X testRepository X X","title":"Step configuration"},{"location":"steps/seleniumExecuteTests/#dependencies","text":"The step depends on the following Jenkins plugins credentials-binding docker git kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/seleniumExecuteTests/#side-effects","text":"none","title":"Side effects"},{"location":"steps/seleniumExecuteTests/#exceptions","text":"none","title":"Exceptions"},{"location":"steps/setupCommonPipelineEnvironment/","text":"setupCommonPipelineEnvironment \u00b6 Description \u00b6 Initializes the commonPipelineEnvironment , which is used throughout the complete pipeline. Tip This step needs to run at the beginning of a pipeline right after the SCM checkout. Then subsequent pipeline steps consume the information from commonPipelineEnvironment ; it does not need to be passed to pipeline steps explicitly. Prerequisites \u00b6 A configuration file with properties. The property values are used as default values in many pipeline steps. Parameters \u00b6 name mandatory default possible values collectTelemetryData no true configFile no customDefaults no customDefaultsCredentialsId no customDefaultsFromFiles no script yes collectTelemetryData - configFile - Path to the pipeline configuration file defining project specific settings. customDefaults - A list of file names which will be extracted from library resources and which serve as source for default values for the pipeline configuration. These are merged with and override built-in defaults, with a parameter supplied by the last resource file taking precedence over the same parameter supplied in an earlier resource file or built-in default. customDefaultsCredentialsId - Credentials (username and password) used to download custom defaults if access is secured. customDefaultsFromFiles - A list of file paths or URLs which must point to YAML content. These work exactly like customDefaults , but from local or remote files instead of library resources. They are merged with and take precedence over customDefaults . script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage collectTelemetryData X configFile customDefaults customDefaultsCredentialsId X customDefaultsFromFiles script Dependencies \u00b6 The step depends on the following Jenkins plugins http_request pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-scm-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Side effects \u00b6 none Exceptions \u00b6 none Example \u00b6 setupCommonPipelineEnvironment script: this","title":"setupCommonPipelineEnvironment"},{"location":"steps/setupCommonPipelineEnvironment/#setupcommonpipelineenvironment","text":"","title":"setupCommonPipelineEnvironment"},{"location":"steps/setupCommonPipelineEnvironment/#description","text":"Initializes the commonPipelineEnvironment , which is used throughout the complete pipeline. Tip This step needs to run at the beginning of a pipeline right after the SCM checkout. Then subsequent pipeline steps consume the information from commonPipelineEnvironment ; it does not need to be passed to pipeline steps explicitly.","title":"Description"},{"location":"steps/setupCommonPipelineEnvironment/#prerequisites","text":"A configuration file with properties. The property values are used as default values in many pipeline steps.","title":"Prerequisites"},{"location":"steps/setupCommonPipelineEnvironment/#parameters","text":"name mandatory default possible values collectTelemetryData no true configFile no customDefaults no customDefaultsCredentialsId no customDefaultsFromFiles no script yes collectTelemetryData - configFile - Path to the pipeline configuration file defining project specific settings. customDefaults - A list of file names which will be extracted from library resources and which serve as source for default values for the pipeline configuration. These are merged with and override built-in defaults, with a parameter supplied by the last resource file taking precedence over the same parameter supplied in an earlier resource file or built-in default. customDefaultsCredentialsId - Credentials (username and password) used to download custom defaults if access is secured. customDefaultsFromFiles - A list of file paths or URLs which must point to YAML content. These work exactly like customDefaults , but from local or remote files instead of library resources. They are merged with and take precedence over customDefaults . script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters.","title":"Parameters"},{"location":"steps/setupCommonPipelineEnvironment/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage collectTelemetryData X configFile customDefaults customDefaultsCredentialsId X customDefaultsFromFiles script","title":"Step configuration"},{"location":"steps/setupCommonPipelineEnvironment/#dependencies","text":"The step depends on the following Jenkins plugins http_request pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-scm-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/setupCommonPipelineEnvironment/#side-effects","text":"none","title":"Side effects"},{"location":"steps/setupCommonPipelineEnvironment/#exceptions","text":"none","title":"Exceptions"},{"location":"steps/setupCommonPipelineEnvironment/#example","text":"setupCommonPipelineEnvironment script: this","title":"Example"},{"location":"steps/slackSendNotification/","text":"slackSendNotification \u00b6 Description \u00b6 Sends notifications to the Slack channel about the build status. Notification contains: Build status Repo Owner Repo Name Branch Name Jenkins Build Number Jenkins Build URL Prerequisites \u00b6 Installed and configured Slack JenkinsCI integration secret text Jenkins credentials with the Slack token Installed and configured Jenkins Slack plugin Parameters \u00b6 name mandatory default possible values baseUrl no channel no color no ${buildStatus == 'SUCCESS'?'#008000':'#E60000'} one of good , warning , danger , or any hex color code (eg. #439FE0 ) credentialsId no Jenkins credentials id message no script yes baseUrl - Allows overriding the Slack Plugin Integration Base Url specified in the global configuration. channel - Allows overriding of the default massaging channel from the plugin configuration. color - Defines the message color color defines the message color. credentialsId - The credentials id for the Slack token. message - Send a custom message into the Slack channel. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage baseUrl X channel X color X credentialsId X message X script Dependencies \u00b6 The step depends on the following Jenkins plugins pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Example \u00b6 Usage of pipeline step: pipeline { agent any stages { stage ( 'Build' ) { steps { echo \"do something\" } } } post { always { slackSendNotification script: this } } }","title":"slackSendNotification"},{"location":"steps/slackSendNotification/#slacksendnotification","text":"","title":"slackSendNotification"},{"location":"steps/slackSendNotification/#description","text":"Sends notifications to the Slack channel about the build status. Notification contains: Build status Repo Owner Repo Name Branch Name Jenkins Build Number Jenkins Build URL","title":"Description"},{"location":"steps/slackSendNotification/#prerequisites","text":"Installed and configured Slack JenkinsCI integration secret text Jenkins credentials with the Slack token Installed and configured Jenkins Slack plugin","title":"Prerequisites"},{"location":"steps/slackSendNotification/#parameters","text":"name mandatory default possible values baseUrl no channel no color no ${buildStatus == 'SUCCESS'?'#008000':'#E60000'} one of good , warning , danger , or any hex color code (eg. #439FE0 ) credentialsId no Jenkins credentials id message no script yes baseUrl - Allows overriding the Slack Plugin Integration Base Url specified in the global configuration. channel - Allows overriding of the default massaging channel from the plugin configuration. color - Defines the message color color defines the message color. credentialsId - The credentials id for the Slack token. message - Send a custom message into the Slack channel. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters.","title":"Parameters"},{"location":"steps/slackSendNotification/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage baseUrl X channel X color X credentialsId X message X script","title":"Step configuration"},{"location":"steps/slackSendNotification/#dependencies","text":"The step depends on the following Jenkins plugins pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/slackSendNotification/#example","text":"Usage of pipeline step: pipeline { agent any stages { stage ( 'Build' ) { steps { echo \"do something\" } } } post { always { slackSendNotification script: this } } }","title":"Example"},{"location":"steps/snykExecute/","text":"snykExecute \u00b6 Description \u00b6 This step performs an open source vulnerability scan on a Node project or Node module inside an MTA project through snyk.io. Prerequisites \u00b6 Snyk account - have an account on snyk.io Snyk token - have a Snyk user token Parameters \u00b6 name mandatory default possible values buildDescriptorFile no ./package.json dockerEnvVars no dockerImage no node:lts-stretch dockerOptions no dockerWorkspace no exclude no [] monitor no true scanType no npm npm , mta script yes snykCredentialsId yes Jenkins credentials id snykOrg no toHtml no false toJson no false buildDescriptorFile - The path to the build descriptor file, e.g. ./package.json . dockerEnvVars - Environment variables to set in the container, e.g. [http_proxy: 'proxy:8080']. dockerImage - Name of the docker image that should be used. Configure with empty value to execute the command directly on the Jenkins system (not using a container). Omit to use the default image (cf. default_pipeline_environment.yml ) Overwrite to use custom Docker image. dockerOptions - Docker only: Docker options to be set when starting the container (List or String). dockerWorkspace - Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . exclude - Only scanType 'mta': Exclude modules from MTA projects. monitor - Monitor the application's dependencies for new vulnerabilities. scanType - The type of project that should be scanned. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. snykCredentialsId - Credentials for accessing the Snyk API. snykOrg - Only needed for monitor: true : The organisation ID to determine the organisation to report to. toHtml - Generate and archive a HTML report. toJson - Generate and archive a JSON report. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage buildDescriptorFile X dockerEnvVars X dockerImage X dockerOptions X dockerWorkspace X exclude X monitor X scanType X script snykCredentialsId X X snykOrg X toHtml X toJson X Dependencies \u00b6 The step depends on the following Jenkins plugins credentials-binding docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Side effects \u00b6 Step uses dockerExecute inside. Exceptions \u00b6 none Example \u00b6 snykExecute script: this , snykCredentialsId: 'mySnykToken'","title":"snykExecute"},{"location":"steps/snykExecute/#snykexecute","text":"","title":"snykExecute"},{"location":"steps/snykExecute/#description","text":"This step performs an open source vulnerability scan on a Node project or Node module inside an MTA project through snyk.io.","title":"Description"},{"location":"steps/snykExecute/#prerequisites","text":"Snyk account - have an account on snyk.io Snyk token - have a Snyk user token","title":"Prerequisites"},{"location":"steps/snykExecute/#parameters","text":"name mandatory default possible values buildDescriptorFile no ./package.json dockerEnvVars no dockerImage no node:lts-stretch dockerOptions no dockerWorkspace no exclude no [] monitor no true scanType no npm npm , mta script yes snykCredentialsId yes Jenkins credentials id snykOrg no toHtml no false toJson no false buildDescriptorFile - The path to the build descriptor file, e.g. ./package.json . dockerEnvVars - Environment variables to set in the container, e.g. [http_proxy: 'proxy:8080']. dockerImage - Name of the docker image that should be used. Configure with empty value to execute the command directly on the Jenkins system (not using a container). Omit to use the default image (cf. default_pipeline_environment.yml ) Overwrite to use custom Docker image. dockerOptions - Docker only: Docker options to be set when starting the container (List or String). dockerWorkspace - Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . exclude - Only scanType 'mta': Exclude modules from MTA projects. monitor - Monitor the application's dependencies for new vulnerabilities. scanType - The type of project that should be scanned. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. snykCredentialsId - Credentials for accessing the Snyk API. snykOrg - Only needed for monitor: true : The organisation ID to determine the organisation to report to. toHtml - Generate and archive a HTML report. toJson - Generate and archive a JSON report.","title":"Parameters"},{"location":"steps/snykExecute/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage buildDescriptorFile X dockerEnvVars X dockerImage X dockerOptions X dockerWorkspace X exclude X monitor X scanType X script snykCredentialsId X X snykOrg X toHtml X toJson X","title":"Step configuration"},{"location":"steps/snykExecute/#dependencies","text":"The step depends on the following Jenkins plugins credentials-binding docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/snykExecute/#side-effects","text":"Step uses dockerExecute inside.","title":"Side effects"},{"location":"steps/snykExecute/#exceptions","text":"none","title":"Exceptions"},{"location":"steps/snykExecute/#example","text":"snykExecute script: this , snykCredentialsId: 'mySnykToken'","title":"Example"},{"location":"steps/sonarExecuteScan/","text":"sonarExecuteScan \u00b6 Executes the Sonar scanner Description \u00b6 The step executes the sonar-scanner cli command to scan the defined sources and publish the results to a SonarQube instance. Usage \u00b6 We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line . Jenkins pipelines \u00b6 sonarExecuteScan script: this Command line \u00b6 piper sonarExecuteScan Outputs \u00b6 Output type Details influx measurement step_data sonar Prerequisites \u00b6 The project needs a sonar-project.properties file that describes the project and defines certain settings, see here . A SonarQube instance needs to be defined in the Jenkins. Parameters \u00b6 Overview \u00b6 Name Mandatory Additional information githubTokenCredentialsId yes id of credentials ( using credentials ) script yes reference to Jenkins main pipeline script sonarTokenCredentialsId yes id of credentials ( using credentials ) branchName no changeBranch no changeId no changeTarget no containerCommand no containerShell no customTlsCertificateLinks no disableInlineComments no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no dockerVolumeBind no dockerWorkspace no githubApiUrl no githubToken no pass via ENV or Jenkins credentials ( githubTokenCredentialsId ) host no instance no legacyPRHandling no options no organization no owner no projectVersion no pullRequestProvider no repository no sonarScannerDownloadUrl no token no pass via ENV or Jenkins credentials ( sonarTokenCredentialsId ) verbose no activates debug output Details \u00b6 branchName \u00b6 Non-Pull-Request only: Name of the SonarQube branch that should be used to report findings to. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_branchName (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none changeBranch \u00b6 Pull-Request only: The name of the pull-request branch. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_changeBranch (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2610 steps \u2610 stages Resource references none changeId \u00b6 Pull-Request only: The id of the pull-request. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_changeId (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2610 steps \u2610 stages Resource references none changeTarget \u00b6 Pull-Request only: The name of the base branch. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_changeTarget (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2610 steps \u2610 stages Resource references none containerCommand \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default (/usr/bin/tail -f /dev/null). back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none containerShell \u00b6 Jenkins-specific: Used for proper environment setup. Allows to specify the shell to be executed for container with containerName. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none customTlsCertificateLinks \u00b6 List of download links to custom TLS certificates. This is required to ensure trusted connections to instances with custom certificates. back to overview Scope Details Aliases - Type []string Mandatory no Default $PIPER_customTlsCertificateLinks (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none disableInlineComments \u00b6 Pull-Request only: Disables the pull-request decoration with inline comments. DEPRECATED: only supported in SonarQube < 7.2 back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none dockerEnvVars \u00b6 Jenkins-specific: Used for proper environment setup. Environment variables to set in the container, e.g. [http_proxy: \"proxy:8080\"]. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerImage \u00b6 Jenkins-specific: Used for proper environment setup. Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerName \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Name of the container launching dockerImage. SideCar only: Name of the container in local network. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerOptions \u00b6 Jenkins-specific: Used for proper environment setup. Docker options to be set when starting the container. back to overview Scope Details Aliases - Type []string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerPullImage \u00b6 Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerVolumeBind \u00b6 Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the docker container. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerWorkspace \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none githubApiUrl \u00b6 Pull-Request only: The URL to the Github API. see GitHub plugin docs DEPRECATED: only supported in SonarQube < 7.2 back to overview Scope Details Aliases - Type string Mandatory no Default https://api.github.com Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none githubToken \u00b6 Pull-Request only: Token for Github to set status on the Pull-Request. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_githubToken (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2610 steps \u2610 stages Resource references Jenkins credential id: id: githubTokenCredentialsId reference to: `` githubTokenCredentialsId \u00b6 Jenkins-specific: Used for proper environment setup. Jenkins 'Secret text' credentials ID containing the token used to authenticate with the Github Server. back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none host \u00b6 The URL to the Sonar backend. back to overview Scope Details Aliases sonarServerUrl Type string Mandatory no Default $PIPER_host (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none instance \u00b6 Jenkins only: The name of the SonarQube instance defined in the Jenkins settings. DEPRECATED: use host parameter instead back to overview Scope Details Aliases - Type string Mandatory no Default SonarCloud Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none legacyPRHandling \u00b6 Pull-Request only: Activates the pull-request handling using the GitHub Plugin . DEPRECATED: only supported in SonarQube < 7.2 back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none options \u00b6 A list of options which are passed to the sonar-scanner. back to overview Scope Details Aliases - Type []string Mandatory no Default $PIPER_options (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none organization \u00b6 SonarCloud.io only: Organization that the project will be assigned to in SonarCloud.io. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_organization (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none owner \u00b6 Pull-Request only: The owner of the scm repository. back to overview Scope Details Aliases githubOrg Type string Mandatory no Default $PIPER_owner (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references commonPipelineEnvironment : reference to: github/owner projectVersion \u00b6 The project version that is reported to SonarQube. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_projectVersion (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references commonPipelineEnvironment : reference to: artifactVersion pullRequestProvider \u00b6 Pull-Request only: The scm provider. back to overview Scope Details Aliases - Type string Mandatory no Default GitHub Possible values - GitHub Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none repository \u00b6 Pull-Request only: The scm repository. back to overview Scope Details Aliases githubRepo Type string Mandatory no Default $PIPER_repository (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references commonPipelineEnvironment : reference to: github/repository script \u00b6 Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none sonarScannerDownloadUrl \u00b6 URL to the sonar-scanner-cli archive. back to overview Scope Details Aliases - Type string Mandatory no Default https://binaries.sonarsource.com/Distribution/sonar-scanner-cli/sonar-scanner-cli-4.4.0.2170-linux.zip Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none sonarTokenCredentialsId \u00b6 Jenkins-specific: Used for proper environment setup. Jenkins 'Secret text' credentials ID containing the token used to authenticate with the Sonar Server. back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none token \u00b6 Token used to authenticate with the Sonar Server. back to overview Scope Details Aliases sonarToken Type string Mandatory no Default $PIPER_token (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2610 steps \u2610 stages Resource references Jenkins credential id: id: sonarTokenCredentialsId reference to: `` verbose \u00b6 verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none \u00b6 Exceptions \u00b6 none Examples \u00b6","title":"sonarExecuteScan"},{"location":"steps/sonarExecuteScan/#sonarexecutescan","text":"Executes the Sonar scanner","title":"sonarExecuteScan"},{"location":"steps/sonarExecuteScan/#description","text":"The step executes the sonar-scanner cli command to scan the defined sources and publish the results to a SonarQube instance.","title":"Description"},{"location":"steps/sonarExecuteScan/#usage","text":"We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line .","title":"Usage"},{"location":"steps/sonarExecuteScan/#jenkins-pipelines","text":"sonarExecuteScan script: this","title":"Jenkins pipelines"},{"location":"steps/sonarExecuteScan/#command-line","text":"piper sonarExecuteScan","title":"Command line"},{"location":"steps/sonarExecuteScan/#outputs","text":"Output type Details influx measurement step_data sonar","title":"Outputs"},{"location":"steps/sonarExecuteScan/#prerequisites","text":"The project needs a sonar-project.properties file that describes the project and defines certain settings, see here . A SonarQube instance needs to be defined in the Jenkins.","title":"Prerequisites"},{"location":"steps/sonarExecuteScan/#parameters","text":"","title":"Parameters"},{"location":"steps/sonarExecuteScan/#overview","text":"Name Mandatory Additional information githubTokenCredentialsId yes id of credentials ( using credentials ) script yes reference to Jenkins main pipeline script sonarTokenCredentialsId yes id of credentials ( using credentials ) branchName no changeBranch no changeId no changeTarget no containerCommand no containerShell no customTlsCertificateLinks no disableInlineComments no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no dockerVolumeBind no dockerWorkspace no githubApiUrl no githubToken no pass via ENV or Jenkins credentials ( githubTokenCredentialsId ) host no instance no legacyPRHandling no options no organization no owner no projectVersion no pullRequestProvider no repository no sonarScannerDownloadUrl no token no pass via ENV or Jenkins credentials ( sonarTokenCredentialsId ) verbose no activates debug output","title":"Overview"},{"location":"steps/sonarExecuteScan/#details","text":"","title":"Details"},{"location":"steps/sonarExecuteScan/#branchname","text":"Non-Pull-Request only: Name of the SonarQube branch that should be used to report findings to. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_branchName (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"branchName"},{"location":"steps/sonarExecuteScan/#changebranch","text":"Pull-Request only: The name of the pull-request branch. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_changeBranch (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2610 steps \u2610 stages Resource references none","title":"changeBranch"},{"location":"steps/sonarExecuteScan/#changeid","text":"Pull-Request only: The id of the pull-request. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_changeId (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2610 steps \u2610 stages Resource references none","title":"changeId"},{"location":"steps/sonarExecuteScan/#changetarget","text":"Pull-Request only: The name of the base branch. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_changeTarget (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2610 steps \u2610 stages Resource references none","title":"changeTarget"},{"location":"steps/sonarExecuteScan/#containercommand","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default (/usr/bin/tail -f /dev/null). back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"containerCommand"},{"location":"steps/sonarExecuteScan/#containershell","text":"Jenkins-specific: Used for proper environment setup. Allows to specify the shell to be executed for container with containerName. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"containerShell"},{"location":"steps/sonarExecuteScan/#customtlscertificatelinks","text":"List of download links to custom TLS certificates. This is required to ensure trusted connections to instances with custom certificates. back to overview Scope Details Aliases - Type []string Mandatory no Default $PIPER_customTlsCertificateLinks (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"customTlsCertificateLinks"},{"location":"steps/sonarExecuteScan/#disableinlinecomments","text":"Pull-Request only: Disables the pull-request decoration with inline comments. DEPRECATED: only supported in SonarQube < 7.2 back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"disableInlineComments"},{"location":"steps/sonarExecuteScan/#dockerenvvars","text":"Jenkins-specific: Used for proper environment setup. Environment variables to set in the container, e.g. [http_proxy: \"proxy:8080\"]. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerEnvVars"},{"location":"steps/sonarExecuteScan/#dockerimage","text":"Jenkins-specific: Used for proper environment setup. Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerImage"},{"location":"steps/sonarExecuteScan/#dockername","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Name of the container launching dockerImage. SideCar only: Name of the container in local network. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerName"},{"location":"steps/sonarExecuteScan/#dockeroptions","text":"Jenkins-specific: Used for proper environment setup. Docker options to be set when starting the container. back to overview Scope Details Aliases - Type []string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerOptions"},{"location":"steps/sonarExecuteScan/#dockerpullimage","text":"Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerPullImage"},{"location":"steps/sonarExecuteScan/#dockervolumebind","text":"Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the docker container. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerVolumeBind"},{"location":"steps/sonarExecuteScan/#dockerworkspace","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerWorkspace"},{"location":"steps/sonarExecuteScan/#githubapiurl","text":"Pull-Request only: The URL to the Github API. see GitHub plugin docs DEPRECATED: only supported in SonarQube < 7.2 back to overview Scope Details Aliases - Type string Mandatory no Default https://api.github.com Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"githubApiUrl"},{"location":"steps/sonarExecuteScan/#githubtoken","text":"Pull-Request only: Token for Github to set status on the Pull-Request. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_githubToken (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2610 steps \u2610 stages Resource references Jenkins credential id: id: githubTokenCredentialsId reference to: ``","title":"githubToken"},{"location":"steps/sonarExecuteScan/#githubtokencredentialsid","text":"Jenkins-specific: Used for proper environment setup. Jenkins 'Secret text' credentials ID containing the token used to authenticate with the Github Server. back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"githubTokenCredentialsId"},{"location":"steps/sonarExecuteScan/#host","text":"The URL to the Sonar backend. back to overview Scope Details Aliases sonarServerUrl Type string Mandatory no Default $PIPER_host (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"host"},{"location":"steps/sonarExecuteScan/#instance","text":"Jenkins only: The name of the SonarQube instance defined in the Jenkins settings. DEPRECATED: use host parameter instead back to overview Scope Details Aliases - Type string Mandatory no Default SonarCloud Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"instance"},{"location":"steps/sonarExecuteScan/#legacyprhandling","text":"Pull-Request only: Activates the pull-request handling using the GitHub Plugin . DEPRECATED: only supported in SonarQube < 7.2 back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"legacyPRHandling"},{"location":"steps/sonarExecuteScan/#options","text":"A list of options which are passed to the sonar-scanner. back to overview Scope Details Aliases - Type []string Mandatory no Default $PIPER_options (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"options"},{"location":"steps/sonarExecuteScan/#organization","text":"SonarCloud.io only: Organization that the project will be assigned to in SonarCloud.io. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_organization (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"organization"},{"location":"steps/sonarExecuteScan/#owner","text":"Pull-Request only: The owner of the scm repository. back to overview Scope Details Aliases githubOrg Type string Mandatory no Default $PIPER_owner (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references commonPipelineEnvironment : reference to: github/owner","title":"owner"},{"location":"steps/sonarExecuteScan/#projectversion","text":"The project version that is reported to SonarQube. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_projectVersion (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references commonPipelineEnvironment : reference to: artifactVersion","title":"projectVersion"},{"location":"steps/sonarExecuteScan/#pullrequestprovider","text":"Pull-Request only: The scm provider. back to overview Scope Details Aliases - Type string Mandatory no Default GitHub Possible values - GitHub Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"pullRequestProvider"},{"location":"steps/sonarExecuteScan/#repository","text":"Pull-Request only: The scm repository. back to overview Scope Details Aliases githubRepo Type string Mandatory no Default $PIPER_repository (if set) Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references commonPipelineEnvironment : reference to: github/repository","title":"repository"},{"location":"steps/sonarExecuteScan/#script","text":"Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none","title":"script"},{"location":"steps/sonarExecuteScan/#sonarscannerdownloadurl","text":"URL to the sonar-scanner-cli archive. back to overview Scope Details Aliases - Type string Mandatory no Default https://binaries.sonarsource.com/Distribution/sonar-scanner-cli/sonar-scanner-cli-4.4.0.2170-linux.zip Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"sonarScannerDownloadUrl"},{"location":"steps/sonarExecuteScan/#sonartokencredentialsid","text":"Jenkins-specific: Used for proper environment setup. Jenkins 'Secret text' credentials ID containing the token used to authenticate with the Sonar Server. back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"sonarTokenCredentialsId"},{"location":"steps/sonarExecuteScan/#token","text":"Token used to authenticate with the Sonar Server. back to overview Scope Details Aliases sonarToken Type string Mandatory no Default $PIPER_token (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2610 steps \u2610 stages Resource references Jenkins credential id: id: sonarTokenCredentialsId reference to: ``","title":"token"},{"location":"steps/sonarExecuteScan/#verbose","text":"verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"verbose"},{"location":"steps/sonarExecuteScan/#exceptions","text":"none","title":"Exceptions"},{"location":"steps/sonarExecuteScan/#examples","text":"","title":"Examples"},{"location":"steps/spinnakerTriggerPipeline/","text":"spinnakerTriggerPipeline \u00b6 Description \u00b6 Triggers a Spinnaker pipeline from a Jenkins pipeline. Spinnaker is for example used for Continuos Deployment scenarios to various Clouds. Parameters \u00b6 name mandatory default possible values script yes spinnaker/application yes spinnaker/certFileCredentialsId no spinnaker/gateUrl yes spinnaker/keyFileCredentialsId no spinnaker/pipelineNameOrId yes spinnaker/pipelineParameters no timeout no 60 verbose no true , false script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. spinnaker/application - spinnaker/certFileCredentialsId - Defines the id of the file credentials in your Jenkins credentials store which contain the client certificate file for Spinnaker authentication. spinnaker/gateUrl - Defines the url of the Spinnaker Gateway Service as API endpoint for communication with Spinnaker. spinnaker/keyFileCredentialsId - Defines the id of the file credentials in your Jenkins credentials store which contain the private key file for Spinnaker authentication. spinnaker/pipelineNameOrId - Defines the name/id of the Spinnaker pipeline. spinnaker/pipelineParameters - Parameter map containing Spinnaker pipeline parameters. timeout - Defines the timeout in minutes for checking the Spinnaker pipeline result. By setting to 0 the check can be de-activated. verbose - Whether verbose output should be produced. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage script spinnaker/application X X spinnaker/certFileCredentialsId X X spinnaker/gateUrl X X spinnaker/keyFileCredentialsId X X spinnaker/pipelineNameOrId X X spinnaker/pipelineParameters X X timeout X verbose X X Dependencies \u00b6 The step depends on the following Jenkins plugins credentials-binding pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"spinnakerTriggerPipeline"},{"location":"steps/spinnakerTriggerPipeline/#spinnakertriggerpipeline","text":"","title":"spinnakerTriggerPipeline"},{"location":"steps/spinnakerTriggerPipeline/#description","text":"Triggers a Spinnaker pipeline from a Jenkins pipeline. Spinnaker is for example used for Continuos Deployment scenarios to various Clouds.","title":"Description"},{"location":"steps/spinnakerTriggerPipeline/#parameters","text":"name mandatory default possible values script yes spinnaker/application yes spinnaker/certFileCredentialsId no spinnaker/gateUrl yes spinnaker/keyFileCredentialsId no spinnaker/pipelineNameOrId yes spinnaker/pipelineParameters no timeout no 60 verbose no true , false script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. spinnaker/application - spinnaker/certFileCredentialsId - Defines the id of the file credentials in your Jenkins credentials store which contain the client certificate file for Spinnaker authentication. spinnaker/gateUrl - Defines the url of the Spinnaker Gateway Service as API endpoint for communication with Spinnaker. spinnaker/keyFileCredentialsId - Defines the id of the file credentials in your Jenkins credentials store which contain the private key file for Spinnaker authentication. spinnaker/pipelineNameOrId - Defines the name/id of the Spinnaker pipeline. spinnaker/pipelineParameters - Parameter map containing Spinnaker pipeline parameters. timeout - Defines the timeout in minutes for checking the Spinnaker pipeline result. By setting to 0 the check can be de-activated. verbose - Whether verbose output should be produced.","title":"Parameters"},{"location":"steps/spinnakerTriggerPipeline/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage script spinnaker/application X X spinnaker/certFileCredentialsId X X spinnaker/gateUrl X X spinnaker/keyFileCredentialsId X X spinnaker/pipelineNameOrId X X spinnaker/pipelineParameters X X timeout X verbose X X","title":"Step configuration"},{"location":"steps/spinnakerTriggerPipeline/#dependencies","text":"The step depends on the following Jenkins plugins credentials-binding pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/testsPublishResults/","text":"testsPublishResults \u00b6 Description \u00b6 This step can publish test results from various sources. Prerequisites \u00b6 test result files - To use this step, there must be test result files available. installed plugins: junit jacoco cobertura performance Pipeline configuration \u00b6 none Explanation of pipeline step \u00b6 Usage of pipeline step: testsPublishResults ( junit: [ updateResults: true , archive: true ], jacoco: [ archive: true ] ) Parameters \u00b6 name mandatory default possible values cobertura no [pattern:**/target/coverage/**/cobertura-coverage.xml, onlyStableBuilds:true, allowEmptyResults:true, archive:false, active:false] true , false , Map cucumber no [pattern:**/e2e/*.json, allowEmptyResults:true, archive:false, active:false] true , false , Map failOnError no false true , false jacoco no [pattern:**/target/*.exec, allowEmptyResults:true, archive:false, active:false] true , false , Map jmeter no [pattern:**/*.jtl, errorFailedThreshold:20, errorUnstableThreshold:10, errorUnstableResponseTimeThreshold:, relativeFailedThresholdPositive:0, relativeFailedThresholdNegative:0, relativeUnstableThresholdPositive:0, relativeUnstableThresholdNegative:0, modeOfThreshold:false, modeThroughput:false, nthBuildNumber:0, configType:PRT, failBuildIfNoResultFile:false, compareBuildPrevious:true, allowEmptyResults:true, archive:false, active:false] true , false , Map junit no [pattern:**/TEST-*.xml, updateResults:false, allowEmptyResults:true, archive:false, active:false] true , false , Map script yes cobertura - Publishes code coverage with the Cobertura plugin . cucumber - Publishes test results with the Cucumber plugin . failOnError - If it is set to true the step will fail the build if JUnit detected any failing tests. jacoco - Publishes code coverage with the JaCoCo plugin . jmeter - Publishes performance test results with the Performance plugin . junit - Publishes test results files in JUnit format with the JUnit Plugin . script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. junit \u00b6 parameter mandatory default possible values pattern no '**/TEST-*.xml' archive no false true, false updateResults no false true, false allowEmptyResults no true true, false jacoco \u00b6 parameter mandatory default possible values pattern no '**/target/*.exec' include no '' '**/*.class' exclude no '' '**/Test*' archive no false true, false allowEmptyResults no true true, false cobertura \u00b6 parameter mandatory default possible values pattern no '**/target/coverage/cobertura-coverage.xml' archive no false true, false allowEmptyResults no true true, false onlyStableBuilds no true true, false jmeter \u00b6 parameter mandatory default possible values pattern no '**/*.jtl' errorFailedThreshold no 20 errorUnstableThreshold no 10 errorUnstableResponseTimeThreshold no `` relativeFailedThresholdPositive no 0 relativeFailedThresholdNegative no 0 relativeUnstableThresholdPositive no 0 relativeUnstableThresholdNegative no 0 modeOfThreshold no false true, false modeThroughput no false true, false nthBuildNumber no 0 configType no PRT failBuildIfNoResultFile no false true, false compareBuildPrevious no true true, false archive no false true, false allowEmptyResults no true true, false Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage cobertura X X cucumber X X failOnError X jacoco X X jmeter X X junit X X script Dependencies \u00b6 The step depends on the following Jenkins plugins cobertura cucumber-testresult-plugin jacoco junit performance pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Side effects \u00b6 none Exceptions \u00b6 none Example \u00b6 // publish test results with coverage testsPublishResults ( junit: [ updateResults: true , archive: true ], jacoco: [ archive: true ] ) // publish test results with coverage testsPublishResults ( junit: [ pattern: '**/target/TEST*.xml' , archive: true ], cobertura: [ pattern: '**/target/coverage/cobertura-coverage.xml' ] )","title":"testsPublishResults"},{"location":"steps/testsPublishResults/#testspublishresults","text":"","title":"testsPublishResults"},{"location":"steps/testsPublishResults/#description","text":"This step can publish test results from various sources.","title":"Description"},{"location":"steps/testsPublishResults/#prerequisites","text":"test result files - To use this step, there must be test result files available. installed plugins: junit jacoco cobertura performance","title":"Prerequisites"},{"location":"steps/testsPublishResults/#pipeline-configuration","text":"none","title":"Pipeline configuration"},{"location":"steps/testsPublishResults/#explanation-of-pipeline-step","text":"Usage of pipeline step: testsPublishResults ( junit: [ updateResults: true , archive: true ], jacoco: [ archive: true ] )","title":"Explanation of pipeline step"},{"location":"steps/testsPublishResults/#parameters","text":"name mandatory default possible values cobertura no [pattern:**/target/coverage/**/cobertura-coverage.xml, onlyStableBuilds:true, allowEmptyResults:true, archive:false, active:false] true , false , Map cucumber no [pattern:**/e2e/*.json, allowEmptyResults:true, archive:false, active:false] true , false , Map failOnError no false true , false jacoco no [pattern:**/target/*.exec, allowEmptyResults:true, archive:false, active:false] true , false , Map jmeter no [pattern:**/*.jtl, errorFailedThreshold:20, errorUnstableThreshold:10, errorUnstableResponseTimeThreshold:, relativeFailedThresholdPositive:0, relativeFailedThresholdNegative:0, relativeUnstableThresholdPositive:0, relativeUnstableThresholdNegative:0, modeOfThreshold:false, modeThroughput:false, nthBuildNumber:0, configType:PRT, failBuildIfNoResultFile:false, compareBuildPrevious:true, allowEmptyResults:true, archive:false, active:false] true , false , Map junit no [pattern:**/TEST-*.xml, updateResults:false, allowEmptyResults:true, archive:false, active:false] true , false , Map script yes cobertura - Publishes code coverage with the Cobertura plugin . cucumber - Publishes test results with the Cucumber plugin . failOnError - If it is set to true the step will fail the build if JUnit detected any failing tests. jacoco - Publishes code coverage with the JaCoCo plugin . jmeter - Publishes performance test results with the Performance plugin . junit - Publishes test results files in JUnit format with the JUnit Plugin . script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters.","title":"Parameters"},{"location":"steps/testsPublishResults/#junit","text":"parameter mandatory default possible values pattern no '**/TEST-*.xml' archive no false true, false updateResults no false true, false allowEmptyResults no true true, false","title":"junit"},{"location":"steps/testsPublishResults/#jacoco","text":"parameter mandatory default possible values pattern no '**/target/*.exec' include no '' '**/*.class' exclude no '' '**/Test*' archive no false true, false allowEmptyResults no true true, false","title":"jacoco"},{"location":"steps/testsPublishResults/#cobertura","text":"parameter mandatory default possible values pattern no '**/target/coverage/cobertura-coverage.xml' archive no false true, false allowEmptyResults no true true, false onlyStableBuilds no true true, false","title":"cobertura"},{"location":"steps/testsPublishResults/#jmeter","text":"parameter mandatory default possible values pattern no '**/*.jtl' errorFailedThreshold no 20 errorUnstableThreshold no 10 errorUnstableResponseTimeThreshold no `` relativeFailedThresholdPositive no 0 relativeFailedThresholdNegative no 0 relativeUnstableThresholdPositive no 0 relativeUnstableThresholdNegative no 0 modeOfThreshold no false true, false modeThroughput no false true, false nthBuildNumber no 0 configType no PRT failBuildIfNoResultFile no false true, false compareBuildPrevious no true true, false archive no false true, false allowEmptyResults no true true, false","title":"jmeter"},{"location":"steps/testsPublishResults/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage cobertura X X cucumber X X failOnError X jacoco X X jmeter X X junit X X script","title":"Step configuration"},{"location":"steps/testsPublishResults/#dependencies","text":"The step depends on the following Jenkins plugins cobertura cucumber-testresult-plugin jacoco junit performance pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/testsPublishResults/#side-effects","text":"none","title":"Side effects"},{"location":"steps/testsPublishResults/#exceptions","text":"none","title":"Exceptions"},{"location":"steps/testsPublishResults/#example","text":"// publish test results with coverage testsPublishResults ( junit: [ updateResults: true , archive: true ], jacoco: [ archive: true ] ) // publish test results with coverage testsPublishResults ( junit: [ pattern: '**/target/TEST*.xml' , archive: true ], cobertura: [ pattern: '**/target/coverage/cobertura-coverage.xml' ] )","title":"Example"},{"location":"steps/tmsUpload/","text":"tmsUpload \u00b6 Description \u00b6 This step allows you to upload an MTA file (multi-target application archive) and multiple MTA extension descriptors into a TMS (SAP Cloud Platform Transport Management Service) landscape for further TMS-controlled distribution through a TMS-configured landscape. TMS lets you manage transports between SAP Cloud Platform accounts in Neo and Cloud Foundry, such as from DEV to TEST and PROD accounts. For more information, see official documentation of Transport Management Service Prerequisites You have subscribed to and set up TMS, as described in Setup and Configuration of SAP Cloud Platform Transport Management , which includes the configuration of a node to be used for uploading an MTA file. A corresponding service key has been created, as described in Set Up the Environment to Transport Content Archives directly in an Application . This service key (JSON) must be stored as a secret text within the Jenkins secure store. Parameters \u00b6 name mandatory default possible values credentialsId yes customDescription no mtaPath yes mtaVersion no * nodeExtDescriptorMapping no nodeName yes proxy no script yes stashContent no [buildResult] verbose no true , false credentialsId - Credentials to be used for the file and node uploads to the Transport Management Service. customDescription - Can be used as the description of a transport request. Will overwrite the default. (Default: Corresponding Git Commit-ID) mtaPath - Defines the path to *.mtar for the upload to the Transport Management Service. If not specified, it will use the mtar file created in mtaBuild. mtaVersion - Defines the version of the MTA for which the MTA extension descriptor will be used. You can use an asterisk (*) to accept any MTA version, or use a specific version compliant with SemVer 2.0, e.g. 1.0.0 (see semver.org). If the parameter is not configured, an asterisk is used. nodeExtDescriptorMapping - Available only for transports in Cloud Foundry environment. Defines a mapping between a transport node name and an MTA extension descriptor file path that you want to use for the transport node, e.g. nodeExtDescriptorMapping: [nodeName: 'example.mtaext', nodeName2: 'example2.mtaext', \u2026]`. nodeName - Defines the name of the node to which the *.mtar file should be uploaded. proxy - Proxy which should be used for the communication with the Transport Management Service Backend. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. stashContent - If specific stashes should be considered, their names need to be passed via the parameter stashContent . verbose - Print more detailed information into the log. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage credentialsId X customDescription X mtaPath X mtaVersion X nodeExtDescriptorMapping X nodeName X proxy X script stashContent X verbose X X Dependencies \u00b6 The step depends on the following Jenkins plugins credentials-binding pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"tmsUpload"},{"location":"steps/tmsUpload/#tmsupload","text":"","title":"tmsUpload"},{"location":"steps/tmsUpload/#description","text":"This step allows you to upload an MTA file (multi-target application archive) and multiple MTA extension descriptors into a TMS (SAP Cloud Platform Transport Management Service) landscape for further TMS-controlled distribution through a TMS-configured landscape. TMS lets you manage transports between SAP Cloud Platform accounts in Neo and Cloud Foundry, such as from DEV to TEST and PROD accounts. For more information, see official documentation of Transport Management Service Prerequisites You have subscribed to and set up TMS, as described in Setup and Configuration of SAP Cloud Platform Transport Management , which includes the configuration of a node to be used for uploading an MTA file. A corresponding service key has been created, as described in Set Up the Environment to Transport Content Archives directly in an Application . This service key (JSON) must be stored as a secret text within the Jenkins secure store.","title":"Description"},{"location":"steps/tmsUpload/#parameters","text":"name mandatory default possible values credentialsId yes customDescription no mtaPath yes mtaVersion no * nodeExtDescriptorMapping no nodeName yes proxy no script yes stashContent no [buildResult] verbose no true , false credentialsId - Credentials to be used for the file and node uploads to the Transport Management Service. customDescription - Can be used as the description of a transport request. Will overwrite the default. (Default: Corresponding Git Commit-ID) mtaPath - Defines the path to *.mtar for the upload to the Transport Management Service. If not specified, it will use the mtar file created in mtaBuild. mtaVersion - Defines the version of the MTA for which the MTA extension descriptor will be used. You can use an asterisk (*) to accept any MTA version, or use a specific version compliant with SemVer 2.0, e.g. 1.0.0 (see semver.org). If the parameter is not configured, an asterisk is used. nodeExtDescriptorMapping - Available only for transports in Cloud Foundry environment. Defines a mapping between a transport node name and an MTA extension descriptor file path that you want to use for the transport node, e.g. nodeExtDescriptorMapping: [nodeName: 'example.mtaext', nodeName2: 'example2.mtaext', \u2026]`. nodeName - Defines the name of the node to which the *.mtar file should be uploaded. proxy - Proxy which should be used for the communication with the Transport Management Service Backend. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. stashContent - If specific stashes should be considered, their names need to be passed via the parameter stashContent . verbose - Print more detailed information into the log.","title":"Parameters"},{"location":"steps/tmsUpload/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage credentialsId X customDescription X mtaPath X mtaVersion X nodeExtDescriptorMapping X nodeName X proxy X script stashContent X verbose X X","title":"Step configuration"},{"location":"steps/tmsUpload/#dependencies","text":"The step depends on the following Jenkins plugins credentials-binding pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/transportRequestCreate/","text":"transportRequestCreate \u00b6 Description \u00b6 Creates a Transport Request for a Change Document on the Solution Manager (type SOLMAN ) or a Transport Request inside an ABAP system (type CTS ) The id of the transport request is availabe via commonPipelineEnvironment.getTransportRequestId() Prerequisites \u00b6 Change Management Client 2.0.0 or compatible version - available for download on Maven Central. Note: This is only required if you don't use a Docker-based environment. Solution Manager version ST720 SP08 or newer. Parameters \u00b6 name mandatory default possible values changeDocumentId yes changeManagement/changeDocumentLabel no ChangeDocument\\s?: regex pattern changeManagement/clientOpts no `` changeManagement/credentialsId no CM changeManagement/endpoint yes changeManagement/git/format no %b see git log --help changeManagement/git/from no origin/master changeManagement/git/to no HEAD changeManagement/rfc/developmentClient yes changeManagement/rfc/developmentInstance yes changeManagement/type no NONE SOLMAN , CTS , RFC description yes developmentSystemId yes script yes targetSystem yes transportType yes verbose no false changeDocumentId - The id of the change document to that the transport request is bound to. Typically this value is provided via commit message in the commit history. Only for SOLMAN . changeManagement/changeDocumentLabel - A pattern used for identifying lines holding the change document id. changeManagement/clientOpts - Additional options for cm command line client, e.g. JAVA_OPTS. changeManagement/credentialsId - The id of the credentials to connect to the Solution Manager. The credentials needs to be maintained on Jenkins. changeManagement/endpoint - The service endpoint, e.g. Solution Manager, ABAP System. changeManagement/git/format - Specifies what part of the commit is scanned. By default the body of the commit message is scanned. changeManagement/git/from - The starting point for retrieving the change document id. changeManagement/git/to - The end point for retrieving the change document id. changeManagement/rfc/developmentClient - AS ABAP client number. Only for RFC . changeManagement/rfc/developmentInstance - AS ABAP instance number. Only for RFC . changeManagement/type - Defines where the transport request is created, e.g. SAP Solution Manager, ABAP System. description - The description of the transport request. Only for CTS . developmentSystemId - The logical system id for which the transport request is created. The format is <SID>~<TYPE>(/<CLIENT>)? . For ABAP Systems the developmentSystemId looks like DEV~ABAP/100 . For non-ABAP systems the developmentSystemId looks like e.g. L21~EXT_SRV or J01~JAVA . In case the system type is not known (in the examples provided here: EXT_SRV or JAVA ) the information can be retrieved from the Solution Manager instance. Only for SOLMAN . script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. targetSystem - The system receiving the transport request. Only for CTS . transportType - Typically W (workbench) or C customizing. Only for CTS . verbose - Provides additional details. Only for RFC . Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage changeDocumentId changeManagement/changeDocumentLabel X changeManagement/clientOpts X changeManagement/credentialsId X changeManagement/endpoint X changeManagement/git/format X changeManagement/git/from X changeManagement/git/to X changeManagement/rfc/developmentClient X changeManagement/rfc/developmentInstance X changeManagement/type X description X developmentSystemId X script targetSystem X transportType X verbose X Dependencies \u00b6 The step depends on the following Jenkins plugins credentials-binding docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. The step is configured using a customer configuration file provided as resource in an custom shared library. @Library ( 'piper-lib-os@master' ) _ // the shared lib containing the additional configuration // needs to be configured in Jenkins @Library ( 'foo@master' ) __ // inside the shared lib denoted by 'foo' the additional configuration file // needs to be located under 'resources' ('resoures/myConfig.yml') prepareDefaultValues script: this , customDefaults: 'myConfig.yml' Example content of 'resources/myConfig.yml' in branch 'master' of the repository denoted by 'foo' : general : changeManagement : changeDocumentLabel : 'ChangeDocument\\s?:' cmClientOpts : '-Djavax.net.ssl.trustStore=<path to truststore>' credentialsId : 'CM' type : 'SOLMAN' endpoint : 'https://example.org/cm' git : from : 'HEAD~1' to : 'HEAD' format : '%b' The properties configured in section 'general/changeManagement' are shared between all change managment related steps. The properties can also be configured on a per-step basis: [ ... ] steps : transportRequestCreate : changeManagement : type : 'SOLMAN' endpoint : 'https://example.org/cm' [ ... ] The parameters can also be provided when the step is invoked. For examples see below. Return value \u00b6 none Exceptions \u00b6 AbortException : If the creation of the transport request fails. IllegalStateException : If the change id is not provided. Example \u00b6 // SOLMAN def transportRequestId = transportRequestCreate script: this , changeDocumentId: '001,' changeManagement: [ type: 'SOLMAN' endpoint: 'https://example.org/cm' ] // CTS def transportRequestId = transportRequestCreate script: this , transportType: 'W' , targetSystem: 'XYZ' , description: 'the description' , changeManagement: [ type: 'CTS' endpoint: 'https://example.org/cm' ]","title":"transportRequestCreate"},{"location":"steps/transportRequestCreate/#transportrequestcreate","text":"","title":"transportRequestCreate"},{"location":"steps/transportRequestCreate/#description","text":"Creates a Transport Request for a Change Document on the Solution Manager (type SOLMAN ) or a Transport Request inside an ABAP system (type CTS ) The id of the transport request is availabe via commonPipelineEnvironment.getTransportRequestId()","title":"Description"},{"location":"steps/transportRequestCreate/#prerequisites","text":"Change Management Client 2.0.0 or compatible version - available for download on Maven Central. Note: This is only required if you don't use a Docker-based environment. Solution Manager version ST720 SP08 or newer.","title":"Prerequisites"},{"location":"steps/transportRequestCreate/#parameters","text":"name mandatory default possible values changeDocumentId yes changeManagement/changeDocumentLabel no ChangeDocument\\s?: regex pattern changeManagement/clientOpts no `` changeManagement/credentialsId no CM changeManagement/endpoint yes changeManagement/git/format no %b see git log --help changeManagement/git/from no origin/master changeManagement/git/to no HEAD changeManagement/rfc/developmentClient yes changeManagement/rfc/developmentInstance yes changeManagement/type no NONE SOLMAN , CTS , RFC description yes developmentSystemId yes script yes targetSystem yes transportType yes verbose no false changeDocumentId - The id of the change document to that the transport request is bound to. Typically this value is provided via commit message in the commit history. Only for SOLMAN . changeManagement/changeDocumentLabel - A pattern used for identifying lines holding the change document id. changeManagement/clientOpts - Additional options for cm command line client, e.g. JAVA_OPTS. changeManagement/credentialsId - The id of the credentials to connect to the Solution Manager. The credentials needs to be maintained on Jenkins. changeManagement/endpoint - The service endpoint, e.g. Solution Manager, ABAP System. changeManagement/git/format - Specifies what part of the commit is scanned. By default the body of the commit message is scanned. changeManagement/git/from - The starting point for retrieving the change document id. changeManagement/git/to - The end point for retrieving the change document id. changeManagement/rfc/developmentClient - AS ABAP client number. Only for RFC . changeManagement/rfc/developmentInstance - AS ABAP instance number. Only for RFC . changeManagement/type - Defines where the transport request is created, e.g. SAP Solution Manager, ABAP System. description - The description of the transport request. Only for CTS . developmentSystemId - The logical system id for which the transport request is created. The format is <SID>~<TYPE>(/<CLIENT>)? . For ABAP Systems the developmentSystemId looks like DEV~ABAP/100 . For non-ABAP systems the developmentSystemId looks like e.g. L21~EXT_SRV or J01~JAVA . In case the system type is not known (in the examples provided here: EXT_SRV or JAVA ) the information can be retrieved from the Solution Manager instance. Only for SOLMAN . script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. targetSystem - The system receiving the transport request. Only for CTS . transportType - Typically W (workbench) or C customizing. Only for CTS . verbose - Provides additional details. Only for RFC .","title":"Parameters"},{"location":"steps/transportRequestCreate/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage changeDocumentId changeManagement/changeDocumentLabel X changeManagement/clientOpts X changeManagement/credentialsId X changeManagement/endpoint X changeManagement/git/format X changeManagement/git/from X changeManagement/git/to X changeManagement/rfc/developmentClient X changeManagement/rfc/developmentInstance X changeManagement/type X description X developmentSystemId X script targetSystem X transportType X verbose X","title":"Step configuration"},{"location":"steps/transportRequestCreate/#dependencies","text":"The step depends on the following Jenkins plugins credentials-binding docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. The step is configured using a customer configuration file provided as resource in an custom shared library. @Library ( 'piper-lib-os@master' ) _ // the shared lib containing the additional configuration // needs to be configured in Jenkins @Library ( 'foo@master' ) __ // inside the shared lib denoted by 'foo' the additional configuration file // needs to be located under 'resources' ('resoures/myConfig.yml') prepareDefaultValues script: this , customDefaults: 'myConfig.yml' Example content of 'resources/myConfig.yml' in branch 'master' of the repository denoted by 'foo' : general : changeManagement : changeDocumentLabel : 'ChangeDocument\\s?:' cmClientOpts : '-Djavax.net.ssl.trustStore=<path to truststore>' credentialsId : 'CM' type : 'SOLMAN' endpoint : 'https://example.org/cm' git : from : 'HEAD~1' to : 'HEAD' format : '%b' The properties configured in section 'general/changeManagement' are shared between all change managment related steps. The properties can also be configured on a per-step basis: [ ... ] steps : transportRequestCreate : changeManagement : type : 'SOLMAN' endpoint : 'https://example.org/cm' [ ... ] The parameters can also be provided when the step is invoked. For examples see below.","title":"Dependencies"},{"location":"steps/transportRequestCreate/#return-value","text":"none","title":"Return value"},{"location":"steps/transportRequestCreate/#exceptions","text":"AbortException : If the creation of the transport request fails. IllegalStateException : If the change id is not provided.","title":"Exceptions"},{"location":"steps/transportRequestCreate/#example","text":"// SOLMAN def transportRequestId = transportRequestCreate script: this , changeDocumentId: '001,' changeManagement: [ type: 'SOLMAN' endpoint: 'https://example.org/cm' ] // CTS def transportRequestId = transportRequestCreate script: this , transportType: 'W' , targetSystem: 'XYZ' , description: 'the description' , changeManagement: [ type: 'CTS' endpoint: 'https://example.org/cm' ]","title":"Example"},{"location":"steps/transportRequestRelease/","text":"transportRequestRelease \u00b6 Description \u00b6 Releases a Transport Request. Prerequisites \u00b6 Change Management Client 2.0.0 or compatible version - available for download on Maven Central. Note: This is only required if you don't use a Docker-based environment. Parameters \u00b6 name mandatory default possible values changeDocumentId yes changeManagement/clientOpts no `` changeManagement/credentialsId no CM changeManagement/endpoint yes changeManagement/git/format no %b see git log --help changeManagement/git/from no origin/master changeManagement/git/to no HEAD changeManagement/rfc/developmentClient yes changeManagement/rfc/developmentInstance yes script yes transportRequestId yes verbose no false changeDocumentId - The id of the change document to that the transport request is bound to. Typically this value is provided via commit message in the commit history. Only for SOLMAN . changeManagement/clientOpts - Additional options for cm command line client, e.g. JAVA_OPTS. changeManagement/credentialsId - The id of the credentials to connect to the Solution Manager. The credentials needs to be maintained on Jenkins. changeManagement/endpoint - The service endpoint, e.g. Solution Manager, ABAP System. changeManagement/git/format - Specifies what part of the commit is scanned. By default the body of the commit message is scanned. changeManagement/git/from - The starting point for retrieving the change document id. changeManagement/git/to - The end point for retrieving the change document id. changeManagement/rfc/developmentClient - AS ABAP client number. Only for RFC . changeManagement/rfc/developmentInstance - AS ABAP instance number. Only for RFC . script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. transportRequestId - The id of the transport request to release. verbose - Provides additional details. Only for RFC . Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage changeDocumentId changeManagement/clientOpts X changeManagement/credentialsId X changeManagement/endpoint X changeManagement/git/format X changeManagement/git/from X changeManagement/git/to X changeManagement/rfc/developmentClient X changeManagement/rfc/developmentInstance X script transportRequestId verbose Dependencies \u00b6 The step depends on the following Jenkins plugins credentials-binding docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. The step is configured using a customer configuration file provided as resource in an custom shared library. @Library ( 'piper-lib-os@master' ) _ // the shared lib containing the additional configuration // needs to be configured in Jenkins @Library ( 'foo@master' ) __ // inside the shared lib denoted by 'foo' the additional configuration file // needs to be located under 'resources' ('resoures/myConfig.yml') prepareDefaultValues script: this , customDefaults: 'myConfig.yml' Example content of 'resources/myConfig.yml' in branch 'master' of the repository denoted by 'foo' : general : changeManagement : changeDocumentLabel : 'ChangeDocument\\s?:' cmClientOpts : '-Djavax.net.ssl.trustStore=<path to truststore>' credentialsId : 'CM' type : 'SOLMAN' endpoint : 'https://example.org/cm' git : from : 'HEAD~1' to : 'HEAD' format : '%b' The properties configured in section 'general/changeManagement' are shared between all change managment related steps. The properties can also be configured on a per-step basis: [ ... ] steps : transportRequestRelease : changeManagement : type : 'SOLMAN' endpoint : 'https://example.org/cm' [ ... ] The parameters can also be provided when the step is invoked. For examples see below. Exceptions \u00b6 IllegalArgumentException : If the change id is not provided ( SOLMAN only) If the transport request id is not provided. AbortException : If the release of the transport request fails. Example \u00b6 // SOLMAN transportRequestRelease script: this , changeDocumentId: '001' , transportRequestId: '001' , changeManagement: [ type: 'SOLMAN' endpoint: 'https://example.org/cm' ] // CTS transportRequestRelease script: this , transportRequestId: '001' , changeManagement: [ type: 'CTS' endpoint: 'https://example.org/cm' ]","title":"transportRequestRelease"},{"location":"steps/transportRequestRelease/#transportrequestrelease","text":"","title":"transportRequestRelease"},{"location":"steps/transportRequestRelease/#description","text":"Releases a Transport Request.","title":"Description"},{"location":"steps/transportRequestRelease/#prerequisites","text":"Change Management Client 2.0.0 or compatible version - available for download on Maven Central. Note: This is only required if you don't use a Docker-based environment.","title":"Prerequisites"},{"location":"steps/transportRequestRelease/#parameters","text":"name mandatory default possible values changeDocumentId yes changeManagement/clientOpts no `` changeManagement/credentialsId no CM changeManagement/endpoint yes changeManagement/git/format no %b see git log --help changeManagement/git/from no origin/master changeManagement/git/to no HEAD changeManagement/rfc/developmentClient yes changeManagement/rfc/developmentInstance yes script yes transportRequestId yes verbose no false changeDocumentId - The id of the change document to that the transport request is bound to. Typically this value is provided via commit message in the commit history. Only for SOLMAN . changeManagement/clientOpts - Additional options for cm command line client, e.g. JAVA_OPTS. changeManagement/credentialsId - The id of the credentials to connect to the Solution Manager. The credentials needs to be maintained on Jenkins. changeManagement/endpoint - The service endpoint, e.g. Solution Manager, ABAP System. changeManagement/git/format - Specifies what part of the commit is scanned. By default the body of the commit message is scanned. changeManagement/git/from - The starting point for retrieving the change document id. changeManagement/git/to - The end point for retrieving the change document id. changeManagement/rfc/developmentClient - AS ABAP client number. Only for RFC . changeManagement/rfc/developmentInstance - AS ABAP instance number. Only for RFC . script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. transportRequestId - The id of the transport request to release. verbose - Provides additional details. Only for RFC .","title":"Parameters"},{"location":"steps/transportRequestRelease/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage changeDocumentId changeManagement/clientOpts X changeManagement/credentialsId X changeManagement/endpoint X changeManagement/git/format X changeManagement/git/from X changeManagement/git/to X changeManagement/rfc/developmentClient X changeManagement/rfc/developmentInstance X script transportRequestId verbose","title":"Step configuration"},{"location":"steps/transportRequestRelease/#dependencies","text":"The step depends on the following Jenkins plugins credentials-binding docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. The step is configured using a customer configuration file provided as resource in an custom shared library. @Library ( 'piper-lib-os@master' ) _ // the shared lib containing the additional configuration // needs to be configured in Jenkins @Library ( 'foo@master' ) __ // inside the shared lib denoted by 'foo' the additional configuration file // needs to be located under 'resources' ('resoures/myConfig.yml') prepareDefaultValues script: this , customDefaults: 'myConfig.yml' Example content of 'resources/myConfig.yml' in branch 'master' of the repository denoted by 'foo' : general : changeManagement : changeDocumentLabel : 'ChangeDocument\\s?:' cmClientOpts : '-Djavax.net.ssl.trustStore=<path to truststore>' credentialsId : 'CM' type : 'SOLMAN' endpoint : 'https://example.org/cm' git : from : 'HEAD~1' to : 'HEAD' format : '%b' The properties configured in section 'general/changeManagement' are shared between all change managment related steps. The properties can also be configured on a per-step basis: [ ... ] steps : transportRequestRelease : changeManagement : type : 'SOLMAN' endpoint : 'https://example.org/cm' [ ... ] The parameters can also be provided when the step is invoked. For examples see below.","title":"Dependencies"},{"location":"steps/transportRequestRelease/#exceptions","text":"IllegalArgumentException : If the change id is not provided ( SOLMAN only) If the transport request id is not provided. AbortException : If the release of the transport request fails.","title":"Exceptions"},{"location":"steps/transportRequestRelease/#example","text":"// SOLMAN transportRequestRelease script: this , changeDocumentId: '001' , transportRequestId: '001' , changeManagement: [ type: 'SOLMAN' endpoint: 'https://example.org/cm' ] // CTS transportRequestRelease script: this , transportRequestId: '001' , changeManagement: [ type: 'CTS' endpoint: 'https://example.org/cm' ]","title":"Example"},{"location":"steps/transportRequestUploadFile/","text":"transportRequestUploadFile \u00b6 Description \u00b6 Uploads a file to a Transport Request. CTS upload is currently not supported. We are working on a new way to handle CTS uploads. Prerequisites \u00b6 Change Management Client 2.0.0 or compatible version - available for download on Maven Central. Note: This is only required if you don't use a Docker-based environment. Parameters \u00b6 name mandatory default possible values abapPackage yes acceptUnixStyleLineEndings no true applicationDescription yes applicationId yes applicationName yes applicationUrl yes changeDocumentId yes changeManagement/changeDocumentLabel no ChangeDocument\\s?: regex pattern changeManagement/changeManagement/transportRequestLabel no changeManagement/clientOpts no `` changeManagement/credentialsId no CM changeManagement/endpoint yes changeManagement/git/format no %b see git log --help changeManagement/git/from no origin/master changeManagement/git/to no HEAD changeManagement/rfc/developmentClient yes changeManagement/rfc/developmentInstance yes changeManagement/rfc/docker/envVars no [:] changeManagement/rfc/docker/image no rfc changeManagement/rfc/docker/options no [] changeManagement/rfc/docker/pullImage no true changeManagement/type no NONE SOLMAN , CTS , RFC codePage no UTF-8 failOnWarning no true filePath yes script yes transportRequestId yes verbose no false abapPackage - The ABAP package name of your application. acceptUnixStyleLineEndings - applicationDescription - applicationId - The id of the application. Only for SOLMAN . applicationName - applicationUrl - The URL where to find the UI5 package to upload to the transport request. Only for RFC . changeDocumentId - The id of the change document to that the transport request is bound to. Typically this value is provided via commit message in the commit history. Only for SOLMAN . changeManagement/changeDocumentLabel - A pattern used for identifying lines holding the change document id. changeManagement/changeManagement/transportRequestLabel - A pattern used for identifying lines holding the transport request id. changeManagement/clientOpts - Additional options for cm command line client, e.g. JAVA_OPTS. changeManagement/credentialsId - The id of the credentials to connect to the Solution Manager. The credentials needs to be maintained on Jenkins. changeManagement/endpoint - The service endpoint, e.g. Solution Manager, ABAP System. changeManagement/git/format - Specifies what part of the commit is scanned. By default the body of the commit message is scanned. changeManagement/git/from - The starting point for retrieving the change document id. changeManagement/git/to - The end point for retrieving the change document id. changeManagement/rfc/developmentClient - AS ABAP client number. Only for RFC . changeManagement/rfc/developmentInstance - AS ABAP instance number. Only for RFC . changeManagement/rfc/docker/envVars - changeManagement/rfc/docker/image - changeManagement/rfc/docker/options - changeManagement/rfc/docker/pullImage - changeManagement/type - Defines where the transport request is created, e.g. SAP Solution Manager, ABAP System. codePage - The code page of your ABAP system. E.g. UTF-8. failOnWarning - filePath - The path of the file to upload. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. transportRequestId - The id of the transport request to upload the file. verbose - Provides additional details. Only for RFC . Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage abapPackage X acceptUnixStyleLineEndings X applicationDescription X applicationId X applicationName X applicationUrl X changeDocumentId changeManagement/changeDocumentLabel X X changeManagement/changeManagement/transportRequestLabel X X changeManagement/clientOpts X X changeManagement/credentialsId X X changeManagement/endpoint X X changeManagement/git/format X X changeManagement/git/from X X changeManagement/git/to X X changeManagement/rfc/developmentClient X X changeManagement/rfc/developmentInstance X X changeManagement/rfc/docker/envVars X X changeManagement/rfc/docker/image X X changeManagement/rfc/docker/options X X changeManagement/rfc/docker/pullImage X X changeManagement/type X X codePage X failOnWarning filePath X script transportRequestId verbose X Dependencies \u00b6 The step depends on the following Jenkins plugins credentials-binding docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. The step is configured using a customer configuration file provided as resource in an custom shared library. @Library ( 'piper-lib-os@master' ) _ // the shared lib containing the additional configuration // needs to be configured in Jenkins @Library ( 'foo@master' ) __ // inside the shared lib denoted by 'foo' the additional configuration file // needs to be located under 'resources' ('resoures/myConfig.yml') prepareDefaultValues script: this , customDefaults: 'myConfig.yml' Example content of 'resources/myConfig.yml' in branch 'master' of the repository denoted by 'foo' : general : changeManagement : changeDocumentLabel : 'ChangeDocument\\s?:' cmClientOpts : '-Djavax.net.ssl.trustStore=<path to truststore>' credentialsId : 'CM' type : 'SOLMAN' endpoint : 'https://example.org/cm' git : from : 'HEAD~1' to : 'HEAD' format : '%b' The properties configured in section 'general/changeManagement' are shared between all change managment related steps. The properties can also be configured on a per-step basis: [ ... ] steps : transportRequestUploadFile : applicationId : 'FOO' changeManagement : type : 'SOLMAN' endpoint : 'https://example.org/cm' [ ... ] The parameters can also be provided when the step is invoked. For examples see below. Exceptions \u00b6 IllegalArgumentException : If the change id is not provided ( SOLMAN only). If the transport request id is not provided. If the application id is not provided ( SOLMAN only). If the file path is not provided. AbortException : If the upload fails. Example \u00b6 // SOLMAN transportRequestUploadFile ( script: this , changeDocumentId: '001' , // typically provided via git commit history transportRequestId: '001' , // typically provided via git commit history applicationId: '001' , filePath: '/path' , changeManagement: [ type: 'SOLMAN' endpoint: 'https://example.org/cm' ] ) // CTS // NOTE: CTS upload currently not supported! transportRequestUploadFile ( script: this , transportRequestId: '001' , // typically provided via git commit history filePath: '/path' , changeManagement: [ type: 'CTS' endpoint: 'https://example.org/cm' ] )","title":"transportRequestUploadFile"},{"location":"steps/transportRequestUploadFile/#transportrequestuploadfile","text":"","title":"transportRequestUploadFile"},{"location":"steps/transportRequestUploadFile/#description","text":"Uploads a file to a Transport Request. CTS upload is currently not supported. We are working on a new way to handle CTS uploads.","title":"Description"},{"location":"steps/transportRequestUploadFile/#prerequisites","text":"Change Management Client 2.0.0 or compatible version - available for download on Maven Central. Note: This is only required if you don't use a Docker-based environment.","title":"Prerequisites"},{"location":"steps/transportRequestUploadFile/#parameters","text":"name mandatory default possible values abapPackage yes acceptUnixStyleLineEndings no true applicationDescription yes applicationId yes applicationName yes applicationUrl yes changeDocumentId yes changeManagement/changeDocumentLabel no ChangeDocument\\s?: regex pattern changeManagement/changeManagement/transportRequestLabel no changeManagement/clientOpts no `` changeManagement/credentialsId no CM changeManagement/endpoint yes changeManagement/git/format no %b see git log --help changeManagement/git/from no origin/master changeManagement/git/to no HEAD changeManagement/rfc/developmentClient yes changeManagement/rfc/developmentInstance yes changeManagement/rfc/docker/envVars no [:] changeManagement/rfc/docker/image no rfc changeManagement/rfc/docker/options no [] changeManagement/rfc/docker/pullImage no true changeManagement/type no NONE SOLMAN , CTS , RFC codePage no UTF-8 failOnWarning no true filePath yes script yes transportRequestId yes verbose no false abapPackage - The ABAP package name of your application. acceptUnixStyleLineEndings - applicationDescription - applicationId - The id of the application. Only for SOLMAN . applicationName - applicationUrl - The URL where to find the UI5 package to upload to the transport request. Only for RFC . changeDocumentId - The id of the change document to that the transport request is bound to. Typically this value is provided via commit message in the commit history. Only for SOLMAN . changeManagement/changeDocumentLabel - A pattern used for identifying lines holding the change document id. changeManagement/changeManagement/transportRequestLabel - A pattern used for identifying lines holding the transport request id. changeManagement/clientOpts - Additional options for cm command line client, e.g. JAVA_OPTS. changeManagement/credentialsId - The id of the credentials to connect to the Solution Manager. The credentials needs to be maintained on Jenkins. changeManagement/endpoint - The service endpoint, e.g. Solution Manager, ABAP System. changeManagement/git/format - Specifies what part of the commit is scanned. By default the body of the commit message is scanned. changeManagement/git/from - The starting point for retrieving the change document id. changeManagement/git/to - The end point for retrieving the change document id. changeManagement/rfc/developmentClient - AS ABAP client number. Only for RFC . changeManagement/rfc/developmentInstance - AS ABAP instance number. Only for RFC . changeManagement/rfc/docker/envVars - changeManagement/rfc/docker/image - changeManagement/rfc/docker/options - changeManagement/rfc/docker/pullImage - changeManagement/type - Defines where the transport request is created, e.g. SAP Solution Manager, ABAP System. codePage - The code page of your ABAP system. E.g. UTF-8. failOnWarning - filePath - The path of the file to upload. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. transportRequestId - The id of the transport request to upload the file. verbose - Provides additional details. Only for RFC .","title":"Parameters"},{"location":"steps/transportRequestUploadFile/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage abapPackage X acceptUnixStyleLineEndings X applicationDescription X applicationId X applicationName X applicationUrl X changeDocumentId changeManagement/changeDocumentLabel X X changeManagement/changeManagement/transportRequestLabel X X changeManagement/clientOpts X X changeManagement/credentialsId X X changeManagement/endpoint X X changeManagement/git/format X X changeManagement/git/from X X changeManagement/git/to X X changeManagement/rfc/developmentClient X X changeManagement/rfc/developmentInstance X X changeManagement/rfc/docker/envVars X X changeManagement/rfc/docker/image X X changeManagement/rfc/docker/options X X changeManagement/rfc/docker/pullImage X X changeManagement/type X X codePage X failOnWarning filePath X script transportRequestId verbose X","title":"Step configuration"},{"location":"steps/transportRequestUploadFile/#dependencies","text":"The step depends on the following Jenkins plugins credentials-binding docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. The step is configured using a customer configuration file provided as resource in an custom shared library. @Library ( 'piper-lib-os@master' ) _ // the shared lib containing the additional configuration // needs to be configured in Jenkins @Library ( 'foo@master' ) __ // inside the shared lib denoted by 'foo' the additional configuration file // needs to be located under 'resources' ('resoures/myConfig.yml') prepareDefaultValues script: this , customDefaults: 'myConfig.yml' Example content of 'resources/myConfig.yml' in branch 'master' of the repository denoted by 'foo' : general : changeManagement : changeDocumentLabel : 'ChangeDocument\\s?:' cmClientOpts : '-Djavax.net.ssl.trustStore=<path to truststore>' credentialsId : 'CM' type : 'SOLMAN' endpoint : 'https://example.org/cm' git : from : 'HEAD~1' to : 'HEAD' format : '%b' The properties configured in section 'general/changeManagement' are shared between all change managment related steps. The properties can also be configured on a per-step basis: [ ... ] steps : transportRequestUploadFile : applicationId : 'FOO' changeManagement : type : 'SOLMAN' endpoint : 'https://example.org/cm' [ ... ] The parameters can also be provided when the step is invoked. For examples see below.","title":"Dependencies"},{"location":"steps/transportRequestUploadFile/#exceptions","text":"IllegalArgumentException : If the change id is not provided ( SOLMAN only). If the transport request id is not provided. If the application id is not provided ( SOLMAN only). If the file path is not provided. AbortException : If the upload fails.","title":"Exceptions"},{"location":"steps/transportRequestUploadFile/#example","text":"// SOLMAN transportRequestUploadFile ( script: this , changeDocumentId: '001' , // typically provided via git commit history transportRequestId: '001' , // typically provided via git commit history applicationId: '001' , filePath: '/path' , changeManagement: [ type: 'SOLMAN' endpoint: 'https://example.org/cm' ] ) // CTS // NOTE: CTS upload currently not supported! transportRequestUploadFile ( script: this , transportRequestId: '001' , // typically provided via git commit history filePath: '/path' , changeManagement: [ type: 'CTS' endpoint: 'https://example.org/cm' ] )","title":"Example"},{"location":"steps/uiVeri5ExecuteTests/","text":"uiVeri5ExecuteTests \u00b6 Description \u00b6 With this step UIVeri5 tests can be executed. UIVeri5 describes following benefits on its GitHub page: Automatic synchronization with UI5 app rendering so there is no need to add waits and sleeps to your test. Tests are reliable by design. Tests are written in synchronous manner, no callbacks, no promise chaining so are really simple to write and maintain. Full power of webdriverjs, protractor and jasmine - deferred selectors, custom matchers, custom locators. Control locators (OPA5 declarative matchers) allow locating and interacting with UI5 controls. Does not depend on testability support in applications - works with autorefreshing views, resizing elements, animated transitions. Declarative authentications - authentication flow over OAuth2 providers, etc. Console operation, CI ready, fully configurable, no need for java (comming soon) or IDE. Covers full ui5 browser matrix - Chrome,Firefox,IE,Edge,Safari,iOS,Android. Open-source, modify to suite your specific neeeds. Browser Matrix With this step and the underlying Docker image ( selenium/standalone-chrome ) only Chrome tests are possible. Testing of further browsers can be done with using a custom Docker image. Prerequisites \u00b6 Parameters \u00b6 name mandatory default possible values dockerEnvVars no [:] dockerImage no dockerWorkspace no failOnError no false true , false gitBranch no gitSshKeyCredentialsId no `` Jenkins credentials id installCommand no npm install @ui5/uiveri5 --global --quiet runCommand no uiveri5 --seleniumAddress='http://${config.seleniumHost}:${config.seleniumPort}/wd/hub' script yes seleniumHost no seleniumHubCredentialsId no seleniumPort no 4444 sidecarEnvVars no sidecarImage no stashContent no [buildDescriptor, tests] testOptions no `` testRepository no testServerUrl no dockerEnvVars - Environment variables to set in the container, e.g. [http_proxy: 'proxy:8080']. dockerImage - Name of the docker image that should be used. Configure with empty value to execute the command directly on the Jenkins system (not using a container). Omit to use the default image (cf. default_pipeline_environment.yml ) Overwrite to use custom Docker image. dockerWorkspace - Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . failOnError - With failOnError the behavior in case tests fail can be defined. gitBranch - Only if testRepository is provided: Branch of testRepository, defaults to master. gitSshKeyCredentialsId - Only if testRepository is provided: Credentials for a protected testRepository installCommand - The command that is executed to install the test tool. runCommand - The command that is executed to start the tests. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. seleniumHost - The host of the selenium hub, this is set automatically to localhost in a Kubernetes environment (determined by the ON_K8S environment variable) of to selenium in any other case. The value is only needed for the runCommand . seleniumHubCredentialsId - Defines the id of the user/password credentials to be used to connect to a Selenium Hub. The credentials are provided in the environment variables PIPER_SELENIUM_HUB_USER and PIPER_SELENIUM_HUB_PASSWORD . seleniumPort - The port of the selenium hub. The value is only needed for the runCommand . sidecarEnvVars - as dockerEnvVars for the sidecar container sidecarImage - as dockerImage for the sidecar container stashContent - Specific stashes that should be considered for the step execution. testOptions - This allows to set specific options for the UIVeri5 execution. Details can be found in the UIVeri5 documentation . testRepository - Define an additional repository where the test implementation is located. For protected repositories the testRepository needs to contain the ssh git url. testServerUrl - The testServerUrl is passed as environment variable TARGET_SERVER_URL to the test execution. The tests should read the host information from this environment variable in order to be infrastructure agnostic. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage dockerEnvVars X dockerImage X dockerWorkspace X failOnError X gitBranch X gitSshKeyCredentialsId X X installCommand X runCommand X script seleniumHost X seleniumHubCredentialsId X seleniumPort X sidecarEnvVars X sidecarImage X stashContent X testOptions X testRepository X testServerUrl X Dependencies \u00b6 The step depends on the following Jenkins plugins credentials-binding git pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Exceptions \u00b6 If you see an error like fatal: Not a git repository (or any parent up to mount point /home/jenkins) it is likely that your test description cannot be found. Please make sure to point parameter testOptions to your conf.js file like testOptions: './path/to/my/tests/conf.js' Examples \u00b6 Passing credentials from Jenkins \u00b6 When running acceptance tests in a real environment, authentication will be enabled in most cases. UIVeri5 includes features to automatically perform the login with credentials in the conf.js . However, having credentials to the acceptance system stored in plain text is not an optimal solution. Therefore, UIVeri5 allows templating to set parameters at runtime, as shown in the following example conf.js : // Read environment variables const defaultParams = { url : process . env . TARGET_SERVER_URL , user : process . env . TEST_USER , pass : process . env . TEST_PASS }; // Resolve path to specs relative to the working directory const path = require ( 'path' ); const specs = path . relative ( process . cwd (), path . join ( __dirname , '*.spec.js' )); // export UIVeri5 config exports . config = { profile : 'integration' , baseUrl : '${params.url}' , specs : specs , params : defaultParams , // can be overridden via cli `--params.<key>=<value>` auth : { // set up authorization for CF XSUAA 'sapcloud-form' : { user : '${params.user}' , pass : '${params.pass}' , userFieldSelector : 'input[name=\"username\"]' , passFieldSelector : 'input[name=\"password\"]' , logonButtonSelector : 'input[type=\"submit\"]' , redirectUrl : /cp.portal\\/site/ } } }; While default values for baseUrl , user and pass are read from the environment, they can also be overridden when calling the CLI. In a custom Pipeline, this is very simple: Just wrap the call to uiVeri5ExecuteTests in withCredentials ( TARGET_SERVER_URL is read from config.yml ): withCredentials ([ usernamePassword ( credentialsId: 'MY_ACCEPTANCE_CREDENTIALS' , passwordVariable: 'password' , usernameVariable: 'username' )]) { uiVeri5ExecuteTests script: this , testOptions: \"./uiveri5/conf.js --params.user=${username} --params.pass=${password}\" } In a Pipeline Template, a Stage Exit can be used to fetch the credentials and store them in the environment. As the environment is passed down to uiVeri5ExecuteTests, the variables will be present there. This is an example for the stage exit .pipeline/extensions/Acceptance.groovy where the credentialsId is read from the config.yml : void call ( Map params ) { // read username and password from the credential store withCredentials ([ usernamePassword ( credentialsId: params . config . acceptanceCredentialsId , passwordVariable: 'password' , usernameVariable: 'username' )]) { // store the result in the environment variables for executeUIVeri5Test withEnv ([ \"TEST_USER=${username}\" , \"TEST_PASS=${password}\" ]) { //execute original stage as defined in the template params . originalStage () } } } return this","title":"uiVeri5ExecuteTests"},{"location":"steps/uiVeri5ExecuteTests/#uiveri5executetests","text":"","title":"uiVeri5ExecuteTests"},{"location":"steps/uiVeri5ExecuteTests/#description","text":"With this step UIVeri5 tests can be executed. UIVeri5 describes following benefits on its GitHub page: Automatic synchronization with UI5 app rendering so there is no need to add waits and sleeps to your test. Tests are reliable by design. Tests are written in synchronous manner, no callbacks, no promise chaining so are really simple to write and maintain. Full power of webdriverjs, protractor and jasmine - deferred selectors, custom matchers, custom locators. Control locators (OPA5 declarative matchers) allow locating and interacting with UI5 controls. Does not depend on testability support in applications - works with autorefreshing views, resizing elements, animated transitions. Declarative authentications - authentication flow over OAuth2 providers, etc. Console operation, CI ready, fully configurable, no need for java (comming soon) or IDE. Covers full ui5 browser matrix - Chrome,Firefox,IE,Edge,Safari,iOS,Android. Open-source, modify to suite your specific neeeds. Browser Matrix With this step and the underlying Docker image ( selenium/standalone-chrome ) only Chrome tests are possible. Testing of further browsers can be done with using a custom Docker image.","title":"Description"},{"location":"steps/uiVeri5ExecuteTests/#prerequisites","text":"","title":"Prerequisites"},{"location":"steps/uiVeri5ExecuteTests/#parameters","text":"name mandatory default possible values dockerEnvVars no [:] dockerImage no dockerWorkspace no failOnError no false true , false gitBranch no gitSshKeyCredentialsId no `` Jenkins credentials id installCommand no npm install @ui5/uiveri5 --global --quiet runCommand no uiveri5 --seleniumAddress='http://${config.seleniumHost}:${config.seleniumPort}/wd/hub' script yes seleniumHost no seleniumHubCredentialsId no seleniumPort no 4444 sidecarEnvVars no sidecarImage no stashContent no [buildDescriptor, tests] testOptions no `` testRepository no testServerUrl no dockerEnvVars - Environment variables to set in the container, e.g. [http_proxy: 'proxy:8080']. dockerImage - Name of the docker image that should be used. Configure with empty value to execute the command directly on the Jenkins system (not using a container). Omit to use the default image (cf. default_pipeline_environment.yml ) Overwrite to use custom Docker image. dockerWorkspace - Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . failOnError - With failOnError the behavior in case tests fail can be defined. gitBranch - Only if testRepository is provided: Branch of testRepository, defaults to master. gitSshKeyCredentialsId - Only if testRepository is provided: Credentials for a protected testRepository installCommand - The command that is executed to install the test tool. runCommand - The command that is executed to start the tests. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. seleniumHost - The host of the selenium hub, this is set automatically to localhost in a Kubernetes environment (determined by the ON_K8S environment variable) of to selenium in any other case. The value is only needed for the runCommand . seleniumHubCredentialsId - Defines the id of the user/password credentials to be used to connect to a Selenium Hub. The credentials are provided in the environment variables PIPER_SELENIUM_HUB_USER and PIPER_SELENIUM_HUB_PASSWORD . seleniumPort - The port of the selenium hub. The value is only needed for the runCommand . sidecarEnvVars - as dockerEnvVars for the sidecar container sidecarImage - as dockerImage for the sidecar container stashContent - Specific stashes that should be considered for the step execution. testOptions - This allows to set specific options for the UIVeri5 execution. Details can be found in the UIVeri5 documentation . testRepository - Define an additional repository where the test implementation is located. For protected repositories the testRepository needs to contain the ssh git url. testServerUrl - The testServerUrl is passed as environment variable TARGET_SERVER_URL to the test execution. The tests should read the host information from this environment variable in order to be infrastructure agnostic.","title":"Parameters"},{"location":"steps/uiVeri5ExecuteTests/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage dockerEnvVars X dockerImage X dockerWorkspace X failOnError X gitBranch X gitSshKeyCredentialsId X X installCommand X runCommand X script seleniumHost X seleniumHubCredentialsId X seleniumPort X sidecarEnvVars X sidecarImage X stashContent X testOptions X testRepository X testServerUrl X","title":"Step configuration"},{"location":"steps/uiVeri5ExecuteTests/#dependencies","text":"The step depends on the following Jenkins plugins credentials-binding git pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/uiVeri5ExecuteTests/#exceptions","text":"If you see an error like fatal: Not a git repository (or any parent up to mount point /home/jenkins) it is likely that your test description cannot be found. Please make sure to point parameter testOptions to your conf.js file like testOptions: './path/to/my/tests/conf.js'","title":"Exceptions"},{"location":"steps/uiVeri5ExecuteTests/#examples","text":"","title":"Examples"},{"location":"steps/uiVeri5ExecuteTests/#passing-credentials-from-jenkins","text":"When running acceptance tests in a real environment, authentication will be enabled in most cases. UIVeri5 includes features to automatically perform the login with credentials in the conf.js . However, having credentials to the acceptance system stored in plain text is not an optimal solution. Therefore, UIVeri5 allows templating to set parameters at runtime, as shown in the following example conf.js : // Read environment variables const defaultParams = { url : process . env . TARGET_SERVER_URL , user : process . env . TEST_USER , pass : process . env . TEST_PASS }; // Resolve path to specs relative to the working directory const path = require ( 'path' ); const specs = path . relative ( process . cwd (), path . join ( __dirname , '*.spec.js' )); // export UIVeri5 config exports . config = { profile : 'integration' , baseUrl : '${params.url}' , specs : specs , params : defaultParams , // can be overridden via cli `--params.<key>=<value>` auth : { // set up authorization for CF XSUAA 'sapcloud-form' : { user : '${params.user}' , pass : '${params.pass}' , userFieldSelector : 'input[name=\"username\"]' , passFieldSelector : 'input[name=\"password\"]' , logonButtonSelector : 'input[type=\"submit\"]' , redirectUrl : /cp.portal\\/site/ } } }; While default values for baseUrl , user and pass are read from the environment, they can also be overridden when calling the CLI. In a custom Pipeline, this is very simple: Just wrap the call to uiVeri5ExecuteTests in withCredentials ( TARGET_SERVER_URL is read from config.yml ): withCredentials ([ usernamePassword ( credentialsId: 'MY_ACCEPTANCE_CREDENTIALS' , passwordVariable: 'password' , usernameVariable: 'username' )]) { uiVeri5ExecuteTests script: this , testOptions: \"./uiveri5/conf.js --params.user=${username} --params.pass=${password}\" } In a Pipeline Template, a Stage Exit can be used to fetch the credentials and store them in the environment. As the environment is passed down to uiVeri5ExecuteTests, the variables will be present there. This is an example for the stage exit .pipeline/extensions/Acceptance.groovy where the credentialsId is read from the config.yml : void call ( Map params ) { // read username and password from the credential store withCredentials ([ usernamePassword ( credentialsId: params . config . acceptanceCredentialsId , passwordVariable: 'password' , usernameVariable: 'username' )]) { // store the result in the environment variables for executeUIVeri5Test withEnv ([ \"TEST_USER=${username}\" , \"TEST_PASS=${password}\" ]) { //execute original stage as defined in the template params . originalStage () } } } return this","title":"Passing credentials from Jenkins"},{"location":"steps/whitesourceExecuteScan/","text":"whitesourceExecuteScan \u00b6 Description \u00b6 BETA With this step WhiteSource security and license compliance scans can be executed and assessed. WhiteSource is a Software as a Service offering based on a so called unified agent that locally determines the dependency tree of a node.js, Java, Python, Ruby, or Scala based solution and sends it to the WhiteSource server for a policy based license compliance check and additional Free and Open Source Software Publicly Known Vulnerabilities detection. Docker Images The underlying Docker images are public and specific to the solution's programming language(s) and therefore may have to be exchanged to fit to and support the relevant scenario. The default Python environment used is i.e. Python 3 based. Restrictions Currently the step does contain hardened scan configurations for scanType 'pip' and 'go' . Other environments are still being elaborated, so please thoroughly check your results and do not take them for granted by default. Also not all environments have been thoroughly tested already therefore you might need to tweak around with the default containers used or create your own ones to adequately support your scenario. To do so please modify dockerImage and dockerWorkspace parameters. The step expects an environment containing the programming language related compiler/interpreter as well as the related build tool. For a list of the supported build tools per environment please refer to the WhiteSource Unified Agent Documentation . Prerequisites \u00b6 Your company has registered an account with WhiteSource and you have enabled the use of so called User Keys to manage access to your organization in WhiteSource via dedicated privileges. Scanning your products without adequate user level access protection imposed on the WhiteSource backend would simply allow access based on the organization token. Parameters \u00b6 name mandatory default possible values agentDownloadUrl no https://github.com/whitesource/unified-agent-distribution/releases/latest/download/${config.agentFileName} agentFileName no wss-unified-agent.jar agentParameters no `` buildDescriptorExcludeList no [] buildDescriptorFile no scanType= golang : ./Gopkg.toml scanType= maven : ./pom.xml scanType= mta : <empty> scanType= npm : ./package.json scanType= pip : ./setup.py scanType= sbt : ./build.sbt scanType= dub : ./dub.json configFilePath no ./wss-unified-agent.config createProductFromPipeline no true cvssSeverityLimit no -1 -1 to switch failing off, any positive integer between 0 and 10 to fail on issues with the specified limit or above dockerEnvVars no scanType= golang : <empty> scanType= maven : <empty> scanType= mta : <empty> scanType= npm : <empty> scanType= pip : <empty> scanType= sbt : <empty> scanType= dub : <empty> dockerImage no scanType= golang : golang:1.12-stretch scanType= maven : maven:3.5-jdk-8 scanType= mta : <empty> scanType= npm : node:lts-stretch scanType= pip : python:3.7.2-stretch scanType= sbt : hseeberger/scala-sbt:8u181_2.12.8_1.2.8 scanType= dub : buildpack-deps:stretch-curl dockerOptions no scanType= golang : <empty> scanType= maven : <empty> scanType= mta : <empty> scanType= npm : <empty> scanType= pip : <empty> scanType= sbt : <empty> scanType= dub : <empty> dockerWorkspace no scanType= golang : /home/dep scanType= maven : /home/java scanType= mta : <empty> scanType= npm : /home/node scanType= pip : /home/python scanType= sbt : /home/scala scanType= dub : /home/dub emailAddressesOfInitialProductAdmins no [] installCommand no licensingVulnerabilities no true true , false parallelLimit no 15 reporting no true true , false scanImage no scanImageRegistryUrl no scanType no golang , maven , mta , npm , pip , sbt , dub script yes securityVulnerabilities no true true , false stashContent no scanType= golang : [buildDescriptor, opensourceConfiguration, checkmarx] scanType= maven : [buildDescriptor, opensourceConfiguration] scanType= mta : [buildDescriptor, opensourceConfiguration] scanType= npm : [buildDescriptor, opensourceConfiguration] scanType= pip : [buildDescriptor, opensourceConfiguration] scanType= sbt : [buildDescriptor, opensourceConfiguration] scanType= dub : [buildDescriptor, checkmarx] timeout no 0 verbose no false true , false vulnerabilityReportFileName no piper_whitesource_vulnerability_report vulnerabilityReportTitle no WhiteSource Security Vulnerability Report whitesource/jreDownloadUrl no whitesource/orgAdminUserTokenCredentialsId no whitesource/orgToken yes whitesource/productName yes whitesource/productToken no whitesource/productVersion no whitesource/projectNames no whitesource/serviceUrl no https://saas.whitesourcesoftware.com/api whitesource/userTokenCredentialsId yes agentDownloadUrl - URL used to download the latest version of the WhiteSource Unified Agent. agentFileName - Locally used name for the Unified Agent jar file after download. agentParameters - Additional parameters passed to the Unified Agent command line. buildDescriptorExcludeList - List of build descriptors and therefore modules to exclude from the scan and assessment activities. buildDescriptorFile - Explicit path to the build descriptor file. configFilePath - Explicit path to the WhiteSource Unified Agent configuration file. createProductFromPipeline - Whether to create the related WhiteSource product on the fly based on the supplied pipeline configuration. cvssSeverityLimit - Limit of tollerable CVSS v3 score upon assessment and in consequence fails the build, defaults to -1 . dockerEnvVars - Environment variables to set in the container, e.g. [http_proxy: 'proxy:8080']. dockerImage - Docker image to be used for scanning. dockerOptions - Docker only: Docker options to be set when starting the container (List or String). dockerWorkspace - Docker workspace to be used for scanning. emailAddressesOfInitialProductAdmins - The list of email addresses to assign as product admins for newly created WhiteSource products. installCommand - Install command that can be used to populate the default docker image for some scenarios. licensingVulnerabilities - Whether license compliance is considered and reported as part of the assessment. parallelLimit - Limit of parallel jobs being run at once in case of scanType: 'mta' based scenarios, defaults to 15 . reporting - Whether assessment is being done at all, defaults to true . scanImage - For scanType: docker : defines the docker image which should be scanned scanImageRegistryUrl - For scanType: docker : defines the registry where the scanImage is located scanType - Type of development stack used to implement the solution. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. securityVulnerabilities - Whether security compliance is considered and reported as part of the assessment. stashContent - List of stashes to be unstashed into the workspace before performing the scan. timeout - Timeout in seconds until a HTTP call is forcefully terminated. verbose - Whether verbose output should be produced. vulnerabilityReportFileName - Name of the file the vulnerability report is written to. vulnerabilityReportTitle - Title of vulnerability report written during the assessment phase. whitesource/jreDownloadUrl - URL used for downloading the Java Runtime Environment (JRE) required to run the WhiteSource Unified Agent. whitesource/orgAdminUserTokenCredentialsId - Jenkins credentials ID referring to the organization admin's token. whitesource/orgToken - WhiteSource token identifying your organization. whitesource/productName - Name of the WhiteSource product to be created and used for results aggregation. whitesource/productToken - Token of the WhiteSource product to be created and used for results aggregation, usually determined automatically. whitesource/productVersion - Version of the WhiteSource product to be created and used for results aggregation, usually determined automatically. whitesource/projectNames - List of WhiteSource projects to be included in the assessment part of the step, usually determined automatically. whitesource/serviceUrl - URL to the WhiteSource server API used for communication, defaults to https://saas.whitesourcesoftware.com/api . whitesource/userTokenCredentialsId - Jenkins credentials ID referring to the product admin's token. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage agentDownloadUrl X agentFileName X agentParameters X buildDescriptorExcludeList X buildDescriptorFile X configFilePath X createProductFromPipeline X cvssSeverityLimit X dockerEnvVars X dockerImage X dockerOptions X dockerWorkspace X emailAddressesOfInitialProductAdmins X installCommand X licensingVulnerabilities X parallelLimit X reporting X scanImage X scanImageRegistryUrl X scanType X X script securityVulnerabilities X stashContent X timeout X verbose X X vulnerabilityReportFileName X vulnerabilityReportTitle X whitesource/jreDownloadUrl X X whitesource/orgAdminUserTokenCredentialsId X X whitesource/orgToken X X whitesource/productName X X whitesource/productToken X X whitesource/productVersion X X whitesource/projectNames X X whitesource/serviceUrl X X whitesource/userTokenCredentialsId X X Dependencies \u00b6 The step depends on the following Jenkins plugins credentials-binding docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Exceptions \u00b6 None Examples \u00b6 whitesourceExecuteScan script: this , scanType: 'pip' , productName: 'My Whitesource Product' , userTokenCredentialsId: 'companyAdminToken' , orgAdminUserTokenCredentialsId: 'orgAdminToken' , orgToken: 'myWhitesourceOrganizationToken'","title":"whitesourceExecuteScan"},{"location":"steps/whitesourceExecuteScan/#whitesourceexecutescan","text":"","title":"whitesourceExecuteScan"},{"location":"steps/whitesourceExecuteScan/#description","text":"BETA With this step WhiteSource security and license compliance scans can be executed and assessed. WhiteSource is a Software as a Service offering based on a so called unified agent that locally determines the dependency tree of a node.js, Java, Python, Ruby, or Scala based solution and sends it to the WhiteSource server for a policy based license compliance check and additional Free and Open Source Software Publicly Known Vulnerabilities detection. Docker Images The underlying Docker images are public and specific to the solution's programming language(s) and therefore may have to be exchanged to fit to and support the relevant scenario. The default Python environment used is i.e. Python 3 based. Restrictions Currently the step does contain hardened scan configurations for scanType 'pip' and 'go' . Other environments are still being elaborated, so please thoroughly check your results and do not take them for granted by default. Also not all environments have been thoroughly tested already therefore you might need to tweak around with the default containers used or create your own ones to adequately support your scenario. To do so please modify dockerImage and dockerWorkspace parameters. The step expects an environment containing the programming language related compiler/interpreter as well as the related build tool. For a list of the supported build tools per environment please refer to the WhiteSource Unified Agent Documentation .","title":"Description"},{"location":"steps/whitesourceExecuteScan/#prerequisites","text":"Your company has registered an account with WhiteSource and you have enabled the use of so called User Keys to manage access to your organization in WhiteSource via dedicated privileges. Scanning your products without adequate user level access protection imposed on the WhiteSource backend would simply allow access based on the organization token.","title":"Prerequisites"},{"location":"steps/whitesourceExecuteScan/#parameters","text":"name mandatory default possible values agentDownloadUrl no https://github.com/whitesource/unified-agent-distribution/releases/latest/download/${config.agentFileName} agentFileName no wss-unified-agent.jar agentParameters no `` buildDescriptorExcludeList no [] buildDescriptorFile no scanType= golang : ./Gopkg.toml scanType= maven : ./pom.xml scanType= mta : <empty> scanType= npm : ./package.json scanType= pip : ./setup.py scanType= sbt : ./build.sbt scanType= dub : ./dub.json configFilePath no ./wss-unified-agent.config createProductFromPipeline no true cvssSeverityLimit no -1 -1 to switch failing off, any positive integer between 0 and 10 to fail on issues with the specified limit or above dockerEnvVars no scanType= golang : <empty> scanType= maven : <empty> scanType= mta : <empty> scanType= npm : <empty> scanType= pip : <empty> scanType= sbt : <empty> scanType= dub : <empty> dockerImage no scanType= golang : golang:1.12-stretch scanType= maven : maven:3.5-jdk-8 scanType= mta : <empty> scanType= npm : node:lts-stretch scanType= pip : python:3.7.2-stretch scanType= sbt : hseeberger/scala-sbt:8u181_2.12.8_1.2.8 scanType= dub : buildpack-deps:stretch-curl dockerOptions no scanType= golang : <empty> scanType= maven : <empty> scanType= mta : <empty> scanType= npm : <empty> scanType= pip : <empty> scanType= sbt : <empty> scanType= dub : <empty> dockerWorkspace no scanType= golang : /home/dep scanType= maven : /home/java scanType= mta : <empty> scanType= npm : /home/node scanType= pip : /home/python scanType= sbt : /home/scala scanType= dub : /home/dub emailAddressesOfInitialProductAdmins no [] installCommand no licensingVulnerabilities no true true , false parallelLimit no 15 reporting no true true , false scanImage no scanImageRegistryUrl no scanType no golang , maven , mta , npm , pip , sbt , dub script yes securityVulnerabilities no true true , false stashContent no scanType= golang : [buildDescriptor, opensourceConfiguration, checkmarx] scanType= maven : [buildDescriptor, opensourceConfiguration] scanType= mta : [buildDescriptor, opensourceConfiguration] scanType= npm : [buildDescriptor, opensourceConfiguration] scanType= pip : [buildDescriptor, opensourceConfiguration] scanType= sbt : [buildDescriptor, opensourceConfiguration] scanType= dub : [buildDescriptor, checkmarx] timeout no 0 verbose no false true , false vulnerabilityReportFileName no piper_whitesource_vulnerability_report vulnerabilityReportTitle no WhiteSource Security Vulnerability Report whitesource/jreDownloadUrl no whitesource/orgAdminUserTokenCredentialsId no whitesource/orgToken yes whitesource/productName yes whitesource/productToken no whitesource/productVersion no whitesource/projectNames no whitesource/serviceUrl no https://saas.whitesourcesoftware.com/api whitesource/userTokenCredentialsId yes agentDownloadUrl - URL used to download the latest version of the WhiteSource Unified Agent. agentFileName - Locally used name for the Unified Agent jar file after download. agentParameters - Additional parameters passed to the Unified Agent command line. buildDescriptorExcludeList - List of build descriptors and therefore modules to exclude from the scan and assessment activities. buildDescriptorFile - Explicit path to the build descriptor file. configFilePath - Explicit path to the WhiteSource Unified Agent configuration file. createProductFromPipeline - Whether to create the related WhiteSource product on the fly based on the supplied pipeline configuration. cvssSeverityLimit - Limit of tollerable CVSS v3 score upon assessment and in consequence fails the build, defaults to -1 . dockerEnvVars - Environment variables to set in the container, e.g. [http_proxy: 'proxy:8080']. dockerImage - Docker image to be used for scanning. dockerOptions - Docker only: Docker options to be set when starting the container (List or String). dockerWorkspace - Docker workspace to be used for scanning. emailAddressesOfInitialProductAdmins - The list of email addresses to assign as product admins for newly created WhiteSource products. installCommand - Install command that can be used to populate the default docker image for some scenarios. licensingVulnerabilities - Whether license compliance is considered and reported as part of the assessment. parallelLimit - Limit of parallel jobs being run at once in case of scanType: 'mta' based scenarios, defaults to 15 . reporting - Whether assessment is being done at all, defaults to true . scanImage - For scanType: docker : defines the docker image which should be scanned scanImageRegistryUrl - For scanType: docker : defines the registry where the scanImage is located scanType - Type of development stack used to implement the solution. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. securityVulnerabilities - Whether security compliance is considered and reported as part of the assessment. stashContent - List of stashes to be unstashed into the workspace before performing the scan. timeout - Timeout in seconds until a HTTP call is forcefully terminated. verbose - Whether verbose output should be produced. vulnerabilityReportFileName - Name of the file the vulnerability report is written to. vulnerabilityReportTitle - Title of vulnerability report written during the assessment phase. whitesource/jreDownloadUrl - URL used for downloading the Java Runtime Environment (JRE) required to run the WhiteSource Unified Agent. whitesource/orgAdminUserTokenCredentialsId - Jenkins credentials ID referring to the organization admin's token. whitesource/orgToken - WhiteSource token identifying your organization. whitesource/productName - Name of the WhiteSource product to be created and used for results aggregation. whitesource/productToken - Token of the WhiteSource product to be created and used for results aggregation, usually determined automatically. whitesource/productVersion - Version of the WhiteSource product to be created and used for results aggregation, usually determined automatically. whitesource/projectNames - List of WhiteSource projects to be included in the assessment part of the step, usually determined automatically. whitesource/serviceUrl - URL to the WhiteSource server API used for communication, defaults to https://saas.whitesourcesoftware.com/api . whitesource/userTokenCredentialsId - Jenkins credentials ID referring to the product admin's token.","title":"Parameters"},{"location":"steps/whitesourceExecuteScan/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage agentDownloadUrl X agentFileName X agentParameters X buildDescriptorExcludeList X buildDescriptorFile X configFilePath X createProductFromPipeline X cvssSeverityLimit X dockerEnvVars X dockerImage X dockerOptions X dockerWorkspace X emailAddressesOfInitialProductAdmins X installCommand X licensingVulnerabilities X parallelLimit X reporting X scanImage X scanImageRegistryUrl X scanType X X script securityVulnerabilities X stashContent X timeout X verbose X X vulnerabilityReportFileName X vulnerabilityReportTitle X whitesource/jreDownloadUrl X X whitesource/orgAdminUserTokenCredentialsId X X whitesource/orgToken X X whitesource/productName X X whitesource/productToken X X whitesource/productVersion X X whitesource/projectNames X X whitesource/serviceUrl X X whitesource/userTokenCredentialsId X X","title":"Step configuration"},{"location":"steps/whitesourceExecuteScan/#dependencies","text":"The step depends on the following Jenkins plugins credentials-binding docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/whitesourceExecuteScan/#exceptions","text":"None","title":"Exceptions"},{"location":"steps/whitesourceExecuteScan/#examples","text":"whitesourceExecuteScan script: this , scanType: 'pip' , productName: 'My Whitesource Product' , userTokenCredentialsId: 'companyAdminToken' , orgAdminUserTokenCredentialsId: 'orgAdminToken' , orgToken: 'myWhitesourceOrganizationToken'","title":"Examples"},{"location":"steps/writeTemporaryCredentials/","text":"writeTemporaryCredentials \u00b6 Description \u00b6 Writes credentials to a temporary file and deletes it after the body has been executed. Parameters \u00b6 name mandatory default possible values credentials no credentialsDirectories no [./, integration-tests/src/test/resources] script yes credentials - The list of credentials that are written to a temporary file for the execution of the body. Each element of credentials must be a map containing a property alias and a property credentialId. You have to ensure that corresponding credential entries exist in your Jenkins configuration. credentialsDirectories - The list of paths to directories where credentials files need to be placed. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage credentials X credentialsDirectories X script","title":"writeTemporaryCredentials"},{"location":"steps/writeTemporaryCredentials/#writetemporarycredentials","text":"","title":"writeTemporaryCredentials"},{"location":"steps/writeTemporaryCredentials/#description","text":"Writes credentials to a temporary file and deletes it after the body has been executed.","title":"Description"},{"location":"steps/writeTemporaryCredentials/#parameters","text":"name mandatory default possible values credentials no credentialsDirectories no [./, integration-tests/src/test/resources] script yes credentials - The list of credentials that are written to a temporary file for the execution of the body. Each element of credentials must be a map containing a property alias and a property credentialId. You have to ensure that corresponding credential entries exist in your Jenkins configuration. credentialsDirectories - The list of paths to directories where credentials files need to be placed. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters.","title":"Parameters"},{"location":"steps/writeTemporaryCredentials/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage credentials X credentialsDirectories X script","title":"Step configuration"},{"location":"steps/xsDeploy/","text":"xsDeploy \u00b6 Performs xs deployment Description \u00b6 Performs xs deployment Usage \u00b6 We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line . Jenkins pipelines \u00b6 xsDeploy script: this Command line \u00b6 piper xsDeploy Outputs \u00b6 Output type Details commonPipelineEnvironment operationId Parameters \u00b6 Overview \u00b6 Name Mandatory Additional information apiUrl yes credentialsId yes id of credentials ( using credentials ) loginOpts yes mode yes mtaPath yes org yes password yes pass via ENV or Jenkins credentials script yes reference to Jenkins main pipeline script space yes user yes pass via ENV or Jenkins credentials action no containerCommand no containerShell no deployOpts no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no dockerVolumeBind no dockerWorkspace no operationId no operationIdLogPattern no verbose no activates debug output xsSessionFile no Details \u00b6 action \u00b6 Used for finalizing the blue-green deployment. back to overview Scope Details Aliases - Type string Mandatory no Default NONE Possible values - NONE - Resume - Abort - Retry Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none apiUrl \u00b6 The api url (e.g. https://example.org:12345 back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_apiUrl (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none containerCommand \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default (/usr/bin/tail -f /dev/null). back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none containerShell \u00b6 Jenkins-specific: Used for proper environment setup. Allows to specify the shell to be executed for container with containerName. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none credentialsId \u00b6 Jenkins-specific: Used for proper environment setup. Jenkins username/password credential for accessing xs endpoint. back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none deployOpts \u00b6 Additional options appended to the deploy command. Only needed for sophisticated cases. When provided it is the duty of the provider to ensure proper quoting / escaping. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_deployOpts (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none dockerEnvVars \u00b6 Jenkins-specific: Used for proper environment setup. Environment variables to set in the container, e.g. [http_proxy: \"proxy:8080\"]. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerImage \u00b6 Jenkins-specific: Used for proper environment setup. Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerName \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Name of the container launching dockerImage. SideCar only: Name of the container in local network. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerOptions \u00b6 Jenkins-specific: Used for proper environment setup. Docker options to be set when starting the container. back to overview Scope Details Aliases - Type []string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerPullImage \u00b6 Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerVolumeBind \u00b6 Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the docker container. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none dockerWorkspace \u00b6 Jenkins-specific: Used for proper environment setup. Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none loginOpts \u00b6 Additional options appended to the login command. Only needed for sophisticated cases. When provided it is the duty of the provider to ensure proper quoting / escaping. back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_loginOpts (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none mode \u00b6 Controls if there is a standard deployment or a blue green deployment. Values: 'DEPLOY', 'BG_DEPLOY' back to overview Scope Details Aliases - Type string Mandatory no Default DEPLOY Possible values - NONE - DEPLOY - BG_DEPLOY Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none mtaPath \u00b6 Path to deployable back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_mtaPath (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references commonPipelineEnvironment : reference to: mtaPath operationId \u00b6 The operation ID. Used in case of bg-deploy in order to resume or abort a previously started deployment. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_operationId (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references commonPipelineEnvironment : reference to: operationId operationIdLogPattern \u00b6 Regex pattern for retrieving the ID of the operation from the xs log. back to overview Scope Details Aliases deployIdLogPattern Type string Mandatory no Default ^.*xs bg-deploy -i (.*) -a.*$ Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none org \u00b6 The org back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_org (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none password \u00b6 Password back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_password (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none script \u00b6 Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none space \u00b6 The space back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_space (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none user \u00b6 User back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_user (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none verbose \u00b6 verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none xsSessionFile \u00b6 The file keeping the xs session. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_xsSessionFile (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none \u00b6 Side effects \u00b6 none Example \u00b6 xsDeploy script: this , mtaPath: 'path/to/archiveFile.mtar' , credentialsId: 'my-credentials-id' , apiUrl: 'https://example.org/xs' , space: 'mySpace' , org: 'myOrg' Example configuration: steps : <...> xsDeploy : mtaPath : path/to/archiveFile.mtar credentialsId : my-credentials-id apiUrl : https://example.org/xs space : mySpace org : myOrg","title":"xsDeploy"},{"location":"steps/xsDeploy/#xsdeploy","text":"Performs xs deployment","title":"xsDeploy"},{"location":"steps/xsDeploy/#description","text":"Performs xs deployment","title":"Description"},{"location":"steps/xsDeploy/#usage","text":"We recommend to define values of step parameters via config.yml file . In this case, calling the step is reduced to one simple line. Calling the step can be done either via the Jenkins library step or on the command line .","title":"Usage"},{"location":"steps/xsDeploy/#jenkins-pipelines","text":"xsDeploy script: this","title":"Jenkins pipelines"},{"location":"steps/xsDeploy/#command-line","text":"piper xsDeploy","title":"Command line"},{"location":"steps/xsDeploy/#outputs","text":"Output type Details commonPipelineEnvironment operationId","title":"Outputs"},{"location":"steps/xsDeploy/#parameters","text":"","title":"Parameters"},{"location":"steps/xsDeploy/#overview","text":"Name Mandatory Additional information apiUrl yes credentialsId yes id of credentials ( using credentials ) loginOpts yes mode yes mtaPath yes org yes password yes pass via ENV or Jenkins credentials script yes reference to Jenkins main pipeline script space yes user yes pass via ENV or Jenkins credentials action no containerCommand no containerShell no deployOpts no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no dockerVolumeBind no dockerWorkspace no operationId no operationIdLogPattern no verbose no activates debug output xsSessionFile no","title":"Overview"},{"location":"steps/xsDeploy/#details","text":"","title":"Details"},{"location":"steps/xsDeploy/#action","text":"Used for finalizing the blue-green deployment. back to overview Scope Details Aliases - Type string Mandatory no Default NONE Possible values - NONE - Resume - Abort - Retry Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"action"},{"location":"steps/xsDeploy/#apiurl","text":"The api url (e.g. https://example.org:12345 back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_apiUrl (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"apiUrl"},{"location":"steps/xsDeploy/#containercommand","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default (/usr/bin/tail -f /dev/null). back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"containerCommand"},{"location":"steps/xsDeploy/#containershell","text":"Jenkins-specific: Used for proper environment setup. Allows to specify the shell to be executed for container with containerName. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"containerShell"},{"location":"steps/xsDeploy/#credentialsid","text":"Jenkins-specific: Used for proper environment setup. Jenkins username/password credential for accessing xs endpoint. back to overview Scope Details Aliases - Type string Mandatory yes Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"credentialsId"},{"location":"steps/xsDeploy/#deployopts","text":"Additional options appended to the deploy command. Only needed for sophisticated cases. When provided it is the duty of the provider to ensure proper quoting / escaping. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_deployOpts (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"deployOpts"},{"location":"steps/xsDeploy/#dockerenvvars","text":"Jenkins-specific: Used for proper environment setup. Environment variables to set in the container, e.g. [http_proxy: \"proxy:8080\"]. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerEnvVars"},{"location":"steps/xsDeploy/#dockerimage","text":"Jenkins-specific: Used for proper environment setup. Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerImage"},{"location":"steps/xsDeploy/#dockername","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Name of the container launching dockerImage. SideCar only: Name of the container in local network. back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerName"},{"location":"steps/xsDeploy/#dockeroptions","text":"Jenkins-specific: Used for proper environment setup. Docker options to be set when starting the container. back to overview Scope Details Aliases - Type []string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerOptions"},{"location":"steps/xsDeploy/#dockerpullimage","text":"Jenkins-specific: Used for proper environment setup. Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerPullImage"},{"location":"steps/xsDeploy/#dockervolumebind","text":"Jenkins-specific: Used for proper environment setup. Volumes that should be mounted into the docker container. back to overview Scope Details Aliases - Type map[string]string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerVolumeBind"},{"location":"steps/xsDeploy/#dockerworkspace","text":"Jenkins-specific: Used for proper environment setup. Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . back to overview Scope Details Aliases - Type string Mandatory no Default Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"dockerWorkspace"},{"location":"steps/xsDeploy/#loginopts","text":"Additional options appended to the login command. Only needed for sophisticated cases. When provided it is the duty of the provider to ensure proper quoting / escaping. back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_loginOpts (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"loginOpts"},{"location":"steps/xsDeploy/#mode","text":"Controls if there is a standard deployment or a blue green deployment. Values: 'DEPLOY', 'BG_DEPLOY' back to overview Scope Details Aliases - Type string Mandatory no Default DEPLOY Possible values - NONE - DEPLOY - BG_DEPLOY Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"mode"},{"location":"steps/xsDeploy/#mtapath","text":"Path to deployable back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_mtaPath (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references commonPipelineEnvironment : reference to: mtaPath","title":"mtaPath"},{"location":"steps/xsDeploy/#operationid","text":"The operation ID. Used in case of bg-deploy in order to resume or abort a previously started deployment. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_operationId (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references commonPipelineEnvironment : reference to: operationId","title":"operationId"},{"location":"steps/xsDeploy/#operationidlogpattern","text":"Regex pattern for retrieving the ID of the operation from the xs log. back to overview Scope Details Aliases deployIdLogPattern Type string Mandatory no Default ^.*xs bg-deploy -i (.*) -a.*$ Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"operationIdLogPattern"},{"location":"steps/xsDeploy/#org","text":"The org back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_org (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"org"},{"location":"steps/xsDeploy/#password","text":"Password back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_password (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"password"},{"location":"steps/xsDeploy/#script","text":"Jenkins-specific: Used for proper environment setup. The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. back to overview Scope Details Aliases - Type Jenkins Script Mandatory yes Default Secret no Configuration scope \u2610 parameter \u2610 general \u2610 steps \u2610 stages Resource references none","title":"script"},{"location":"steps/xsDeploy/#space","text":"The space back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_space (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"space"},{"location":"steps/xsDeploy/#user","text":"User back to overview Scope Details Aliases - Type string Mandatory yes Default $PIPER_user (if set) Secret yes Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"user"},{"location":"steps/xsDeploy/#verbose","text":"verbose output back to overview Scope Details Aliases - Type bool Mandatory no Default false Possible values - true - false Secret no Configuration scope \u2612 parameter \u2612 general \u2612 steps \u2612 stages Resource references none","title":"verbose"},{"location":"steps/xsDeploy/#xssessionfile","text":"The file keeping the xs session. back to overview Scope Details Aliases - Type string Mandatory no Default $PIPER_xsSessionFile (if set) Secret no Configuration scope \u2612 parameter \u2610 general \u2612 steps \u2612 stages Resource references none","title":"xsSessionFile"},{"location":"steps/xsDeploy/#side-effects","text":"none","title":"Side effects"},{"location":"steps/xsDeploy/#example","text":"xsDeploy script: this , mtaPath: 'path/to/archiveFile.mtar' , credentialsId: 'my-credentials-id' , apiUrl: 'https://example.org/xs' , space: 'mySpace' , org: 'myOrg' Example configuration: steps : <...> xsDeploy : mtaPath : path/to/archiveFile.mtar credentialsId : my-credentials-id apiUrl : https://example.org/xs space : mySpace org : myOrg","title":"Example"}]}